Commit:
8d7a5b792b32aa7524080480ae1fbfddb5d39a91
Chris Mattmann
mattmann@apache.org
2012-07-10 17:41:14 +0000
Prep for 1.2 RC #1
diff --git a/CHANGES.txt b/CHANGES.txt
index 3a1a6a0e9..9e1032b67 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -1,4 +1,4 @@
-Release 1.2 - Current Development
+Release 1.2 - 07/10/2012
 ---------------------------------
 
   * Tika's JAX-RS based Network server now is based on Apache CXF,

Commit:
dcd70501358a71cb6b7e1da5337ec86c4018037e
Chris Mattmann
mattmann@apache.org
2012-07-10 17:40:04 +0000
Fix for TIKA-945 Upgrade tika-server to CXF 2.6.1
diff --git a/tika-server/pom.xml b/tika-server/pom.xml
index c0c741c28..b38cd7097 100644
--- a/tika-server/pom.xml
+++ b/tika-server/pom.xml
@@ -41,12 +41,12 @@
     <dependency>
       <groupId>org.apache.cxf</groupId>
       <artifactId>cxf-rt-frontend-jaxrs</artifactId>
-      <version>2.5.2</version>
+      <version>2.6.1</version>
     </dependency>
     <dependency>
       <groupId>org.apache.cxf</groupId>
       <artifactId>cxf-rt-transports-http-jetty</artifactId>
-      <version>2.5.2</version>
+      <version>2.6.1</version>
     </dependency>
     <dependency>
       <groupId>commons-cli</groupId>

Commit:
2ecd4343453879f8a03e8751ac74ed5f72c2d221
Jukka Zitting
jukka@apache.org
2012-07-08 23:27:42 +0000
TIKA-892: Tika does not use the HTML5 meta charset tag when determining charset
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlEncodingDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlEncodingDetector.java
index 80ddab9dc..399b49540 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlEncodingDetector.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlEncodingDetector.java
@@ -19,7 +19,6 @@ package org.apache.tika.parser.html;
 import java.io.IOException;
 import java.io.InputStream;
 import java.nio.ByteBuffer;
-import java.nio.CharBuffer;
 import java.nio.charset.Charset;
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
@@ -48,6 +47,9 @@ public class HtmlEncodingDetector implements EncodingDetector {
             + "Content-Type['\\\"]\\s+content\\s*=\\s*['\\\"]"
             + "([^'\\\"]+)['\\\"]");
 
+    private static final Pattern META_CHARSET_PATTERN = Pattern.compile(
+            "(?is)<meta\\s+charset\\s*=\\s*['\\\"]([^'\\\"]+)['\\\"]");
+
     private static final Charset ASCII = Charset.forName("US-ASCII");
 
     public Charset detect(InputStream input, Metadata metadata)
@@ -67,20 +69,31 @@ public class HtmlEncodingDetector implements EncodingDetector {
         }
         input.reset();
 
-        // Interpret the head as ASCII and try to spot a http-equiv setting
-        CharBuffer head = ASCII.decode(ByteBuffer.wrap(buffer, 0, n));
-        Matcher matcher = HTTP_EQUIV_PATTERN.matcher(head.toString());
-        if (matcher.find()) {
-            MediaType type = MediaType.parse(matcher.group(1));
+        // Interpret the head as ASCII and try to spot a meta tag with
+        // a possible character encoding hint
+        String charset = null;
+        String head = ASCII.decode(ByteBuffer.wrap(buffer, 0, n)).toString();
+
+        Matcher equiv = HTTP_EQUIV_PATTERN.matcher(head);
+        if (equiv.find()) {
+            MediaType type = MediaType.parse(equiv.group(1));
             if (type != null) {
-                String charset = type.getParameters().get("charset");
-                if (charset != null) {
-                    try {
-                        return CharsetUtils.forName(charset);
-                    } catch (Exception e) {
-                        // ignore
-                    }
-                }
+                charset = type.getParameters().get("charset");
+            }
+        }
+        if (charset == null) {
+            // TIKA-892: HTML5 meta charset tag
+            Matcher meta = META_CHARSET_PATTERN.matcher(head);
+            if (meta.find()) {
+                charset = meta.group(1);
+            }
+        }
+
+        if (charset != null) {
+            try {
+                return CharsetUtils.forName(charset);
+            } catch (Exception e) {
+                // ignore
             }
         }
 
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/html/HtmlParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/html/HtmlParserTest.java
index 4976640be..7aafdb4ca 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/html/HtmlParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/html/HtmlParserTest.java
@@ -248,6 +248,22 @@ public class HtmlParserTest extends TestCase {
         assertEquals("ISO-8859-1", metadata.get(Metadata.CONTENT_ENCODING));
     }
 
+    /**
+     * Test case for TIKA-892
+     * @see <a href="https://issues.apache.org/jira/browse/TIKA-892">TIKA-892</a>
+     */
+    public void testHtml5Charset() throws Exception {
+        String test =
+                "<html><head><meta charset=\"ISO-8859-15\" />"
+                + "<title>the name is \u00e1ndre</title>"
+                + "</head><body></body></html>";
+        Metadata metadata = new Metadata();
+        new HtmlParser().parse(
+                new ByteArrayInputStream(test.getBytes("ISO-8859-1")),
+                new BodyContentHandler(), metadata, new ParseContext());
+        assertEquals("ISO-8859-15", metadata.get(Metadata.CONTENT_ENCODING));
+    }
+
     /**
      * Test case for TIKA-334
      * @see <a href="https://issues.apache.org/jira/browse/TIKA-334">TIKA-334</a>

Commit:
b7ada46ce72027b5a5c5a0bd455aaaff38144b51
Jukka Zitting
jukka@apache.org
2012-07-08 23:17:34 +0000
TIKA-431: Tika currently misuses the HTTP Content-Encoding header, and does not seem to use the charset part of the Content-Type header properly.
diff --git a/tika-core/src/main/java/org/apache/tika/mime/MediaTypeRegistry.java b/tika-core/src/main/java/org/apache/tika/mime/MediaTypeRegistry.java
index b5ef72f5e..497d0367f 100644
--- a/tika-core/src/main/java/org/apache/tika/mime/MediaTypeRegistry.java
+++ b/tika-core/src/main/java/org/apache/tika/mime/MediaTypeRegistry.java
@@ -96,6 +96,9 @@ public class MediaTypeRegistry implements Serializable {
     }
 
     public MediaType normalize(MediaType type) {
+        if (type == null) {
+            return null;
+        }
         MediaType canonical = registry.get(type.getBaseType());
         if (canonical == null) {
             return type;
@@ -108,11 +111,11 @@ public class MediaTypeRegistry implements Serializable {
 
     /**
      * Checks whether the given media type a is a specialization of a more
-     * generic type b.
+     * generic type b. Both types should be already normalised.
      *
      * @since Apache Tika 0.8
-     * @param a media type
-     * @param b suspected supertype
+     * @param a media type, normalised
+     * @param b suspected supertype, normalised
      * @return <code>true</code> if b is a supertype of a,
      *         <code>false</code> otherwise
      */
@@ -122,11 +125,11 @@ public class MediaTypeRegistry implements Serializable {
 
     /**
      * Checks whether the given media type equals the given base type or
-     * is a specialization of it.
+     * is a specialization of it. Both types should be already normalised.
      *
      * @since Apache Tika 1.2
-     * @param a media type
-     * @param b base type
+     * @param a media type, normalised
+     * @param b base type, normalised
      * @return <code>true</code> if b equals a or is a specialization of it,
      *         <code>false</code> otherwise
      */
@@ -134,6 +137,21 @@ public class MediaTypeRegistry implements Serializable {
         return a != null && (a.equals(b) || isSpecializationOf(a, b));
     }
 
+    /**
+     * Parses and normalises the given media type string and checks whether
+     * the result equals the given base type or is a specialization of it.
+     * The given base type should already be normalised.
+     *
+     * @since Apache Tika 1.2
+     * @param a media type
+     * @param b base type, normalised
+     * @return <code>true</code> if b equals a or is a specialization of it,
+     *         <code>false</code> otherwise
+     */
+    public boolean isInstanceOf(String a, MediaType b) {
+        return isInstanceOf(normalize(MediaType.parse(a)), b);
+    }
+
     /**
      * Returns the supertype of the given type. If the given type has any
      * parameters, then the respective base type is returned. Otherwise
@@ -149,7 +167,9 @@ public class MediaTypeRegistry implements Serializable {
      * @return supertype, or <code>null</code> for application/octet-stream
      */
     public MediaType getSupertype(MediaType type) {
-        if (type.hasParameters()) {
+        if (type == null) {
+            return null;
+        } else if (type.hasParameters()) {
             return type.getBaseType();
         } else if (inheritance.containsKey(type)) {
             return inheritance.get(type);

Commit:
09c6122d4cb05da6a3e9d4b0eaaf3d5ecfc33d61
Jukka Zitting
jukka@apache.org
2012-07-08 23:09:39 +0000
TIKA-431: Tika currently misuses the HTTP Content-Encoding header, and does not seem to use the charset part of the Content-Type header properly.
diff --git a/tika-core/src/main/java/org/apache/tika/mime/MediaTypeRegistry.java b/tika-core/src/main/java/org/apache/tika/mime/MediaTypeRegistry.java
index 97f0678b3..b5ef72f5e 100644
--- a/tika-core/src/main/java/org/apache/tika/mime/MediaTypeRegistry.java
+++ b/tika-core/src/main/java/org/apache/tika/mime/MediaTypeRegistry.java
@@ -117,8 +117,21 @@ public class MediaTypeRegistry implements Serializable {
      *         <code>false</code> otherwise
      */
     public boolean isSpecializationOf(MediaType a, MediaType b) {
-        MediaType x = getSupertype(a);
-        return x != null && (x.equals(b) || isSpecializationOf(x, b));
+        return isInstanceOf(getSupertype(a), b);
+    }
+
+    /**
+     * Checks whether the given media type equals the given base type or
+     * is a specialization of it.
+     *
+     * @since Apache Tika 1.2
+     * @param a media type
+     * @param b base type
+     * @return <code>true</code> if b equals a or is a specialization of it,
+     *         <code>false</code> otherwise
+     */
+    public boolean isInstanceOf(MediaType a, MediaType b) {
+        return a != null && (a.equals(b) || isSpecializationOf(a, b));
     }
 
     /**

Commit:
ee57f9573e450bdd8a2ff3c6d252ac5773b2834c
Jukka Zitting
jukka@apache.org
2012-07-08 22:51:55 +0000
set svn:eol-style to avoid test failures on Windows
Commit:
7d89a5e455686a945f2e3302f0d201e5e6c4a985
Jukka Zitting
jukka@apache.org
2012-07-08 22:44:00 +0000
TIKA-431: Tika currently misuses the HTTP Content-Encoding header, and does not seem to use the charset part of the Content-Type header properly.
diff --git a/.gitattributes b/.gitattributes
index c75b2a453..64c8501dd 100644
--- a/.gitattributes
+++ b/.gitattributes
@@ -1,2 +1,4 @@
 tika-parsers/src/test/resources/test-documents/testARofText.ar eol=lf
 tika-parsers/src/test/resources/test-documents/testEMLX.emlx eol=lf
+tika-parsers/src/test/resources/test-documents/testTXT.txt eol=lf
+tika-parsers/src/test/resources/test-documents/testHTML.html eol=lf
diff --git a/CHANGES.txt b/CHANGES.txt
index 01b542ff7..3a1a6a0e9 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -43,6 +43,15 @@ Release 1.2 - Current Development
     ICU4J algorithms are still used as a fallback thanks to their wider
     coverage of custom character encodings. (TIKA-322, TIKA-471)
 
+  * Charset parameter: Related to the character encoding improvements
+    mentioned above, Tika now returns the detected character encoding as
+    a "charset" parameter of the content type metadata field for text/plain
+    and text/html documents. For example, instead of just "text/plain", the
+    returned content type will be something like "text/plain; charset=UTF-8"
+    for a UTF-8 encoded text document. Character encoding information is still
+    present also in the content encoding metadata field for backwards
+    compatibility, but that field should be considered deprecated. (TIKA-431)
+
   * Extraction of embedded resources from OLE2 Office Documents, where
     the resource isn't another office document, has been fixed (TIKA-948)
 
diff --git a/tika-core/src/main/java/org/apache/tika/config/ServiceLoader.java b/tika-core/src/main/java/org/apache/tika/config/ServiceLoader.java
index 0e025da13..e2f80ef59 100644
--- a/tika-core/src/main/java/org/apache/tika/config/ServiceLoader.java
+++ b/tika-core/src/main/java/org/apache/tika/config/ServiceLoader.java
@@ -26,10 +26,8 @@ import java.util.Collection;
 import java.util.Collections;
 import java.util.Enumeration;
 import java.util.HashMap;
-import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
-import java.util.Set;
 import java.util.regex.Pattern;
 
 /**
diff --git a/tika-core/src/main/java/org/apache/tika/detect/TextDetector.java b/tika-core/src/main/java/org/apache/tika/detect/TextDetector.java
index 31a1fa509..09d3af08d 100644
--- a/tika-core/src/main/java/org/apache/tika/detect/TextDetector.java
+++ b/tika-core/src/main/java/org/apache/tika/detect/TextDetector.java
@@ -116,30 +116,18 @@ public class TextDetector implements Detector {
 
         input.mark(bytesToTest);
         try {
-            int chars = 0;
-            int controls = 0;
-            int asciis = 0;
-            int ch = input.read();
-            while (ch != -1 && chars < bytesToTest) {
-                if (ch < IS_CONTROL_BYTE.length && IS_CONTROL_BYTE[ch]) {
-                    controls++;
-                } else if (ch < 127) {
-                    asciis++;
-                }
-                ch = input.read();
-                chars++;
+            TextStatistics stats = new TextStatistics();
+
+            byte[] buffer = new byte[1024];
+            int n = 0;
+            int m = input.read(buffer, 0, Math.min(bytesToTest, buffer.length));
+            while (m != -1 && n < bytesToTest) {
+                stats.addData(buffer, 0, m);
+                n += m;
+                m = input.read(buffer, 0, Math.min(bytesToTest - n, buffer.length));
             }
-            if (chars == 0) {
-                // Empty document, so treat it as binary
-                // See https://issues.apache.org/jira/browse/TIKA-483
-                return MediaType.OCTET_STREAM;
-            } else if (controls == 0) {
-                // No control characters, so treat it as text
-                return MediaType.TEXT_PLAIN;
-            } else if (controls < chars * 2 / 100
-                    && asciis > chars * 90 / 100) {
-                // Almost plain text (< 2% control, > 90% ASCII range)
-                // See https://issues.apache.org/jira/browse/TIKA-688
+
+            if (stats.isMostlyAscii()) {
                 return MediaType.TEXT_PLAIN;
             } else {
                 return MediaType.OCTET_STREAM;
diff --git a/tika-core/src/main/java/org/apache/tika/detect/TextStatistics.java b/tika-core/src/main/java/org/apache/tika/detect/TextStatistics.java
new file mode 100644
index 000000000..581a1334d
--- /dev/null
+++ b/tika-core/src/main/java/org/apache/tika/detect/TextStatistics.java
@@ -0,0 +1,133 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.detect;
+
+/**
+ * Utility class for computing a histogram of the bytes seen in a stream.
+ *
+ * @since Apache Tika 1.2
+ */
+public class TextStatistics {
+
+    private final int[] counts = new int[256];
+
+    private int total = 0;
+
+    public void addData(byte[] buffer, int offset, int length) {
+        for (int i = 0; i < length; i++) {
+            counts[buffer[offset + i] & 0xff]++;
+            total++;
+        }
+    }
+
+    /**
+     * Checks whether at least one byte was seen and that the bytes that
+     * were seen were mostly plain text (i.e. < 2% control, > 90% ASCII range).
+     *
+     * @see <a href="https://issues.apache.org/jira/browse/TIKA-483">TIKA-483</a>
+     * @see <a href="https://issues.apache.org/jira/browse/TIKA-688">TIKA-688</a>
+     * @return <code>true</code> if the seen bytes were mostly safe ASCII,
+     *         <code>false</code> otherwise
+     */
+    public boolean isMostlyAscii() {
+        int control = count(0, 0x20);
+        int ascii = count(0x20, 128);
+        int safe = countSafeControl();
+        return total > 0
+                && (control - safe) * 100 < total * 2
+                && (ascii + safe) * 100 > total * 90;
+    }
+
+    /**
+     * Returns the total number of bytes seen so far.
+     *
+     * @return count of all bytes
+     */
+    public int count() {
+        return total;
+    }
+
+    /**
+     * Returns the number of occurrences of the given byte.
+     *
+     * @param b byte
+     * @return count of the given byte
+     */
+    public int count(int b) {
+        return counts[b & 0xff];
+    }
+
+    /**
+     * Counts control characters (i.e. < 0x20, excluding tab, CR, LF,
+     * page feed and escape).
+     * <p>
+     * This definition of control characters is based on section 4 of the
+     * "Content-Type Processing Model" Internet-draft
+     * (<a href="http://webblaze.cs.berkeley.edu/2009/mime-sniff/mime-sniff.txt"
+     * >draft-abarth-mime-sniff-01</a>).
+     * <pre>
+     * +-------------------------+
+     * | Binary data byte ranges |
+     * +-------------------------+
+     * | 0x00 -- 0x08            |
+     * | 0x0B                    |
+     * | 0x0E -- 0x1A            |
+     * | 0x1C -- 0x1F            |
+     * +-------------------------+
+     * </pre>
+     *
+     * @see <a href="https://issues.apache.org/jira/browse/TIKA-154">TIKA-154</a>
+     * @return count of control characters
+     */
+    public int countControl() {
+        return count(0, 0x20) - countSafeControl();
+    }
+
+    /**
+     * Counts "safe" (i.e. seven-bit non-control) ASCII characters.
+     *
+     * @see #countControl()
+     * @return count of safe ASCII characters
+     */
+    public int countSafeAscii() {
+        return count(0x20, 128) + countSafeControl();
+    }
+
+    /**
+     * Counts eight bit characters, i.e. bytes with their highest bit set.
+     *
+     * @return count of eight bit characters
+     */
+    public int countEightBit() {
+        return count(128, 256);
+    }
+
+    private int count(int from, int to) {
+        assert 0 <= from && to < counts.length;
+        int count = 0;
+        for (int i = from; i < to; i++) {
+            count += counts[i];
+        }
+        return count;
+    }
+
+    private int countSafeControl() {
+        return count('\t') + count('\n') + count('\r') // tab, LF, CR
+                + count(0x0c) + count(0x1b);           // new page, escape
+    }
+
+}
diff --git a/tika-core/src/main/java/org/apache/tika/mime/MediaType.java b/tika-core/src/main/java/org/apache/tika/mime/MediaType.java
index 5eb0cb277..0080c4aab 100644
--- a/tika-core/src/main/java/org/apache/tika/mime/MediaType.java
+++ b/tika-core/src/main/java/org/apache/tika/mime/MediaType.java
@@ -17,6 +17,7 @@
 package org.apache.tika.mime;
 
 import java.io.Serializable;
+import java.nio.charset.Charset;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
@@ -72,6 +73,8 @@ public final class MediaType implements Comparable<MediaType>, Serializable {
 
     public static final MediaType TEXT_PLAIN = parse("text/plain");
 
+    public static final MediaType TEXT_HTML = parse("text/html");
+
     public static final MediaType APPLICATION_XML = parse("application/xml");
 
     public static final MediaType APPLICATION_ZIP = parse("application/zip");
@@ -345,6 +348,28 @@ public final class MediaType implements Comparable<MediaType>, Serializable {
                 union(type.parameters, parameters));
     }
 
+    /**
+     * Creates a media type by adding a parameter to a base type.
+     *
+     * @param type base type
+     * @param name parameter name
+     * @param value parameter value
+     * @since Apache Tika 1.2
+     */
+    public MediaType(MediaType type, String name, String value) {
+        this(type, Collections.singletonMap(name, value));
+    }
+
+    /**
+     * Creates a media type by adding the "charset" parameter to a base type.
+     *
+     * @param type base type
+     * @param charset charset value
+     * @since Apache Tika 1.2
+     */
+    public MediaType(MediaType type, Charset charset) {
+        this(type, "charset", charset.name());
+    }
     /**
      * Returns the base form of the MediaType, excluding
      *  any parameters, such as "text/plain" for
diff --git a/tika-core/src/main/java/org/apache/tika/mime/package-info.java b/tika-core/src/main/java/org/apache/tika/mime/package-info.java
index 4e3246f5c..104dc3acf 100644
--- a/tika-core/src/main/java/org/apache/tika/mime/package-info.java
+++ b/tika-core/src/main/java/org/apache/tika/mime/package-info.java
@@ -18,5 +18,5 @@
 /**
  * Media type information.
  */
-@aQute.bnd.annotation.Version("1.0.0")
+@aQute.bnd.annotation.Version("1.2.0")
 package org.apache.tika.mime;
diff --git a/tika-core/src/test/java/org/apache/tika/detect/TextDetectorTest.java b/tika-core/src/test/java/org/apache/tika/detect/TextDetectorTest.java
index 441da0585..cdf625a14 100644
--- a/tika-core/src/test/java/org/apache/tika/detect/TextDetectorTest.java
+++ b/tika-core/src/test/java/org/apache/tika/detect/TextDetectorTest.java
@@ -51,16 +51,16 @@ public class TextDetectorTest extends TestCase {
     public void testDetectText() throws Exception {
         assertText("Hello, World!".getBytes("UTF-8"));
         assertText(" \t\r\n".getBytes("UTF-8"));
-        assertText(new byte[] { -1, -2, -3, 0x09, 0x0A, 0x0C, 0x0D, 0x1B });
+        assertNotText(new byte[] { -1, -2, -3, 0x09, 0x0A, 0x0C, 0x0D, 0x1B });
         assertNotText(new byte[] { 0 });
         assertNotText(new byte[] { 'H', 'e', 'l', 'l', 'o', 0 });
 
         byte[] data = new byte[512];
         Arrays.fill(data, (byte) '.');
         assertText(data);
-        Arrays.fill(data, 100, 109, (byte) 0x1f);
-        assertText(data); // almost text
         Arrays.fill(data, 100, 110, (byte) 0x1f);
+        assertText(data); // almost text
+        Arrays.fill(data, 100, 111, (byte) 0x1f);
         assertNotText(data); // no longer almost text, too many control chars
         Arrays.fill(data, (byte) 0x1f);
         assertNotText(data);
diff --git a/tika-core/src/test/java/org/apache/tika/mime/MimeDetectionTest.java b/tika-core/src/test/java/org/apache/tika/mime/MimeDetectionTest.java
index 996b8a995..58dfbbe21 100644
--- a/tika-core/src/test/java/org/apache/tika/mime/MimeDetectionTest.java
+++ b/tika-core/src/test/java/org/apache/tika/mime/MimeDetectionTest.java
@@ -67,13 +67,13 @@ public class MimeDetectionTest extends TestCase {
 
     public void testByteOrderMark() throws Exception {
         assertEquals(MediaType.TEXT_PLAIN, mimeTypes.detect(
-                new ByteArrayInputStream("\ufffetest".getBytes("UTF-16LE")),
+                new ByteArrayInputStream("\ufefftest".getBytes("UTF-16LE")),
                 new Metadata()));
         assertEquals(MediaType.TEXT_PLAIN, mimeTypes.detect(
-                new ByteArrayInputStream("\ufffetest".getBytes("UTF-16BE")),
+                new ByteArrayInputStream("\ufefftest".getBytes("UTF-16BE")),
                 new Metadata()));
         assertEquals(MediaType.TEXT_PLAIN, mimeTypes.detect(
-                new ByteArrayInputStream("\ufffetest".getBytes("UTF-8")),
+                new ByteArrayInputStream("\ufefftest".getBytes("UTF-8")),
                 new Metadata()));
     }
 
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlParser.java
index 4be67e7d2..cc8adc064 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlParser.java
@@ -18,6 +18,7 @@ package org.apache.tika.parser.html;
 
 import java.io.IOException;
 import java.io.InputStream;
+import java.nio.charset.Charset;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashSet;
@@ -57,7 +58,7 @@ public class HtmlParser extends AbstractParser {
             new ServiceLoader(HtmlParser.class.getClassLoader());
 
     /**
-     * HTML schema singleton used to amortize the heavy instantiation time.
+     * HTML schema singleton used to amortise the heavy instantiation time.
      */
     private static final Schema HTML_SCHEMA = new HTMLSchema();
 
@@ -73,11 +74,14 @@ public class HtmlParser extends AbstractParser {
         AutoDetectReader reader = new AutoDetectReader(
                 new CloseShieldInputStream(stream), metadata, LOADER);
         try {
-            if (metadata.get(Metadata.CONTENT_TYPE) == null) {
-                // TODO: Include charset
-                metadata.set(Metadata.CONTENT_TYPE, "text/html");
+            Charset charset = reader.getCharset();
+            String previous = metadata.get(Metadata.CONTENT_TYPE);
+            if (previous == null || previous.startsWith("text/html")) {
+                MediaType type = new MediaType(MediaType.TEXT_HTML, charset);
+                metadata.set(Metadata.CONTENT_TYPE, type.toString());
             }
-            metadata.set(Metadata.CONTENT_ENCODING, reader.getCharset().name());
+            // deprecated, see TIKA-431
+            metadata.set(Metadata.CONTENT_ENCODING, charset.name());
 
             // Get the HTML mapper from the parse context
             HtmlMapper mapper =
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java
index f30fbc29b..82aabaf85 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java
@@ -22,9 +22,7 @@ import java.io.IOException;
 import java.io.InputStream;
 import java.nio.channels.FileChannel;
 import java.util.Collections;
-import java.util.HashMap;
 import java.util.HashSet;
-import java.util.Map;
 import java.util.Set;
 import java.util.regex.Pattern;
 
@@ -76,10 +74,12 @@ public class POIFSContainerDetector implements Detector {
     public static final MediaType GENERAL_EMBEDDED = application("x-tika-msoffice-embedded");
     
     /** An OLE10 Native embedded document within another OLE2 document */
-    public static final MediaType OLE10_NATIVE = new MediaType(GENERAL_EMBEDDED, format("ole10_native")); 
+    public static final MediaType OLE10_NATIVE =
+            new MediaType(GENERAL_EMBEDDED, "format", "ole10_native");
     
     /** Some other kind of embedded document, in a CompObj container within another OLE2 document */
-    public static final MediaType COMP_OBJ = new MediaType(GENERAL_EMBEDDED, format("comp_obj"));
+    public static final MediaType COMP_OBJ =
+            new MediaType(GENERAL_EMBEDDED, "format", "comp_obj");
 
     /** Microsoft Excel */
     public static final MediaType XLS = application("vnd.ms-excel");
@@ -122,13 +122,7 @@ public class POIFSContainerDetector implements Detector {
 
     /** Regexp for matching the MPP Project Data stream */
     private static final Pattern mppDataMatch = Pattern.compile("\\s\\s\\s\\d+");
-    
-    private static Map<String,String> format(String format) {
-       Map<String, String> params = new HashMap<String, String>();
-       params.put("format", format);
-       return params;
-    }
-    
+
     public MediaType detect(InputStream input, Metadata metadata)
              throws IOException {
         // Check if we have access to the document
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/txt/TXTParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/txt/TXTParser.java
index c540e7db6..653177452 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/txt/TXTParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/txt/TXTParser.java
@@ -18,6 +18,7 @@ package org.apache.tika.parser.txt;
 
 import java.io.IOException;
 import java.io.InputStream;
+import java.nio.charset.Charset;
 import java.util.Collections;
 import java.util.Set;
 
@@ -36,20 +37,14 @@ import org.xml.sax.SAXException;
 /**
  * Plain text parser. The text encoding of the document stream is
  * automatically detected based on the byte patterns found at the
- * beginning of the stream. The input metadata key
- * {@link org.apache.tika.metadata.HttpHeaders#CONTENT_ENCODING} is used
- * as an encoding hint if the automatic encoding detection fails.
+ * beginning of the stream and the given document metadata, most
+ * notably the <code>charset</code> parameter of a
+ * {@link org.apache.tika.metadata.HttpHeaders#CONTENT_TYPE} value.
  * <p>
  * This parser sets the following output metadata entries:
  * <dl>
  *   <dt>{@link org.apache.tika.metadata.HttpHeaders#CONTENT_TYPE}</dt>
- *   <dd><code>text/plain</code></dd>
- *   <dt>{@link org.apache.tika.metadata.HttpHeaders#CONTENT_ENCODING}</dt>
- *   <dd>The detected text encoding of the document.</dd>
- *   <dt>
- *     {@link org.apache.tika.metadata.HttpHeaders#CONTENT_LANGUAGE} and
- *     {@link org.apache.tika.metadata.DublinCore#LANGUAGE}
- *   </dt>
+ *   <dd><code>text/plain; charset=...</code></dd>
  * </dl>
  */
 public class TXTParser extends AbstractParser {
@@ -75,8 +70,11 @@ public class TXTParser extends AbstractParser {
         AutoDetectReader reader = new AutoDetectReader(
                 new CloseShieldInputStream(stream), metadata, LOADER);
         try {
-            metadata.set(Metadata.CONTENT_TYPE, "text/plain"); // TODO: charset
-            metadata.set(Metadata.CONTENT_ENCODING, reader.getCharset().name());
+            Charset charset = reader.getCharset();
+            MediaType type = new MediaType(MediaType.TEXT_PLAIN, charset);
+            metadata.set(Metadata.CONTENT_TYPE, type.toString());
+            // deprecated, see TIKA-431
+            metadata.set(Metadata.CONTENT_ENCODING, charset.name());
 
             XHTMLContentHandler xhtml =
                     new XHTMLContentHandler(handler, metadata);
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/txt/UniversalEncodingListener.java b/tika-parsers/src/main/java/org/apache/tika/parser/txt/UniversalEncodingListener.java
index 826febc40..5e215a99f 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/txt/UniversalEncodingListener.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/txt/UniversalEncodingListener.java
@@ -18,6 +18,7 @@ package org.apache.tika.parser.txt;
 
 import java.nio.charset.Charset;
 
+import org.apache.tika.detect.TextStatistics;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.utils.CharsetUtils;
@@ -33,14 +34,16 @@ class UniversalEncodingListener implements CharsetListener {
 
     private static final String CHARSET_ISO_8859_1 = "ISO-8859-1";
 
+    private static final String CHARSET_ISO_8859_15 = "ISO-8859-15";
+
+    private final TextStatistics statistics = new TextStatistics();
+
     private final UniversalDetector detector = new UniversalDetector(this);
 
     private String hint = null;
 
     private Charset charset = null;
 
-    private boolean hasCR = false;
-
     public UniversalEncodingListener(Metadata metadata) {
         MediaType type = MediaType.parse(metadata.get(Metadata.CONTENT_TYPE));
         if (type != null) {
@@ -54,11 +57,20 @@ class UniversalEncodingListener implements CharsetListener {
     public void report(String name) {
         if (Constants.CHARSET_WINDOWS_1252.equals(name)) {
             if (hint != null) {
-                // Use the encoding hint to distinguish between latin charsets
+                // Use the encoding hint when available
                 name = hint;
-            } else if (!hasCR) {
-                // If there are no CRLFs, it's more likely to be ISO-8859-1
-                name = CHARSET_ISO_8859_1;
+            } else if (statistics.count('\r') == 0) {
+                // If there are no CR(LF)s, then the encoding is more
+                // likely to be ISO-8859-1(5) than windows-1252
+                if (statistics.count(0xa4) > 0) { // currency/euro sign
+                    // The general currency sign is hardly ever used in
+                    // ISO-8859-1, so it's more likely that we're dealing
+                    // with ISO-8859-15, where the character is used for
+                    // the euro symbol, which is more commonly used.
+                    name = CHARSET_ISO_8859_15;
+                } else {
+                    name = CHARSET_ISO_8859_1;
+                }
             }
         }
         try {
@@ -73,16 +85,15 @@ class UniversalEncodingListener implements CharsetListener {
     }
 
     public void handleData(byte[] buf, int offset, int length) {
-        for (int i = 0; !hasCR && i < length; i++) {
-            if (buf[offset + i] == '\r') {
-                hasCR = true;
-            }
-        }
+        statistics.addData(buf, offset, length);
         detector.handleData(buf, offset, length);
     }
 
     public Charset dataEnd() {
         detector.dataEnd();
+        if (charset == null && statistics.isMostlyAscii()) {
+            report(Constants.CHARSET_WINDOWS_1252);
+        }
         return charset;
     }
 
diff --git a/tika-parsers/src/test/java/org/apache/tika/mime/MimeTypesTest.java b/tika-parsers/src/test/java/org/apache/tika/mime/MimeTypesTest.java
index 9f45cb7b3..78b42d142 100644
--- a/tika-parsers/src/test/java/org/apache/tika/mime/MimeTypesTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/mime/MimeTypesTest.java
@@ -19,11 +19,6 @@ package org.apache.tika.mime;
 import static org.apache.tika.mime.MediaType.OCTET_STREAM;
 import static org.apache.tika.mime.MediaType.TEXT_PLAIN;
 
-import java.io.ByteArrayInputStream;
-import java.io.IOException;
-
-import org.apache.tika.metadata.Metadata;
-
 import junit.framework.TestCase;
 
 public class MimeTypesTest extends TestCase {
@@ -95,31 +90,4 @@ public class MimeTypesTest extends TestCase {
         assertTrue(html.compareTo(html) == 0);
     }
 
-    /** Test getMimeType(byte[]) 
-     * @throws IOException */
-    public void testGetMimeType_byteArray() throws IOException {
-        // Plain text detection
-        assertText(new byte[] { (byte) 0xFF, (byte) 0xFE });
-        assertText(new byte[] { (byte) 0xFF, (byte) 0xFE });
-        assertText(new byte[] { (byte) 0xEF, (byte) 0xFB, (byte) 0xBF });
-        assertText(new byte[] { 'a', 'b', 'c' });
-        assertText(new byte[] { '\t', '\r', '\n', 0x0C, 0x1B });
-        assertNotText(new byte[] { '\t', '\r', '\n', 0x0E, 0x1C });
-    }
-
-    private void assertText(byte[] prefix) throws IOException {
-        assertMagic("text/plain", prefix);
-    }
-
-    private void assertNotText(byte[] prefix) throws IOException {
-        assertMagic("application/octet-stream", prefix);
-    }
-
-    private void assertMagic(String expected, byte[] prefix) throws IOException {
-        MediaType type =
-                types.detect(new ByteArrayInputStream(prefix), new Metadata());
-        assertNotNull(type);
-        assertEquals(expected, type.toString());
-    }
-
 }
diff --git a/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java b/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
index 57bb4ca96..67b8195c1 100644
--- a/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
+++ b/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
@@ -609,6 +609,32 @@ public class TestMimeTypes extends TestCase {
         assertTypeDetection("testEMLX.emlx", "message/x-emlx");
     }
 
+    /** Test getMimeType(byte[]) */
+    public void testGetMimeType_byteArray() throws IOException {
+        // Plain text detection
+        assertText(new byte[] { (byte) 0xFF, (byte) 0xFE });
+        assertText(new byte[] { (byte) 0xFF, (byte) 0xFE });
+        assertText(new byte[] { (byte) 0xEF, (byte) 0xBB, (byte) 0xBF });
+        assertText(new byte[] { 'a', 'b', 'c' });
+        assertText(new byte[] { '\t', '\r', '\n', 0x0C, 0x1B });
+        assertNotText(new byte[] { '\t', '\r', '\n', 0x0E, 0x1C });
+    }
+
+    private void assertText(byte[] prefix) throws IOException {
+        assertMagic("text/plain", prefix);
+    }
+
+    private void assertNotText(byte[] prefix) throws IOException {
+        assertMagic("application/octet-stream", prefix);
+    }
+
+    private void assertMagic(String expected, byte[] prefix) throws IOException {
+        MediaType type =
+                repo.detect(new ByteArrayInputStream(prefix), new Metadata());
+        assertNotNull(type);
+        assertEquals(expected, type.toString());
+    }
+
     private void assertType(String expected, String filename) throws Exception {
         InputStream stream = TestMimeTypes.class.getResourceAsStream(
                 "/test-documents/" + filename);
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/AutoDetectParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/AutoDetectParserTest.java
index ad62dc417..ee980caa9 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/AutoDetectParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/AutoDetectParserTest.java
@@ -28,7 +28,6 @@ import org.apache.tika.config.TikaConfig;
 import org.apache.tika.detect.Detector;
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.metadata.Metadata;
-import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.metadata.XMPDM;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.sax.BodyContentHandler;
@@ -40,14 +39,14 @@ public class AutoDetectParserTest extends TestCase {
     // Easy to read constants for the MIME types:
     private static final String RAW        = "application/octet-stream";
     private static final String EXCEL      = "application/vnd.ms-excel";
-    private static final String HTML       = "text/html";
+    private static final String HTML       = "text/html; charset=ISO-8859-1";
     private static final String PDF        = "application/pdf";
     private static final String POWERPOINT = "application/vnd.ms-powerpoint";
     private static final String KEYNOTE    = "application/vnd.apple.keynote";
     private static final String PAGES      = "application/vnd.apple.pages";
     private static final String NUMBERS    = "application/vnd.apple.numbers";
     private static final String RTF        = "application/rtf";
-    private static final String PLAINTEXT  = "text/plain";
+    private static final String PLAINTEXT  = "text/plain; charset=ISO-8859-1";
     private static final String WORD       = "application/msword";
     private static final String XML        = "application/xml";
     private static final String RSS        = "application/rss+xml";
@@ -236,11 +235,12 @@ public class AutoDetectParserTest extends TestCase {
         }
     
     }
-    
+
     /**
      * Test to ensure that the Vorbis and FLAC parsers have been correctly
      *  included, and are available
      */
+    @SuppressWarnings("deprecation")
     public void testVorbisFlac() throws Exception {
        // The three test files should all have similar test data
        String[] testFiles = new String[] {
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/html/HtmlParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/html/HtmlParserTest.java
index f5032eecd..4976640be 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/html/HtmlParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/html/HtmlParserTest.java
@@ -571,7 +571,7 @@ public class HtmlParserTest extends TestCase {
         String result = sw.toString();
 
         // <meta> tag for Content-Type should exist, but nothing for Language
-        assertTrue(Pattern.matches("(?s).*<meta name=\"Content-Type\" content=\"text/html; charset=utf-8\"/>.*$", result));
+        assertTrue(Pattern.matches("(?s).*<meta name=\"Content-Type\" content=\"text/html; charset=UTF-8\"/>.*$", result));
         assertFalse(Pattern.matches("(?s).*<meta name=\"Language\".*$", result));
     }
 
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/txt/TXTParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/txt/TXTParserTest.java
index 2267242b0..b670d2d5f 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/txt/TXTParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/txt/TXTParserTest.java
@@ -1,4 +1,4 @@
-/**
+/*
  * Licensed to the Apache Software Foundation (ASF) under one or more
  * contributor license agreements.  See the NOTICE file distributed with
  * this work for additional information regarding copyright ownership.
@@ -26,6 +26,7 @@ import org.apache.tika.parser.Parser;
 import org.apache.tika.sax.BodyContentHandler;
 import org.apache.tika.sax.WriteOutContentHandler;
 import org.xml.sax.ContentHandler;
+import org.xml.sax.helpers.DefaultHandler;
 
 import junit.framework.TestCase;
 
@@ -42,14 +43,14 @@ public class TXTParserTest extends TestCase {
         Metadata metadata = new Metadata();
         StringWriter writer = new StringWriter();
         parser.parse(
-                new ByteArrayInputStream(text.getBytes("UTF-8")),
+                new ByteArrayInputStream(text.getBytes("ISO-8859-1")),
                 new WriteOutContentHandler(writer),
                 metadata,
                 new ParseContext());
         String content = writer.toString();
 
-        assertEquals("text/plain", metadata.get(Metadata.CONTENT_TYPE));
-        
+        assertEquals("text/plain; charset=ISO-8859-1", metadata.get(Metadata.CONTENT_TYPE));
+
         // TIKA-501: Remove language detection from TXTParser
         assertNull(metadata.get(Metadata.CONTENT_LANGUAGE));
         assertNull(metadata.get(TikaCoreProperties.LANGUAGE));
@@ -68,8 +69,8 @@ public class TXTParserTest extends TestCase {
         parser.parse(
                 new ByteArrayInputStream(text.getBytes("UTF-8")),
                 handler, metadata, new ParseContext());
-        assertEquals("text/plain", metadata.get(Metadata.CONTENT_TYPE));
-        assertEquals("UTF-8", metadata.get(Metadata.CONTENT_ENCODING));
+        assertEquals("text/plain; charset=UTF-8", metadata.get(Metadata.CONTENT_TYPE));
+        assertEquals("UTF-8", metadata.get(Metadata.CONTENT_ENCODING)); // deprecated
 
         assertTrue(handler.toString().contains(text));
     }
@@ -79,10 +80,49 @@ public class TXTParserTest extends TestCase {
         Metadata metadata = new Metadata();
         parser.parse(
                 new ByteArrayInputStream(new byte[0]), handler, metadata, new ParseContext());
-        assertEquals("text/plain", metadata.get(Metadata.CONTENT_TYPE));
+        assertEquals("text/plain; charset=UTF-8", metadata.get(Metadata.CONTENT_TYPE));
         assertEquals("\n", handler.toString());
     }
 
+    /**
+     * Test for the heuristics that we use to assign an eight-bit character
+     * encoding to mostly ASCII sequences. If a more specific match can not
+     * be made, a string with a CR(LF) in it is most probably windows-1252,
+     * otherwise ISO-8859-1, except if it contains the currency/euro symbol
+     * (byte 0xa4) in which case it's more likely to be ISO-8859-15.
+     */
+    public void testLatinDetectionHeuristics() throws Exception {
+        String windows = "test\r\n";
+        String unix = "test\n";
+        String euro = "test \u20ac\n";
+
+        Metadata metadata;
+
+        metadata = new Metadata();
+        parser.parse(
+                new ByteArrayInputStream(windows.getBytes("ISO-8859-15")),
+                new DefaultHandler(), metadata, new ParseContext());
+        assertEquals(
+                "text/plain; charset=windows-1252",
+                metadata.get(Metadata.CONTENT_TYPE));
+
+        metadata = new Metadata();
+        parser.parse(
+                new ByteArrayInputStream(unix.getBytes("ISO-8859-15")),
+                new DefaultHandler(), metadata, new ParseContext());
+        assertEquals(
+                "text/plain; charset=ISO-8859-1",
+                metadata.get(Metadata.CONTENT_TYPE));
+
+        metadata = new Metadata();
+        parser.parse(
+                new ByteArrayInputStream(euro.getBytes("ISO-8859-15")),
+                new DefaultHandler(), metadata, new ParseContext());
+        assertEquals(
+                "text/plain; charset=ISO-8859-15",
+                metadata.get(Metadata.CONTENT_TYPE));
+    }
+
     /**
      * Test case for TIKA-240: Drop the BOM when extracting plain text
      *
@@ -111,15 +151,15 @@ public class TXTParserTest extends TestCase {
         parser.parse(
                 new ByteArrayInputStream(test2.getBytes("ISO-8859-1")),
                 new BodyContentHandler(),  metadata, new ParseContext());
-        
-        assertEquals("ISO-8859-1", metadata.get(Metadata.CONTENT_ENCODING));
+        assertEquals("text/plain; charset=ISO-8859-1", metadata.get(Metadata.CONTENT_TYPE));
+        assertEquals("ISO-8859-1", metadata.get(Metadata.CONTENT_ENCODING)); // deprecated
 
-        metadata.set(Metadata.CONTENT_ENCODING, "ISO-8859-15");
+        metadata.set(Metadata.CONTENT_TYPE, "text/plain; charset=ISO-8859-15");
         parser.parse(
                 new ByteArrayInputStream(test2.getBytes("ISO-8859-1")),
                 new BodyContentHandler(),  metadata, new ParseContext());
-
-        assertEquals("ISO-8859-15", metadata.get(Metadata.CONTENT_ENCODING));
+        assertEquals("text/plain; charset=ISO-8859-15", metadata.get(Metadata.CONTENT_TYPE));
+        assertEquals("ISO-8859-15", metadata.get(Metadata.CONTENT_ENCODING)); // deprecated
     }
 
     /**
@@ -136,16 +176,16 @@ public class TXTParserTest extends TestCase {
         parser.parse(
                 new ByteArrayInputStream(test2.getBytes("ISO-8859-1")),
                 new BodyContentHandler(),  metadata, new ParseContext());
-
-        assertEquals("ISO-8859-1", metadata.get(Metadata.CONTENT_ENCODING));
+        assertEquals("text/plain; charset=ISO-8859-1", metadata.get(Metadata.CONTENT_TYPE));
+        assertEquals("ISO-8859-1", metadata.get(Metadata.CONTENT_ENCODING)); // deprecated
 
         metadata = new Metadata();
         metadata.set(Metadata.CONTENT_TYPE, "text/html; charset=ISO-8859-15");
         parser.parse(
                 new ByteArrayInputStream(test2.getBytes("ISO-8859-1")),
                 new BodyContentHandler(),  metadata, new ParseContext());
-
-        assertEquals("ISO-8859-15", metadata.get(Metadata.CONTENT_ENCODING));
+        assertEquals("text/plain; charset=ISO-8859-15", metadata.get(Metadata.CONTENT_TYPE));
+        assertEquals("ISO-8859-15", metadata.get(Metadata.CONTENT_ENCODING)); // deprecated
     }
 
     private void assertExtractText(String msg, String expected, byte[] input)
@@ -157,7 +197,6 @@ public class TXTParserTest extends TestCase {
         };
         Metadata metadata = new Metadata();
         parser.parse(new ByteArrayInputStream(input), handler, metadata, new ParseContext());
-        assertEquals("text/plain", metadata.get(Metadata.CONTENT_TYPE));
         assertEquals(msg, expected, handler.toString());
     }
 
@@ -188,8 +227,7 @@ public class TXTParserTest extends TestCase {
                 metadata,
                 new ParseContext());
 
-        assertEquals("text/plain", metadata.get(Metadata.CONTENT_TYPE));
-        assertEquals("IBM866", metadata.get(Metadata.CONTENT_ENCODING));
+        assertEquals("text/plain; charset=IBM866", metadata.get(Metadata.CONTENT_TYPE));
     }
 
     public void testEBCDIC_CP500() throws Exception {
@@ -201,19 +239,18 @@ public class TXTParserTest extends TestCase {
                 metadata,
                 new ParseContext());
 
-        assertEquals("text/plain", metadata.get(Metadata.CONTENT_TYPE));
-        assertEquals("IBM500", metadata.get(Metadata.CONTENT_ENCODING));
-        
+        assertEquals("text/plain; charset=IBM500", metadata.get(Metadata.CONTENT_TYPE));
+
         // Additional check that it isn't too eager on short blocks of text
         metadata = new Metadata();
         writer = new StringWriter();
         parser.parse(
-                new ByteArrayInputStream("<html><body>hello world</body></html>".getBytes("UTF-8")),
+                new ByteArrayInputStream("<html><body>hello world</body></html>".getBytes("ISO-8859-1")),
                 new WriteOutContentHandler(writer),
                 metadata,
                 new ParseContext());
 
-        assertNotSame("IBM500", metadata.get(Metadata.CONTENT_ENCODING));
+        assertEquals("text/plain; charset=ISO-8859-1", metadata.get(Metadata.CONTENT_TYPE));
     }
 
 }

Commit:
95a1cf9448d0454821b2b6e2bd47480816173094
David Meikle
dmeikle@apache.org
2012-07-08 22:40:15 +0000
TIKA-906: Added basic support for AutoPageNumbers and their formats
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/AutoPageNumberUtils.java b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/AutoPageNumberUtils.java
new file mode 100644
index 000000000..0dda1c088
--- /dev/null
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/AutoPageNumberUtils.java
@@ -0,0 +1,110 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.parser.iwork;
+
+/**
+ * Utility class to allow for conversion from an integer to Roman numerals
+ * or alpha-numeric symbols in line with Pages auto numbering formats.
+ */
+ class AutoPageNumberUtils {
+	
+	private static final String ALPHABET[] = { "A", "B", "C", "D", "E", "F", "G",
+		"H", "I", "J", "K", "L", "M", "N", "O", "P", "Q", "R", "S", "T",
+		"U", "V", "W", "X", "Y", "Z" };
+	
+	private static final int MAX = 26; 
+
+	public static String asAlphaNumeric(int i) {
+		StringBuffer sbuff = new StringBuffer();
+		int index = i % MAX;
+		int ratio = i / MAX;
+		
+		if (index == 0) {
+			ratio--;
+			index = MAX;
+		}
+		
+		for(int j = 0; j <= ratio; j++) {
+			sbuff.append(ALPHABET[index - 1]);		}
+		return sbuff.toString();
+	}
+	
+	public static String asAlphaNumericLower(int i) {
+		return asAlphaNumeric(i).toLowerCase();
+	}
+	
+	/*
+	 * Code copied from jena.apache.org.
+	 * @see com.hp.hpl.jena.sparql.util.RomanNumeral
+	 */
+    public static String asRomanNumerals(int i) {
+        if ( i <= 0 )
+            throw new NumberFormatException("Roman numerals are 1-3999 ("+i+")") ;
+        if ( i > 3999 )
+            throw new NumberFormatException("Roman numerals are 1-3999 ("+i+")") ;
+        StringBuffer sbuff = new StringBuffer() ;
+        
+        i = i2r(sbuff, i, "M", 1000, "CM", 900, "D", 500, "CD", 400 ) ;
+        i = i2r(sbuff, i, "C", 100,  "XC", 90,  "L", 50,  "XL", 40 ) ;
+        i = i2r(sbuff, i, "X", 10,   "IX", 9,   "V", 5,   "IV", 4) ;
+        
+        while ( i >= 1 )
+        {
+            sbuff.append("I") ;
+            i -= 1 ;
+        }
+        return sbuff.toString() ;
+            
+        
+    }
+    
+	public static String asRomanNumeralsLower(int i) {
+		return asRomanNumerals(i).toLowerCase();
+	}
+    
+    private static int i2r(StringBuffer sbuff, int i,
+                           String tens,  int iTens, 
+                           String nines, int iNines,
+                           String fives, int iFives,
+                           String fours, int iFours)
+    {
+        while ( i >= iTens )
+        {
+            sbuff.append(tens) ;
+            i -= iTens ;
+        }
+        
+        if ( i >= iNines )
+        {
+            sbuff.append(nines) ;
+            i -= iNines;
+        }
+
+        if ( i >= iFives )
+        {
+            sbuff.append(fives) ;
+            i -= iFives ;
+        }
+        if ( i >= iFours )
+        {
+            sbuff.append(fours) ;
+            i -= iFours ;
+        }
+        return i ;
+    }
+
+}
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/PagesContentHandler.java b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/PagesContentHandler.java
index 1bab802e1..134bc90b6 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/PagesContentHandler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/PagesContentHandler.java
@@ -28,6 +28,7 @@ import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
+import java.util.regex.Pattern;
 
 class PagesContentHandler extends DefaultHandler {
 
@@ -43,6 +44,8 @@ class PagesContentHandler extends DefaultHandler {
     }
     private DocumentPart inPart = null;
     private boolean ghostText;
+    
+    private static String alphabet = "ABCDEFGHIJKLMNOPQRSTUVWXYZ";
 
     private boolean parseProperty = false;
     private int pageCount = 0;
@@ -132,6 +135,19 @@ class PagesContentHandler extends DefaultHandler {
             inPart = headers.identifyPart(attributes.getValue("sf:name"));
         } else if ("sf:footer".equals(qName)) {
            inPart = footers.identifyPart(attributes.getValue("sf:name"));
+        } else if ("sf:page-number".equals(qName)) {	
+        	if (inPart == DocumentPart.FOOTER_ODD
+        		|| inPart == DocumentPart.FOOTER_FIRST
+        		|| inPart == DocumentPart.FOOTER_EVEN) {
+        		// We are in a footer
+        		footers.hasAutoPageNumber = true;
+        		footers.autoPageNumberFormat = attributes.getValue("sf:format");   
+        	} else {
+        		headers.hasAutoPageNumber = true;
+        		headers.autoPageNumberFormat = attributes.getValue("sf:format");   
+        	}
+
+        	xhtml.characters(Integer.toString(this.pageCount));
         } else if ("sf:footnotes".equals(qName)) {
            footnotes = new Footnotes();
            inPart = DocumentPart.FOOTNOTES;
@@ -324,6 +340,8 @@ class PagesContentHandler extends DefaultHandler {
        private String defaultOdd;
        private String defaultEven;
        private String defaultFirst;
+       private boolean hasAutoPageNumber;
+       private String autoPageNumberFormat;
        // TODO Can there be custom ones?
        
        private HeaderFooter(String type) {
@@ -359,6 +377,19 @@ class PagesContentHandler extends DefaultHandler {
           if (text != null) {
              xhtml.startElement("div", "class", "header");
              xhtml.characters(text);
+             if (hasAutoPageNumber) {
+            	 if (autoPageNumberFormat == null) { // raw number
+            		 xhtml.characters("\t" + pageCount);
+            	 } else if (autoPageNumberFormat.equals("upper-roman")){
+            		 xhtml.characters("\t" + AutoPageNumberUtils.asRomanNumerals(pageCount));
+            	 } else if (autoPageNumberFormat.equals("lower-roman")){
+            		 xhtml.characters("\t" + AutoPageNumberUtils.asRomanNumeralsLower(pageCount));
+            	 } else if (autoPageNumberFormat.equals("upper-alpha")){
+            		 xhtml.characters("\t" + AutoPageNumberUtils.asAlphaNumeric(pageCount));
+            	 } else if (autoPageNumberFormat.equals("lower-alpha")){
+            		 xhtml.characters("\t" + AutoPageNumberUtils.asAlphaNumericLower(pageCount));
+            	 }
+             }
              xhtml.endElement("div");
           }
        }
@@ -414,4 +445,5 @@ class PagesContentHandler extends DefaultHandler {
           }
        }
     }
+
 }
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/iwork/AutoPageNumberUtilsTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/iwork/AutoPageNumberUtilsTest.java
new file mode 100644
index 000000000..a215635c5
--- /dev/null
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/iwork/AutoPageNumberUtilsTest.java
@@ -0,0 +1,56 @@
+package org.apache.tika.parser.iwork;
+
+import junit.framework.TestCase;
+
+/**
+ * Test class for the <code>AutoPageNumberUtils</code> helper class.
+ */
+public class AutoPageNumberUtilsTest extends TestCase {
+
+	/**
+	 * Check upper-case alpha-numeric numbers are generated based on the 
+	 * input page number.
+	 */
+	public void testAlphaUpper() {
+		assertEquals("A", AutoPageNumberUtils.asAlphaNumeric(1));
+		assertEquals("Z", AutoPageNumberUtils.asAlphaNumeric(26));
+		assertEquals("AA", AutoPageNumberUtils.asAlphaNumeric(27));
+		assertEquals("ZZ", AutoPageNumberUtils.asAlphaNumeric(52));
+		assertEquals("AAA", AutoPageNumberUtils.asAlphaNumeric(53));
+		assertEquals("ZZZ", AutoPageNumberUtils.asAlphaNumeric(78));
+	}
+
+	/**
+	 * Check lower-case alpha-numeric numbers are generated based on the 
+	 * input page number.
+	 */
+	public void testAlphaLower() {
+		assertEquals("a", AutoPageNumberUtils.asAlphaNumericLower(1));
+		assertEquals("z", AutoPageNumberUtils.asAlphaNumericLower(26));
+		assertEquals("aa", AutoPageNumberUtils.asAlphaNumericLower(27));
+		assertEquals("zz", AutoPageNumberUtils.asAlphaNumericLower(52));
+		assertEquals("aaa", AutoPageNumberUtils.asAlphaNumericLower(53));
+		assertEquals("zzz", AutoPageNumberUtils.asAlphaNumericLower(78));
+	}
+
+	/**
+	 * Check upper-case Roman numerals numbers are generated based on the 
+	 * input page number.
+	 */
+	public void testRomanUpper() {
+		assertEquals("I", AutoPageNumberUtils.asRomanNumerals(1));
+		assertEquals("XXVI", AutoPageNumberUtils.asRomanNumerals(26));
+		assertEquals("XXVII", AutoPageNumberUtils.asRomanNumerals(27));
+	}
+
+	/**
+	 * Check lower-case Roman numerals numbers are generated based on the 
+	 * input page number.
+	 */
+	public void testRomanLower() {
+		assertEquals("i", AutoPageNumberUtils.asRomanNumeralsLower(1));
+		assertEquals("xxvi", AutoPageNumberUtils.asRomanNumeralsLower(26));
+		assertEquals("xxvii", AutoPageNumberUtils.asRomanNumeralsLower(27));
+	}
+
+}
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
index 8bc2013ec..f385653af 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
@@ -23,7 +23,6 @@ import java.util.List;
 import junit.framework.TestCase;
 
 import org.apache.tika.metadata.Metadata;
-import org.apache.tika.metadata.Office;
 import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.AutoDetectParser;
 import org.apache.tika.parser.ParseContext;
@@ -291,7 +290,8 @@ public class IWorkParserTest extends TestCase {
     public void testParsePagesHeadersFootersFootnotes() throws Exception {
        String footnote = "Footnote: Do a lot of people really use iWork?!?!";
        String header = "THIS IS SOME HEADER TEXT";
-       String footer = "THIS IS SOME FOOTER TEXT";
+       String footer = "THIS IS SOME FOOTER TEXT\t1";
+       String footer2 = "THIS IS SOME FOOTER TEXT\t2";
        
        InputStream input = IWorkParserTest.class.getResourceAsStream("/test-documents/testPagesHeadersFootersFootnotes.pages");
        Metadata metadata = new Metadata();
@@ -308,9 +308,90 @@ public class IWorkParserTest extends TestCase {
        // Check for headers, footers and footnotes
        assertContains(contents, header);
        assertContains(contents, footer);
+       assertContains(contents, footer2);
        assertContains(contents, footnote);
     }
     
+    /**
+     * Check we get upper-case Roman numerals within the footer for AutoPageNumber.
+     */
+    public void testParsePagesHeadersFootersRomanUpper() throws Exception {
+       String header = "THIS IS SOME HEADER TEXT";
+       String footer = "THIS IS SOME FOOTER TEXT\tI";
+       String footer2 = "THIS IS SOME FOOTER TEXT\tII";
+       
+       InputStream input = IWorkParserTest.class.getResourceAsStream("/test-documents/testPagesHeadersFootersRomanUpper.pages");
+       ContentHandler handler = new BodyContentHandler();
+
+       iWorkParser.parse(input, handler, new Metadata(), parseContext);
+       String contents = handler.toString();
+       
+       // Check for headers, footers and footnotes
+       assertContains(contents, header);
+       assertContains(contents, footer);
+       assertContains(contents, footer2);
+    }
+    
+    /**
+     * Check we get lower-case Roman numerals within the footer for AutoPageNumber.
+     */
+    public void testParsePagesHeadersFootersRomanLower() throws Exception {
+       String header = "THIS IS SOME HEADER TEXT";
+       String footer = "THIS IS SOME FOOTER TEXT\ti";
+       String footer2 = "THIS IS SOME FOOTER TEXT\tii";
+       
+       InputStream input = IWorkParserTest.class.getResourceAsStream("/test-documents/testPagesHeadersFootersRomanLower.pages");
+       ContentHandler handler = new BodyContentHandler();
+
+       iWorkParser.parse(input, handler, new Metadata(), parseContext);
+       String contents = handler.toString();
+       
+       // Check for headers, footers and footnotes
+       assertContains(contents, header);
+       assertContains(contents, footer);
+       assertContains(contents, footer2);
+    }
+
+    /**
+     * Check we get upper-case alpha-numeric letters within the footer for AutoPageNumber.
+     */
+    public void testParsePagesHeadersAlphaUpper() throws Exception {
+       String header = "THIS IS SOME HEADER TEXT\tA";
+       String footer = "THIS IS SOME FOOTER TEXT\tA";
+       String footer2 = "THIS IS SOME FOOTER TEXT\tB";
+       
+       InputStream input = IWorkParserTest.class.getResourceAsStream("/test-documents/testPagesHeadersFootersAlphaUpper.pages");
+       ContentHandler handler = new BodyContentHandler();
+
+       iWorkParser.parse(input, handler, new Metadata(), parseContext);
+       String contents = handler.toString();
+       
+       // Check for headers, footers and footnotes
+       assertContains(contents, header);
+       assertContains(contents, footer);
+       assertContains(contents, footer2);
+    }
+ 
+    /**
+     * Check we get lower-case alpha-numeric letters within the footer for AutoPageNumber.
+     */
+    public void testParsePagesHeadersAlphaLower() throws Exception {
+       String header = "THIS IS SOME HEADER TEXT";
+       String footer = "THIS IS SOME FOOTER TEXT\ta";
+       String footer2 = "THIS IS SOME FOOTER TEXT\tb";
+       
+       InputStream input = IWorkParserTest.class.getResourceAsStream("/test-documents/testPagesHeadersFootersAlphaLower.pages");
+       ContentHandler handler = new BodyContentHandler();
+
+       iWorkParser.parse(input, handler, new Metadata(), parseContext);
+       String contents = handler.toString();
+       
+       // Check for headers, footers and footnotes
+       assertContains(contents, header);
+       assertContains(contents, footer);
+       assertContains(contents, footer2);
+    }
+    
     /**
      * Check we get annotations (eg comments) from Pages
      */
@@ -318,7 +399,6 @@ public class IWorkParserTest extends TestCase {
        String commentA = "comment about the APXL file";
        String commentB = "comment about UIMA";
        
-       
        InputStream input = IWorkParserTest.class.getResourceAsStream("/test-documents/testPagesComments.pages");
        Metadata metadata = new Metadata();
        ContentHandler handler = new BodyContentHandler();
diff --git a/tika-parsers/src/test/resources/test-documents/testPagesHeadersFootersAlphaLower.pages b/tika-parsers/src/test/resources/test-documents/testPagesHeadersFootersAlphaLower.pages
new file mode 100644
index 000000000..b690101fe
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testPagesHeadersFootersAlphaLower.pages differ
diff --git a/tika-parsers/src/test/resources/test-documents/testPagesHeadersFootersAlphaUpper.pages b/tika-parsers/src/test/resources/test-documents/testPagesHeadersFootersAlphaUpper.pages
new file mode 100644
index 000000000..7d0caf392
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testPagesHeadersFootersAlphaUpper.pages differ
diff --git a/tika-parsers/src/test/resources/test-documents/testPagesHeadersFootersRomanLower.pages b/tika-parsers/src/test/resources/test-documents/testPagesHeadersFootersRomanLower.pages
new file mode 100644
index 000000000..9cc0edf96
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testPagesHeadersFootersRomanLower.pages differ
diff --git a/tika-parsers/src/test/resources/test-documents/testPagesHeadersFootersRomanUpper.pages b/tika-parsers/src/test/resources/test-documents/testPagesHeadersFootersRomanUpper.pages
new file mode 100644
index 000000000..de976736b
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testPagesHeadersFootersRomanUpper.pages differ

Commit:
c6bcd32b9f0b086743ce0214a925901984a0a3f6
Nick Burch
nick@apache.org
2012-07-08 18:57:48 +0000
Add an entry for TIKA-948
diff --git a/CHANGES.txt b/CHANGES.txt
index 630833746..01b542ff7 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -43,6 +43,9 @@ Release 1.2 - Current Development
     ICU4J algorithms are still used as a fallback thanks to their wider
     coverage of custom character encodings. (TIKA-322, TIKA-471)
 
+  * Extraction of embedded resources from OLE2 Office Documents, where
+    the resource isn't another office document, has been fixed (TIKA-948)
+
 Release 1.1 - 3/7/2012
 ---------------------------------
 

Commit:
ddb997a471a85727b4d59762e4fe2cba7a1fd693
Jukka Zitting
jukka@apache.org
2012-07-08 14:07:21 +0000
TIKA-502: Add programming language mime-types
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 0e7b36b80..9382054dd 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -156,7 +156,7 @@
     <glob pattern="*.fit"/>
     <glob pattern="*.fts"/>
   </mime-type>
-  
+
   <mime-type type="application/font-tdpfr">
     <glob pattern="*.pfr"/>
   </mime-type>
@@ -169,6 +169,12 @@
   <mime-type type="application/ibe-pkg-reply+xml"/>
   <mime-type type="application/ibe-pp-data"/>
   <mime-type type="application/iges"/>
+
+  <mime-type type="application/illustrator">
+    <glob pattern="*.ai"/>]
+    <sub-class-of type="application/postscript"/>
+  </mime-type>
+
   <mime-type type="application/im-iscomposing+xml"/>
   <mime-type type="application/index"/>
   <mime-type type="application/index.cmd"/>
@@ -207,6 +213,7 @@
     <alias type="application/x-javascript"/>
     <alias type="text/javascript"/>
     <sub-class-of type="text/plain"/>
+    <_comment>JavaScript Source Code</_comment>
     <glob pattern="*.js"/>
   </mime-type>
 
@@ -216,6 +223,7 @@
   </mime-type>
 
   <mime-type type="application/java-vm">
+    <alias type="application/x-java"/>
     <magic priority="40">
       <match value="0xcafebabe" type="string" offset="0" />
     </magic>
@@ -382,13 +390,17 @@
   </mime-type>
 
   <mime-type type="application/pgp-encrypted">
+    <alias type="application/pgp"/>
     <glob pattern="*.pgp"/>
   </mime-type>
+
   <mime-type type="application/pgp-keys"/>
+
   <mime-type type="application/pgp-signature">
     <glob pattern="*.asc"/>
     <glob pattern="*.sig"/>
   </mime-type>
+
   <mime-type type="application/pics-rules">
     <glob pattern="*.prf"/>
   </mime-type>
@@ -439,7 +451,6 @@
       <!-- Windows format EPS -->
       <match value="0xc5d0d3c6" type="string" offset="0"/>
     </magic>
-    <glob pattern="*.ai"/>
     <glob pattern="*.ps"/>
     <glob pattern="*.eps"/>
     <glob pattern="*.epsf"/>
@@ -497,6 +508,7 @@
   </mime-type>
 
   <mime-type type="application/rtf">
+    <_comment>Rich Text Format File</_comment>
     <alias type="text/rtf"/>
     <magic priority="50">
       <match value="{\\rtf" type="string" offset="0"/>
@@ -544,11 +556,15 @@
   <mime-type type="application/simple-message-summary"/>
   <mime-type type="application/simplesymbolcontainer"/>
   <mime-type type="application/slate"/>
-  <mime-type type="application/smil"/>
+
   <mime-type type="application/smil+xml">
+    <alias type="application/smil"/>
+    <_comment>SMIL Multimedia</_comment>
     <glob pattern="*.smi"/>
     <glob pattern="*.smil"/>
+    <glob pattern="*.sml"/>
   </mime-type>
+
   <mime-type type="application/soap+fastinfoset"/>
   <mime-type type="application/soap+xml"/>
   <mime-type type="application/sparql-query">
@@ -1088,29 +1104,45 @@
   <mime-type type="application/vnd.kde.karbon">
     <glob pattern="*.karbon"/>
   </mime-type>
+
   <mime-type type="application/vnd.kde.kchart">
+    <alias type="application/x-kchart"/>
+    <_comment>KChart File</_comment>
     <glob pattern="*.chrt"/>
   </mime-type>
+
   <mime-type type="application/vnd.kde.kformula">
     <glob pattern="*.kfo"/>
   </mime-type>
+
   <mime-type type="application/vnd.kde.kivio">
     <glob pattern="*.flw"/>
   </mime-type>
+
   <mime-type type="application/vnd.kde.kontour">
     <glob pattern="*.kon"/>
   </mime-type>
+
   <mime-type type="application/vnd.kde.kpresenter">
+    <alias type="application/x-kpresenter"/>
+    <_comment>KPresenter File</_comment>
     <glob pattern="*.kpr"/>
     <glob pattern="*.kpt"/>
   </mime-type>
+
   <mime-type type="application/vnd.kde.kspread">
+    <alias type="application/x-kspread"/>
+    <_comment>KSpread File</_comment>
     <glob pattern="*.ksp"/>
   </mime-type>
+
   <mime-type type="application/vnd.kde.kword">
+    <alias type="application/x-kword"/>
+    <_comment>KWord File</_comment>
     <glob pattern="*.kwd"/>
     <glob pattern="*.kwt"/>
   </mime-type>
+
   <mime-type type="application/vnd.kenameaapp">
     <glob pattern="*.htke"/>
   </mime-type>
@@ -1154,8 +1186,9 @@
   <mime-type type="application/vnd.lotus-organizer">
     <glob pattern="*.org"/>
   </mime-type>
+
   <mime-type type="application/vnd.lotus-screencam">
-    <glob pattern="*.scm"/>
+    <!-- <glob pattern="*.scm"/> - conflicts with text/x-scheme -->
   </mime-type>
 
   <mime-type type="application/vnd.lotus-wordpro">
@@ -1197,7 +1230,7 @@
   </mime-type>
 
   <mime-type type="application/vnd.mif">
-    <_comment>FrameMaker MIF document</_comment>
+    <_comment>FrameMaker Interchange Format</_comment>
     <alias type="application/x-mif"/>
     <alias type="application/x-frame"/>
     <magic priority="50">
@@ -1208,6 +1241,7 @@
       <match value="\&lt;MML" type="string" offset="0" />
       <match value="\&lt;Book" type="string" offset="0" />
       <match value="\&lt;Maker" type="string" offset="0" />
+      <match value="\x3c\x4d\x49\x46\x46\x69\x6c\x65\x20" type="string" offset="0" />
     </magic>
     <glob pattern="*.mif"/>
   </mime-type>
@@ -1815,11 +1849,13 @@
     <glob pattern="*.dp"/>
   </mime-type>
   <mime-type type="application/vnd.otps.ct-kip+xml"/>
+
   <mime-type type="application/vnd.palm">
-    <glob pattern="*.pdb"/>
+    <!-- <glob pattern="*.pdb"/> - conflicts with chemical/x-pdb -->
     <glob pattern="*.pqa"/>
     <glob pattern="*.oprc"/>
   </mime-type>
+
   <mime-type type="application/vnd.paos.xml"/>
   <mime-type type="application/vnd.pg.format">
     <glob pattern="*.str"/>
@@ -2302,6 +2338,7 @@
   <mime-type type="application/x-authorware-seg">
     <glob pattern="*.aas"/>
   </mime-type>
+
   <mime-type type="application/x-bcpio">
     <glob pattern="*.bcpio"/>
   </mime-type>
@@ -2376,10 +2413,14 @@
   </mime-type>
 
   <mime-type type="application/x-bzip2">
+    <sub-class-of type="application/x-bzip"/>
+    <_comment>Bzip 2 UNIX Compressed File</_comment>
+    <magic priority="40">
+      <match value="\x42\x5a\x68\x39\x31" type="string" offset="0"/>
+    </magic>
     <glob pattern="*.bz2"/>
     <glob pattern="*.tbz2"/>
     <glob pattern="*.boz"/>
-    <sub-class-of type="application/x-bzip"/>
   </mime-type>
 
   <mime-type type="application/x-cdlink">
@@ -2407,6 +2448,7 @@
   </mime-type>
   
   <mime-type type="application/x-cpio">
+    <_comment>UNIX CPIO Archive</_comment>
     <magic priority="50">
       <match value="070707" type="little16" offset="0"/>
       <match value="070707" type="big16" offset="0"/>
@@ -2419,6 +2461,7 @@
 
   <mime-type type="application/x-csh">
     <glob pattern="*.csh"/>
+    <glob pattern="*.tcsh"/>
   </mime-type>
 
   <mime-type type="application/x-debian-package">
@@ -2457,9 +2500,12 @@
   </mime-type>
 
   <mime-type type="application/x-dvi">
+    <_comment>TeX Device Independent Document</_comment>
     <magic priority="50">
       <match value="\367\002" type="string" offset="0"/>
       <match value="0x02f7" type="little16" offset="0"/>
+      <match value="\x1b\x20\x54\x65\x58\x20\x6f\x75\x74\x70\x75\x74\x20"
+             type="string" offset="14"/>
     </magic>
     <glob pattern="*.dvi"/>
   </mime-type>
@@ -2497,6 +2543,11 @@
     <glob pattern="*.emlx"/>
   </mime-type>
 
+  <mime-type type="application/x-killustrator">
+    <_comment>KIllustrator File</_comment>
+    <glob pattern="*.kil"/>
+  </mime-type>
+
   <mime-type type="application/x-object">
     <sub-class-of type="application/x-elf"/>
     <magic priority="50">
@@ -2534,6 +2585,12 @@
     </magic>
   </mime-type>
 
+  <mime-type type="application/x-dosexec">
+    <_comment>DOS/Windows executable (EXE)</_comment>
+    <sub-class-of type="application/x-msdownload"/>
+    <glob pattern="*.exe"/>
+  </mime-type>
+
   <mime-type type="application/x-emf">
     <acronym>EMF</acronym>
     <_comment>Extended Metafile</_comment>
@@ -2639,6 +2696,7 @@
   </mime-type>
 
   <mime-type type="application/x-gtar">
+    <_comment>GNU tar Compressed File Archive (GNU Tape Archive)</_comment>
     <magic priority="40">
       <!-- GNU tar archive -->
       <match value="ustar  \0" type="string" offset="257" />
@@ -2648,8 +2706,10 @@
   </mime-type>
 
   <mime-type type="application/x-gzip">
+    <_comment>Gzip Compressed Archive</_comment>
     <magic priority="40">
       <match value="\037\213" type="string" offset="0" />
+      <match value="\x1f\x8b" type="string" offset="0" />
     </magic>
     <glob pattern="*.tgz" />
     <glob pattern="*.gz" />
@@ -2658,6 +2718,7 @@
   </mime-type>
 
   <mime-type type="application/x-hdf">
+    <_comment>Hierarchical Data Format File</_comment>
     <magic priority="50">
       <match value="0x0e031301" type="big32" offset="0"/>
       <match value="\211HDF\r\n\032" type="string" offset="0"/>
@@ -2719,6 +2780,7 @@
       <match value="%\ -*-latex-*-" type="string" offset="0"/>
     </magic>
     <glob pattern="*.latex"/>
+    <sub-class-of type="application/x-tex"/>
   </mime-type>
 
   <mime-type type="application/x-lha">
@@ -2778,7 +2840,6 @@
   </mime-type>
 
   <mime-type type="application/x-msdownload">
-    <glob pattern="*.exe"/>
     <glob pattern="*.dll"/>
     <glob pattern="*.com"/>
     <glob pattern="*.bat"/>
@@ -2787,6 +2848,7 @@
       <match value="MZ" type="string" offset="0"/>
     </magic>
   </mime-type>
+
   <mime-type type="application/x-msdownload;format=pe">
     <sub-class-of type="application/x-msdownload"/>
     <magic priority="55">
@@ -2915,15 +2977,21 @@
   </mime-type>
   
   <mime-type type="application/x-rar-compressed">
+    <_comment>RAR archive</_comment>
     <alias type="application/x-rar"/>
     <magic priority="50">
       <match value="Rar!" type="string" offset="0"/>
+      <match value="\x52\x61\x72\x21\x1a" type="string" offset="0"/>
     </magic>
     <glob pattern="*.rar"/>
   </mime-type>
 
   <mime-type type="application/x-rpm">
+    <_comment>RedHat Package Manager</_comment>
     <glob pattern="*.rpm"/>
+    <magic priority="50">
+      <match value="\xed\xab\xee\xdb" type="string" offset="0"/>
+    </magic>
   </mime-type>
 
   <mime-type type="application/x-sc">
@@ -2933,12 +3001,15 @@
   </mime-type>
 
   <mime-type type="application/x-sh">
+    <_comment>UNIX/LINUX Shell Script</_comment>
     <magic priority="50">
       <match value="#!/" type="string" offset="0"/>
       <match value="#!\ /" type="string" offset="0"/>
       <match value="#!\t/" type="string" offset="0"/>
+      <match value="eval &quot;exec" type="string" offset="0"/>
     </magic>
     <glob pattern="*.sh"/>
+    <glob pattern="*.bash"/>
     <sub-class-of type="text/plain"/>
   </mime-type>
 
@@ -2985,13 +3056,8 @@
     <glob pattern="*.tar"/>
   </mime-type>
 
-  <mime-type type="application/x-tcl">
-    <alias type="text/x-tcl"/>
-    <glob pattern="*.tcl"/>
-    <sub-class-of type="text/plain"/>
-  </mime-type>
-
   <mime-type type="application/x-tex">
+    <_comment>TeX Source</_comment>
     <alias type="text/x-tex"/>
     <magic priority="50">
       <match value="\\input" type="string" offset="0"/>
@@ -3158,10 +3224,16 @@
   </mime-type>
 
   <mime-type type="application/xml-dtd">
+    <_comment>XML Document Type Definition</_comment>
     <sub-class-of type="text/plain"/>
+    <alias type="text/x-dtd"/>
     <glob pattern="*.dtd"/>
   </mime-type>
-  <mime-type type="application/xml-external-parsed-entity"/>
+
+  <mime-type type="application/xml-external-parsed-entity">
+    <alias type="text/xml-external-parsed-entity"/>
+  </mime-type>
+
   <mime-type type="application/xmpp+xml"/>
   <mime-type type="application/xop+xml">
     <glob pattern="*.xop"/>
@@ -3187,6 +3259,7 @@
   </mime-type>
 
   <mime-type type="application/zip">
+    <_comment>Compressed Archive File</_comment>
     <alias type="application/x-zip-compressed"/>
     <magic priority="40">
       <match value="PK\003\004" type="string" offset="0"/>
@@ -3219,6 +3292,7 @@
   <mime-type type="audio/asc"/>
 
   <mime-type type="audio/basic">
+    <_comment>uLaw/AU Audio File</_comment>
     <magic priority="20">
       <match value=".snd" type="string" offset="0">
         <match value="1" type="big32" offset="12"/>
@@ -3229,6 +3303,7 @@
         <match value="6" type="big32" offset="12"/>
         <match value="7" type="big32" offset="12"/>
       </match>
+      <match offset="0" type="string" value="\x2e\x73\x6e\x64\x00\x00\x00"/>
     </magic>
     <glob pattern="*.au"/>
     <glob pattern="*.snd"/>
@@ -3345,11 +3420,15 @@
   <mime-type type="audio/mpeg4-generic"/>
 
   <mime-type type="audio/ogg">
+    <_comment>Ogg Vorbis Codec Compressed WAV File</_comment>
+    <alias type="application/x-ogg"/>
     <magic priority="60">
       <!-- For a single stream file -->
       <match value="OggS\000.......................\001vorbis" type="string" 
              mask="0xFFFFFFFF00000000000000000000000000000000000000000000000000FFFFFFFFFFFF" 
              offset="0"/>
+      <match value="\x4f\x67\x67\x53\x00\x02\x00\x00\x00\x00\x00\x00\x00\x00"
+             type="string" offset="0"/>
     </magic>
     <glob pattern="*.oga"/>
     <glob pattern="*.ogg"/>
@@ -3463,6 +3542,7 @@
       <!-- Amiga IFF sound sample, somewhat like the more modern AIFF -->
       <match value="FORM....8SVX" type="string" offset="0"
              mask="0xFFFFFFFF00000000FFFFFFFF"/>
+      <match offset="0" type="string" value="\x46\x4f\x52\x4d\x00"/>
     </magic>
     <glob pattern="*.aif"/>
     <glob pattern="*.aiff"/>
@@ -3522,8 +3602,13 @@
   </mime-type>
 
   <mime-type type="audio/x-mpegurl">
+    <_comment>MP3 Playlist File</_comment>
+    <magic priority="50">
+     <match offset="0" type="string" value="\x23\x45\x58\x54\x4d\x33\x55\x0d\x0a"/>
+    </magic>
     <glob pattern="*.m3u"/>
   </mime-type>
+
   <mime-type type="audio/x-ms-wax">
     <glob pattern="*.wax"/>
   </mime-type>
@@ -3546,7 +3631,9 @@
   </mime-type>
 
   <mime-type type="audio/x-pn-realaudio-plugin">
+    <_comment>RealMedia Player Plug-in</_comment>
     <glob pattern="*.rmp"/>
+    <!-- <glob pattern="*.rpm"/> - conflicts with application/x-rpm -->
   </mime-type>
 
   <mime-type type="audio/x-wav">
@@ -3576,7 +3663,12 @@
   <mime-type type="chemical/x-csml">
     <glob pattern="*.csml"/>
   </mime-type>
-  <mime-type type="chemical/x-pdb"/>
+
+  <mime-type type="chemical/x-pdb">
+    <_comment>Brookhaven Protein Databank File</_comment>
+    <glob pattern="*.pdb"/>
+  </mime-type>
+
   <mime-type type="chemical/x-xyz">
     <glob pattern="*.xyz"/>
   </mime-type>
@@ -3694,6 +3786,7 @@
   <mime-type type="image/tiff-fx"/>
 
   <mime-type type="image/vnd.adobe.photoshop">
+    <_comment>Photoshop Image</_comment>
     <alias type="image/x-psd"/>
     <alias type="application/photoshop"/>
     <glob pattern="*.psd"/>
@@ -3841,10 +3934,11 @@
   <mime-type type="image/x-portable-graymap">
     <sub-class-of type="image/x-portable-anymap"/>
     <acronym>PGM</acronym>
-    <_comment>Portable Gray Map</_comment>
+    <_comment>Portable Graymap Graphic</_comment>
     <magic priority="50">
       <match value="P2" type="string" offset="0"/>
       <match value="P5" type="string" offset="0"/>
+      <match offset="0" type="string" value="\x50\x35\x0a"/>
     </magic>
     <glob pattern="*.pgm"/>
   </mime-type>
@@ -3852,11 +3946,12 @@
   <mime-type type="image/x-portable-pixmap">
     <sub-class-of type="image/x-portable-anymap"/>
     <acronym>PXM</acronym>
-    <_comment>Portable Pixel Map</_comment>
+    <_comment>UNIX Portable Bitmap Graphic</_comment>
     <magic priority="50">
       <match value="P3" type="string" offset="0"/>
       <match value="P6" type="string" offset="0"/>
       <match value="P7" type="string" offset="0"/>
+       <match offset="0" type="string" value="\x50\x34\x0a"/>
     </magic>
     <glob pattern="*.ppm"/>
   </mime-type>
@@ -3977,6 +4072,10 @@
   </mime-type>
 
   <mime-type type="image/x-rgb">
+    <_comment>Silicon Graphics RGB Bitmap</_comment>
+    <magic priority="50">
+      <match offset="0" type="string" value="\x01\xda\x01\x01\x00\x03"/>
+    </magic>
     <glob pattern="*.rgb"/>
   </mime-type>
 
@@ -3989,16 +4088,20 @@
   </mime-type>
 
   <mime-type type="image/x-xcf">
+    <_comment>GIMP Image File</_comment>
     <alias type="image/xcf"/>
     <magic priority="50">
       <match type="string" value="gimp xcf " offset="0"/>
     </magic>
+    <glob pattern="*.xcf"/>
   </mime-type>
 
   <mime-type type="image/x-xpixmap">
     <glob pattern="*.xpm"/>
   </mime-type>
+
   <mime-type type="image/x-xwindowdump">
+    <_comment>X Windows Dump</_comment>
     <glob pattern="*.xwd"/>
   </mime-type>
 
@@ -4104,6 +4207,54 @@
   <mime-type type="multipart/report"/>
   <mime-type type="multipart/signed"/>
   <mime-type type="multipart/voice-message"/>
+
+  <mime-type type="text/x-actionscript">
+    <_comment>ActionScript source code</_comment>
+    <glob pattern="*.as"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-ada">
+    <_comment>Ada source code</_comment>
+    <glob pattern="*.ada"/>
+    <glob pattern="*.adb"/>
+    <glob pattern="*.ads"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-applescript">
+    <_comment>AppleScript source code</_comment>
+    <glob pattern="*.applescript"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/asp">
+    <_comment>Active Server Page</_comment>
+    <glob pattern="*.asp"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/aspdotnet">
+    <_comment>ASP .NET</_comment>
+    <glob pattern="*.aspx"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-aspectj">
+    <_comment>AspectJ source code</_comment>
+    <glob pattern="*.aj"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-assembly">
+    <alias type="text/x-asm"/>
+    <_comment>Assembler source code</_comment>
+    <glob pattern="*.s"/>
+    <glob pattern="*.S"/>
+    <glob pattern="*.asm"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
   <mime-type type="text/calendar">
     <glob pattern="*.ics"/>
     <glob pattern="*.ifb"/>
@@ -4118,6 +4269,7 @@
   <mime-type type="text/csv">
     <glob pattern="*.csv"/>
   </mime-type>
+
   <mime-type type="text/directory"/>
   <mime-type type="text/dns"/>
   <mime-type type="text/ecmascript"/>
@@ -4192,7 +4344,6 @@
     <glob pattern="*.conf"/>
     <glob pattern="*.def"/>
     <glob pattern="*.list"/>
-    <glob pattern="*.log"/>
     <glob pattern="*.in"/>
 
     <!-- TIKA-85: http://www.apache.org/dev/svn-eol-style.txt -->
@@ -4205,7 +4356,6 @@
     <glob pattern="*.aart"/>
     <glob pattern="*.ac"/>
     <glob pattern="*.am"/>
-    <glob pattern="*.cgi"/>
     <glob pattern="*.classpath"/>
     <glob pattern="*.cmd"/>
     <glob pattern="*.config"/>
@@ -4231,18 +4381,13 @@
     <glob pattern="*.meta"/>
     <glob pattern="*.n3"/>
     <glob pattern="*.pen"/>
-    <glob pattern="*.pl"/>
-    <glob pattern="*.pm"/>
     <glob pattern="*.pod"/>
     <glob pattern="*.pom"/>
     <glob pattern="*.project"/>
     <glob pattern="*.properties"/>
-    <glob pattern="*.py"/>
-    <glob pattern="*.rb"/>
     <glob pattern="*.rng"/>
     <glob pattern="*.rnx"/>
     <glob pattern="*.roles"/>
-    <glob pattern="*.sql"/>
     <glob pattern="*.tld"/>
     <glob pattern="*.types"/>
     <glob pattern="*.vm"/>
@@ -4263,15 +4408,6 @@
     <glob pattern="*.xwelcome"/>
   </mime-type>
 
-  <mime-type type="application/x-httpd-jsp">
-    <sub-class-of type="text/plain"/>
-    <magic priority="50">
-      <match value="&lt;%@" type="string" offset="0"/>
-      <match value="&lt;%--" type="string" offset="0"/>
-    </magic>
-    <glob pattern="*.jsp"/>
-  </mime-type>
-
   <mime-type type="text/prs.fallenstein.rst"/>
   <mime-type type="text/prs.lines.tag">
     <glob pattern="*.dsc"/>
@@ -4281,7 +4417,7 @@
   <mime-type type="text/richtext">
     <glob pattern="*.rtx"/>
   </mime-type>
-  <mime-type type="text/rtf"/>
+
   <mime-type type="text/rtp-enc-aescm128"/>
   <mime-type type="text/rtx"/>
   <mime-type type="text/sgml">
@@ -4294,6 +4430,7 @@
   </mime-type>
 
   <mime-type type="text/troff">
+    <_comment>Roff/nroff/troff/groff Unformatted Manual Page (UNIX)</_comment>
     <alias type="application/x-troff"/>
     <alias type="application/x-troff-man"/>
     <alias type="application/x-troff-me"/>
@@ -4379,19 +4516,105 @@
     <glob pattern="*.wmls"/>
   </mime-type>
 
-  <mime-type type="text/x-asm">
-    <glob pattern="*.s"/>
-    <glob pattern="*.asm"/>
+  <mime-type type="text/x-awk">
+    <_comment>AWK script</_comment>
+    <magic priority="50">
+      <match value="#!/bin/gawk" type="string" offset="0"/>
+      <match value="#! /bin/gawk" type="string" offset="0"/>
+      <match value="#!/usr/bin/gawk" type="string" offset="0"/>
+      <match value="#! /usr/bin/gawk" type="string" offset="0"/>
+      <match value="#!/usr/local/bin/gawk" type="string" offset="0"/>
+      <match value="#! /usr/local/bin/gawk" type="string" offset="0"/>
+      <match value="#!/bin/awk" type="string" offset="0"/>
+      <match value="#! /bin/awk" type="string" offset="0"/>
+      <match value="#!/usr/bin/awk" type="string" offset="0"/>
+      <match value="#! /usr/bin/awk" type="string" offset="0"/>
+    </magic>
+    <glob pattenr="*.awk"/>
+    <sub-class-of type="text/plain"/>
   </mime-type>
 
-  <mime-type type="text/x-c">
-    <glob pattern="*.c"/>
-    <glob pattern="*.cc"/>
-    <glob pattern="*.cxx"/>
+  <mime-type type="text/x-basic">
+    <_comment>Basic source code</_comment>
+    <glob pattern="*.bas"/>
+    <glob pattern="*.Bas"/>
+    <glob pattern="*.BAS"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-c++hdr">
+    <_comment>C++ source code header</_comment>
+    <glob pattern="*.hpp"/>
+    <glob pattern="*.hxx"/>
+    <glob pattern="*.hh"/>
+    <glob pattern="*.H"/>
+    <glob pattern="*.h++"/>
+    <glob pattern="*.hp"/>
+    <glob pattern="*.HPP"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-c++src">
+    <_comment>C++ source code</_comment>
     <glob pattern="*.cpp"/>
+    <glob pattern="*.cxx"/>
+    <glob pattern="*.cc"/>
+    <glob pattern="*.C"/>
+    <glob pattern="*.c++"/>
+    <glob pattern="*.CPP"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-cgi">
+    <_comment>CGI script</_comment>
+    <glob pattern="*.cgi"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-chdr">
+    <_comment>C source code header</_comment>
     <glob pattern="*.h"/>
-    <glob pattern="*.hh"/>
-    <glob pattern="*.dic"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-csrc">
+    <alias type="text/x-c"/>
+    <_comment>C source code</_comment>
+    <glob pattern="*.c"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-csharp">
+    <_comment>C# source code</_comment>
+    <glob pattern="*.cs"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-cobol">
+    <_comment>COBOL source code</_comment>
+    <glob pattern="*.cbl"/>
+    <glob pattern="*.Cbl"/>
+    <glob pattern="*.CBL"/>
+    <glob pattern="*.cob"/>
+    <glob pattern="*.Cob"/>
+    <glob pattern="*.COB"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-coldfusion">
+    <_comment>ColdFusion source code</_comment>
+    <glob pattern="*.cfm"/>
+    <glob pattern="*.cfml"/>
+    <glob pattern="*.cfc"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-common-lisp">
+    <_comment>Common Lisp source code</_comment>
+    <glob pattern="*.cl"/>
+    <glob pattern="*.jl"/>
+    <glob pattern="*.lisp"/>
+    <glob pattern="*.lsp"/>
     <sub-class-of type="text/plain"/>
   </mime-type>
 
@@ -4405,39 +4628,296 @@
     </magic>
     <glob pattern="*.diff"/>
     <glob pattern="*.patch"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-eiffel">
+    <_comment>Eiffel source code</_comment>
+    <glob pattern="*.e"/>
+    <sub-class-of type="text/plain"/>
   </mime-type>
 
+  <mime-type type="text/x-emacs-lisp">
+    <_comment>Emacs Lisp source code</_comment>
+    <glob pattern="*.el"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-erlang">
+    <_comment>Erlang source code</_comment>
+    <glob pattern="*.erl"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-expect">
+    <_comment>Expect Script</_comment>
+    <glob pattern="*.exp"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-forth">
+    <_comment>Forth source code</_comment>
+    <glob pattern="*.4th"/>
+    <sub-class-of type="text/plain"/>
+   </mime-type>
+
   <mime-type type="text/x-fortran">
+    <_comment>Fortran source code</_comment>
     <glob pattern="*.f"/>
+    <glob pattern="*.F"/>
     <glob pattern="*.for"/>
     <glob pattern="*.f77"/>
     <glob pattern="*.f90"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-groovy">
+    <_comment>Groovy source code</_comment>
+    <glob pattern="*.groovy"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-haskell">
+    <_comment>Haskell source code</_comment>
+    <glob pattern="*.hs"/>
+    <glob pattern="*.lhs"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-idl">
+    <_comment>Inteface Definition Language</_comment>
+    <glob pattern="*.idl"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-java-source">
+    <_comment>Java source code</_comment>
+    <alias type="text/x-java" />
+    <glob pattern="*.java"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-jsp">
+    <_comment>Java Server Page</_comment>
+    <alias type="application/x-httpd-jsp"/>
+    <sub-class-of type="text/plain"/>
+    <magic priority="50">
+      <match value="&lt;%@" type="string" offset="0"/>
+      <match value="&lt;%--" type="string" offset="0"/>
+    </magic>
+    <glob pattern="*.jsp"/>
+  </mime-type>
+
+  <mime-type type="text/x-lex">
+    <_comment>Lex/Flex source code</_comment>
+    <glob pattern="*.l"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-log">
+    <_comment>application log</_comment>
+    <glob pattern="*.log"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-lua">
+    <_comment>Lua source code</_comment>
+    <glob pattern="*.lua"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-ml">
+    <_comment>ML source code</_comment>
+    <glob pattern="*.ml"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-matlab">
+    <_comment>Matlab source code</_comment>
+    <magic priority="50">
+      <match value="function [" type="string" offset="0"/>
+    </magic>
+    <!-- <glob pattern="*.m"/> - conflicts with text/x-objcsrc -->
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-modula">
+    <_comment>Modula source code</_comment>
+    <glob pattern="*.m3"/>
+    <glob pattern="*.i3"/>
+    <glob pattern="*.mg"/>
+    <glob pattern="*.ig"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-objcsrc">
+    <_comment>Objective-C source code</_comment>
+    <glob pattern="*.m"/>
+    <sub-class-of type="text/plain"/>
   </mime-type>
+
   <mime-type type="text/x-pascal">
+    <_comment>Pascal source code</_comment>
     <glob pattern="*.p"/>
+    <glob pattern="*.pp"/>
     <glob pattern="*.pas"/>
+    <glob pattern="*.PAS"/>
+    <glob pattern="*.dpr"/>
+    <sub-class-of type="text/plain"/>
   </mime-type>
 
-  <mime-type type="text/x-java-source">
-    <glob pattern="*.java"/>
+  <mime-type type="text/x-perl">
+    <_comment>Perl script</_comment>
+    <magic priority="50">
+      <match value="eval \&quot;exec /usr/local/bin/perl" type="string" offset="0"/>
+      <match value="#!/bin/perl" type="string" offset="0"/>
+      <match value="#!/bin/env perl" type="string" offset="0"/>
+      <match value="#!/usr/bin/perl" type="string" offset="0"/>
+      <match value="#!/usr/local/bin/perl" type="string" offset="0"/>
+    </magic>
+    <glob pattern="*.pl"/>
+    <glob pattern="*.pm"/>
+    <glob pattern="*.al"/>
+    <glob pattern="*.perl"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-php">
+    <_comment>PHP script</_comment>
+    <magic priority="50">
+      <match value="&lt;?php" type="string" offset="0"/>
+    </magic>
+    <glob pattern="*.php"/>
+    <glob pattern="*.php3"/>
+    <glob pattern="*.php4"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-prolog">
+    <_comment>Prolog source code</_comment>
+    <glob pattern="*.pro"/>
+    <!-- <glob pattern="*.pl"/> - conflicts with text/x-perl -->
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-python">
+    <_comment>Python script</_comment>
+    <magic priority="50">
+      <match value="#!/bin/python" type="string" offset="0"/>
+      <match value="#! /bin/python" type="string" offset="0"/>
+      <match value="eval &quot;exec /bin/python" type="string" offset="0"/>
+      <match value="#!/usr/bin/python" type="string" offset="0"/>
+      <match value="#! /usr/bin/python" type="string" offset="0"/>
+      <match value="eval &quot;exec /usr/bin/python" type="string" offset="0"/>
+      <match value="#!/usr/local/bin/python" type="string" offset="0"/>
+      <match value="#! /usr/local/bin/python" type="string" offset="0"/>
+      <match value="eval &quot;exec /usr/local/bin/python" type="string" offset="0"/>
+      <match value="/bin/env python" type="string" offset="1"/>
+    </magic>
+    <glob pattern="*.py"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-rexx">
+    <_comment>Rexx source code</_comment>
+    <glob pattern="*.rexx"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-ruby">
+    <_comment>Ruby source code</_comment>
+    <glob pattern="*.rb"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-scheme">
+    <_comment>Scheme source code</_comment>
+    <glob pattern="*.scm"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-sed">
+    <_comment>Sed code</_comment>
+    <glob pattern="*.sed"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-sql">
+    <_comment>SQL code</_comment>
+    <glob pattern="*.sql"/>
     <sub-class-of type="text/plain"/>
   </mime-type>
 
   <mime-type type="text/x-setext">
     <glob pattern="*.etx"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-tcl">
+    <alias type="application/x-tcl"/>
+    <_comment>Tcl script</_comment>
+    <glob pattern="*.itk"/>
+    <glob pattern="*.tcl"/>
+    <glob pattern="*.tk"/>
+    <sub-class-of type="text/plain"/>
   </mime-type>
 
   <mime-type type="text/x-uuencode">
     <glob pattern="*.uu"/>
   </mime-type>
+
+  <mime-type type="text/x-vbasic">
+    <_comment>Visual basic source code</_comment>
+    <glob pattern="*.cls"/>
+    <glob pattern="*.Cls"/>
+    <glob pattern="*.CLS"/>
+    <glob pattern="*.frm"/>
+    <glob pattern="*.Frm"/>
+    <glob pattern="*.FRM"/>
+    <sub-class-of type="text/x-basic"/>
+  </mime-type>
+
+  <mime-type type="text/x-vbdotnet">
+    <_comment>VB.NET source code</_comment>
+    <glob pattern="*.vb"/>
+    <sub-class-of type="text/x-vbasic"/>
+  </mime-type>
+
+  <mime-type type="text/x-vbscript">
+    <_comment>VBScript source code</_comment>
+    <glob pattern="*.vbs"/>
+    <sub-class-of type="text/x-vbasic"/>
+  </mime-type>
+
   <mime-type type="text/x-vcalendar">
     <glob pattern="*.vcs"/>
+    <sub-class-of type="text/plain"/>
   </mime-type>
+
   <mime-type type="text/x-vcard">
     <glob pattern="*.vcf"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-verilog">
+    <_comment>Verilog source code</_comment>
+    <glob pattern="*.v"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
+  <mime-type type="text/x-vhdl">
+    <_comment>VHDL source code</_comment>
+    <glob pattern="*.vhd"/>
+    <glob pattern="*.vhdl"/>
+    <sub-class-of type="text/plain"/>
   </mime-type>
-  <mime-type type="text/xml"/>
-  <mime-type type="text/xml-external-parsed-entity"/>
+
+  <mime-type type="text/x-yacc">
+    <_comment>Yacc/Bison source code</_comment>
+    <glob pattern="*.y"/>
+    <sub-class-of type="text/plain"/>
+  </mime-type>
+
   <mime-type type="video/3gpp">
     <magic priority="60">
       <match value="ftyp3ge6" type="string" offset="4"/>
@@ -4507,8 +4987,10 @@
   <mime-type type="video/mp4v-es"/>
 
   <mime-type type="video/mpeg">
+    <_comment>MPEG Movie Clip</_comment>
     <magic priority="50">
       <match value="\000\000\001\263" type="string" offset="0"/>
+      <match value="\000\000\001\272" type="string" offset="0"/>
     </magic>
     <glob pattern="*.mpeg"/>
     <glob pattern="*.mpg"/>
@@ -4650,11 +5132,13 @@
   </mime-type>
 
   <mime-type type="video/x-msvideo">
+    <_comment>Audio Video Interleave File</_comment>
     <alias type="video/avi"/>
     <alias type="video/msvideo"/>
     <magic priority="50">
       <match value="RIFF....AVI " type="string" offset="0"
              mask="0xFFFFFFFF00000000FFFFFFFF"/>
+      <match offset="8" type="string" value="\x41\x56\x49\x20"/>
     </magic>
     <glob pattern="*.avi"/>
   </mime-type>
diff --git a/tika-core/src/test/java/org/apache/tika/TikaDetectionTest.java b/tika-core/src/test/java/org/apache/tika/TikaDetectionTest.java
index dd319081a..bbc7ca392 100644
--- a/tika-core/src/test/java/org/apache/tika/TikaDetectionTest.java
+++ b/tika-core/src/test/java/org/apache/tika/TikaDetectionTest.java
@@ -105,7 +105,7 @@ public class TikaDetectionTest extends TestCase {
         assertEquals("application/pkix-pkipath", tika.detect("x.pkipath"));
         assertEquals("application/pkixcmp", tika.detect("x.pki"));
         assertEquals("application/pls+xml", tika.detect("x.pls"));
-        assertEquals("application/postscript", tika.detect("x.ai"));
+        assertEquals("application/illustrator", tika.detect("x.ai"));
         assertEquals("application/postscript", tika.detect("x.eps"));
         assertEquals("application/postscript", tika.detect("x.ps"));
         assertEquals("application/prs.cww", tika.detect("x.cww"));
@@ -303,7 +303,7 @@ public class TikaDetectionTest extends TestCase {
         assertEquals("application/vnd.lotus-freelance", tika.detect("x.pre"));
         assertEquals("application/vnd.lotus-notes", tika.detect("x.nsf"));
         assertEquals("application/vnd.lotus-organizer", tika.detect("x.org"));
-        assertEquals("application/vnd.lotus-screencam", tika.detect("x.scm"));
+        assertEquals("text/x-scheme", tika.detect("x.scm"));
         assertEquals("application/vnd.lotus-wordpro", tika.detect("x.lwp"));
         assertEquals("application/vnd.macports.portpkg", tika.detect("x.portpkg"));
         assertEquals("application/vnd.mcd", tika.detect("x.mcd"));
@@ -403,7 +403,7 @@ public class TikaDetectionTest extends TestCase {
         assertEquals("application/vnd.openxmlformats-officedocument.wordprocessingml.document", tika.detect("x.docx"));
         assertEquals("application/vnd.openxmlformats-officedocument.wordprocessingml.template", tika.detect("x.dotx"));
         assertEquals("application/vnd.osgi.dp", tika.detect("x.dp"));
-        assertEquals("application/vnd.palm", tika.detect("x.pdb"));
+        assertEquals("chemical/x-pdb", tika.detect("x.pdb"));
         assertEquals("application/vnd.palm", tika.detect("x.pqa"));
         assertEquals("application/vnd.palm", tika.detect("x.oprc"));
         assertEquals("application/vnd.pg.format", tika.detect("x.str"));
@@ -574,7 +574,7 @@ public class TikaDetectionTest extends TestCase {
         assertEquals("application/x-msbinder", tika.detect("x.obd"));
         assertEquals("application/x-mscardfile", tika.detect("x.crd"));
         assertEquals("application/x-msclip", tika.detect("x.clp"));
-        assertEquals("application/x-msdownload", tika.detect("x.exe"));
+        assertEquals("application/x-dosexec", tika.detect("x.exe"));
         assertEquals("application/x-msdownload", tika.detect("x.dll"));
         assertEquals("application/x-msdownload", tika.detect("x.com"));
         assertEquals("application/x-msdownload", tika.detect("x.bat"));
@@ -605,7 +605,7 @@ public class TikaDetectionTest extends TestCase {
         assertEquals("application/x-sv4cpio", tika.detect("x.sv4cpio"));
         assertEquals("application/x-sv4crc", tika.detect("x.sv4crc"));
         assertEquals("application/x-tar", tika.detect("x.tar"));
-        assertEquals("application/x-tcl", tika.detect("x.tcl"));
+        assertEquals("text/x-tcl", tika.detect("x.tcl"));
         assertEquals("application/x-tex", tika.detect("x.tex"));
         assertEquals("application/x-tex-tfm", tika.detect("x.tfm"));
         assertEquals("application/x-texinfo", tika.detect("x.texinfo"));
@@ -744,7 +744,7 @@ public class TikaDetectionTest extends TestCase {
         assertEquals("text/plain", tika.detect("x.conf"));
         assertEquals("text/plain", tika.detect("x.def"));
         assertEquals("text/plain", tika.detect("x.list"));
-        assertEquals("text/plain", tika.detect("x.log"));
+        assertEquals("text/x-log", tika.detect("x.log"));
         assertEquals("text/plain", tika.detect("x.in"));
         assertEquals("text/prs.lines.tag", tika.detect("x.dsc"));
         assertEquals("text/richtext", tika.detect("x.rtx"));
@@ -772,15 +772,14 @@ public class TikaDetectionTest extends TestCase {
         assertEquals("text/vnd.sun.j2me.app-descriptor", tika.detect("x.jad"));
         assertEquals("text/vnd.wap.wml", tika.detect("x.wml"));
         assertEquals("text/vnd.wap.wmlscript", tika.detect("x.wmls"));
-        assertEquals("text/x-asm", tika.detect("x.s"));
-        assertEquals("text/x-asm", tika.detect("x.asm"));
-        assertEquals("text/x-c", tika.detect("x.c"));
-        assertEquals("text/x-c", tika.detect("x.cc"));
-        assertEquals("text/x-c", tika.detect("x.cxx"));
-        assertEquals("text/x-c", tika.detect("x.cpp"));
-        assertEquals("text/x-c", tika.detect("x.h"));
-        assertEquals("text/x-c", tika.detect("x.hh"));
-        assertEquals("text/x-c", tika.detect("x.dic"));
+        assertEquals("text/x-assembly", tika.detect("x.s"));
+        assertEquals("text/x-assembly", tika.detect("x.asm"));
+        assertEquals("text/x-csrc", tika.detect("x.c"));
+        assertEquals("text/x-c++src", tika.detect("x.cc"));
+        assertEquals("text/x-c++src", tika.detect("x.cxx"));
+        assertEquals("text/x-c++src", tika.detect("x.cpp"));
+        assertEquals("text/x-chdr", tika.detect("x.h"));
+        assertEquals("text/x-c++hdr", tika.detect("x.hh"));
         assertEquals("text/x-fortran", tika.detect("x.f"));
         assertEquals("text/x-fortran", tika.detect("x.for"));
         assertEquals("text/x-fortran", tika.detect("x.f77"));

Commit:
b8beefd21e5b33dd824baca096080668e7cff27a
Jukka Zitting
jukka@apache.org
2012-07-08 12:04:17 +0000
TIKA-471: Avoid Charset name bottleneck when multiple threads are using HtmlParser
diff --git a/tika-core/src/main/java/org/apache/tika/utils/CharsetUtils.java b/tika-core/src/main/java/org/apache/tika/utils/CharsetUtils.java
index 5367b1fc9..9cada3cbd 100644
--- a/tika-core/src/main/java/org/apache/tika/utils/CharsetUtils.java
+++ b/tika-core/src/main/java/org/apache/tika/utils/CharsetUtils.java
@@ -16,6 +16,8 @@
  */
 package org.apache.tika.utils;
 
+import static java.util.Locale.ENGLISH;
+
 import java.lang.reflect.Method;
 import java.nio.charset.Charset;
 import java.nio.charset.IllegalCharsetNameException;
@@ -26,19 +28,85 @@ import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 
 public class CharsetUtils {
-    private static final Pattern CHARSET_NAME_PATTERN = Pattern.compile("[ \\\"]*([^ >,;\\\"]+).*");
-    private static final Pattern ISO_NAME_PATTERN = Pattern.compile("(?i).*8859-([\\d]+)");
-    private static final Pattern CP_NAME_PATTERN = Pattern.compile("(?i)cp-([\\d]+)");
-    private static final Pattern WIN_NAME_PATTERN = Pattern.compile("(?i)win(|-)([\\d]+)");
-    
-    // List of common invalid charset names that we can't fix using
-    // pattern matching + heuristic
-    private static final Map<String, String> CHARSET_ALIASES =
-            new HashMap<String, String>();
-
-    private static final Map<String, Charset> STANDARD_CHARSETS =
+
+    private static final Pattern CHARSET_NAME_PATTERN =
+            Pattern.compile("[ \\\"]*([^ >,;\\\"]+).*");
+
+    private static final Pattern ISO_NAME_PATTERN =
+            Pattern.compile(".*8859-(\\d+)");
+
+    private static final Pattern CP_NAME_PATTERN =
+            Pattern.compile("cp-(\\d+)");
+
+    private static final Pattern WIN_NAME_PATTERN =
+            Pattern.compile("win-?(\\d+)");
+
+    private static final Map<String, Charset> COMMON_CHARSETS =
             new HashMap<String, Charset>();
 
+    private static Method getCharsetICU = null;
+    private static Method isSupportedICU = null;
+
+    private static Map<String, Charset> initCommonCharsets(String... names) {
+        Map<String, Charset> charsets = new HashMap<String, Charset>();
+        for (String name : names) {
+            try {
+                Charset charset = Charset.forName(name);
+                COMMON_CHARSETS.put(name.toLowerCase(ENGLISH), charset);
+                for (String alias : charset.aliases()) {
+                    COMMON_CHARSETS.put(alias.toLowerCase(ENGLISH), charset);
+                }
+            } catch (Exception e) {
+                System.out.println(name);
+                // ignore
+            }
+        }
+        return charsets;
+    }
+
+    static {
+        initCommonCharsets(
+                "Big5",
+                "EUC-JP", "EUC-KR", "x-EUC-TW",
+                "GB18030",
+                "IBM855", "IBM866",
+                "ISO-2022-CN", "ISO-2022-JP", "ISO-2022-KR",
+                "ISO-8859-1", "ISO-8859-2", "ISO-8859-3", "ISO-8859-4",
+                "ISO-8859-5", "ISO-8859-6", "ISO-8859-7", "ISO-8859-8",
+                "ISO-8859-9", "ISO-8859-11", "ISO-8859-13", "ISO-8859-15",
+                "KOI8-R",
+                "x-MacCyrillic",
+                "SHIFT_JIS",
+                "UTF-8", "UTF-16BE", "UTF-16LE",
+                "windows-1251", "windows-1252", "windows-1253", "windows-1255");
+
+        // Common aliases/typos not included in standard charset definitions
+        COMMON_CHARSETS.put("iso-8851-1", COMMON_CHARSETS.get("iso-8859-1"));
+        COMMON_CHARSETS.put("windows", COMMON_CHARSETS.get("windows-1252"));
+        COMMON_CHARSETS.put("koi8r", COMMON_CHARSETS.get("koi8-r"));
+
+        // See if we can load the icu4j CharsetICU class
+        Class<?> icuCharset = null;
+        try  {
+            icuCharset = CharsetUtils.class.getClassLoader().loadClass(
+                    "com.ibm.icu.charset.CharsetICU");
+        }  catch (ClassNotFoundException e) {
+        }
+        if (icuCharset != null) {
+            try {
+                getCharsetICU = icuCharset.getMethod("forNameICU", String.class);
+            } catch (Throwable t) {
+                throw new RuntimeException(t);
+            }
+            try {
+                isSupportedICU = icuCharset.getMethod("isSupported", String.class);
+            } catch (Throwable t) {
+            }
+            // TODO: would be nice to somehow log that we
+            // successfully found ICU
+        }
+    }
+
     /**
      * Safely return whether <charsetName> is supported, without throwing exceptions
      * 
@@ -61,7 +129,7 @@ public class CharsetUtils {
             return false;
         }
     }
-    
+
     /**
      * Handle various common charset name errors, and return something
      * that will be considered valid (and is normalized)
@@ -77,44 +145,6 @@ public class CharsetUtils {
         }
     }
 
-    private static Method getCharsetICU;
-    private static Method isSupportedICU;
-
-    static {
-        CHARSET_ALIASES.put("none", null);
-        CHARSET_ALIASES.put("no", null);
-        CHARSET_ALIASES.put("iso-8851-1", "iso-8859-1");
-        CHARSET_ALIASES.put("windows", "windows-1252");
-        CHARSET_ALIASES.put("koi8r", "KOI8-R");
-
-        STANDARD_CHARSETS.put("US-ASCII", Charset.forName("US-ASCII"));
-        STANDARD_CHARSETS.put("ISO-8859-1", Charset.forName("ISO-8859-1"));
-        STANDARD_CHARSETS.put("UTF-8", Charset.forName("UTF-8"));
-        STANDARD_CHARSETS.put("UTF-16BE", Charset.forName("UTF-16BE"));
-        STANDARD_CHARSETS.put("UTF-16LE", Charset.forName("UTF-16LE"));
-        STANDARD_CHARSETS.put("UTF-16", Charset.forName("UTF-16"));
-
-        // See if we can load the icu4j CharsetICU class
-        Class<?> icuCharset = null;
-        try  {
-            icuCharset = CharsetUtils.class.getClassLoader().loadClass("com.ibm.icu.charset.CharsetICU");
-        }  catch (ClassNotFoundException e) {
-        }
-        if (icuCharset != null) {
-            try {
-                getCharsetICU = icuCharset.getMethod("forNameICU", String.class);
-            } catch (Throwable t) {
-                throw new RuntimeException(t);
-            }
-            try {
-                isSupportedICU = icuCharset.getMethod("isSupported", String.class);
-            } catch (Throwable t) {
-            }
-            // TODO: would be nice to somehow log that we
-            // successfully found ICU
-        }
-    }
-
     /** Returns Charset impl, if one exists.  This method
      *  optionally uses ICU4J's CharsetICU.forNameICU,
      *  if it is found on the classpath, else only uses
@@ -127,40 +157,41 @@ public class CharsetUtils {
         // Get rid of cruft around names, like <>, trailing commas, etc.
         Matcher m = CHARSET_NAME_PATTERN.matcher(name);
         if (!m.matches()) {
-            throw new IllegalArgumentException(name);
+            throw new IllegalCharsetNameException(name);
         }
+        name = m.group(1);
 
-        String result = m.group(1);
-        String alias = CHARSET_ALIASES.get(result.toLowerCase());
-        if (alias != null) {
-            // Handle common erroneous charset names.
-            result = alias;
-        } else if (ISO_NAME_PATTERN.matcher(result).matches()) {
-            // Handle "iso 8859-x" error
-            m = ISO_NAME_PATTERN.matcher(result);
-            m.matches();
-            result = "iso-8859-" + m.group(1);
-        } else if (CP_NAME_PATTERN.matcher(result).matches()) {
-            // Handle "cp-xxx" error
-            m = CP_NAME_PATTERN.matcher(result);
-            m.matches();
-            result = "cp" + m.group(1);
-        } else if (WIN_NAME_PATTERN.matcher(result).matches()) {
-            // Handle "winxxx" and "win-xxx" errors
-            m = WIN_NAME_PATTERN.matcher(result);
-            m.matches();
-            result = "windows-" + m.group(2);
-        }
-
-        Charset charset =
-                STANDARD_CHARSETS.get(result.toUpperCase(Locale.ENGLISH));
+        String lower = name.toLowerCase(Locale.ENGLISH);
+        Charset charset = COMMON_CHARSETS.get(lower);
         if (charset != null) {
             return charset;
+        } else if ("none".equals(lower) || "no".equals(lower)) {
+            throw new IllegalCharsetNameException(name);
+        } else {
+            Matcher iso = ISO_NAME_PATTERN.matcher(lower);
+            Matcher cp = CP_NAME_PATTERN.matcher(lower);
+            Matcher win = WIN_NAME_PATTERN.matcher(lower);
+            if (iso.matches()) {
+                // Handle "iso 8859-x" error
+                name = "iso-8859-" + iso.group(1);
+                charset = COMMON_CHARSETS.get(name);
+            } else if (cp.matches()) {
+                // Handle "cp-xxx" error
+                name = "cp" + cp.group(1);
+                charset = COMMON_CHARSETS.get(name);
+            } else if (win.matches()) {
+                // Handle "winxxx" and "win-xxx" errors
+                name = "windows-" + win.group(1);
+                charset = COMMON_CHARSETS.get(name);
+            }
+            if (charset != null) {
+                return charset;
+            }
         }
 
         if (getCharsetICU != null) {
             try {
-                Charset cs = (Charset) getCharsetICU.invoke(null, result);
+                Charset cs = (Charset) getCharsetICU.invoke(null, name);
                 if (cs != null) {
                     return cs;
                 }
@@ -169,6 +200,6 @@ public class CharsetUtils {
             }
         }
 
-        return Charset.forName(result);
+        return Charset.forName(name);
     }
 }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/txt/UniversalEncodingListener.java b/tika-parsers/src/main/java/org/apache/tika/parser/txt/UniversalEncodingListener.java
index fdc601a12..826febc40 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/txt/UniversalEncodingListener.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/txt/UniversalEncodingListener.java
@@ -17,8 +17,6 @@
 package org.apache.tika.parser.txt;
 
 import java.nio.charset.Charset;
-import java.util.HashMap;
-import java.util.Map;
 
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.mime.MediaType;
@@ -35,64 +33,6 @@ class UniversalEncodingListener implements CharsetListener {
 
     private static final String CHARSET_ISO_8859_1 = "ISO-8859-1";
 
-    private static final String CHARSET_ISO_8859_15 = "ISO-8859-15";
-
-    private static Map<String, Charset> makeCC(String... names) {
-        Map<String, Charset> charsets = new HashMap<String, Charset>();
-        for (String name : names) {
-            try {
-                charsets.put(name, Charset.forName(name));
-            } catch (Exception e) {
-                // ignore
-            }
-        }
-        return charsets;
-    }
-
-    private static final Map<String, Charset> CONSTANT_CHARSETS = makeCC(
-            Constants.CHARSET_BIG5,
-            Constants.CHARSET_EUC_JP,
-            Constants.CHARSET_EUC_KR,
-            Constants.CHARSET_EUC_TW,
-            Constants.CHARSET_GB18030,
-            Constants.CHARSET_HZ_GB_2312, // not supported?
-            Constants.CHARSET_IBM855,
-            Constants.CHARSET_IBM866,
-            Constants.CHARSET_ISO_2022_CN,
-            Constants.CHARSET_ISO_2022_JP,
-            Constants.CHARSET_ISO_2022_KR,
-            CHARSET_ISO_8859_1,
-            Constants.CHARSET_ISO_8859_5,
-            Constants.CHARSET_ISO_8859_7,
-            Constants.CHARSET_ISO_8859_8,
-            CHARSET_ISO_8859_15,
-            Constants.CHARSET_KOI8_R,
-            Constants.CHARSET_MACCYRILLIC,
-            Constants.CHARSET_SHIFT_JIS,
-            Constants.CHARSET_UTF_16BE,
-            Constants.CHARSET_UTF_16LE,
-            Constants.CHARSET_UTF_32BE, // not supported?
-            Constants.CHARSET_UTF_32LE, // not supported?
-            Constants.CHARSET_UTF_8,
-            Constants.CHARSET_WINDOWS_1251,
-            Constants.CHARSET_WINDOWS_1252,
-            Constants.CHARSET_WINDOWS_1253,
-            Constants.CHARSET_WINDOWS_1255,
-            Constants.CHARSET_X_ISO_10646_UCS_4_2143, // not supported?
-            Constants.CHARSET_X_ISO_10646_UCS_4_3412); // not supported?
-
-    private static Charset getCharset(String name) {
-        Charset charset = CONSTANT_CHARSETS.get(name);
-        if (charset == null) {
-            try {
-                charset = CharsetUtils.forName(name);
-            } catch (Exception e) {
-                // ignore
-            }
-        }
-        return charset;
-    }
-
     private final UniversalDetector detector = new UniversalDetector(this);
 
     private String hint = null;
@@ -121,7 +61,11 @@ class UniversalEncodingListener implements CharsetListener {
                 name = CHARSET_ISO_8859_1;
             }
         }
-        this.charset = getCharset(name);
+        try {
+            this.charset = CharsetUtils.forName(name);
+        } catch (Exception e) {
+            // ignore
+        }
     }
 
     public boolean isDone() {

Commit:
89941a2ba1e4b13c3de9c5cf050e4dbf1edafca3
Jukka Zitting
jukka@apache.org
2012-07-08 11:04:47 +0000
TIKA-471: Avoid Charset name bottleneck when multiple threads are using HtmlParser
diff --git a/CHANGES.txt b/CHANGES.txt
index aa166f166..630833746 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -37,6 +37,12 @@ Release 1.2 - Current Development
     --password=X command line option to specify the password that Tika CLI
     should use for opening encrypted documents (TIKA-943).
 
+  * Character encodings: Tika's character encoding detection mechanism was
+    improved by adding integration to the juniversalchardet library that
+    implements Mozilla's universal charset detection algorithm. The slower
+    ICU4J algorithms are still used as a fallback thanks to their wider
+    coverage of custom character encodings. (TIKA-322, TIKA-471)
+
 Release 1.1 - 3/7/2012
 ---------------------------------
 
diff --git a/tika-core/src/main/java/org/apache/tika/detect/AutoDetectReader.java b/tika-core/src/main/java/org/apache/tika/detect/AutoDetectReader.java
index ff20551c1..2b4561b5e 100644
--- a/tika-core/src/main/java/org/apache/tika/detect/AutoDetectReader.java
+++ b/tika-core/src/main/java/org/apache/tika/detect/AutoDetectReader.java
@@ -61,7 +61,7 @@ public class AutoDetectReader extends BufferedReader {
             if (charset != null) {
                 try {
                     return CharsetUtils.forName(charset);
-                } catch (IllegalArgumentException e) {
+                } catch (Exception e) {
                     // ignore
                 }
             }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlEncodingDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlEncodingDetector.java
index 9200a936e..80ddab9dc 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlEncodingDetector.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlEncodingDetector.java
@@ -75,7 +75,11 @@ public class HtmlEncodingDetector implements EncodingDetector {
             if (type != null) {
                 String charset = type.getParameters().get("charset");
                 if (charset != null) {
-                    return CharsetUtils.forName(charset);
+                    try {
+                        return CharsetUtils.forName(charset);
+                    } catch (Exception e) {
+                        // ignore
+                    }
                 }
             }
         }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/txt/Icu4jEncodingDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/txt/Icu4jEncodingDetector.java
index 92ca4431d..7e28d8e94 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/txt/Icu4jEncodingDetector.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/txt/Icu4jEncodingDetector.java
@@ -58,7 +58,7 @@ public class Icu4jEncodingDetector implements EncodingDetector {
         for (CharsetMatch match : detector.detectAll()) {
             try {
                 return CharsetUtils.forName(match.getName());
-            } catch (IllegalArgumentException e) {
+            } catch (Exception e) {
                 // ignore
             }
         }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/txt/TXTParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/txt/TXTParser.java
index 83daaeca8..c540e7db6 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/txt/TXTParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/txt/TXTParser.java
@@ -29,7 +29,6 @@ import org.apache.tika.metadata.Metadata;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.parser.AbstractParser;
 import org.apache.tika.parser.ParseContext;
-import org.apache.tika.parser.html.HtmlParser;
 import org.apache.tika.sax.XHTMLContentHandler;
 import org.xml.sax.ContentHandler;
 import org.xml.sax.SAXException;

Commit:
12a974733aa3cbeb82194bfcf843e6d831477d9b
Jukka Zitting
jukka@apache.org
2012-07-08 10:51:13 +0000
TIKA-471: Avoid Charset name bottleneck when multiple threads are using HtmlParser
diff --git a/tika-core/src/main/java/org/apache/tika/utils/CharsetUtils.java b/tika-core/src/main/java/org/apache/tika/utils/CharsetUtils.java
index 1088bcb22..5367b1fc9 100644
--- a/tika-core/src/main/java/org/apache/tika/utils/CharsetUtils.java
+++ b/tika-core/src/main/java/org/apache/tika/utils/CharsetUtils.java
@@ -16,7 +16,6 @@
  */
 package org.apache.tika.utils;
 
-import java.lang.reflect.InvocationTargetException;
 import java.lang.reflect.Method;
 import java.nio.charset.Charset;
 import java.nio.charset.IllegalCharsetNameException;
@@ -71,40 +70,8 @@ public class CharsetUtils {
      * @return potentially remapped/cleaned up version of charset name
      */
     public static String clean(String charsetName) {
-        if (charsetName == null) {
-            return null;
-        }
-        
-        // Get rid of cruft around names, like <>, trailing commas, etc.
-        Matcher m = CHARSET_NAME_PATTERN.matcher(charsetName);
-        if (!m.matches()) {
-            return null;
-        }
-
-        String result = m.group(1);
-        if (CHARSET_ALIASES.containsKey(result.toLowerCase())) {
-            // Handle common erroneous charset names.
-            result = CHARSET_ALIASES.get(result.toLowerCase());
-        } else if (ISO_NAME_PATTERN.matcher(result).matches()) {
-            // Handle "iso 8859-x" error
-            m = ISO_NAME_PATTERN.matcher(result);
-            m.matches();
-            result = "iso-8859-" + m.group(1);
-        } else if (CP_NAME_PATTERN.matcher(result).matches()) {
-            // Handle "cp-xxx" error
-            m = CP_NAME_PATTERN.matcher(result);
-            m.matches();
-            result = "cp" + m.group(1);
-        } else if (WIN_NAME_PATTERN.matcher(result).matches()) {
-            // Handle "winxxx" and "win-xxx" errors
-            m = WIN_NAME_PATTERN.matcher(result);
-            m.matches();
-            result = "windows-" + m.group(2);
-        }
-        
         try {
-            Charset cs = forName(result);
-            return cs.name();
+            return forName(charsetName).name();
         } catch (Exception e) {
             return null;
         }
@@ -153,23 +120,55 @@ public class CharsetUtils {
      *  if it is found on the classpath, else only uses
      *  JDK's builtin Charset.forName. */
     public static Charset forName(String name) {
+        if (name == null) {
+            throw new IllegalArgumentException();
+        }
+
+        // Get rid of cruft around names, like <>, trailing commas, etc.
+        Matcher m = CHARSET_NAME_PATTERN.matcher(name);
+        if (!m.matches()) {
+            throw new IllegalArgumentException(name);
+        }
+
+        String result = m.group(1);
+        String alias = CHARSET_ALIASES.get(result.toLowerCase());
+        if (alias != null) {
+            // Handle common erroneous charset names.
+            result = alias;
+        } else if (ISO_NAME_PATTERN.matcher(result).matches()) {
+            // Handle "iso 8859-x" error
+            m = ISO_NAME_PATTERN.matcher(result);
+            m.matches();
+            result = "iso-8859-" + m.group(1);
+        } else if (CP_NAME_PATTERN.matcher(result).matches()) {
+            // Handle "cp-xxx" error
+            m = CP_NAME_PATTERN.matcher(result);
+            m.matches();
+            result = "cp" + m.group(1);
+        } else if (WIN_NAME_PATTERN.matcher(result).matches()) {
+            // Handle "winxxx" and "win-xxx" errors
+            m = WIN_NAME_PATTERN.matcher(result);
+            m.matches();
+            result = "windows-" + m.group(2);
+        }
+
         Charset charset =
-                STANDARD_CHARSETS.get(name.toUpperCase(Locale.ENGLISH));
+                STANDARD_CHARSETS.get(result.toUpperCase(Locale.ENGLISH));
         if (charset != null) {
             return charset;
         }
 
         if (getCharsetICU != null) {
             try {
-                Charset cs = (Charset) getCharsetICU.invoke(null, name);
+                Charset cs = (Charset) getCharsetICU.invoke(null, result);
                 if (cs != null) {
                     return cs;
                 }
-            } catch (InvocationTargetException ite) {
-            } catch (IllegalAccessException iae) {
+            } catch (Exception e) {
+                // ignore
             }
         }
 
-        return Charset.forName(name);
+        return Charset.forName(result);
     }
 }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlEncodingDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlEncodingDetector.java
index 3727f7c7e..9200a936e 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlEncodingDetector.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlEncodingDetector.java
@@ -75,7 +75,6 @@ public class HtmlEncodingDetector implements EncodingDetector {
             if (type != null) {
                 String charset = type.getParameters().get("charset");
                 if (charset != null) {
-                    charset = CharsetUtils.clean(charset);
                     return CharsetUtils.forName(charset);
                 }
             }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/rtf/GroupState.java b/tika-parsers/src/main/java/org/apache/tika/parser/rtf/GroupState.java
index 99e20f12a..f0290fe6a 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/rtf/GroupState.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/rtf/GroupState.java
@@ -16,6 +16,8 @@
  */
 package org.apache.tika.parser.rtf;
 
+import java.nio.charset.Charset;
+
 /* Holds all state associated with current RTF group, ie {
  * ... }. */
 
@@ -28,7 +30,7 @@ class GroupState {
     public boolean ignore;
     // Default is 1 if no uc control has been seen yet:
     public int ucSkip = 1;
-    public String fontCharset;
+    public Charset fontCharset;
 
     // Create default (root) GroupState
     public GroupState() {
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/rtf/TextExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/rtf/TextExtractor.java
index 7aab4b803..d04567ade 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/rtf/TextExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/rtf/TextExtractor.java
@@ -22,6 +22,7 @@ import java.io.InputStream;
 import java.io.PushbackInputStream;
 import java.nio.ByteBuffer;
 import java.nio.CharBuffer;
+import java.nio.charset.Charset;
 import java.nio.charset.CharsetDecoder;
 import java.nio.charset.CoderResult;
 import java.nio.charset.CodingErrorAction;
@@ -49,6 +50,85 @@ import org.xml.sax.SAXException;
 
 final class TextExtractor {
 
+    private static final Charset ASCII = Charset.forName("US-ASCII");
+
+    private static Charset getCharset(String name) {
+        try {
+            return CharsetUtils.forName(name);
+        } catch (Exception e) {
+            return ASCII;
+        }
+    }
+
+    private static final Charset WINDOWS_1252 = getCharset("WINDOWS-1252");
+    private static final Charset MAC_ROMAN = getCharset("MacRoman");
+    private static final Charset SHIFT_JIS = getCharset("Shift_JIS");
+    private static final Charset WINDOWS_57011 = getCharset("windows-57011");
+    private static final Charset WINDOWS_57010 = getCharset("windows-57010");
+    private static final Charset WINDOWS_57009 = getCharset("windows-57009");
+    private static final Charset WINDOWS_57008 = getCharset("windows-57008");
+    private static final Charset WINDOWS_57007 = getCharset("windows-57007");
+    private static final Charset WINDOWS_57006 = getCharset("windows-57006");
+    private static final Charset WINDOWS_57005 = getCharset("windows-57005");
+    private static final Charset WINDOWS_57004 = getCharset("windows-57004");
+    private static final Charset WINDOWS_57003 = getCharset("windows-57003");
+    private static final Charset X_ISCII91 = getCharset("x-ISCII91");
+    private static final Charset X_MAC_CENTRAL_EUROPE = getCharset("x-MacCentralEurope");
+    private static final Charset MAC_CYRILLIC = getCharset("MacCyrillic");
+    private static final Charset X_JOHAB = getCharset("x-Johab");
+    private static final Charset CP12582 = getCharset("CP1258");
+    private static final Charset CP12572 = getCharset("CP1257");
+    private static final Charset CP12562 = getCharset("CP1256");
+    private static final Charset CP12552 = getCharset("CP1255");
+    private static final Charset CP12542 = getCharset("CP1254");
+    private static final Charset CP12532 = getCharset("CP1253");
+    private static final Charset CP1252 = getCharset("CP1252");
+    private static final Charset CP12512 = getCharset("CP1251");
+    private static final Charset CP12502 = getCharset("CP1250");
+    private static final Charset CP950 = getCharset("CP950");
+    private static final Charset CP949 = getCharset("CP949");
+    private static final Charset MS9362 = getCharset("MS936");
+    private static final Charset MS8742 = getCharset("MS874");
+    private static final Charset CP866 = getCharset("CP866");
+    private static final Charset CP865 = getCharset("CP865");
+    private static final Charset CP864 = getCharset("CP864");
+    private static final Charset CP863 = getCharset("CP863");
+    private static final Charset CP862 = getCharset("CP862");
+    private static final Charset CP860 = getCharset("CP860");
+    private static final Charset CP852 = getCharset("CP852");
+    private static final Charset CP8502 = getCharset("CP850");
+    private static final Charset CP819 = getCharset("CP819");
+    private static final Charset WINDOWS_720 = getCharset("windows-720");
+    private static final Charset WINDOWS_711 = getCharset("windows-711");
+    private static final Charset WINDOWS_710 = getCharset("windows-710");
+    private static final Charset WINDOWS_709 = getCharset("windows-709");
+    private static final Charset ISO_8859_6 = getCharset("ISO-8859-6");
+    private static final Charset CP4372 = getCharset("CP437");
+    private static final Charset CP850 = getCharset("cp850");
+    private static final Charset CP437 = getCharset("cp437");
+    private static final Charset MS874 = getCharset("ms874");
+    private static final Charset CP1257 = getCharset("cp1257");
+    private static final Charset CP1256 = getCharset("cp1256");
+    private static final Charset CP1255 = getCharset("cp1255");
+    private static final Charset CP1258 = getCharset("cp1258");
+    private static final Charset CP1254 = getCharset("cp1254");
+    private static final Charset CP1253 = getCharset("cp1253");
+    private static final Charset MS950 = getCharset("ms950");
+    private static final Charset MS936 = getCharset("ms936");
+    private static final Charset MS1361 = getCharset("ms1361");
+    private static final Charset MS932 = getCharset("MS932");
+    private static final Charset CP1251 = getCharset("cp1251");
+    private static final Charset CP1250 = getCharset("cp1250");
+    private static final Charset MAC_THAI = getCharset("MacThai");
+    private static final Charset MAC_TURKISH = getCharset("MacTurkish");
+    private static final Charset MAC_GREEK = getCharset("MacGreek");
+    private static final Charset MAC_ARABIC = getCharset("MacArabic");
+    private static final Charset MAC_HEBREW = getCharset("MacHebrew");
+    private static final Charset JOHAB = getCharset("johab");
+    private static final Charset BIG5 = getCharset("Big5");
+    private static final Charset GB2312 = getCharset("GB2312");
+    private static final Charset MS949 = getCharset("ms949");
+
     // Hold pending bytes (encoded in the current charset)
     // for text output:
     private byte[] pendingBytes = new byte[16];
@@ -69,16 +149,17 @@ final class TextExtractor {
 
     // Reused when possible:
     private CharsetDecoder decoder;
-    private String lastCharset;
+    private Charset lastCharset;
 
-    private String globalCharset = "windows-1252";
+    private Charset globalCharset = WINDOWS_1252;
     private int globalDefaultFont = -1;
     private int curFontID = -1;
 
     // Holds the font table from this RTF doc, mapping
     // the font number (from \fN control word) to the
     // corresponding charset:
-    private final Map<Integer,String> fontToCharset = new HashMap<Integer,String>();
+    private final Map<Integer, Charset> fontToCharset =
+            new HashMap<Integer, Charset>();
 
     // Group stack: when we open a new group, we push
     // the previous group state onto the stack; when we
@@ -125,110 +206,112 @@ final class TextExtractor {
     // (f0, f1, f2, etc.) to fonts and charsets, using the
     // \fcharsetN control word.  This mapping maps from the
     // N to corresponding Java charset:
-    private static final Map<Integer, String> FCHARSET_MAP = new HashMap<Integer, String>();
+    private static final Map<Integer, Charset> FCHARSET_MAP =
+            new HashMap<Integer, Charset>();
+
     static {
-        FCHARSET_MAP.put(0, "windows-1252"); // ANSI
+        FCHARSET_MAP.put(0, WINDOWS_1252); // ANSI
         // charset 1 is Default
         // charset 2 is Symbol
 
-        FCHARSET_MAP.put(77, "MacRoman"); // Mac Roman
-        FCHARSET_MAP.put(78, "Shift_JIS"); // Mac Shift Jis
-        FCHARSET_MAP.put(79, "ms949"); // Mac Hangul
-        FCHARSET_MAP.put(80, "GB2312"); // Mac GB2312
-        FCHARSET_MAP.put(81, "Big5"); // Mac Big5
-        FCHARSET_MAP.put(82, "johab"); // Mac Johab (old)
-        FCHARSET_MAP.put(83, "MacHebrew"); // Mac Hebrew
-        FCHARSET_MAP.put(84, "MacArabic"); // Mac Arabic
-        FCHARSET_MAP.put(85, "MacGreek"); // Mac Greek
-        FCHARSET_MAP.put(86, "MacTurkish"); // Mac Turkish
-        FCHARSET_MAP.put(87, "MacThai"); // Mac Thai
-        FCHARSET_MAP.put(88, "cp1250"); // Mac East Europe
-        FCHARSET_MAP.put(89, "cp1251"); // Mac Russian
-
-        FCHARSET_MAP.put(128, "MS932"); // Shift JIS
-        FCHARSET_MAP.put(129, "ms949"); // Hangul
-        FCHARSET_MAP.put(130, "ms1361"); // Johab
-        FCHARSET_MAP.put(134, "ms936"); // GB2312
-        FCHARSET_MAP.put(136, "ms950"); // Big5
-        FCHARSET_MAP.put(161, "cp1253"); // Greek
-        FCHARSET_MAP.put(162, "cp1254"); // Turkish
-        FCHARSET_MAP.put(163, "cp1258"); // Vietnamese
-        FCHARSET_MAP.put(177, "cp1255"); // Hebrew
-        FCHARSET_MAP.put(178, "cp1256"); // Arabic
+        FCHARSET_MAP.put(77, MAC_ROMAN); // Mac Roman
+        FCHARSET_MAP.put(78, SHIFT_JIS); // Mac Shift Jis
+        FCHARSET_MAP.put(79, MS949); // Mac Hangul
+        FCHARSET_MAP.put(80, GB2312); // Mac GB2312
+        FCHARSET_MAP.put(81, BIG5); // Mac Big5
+        FCHARSET_MAP.put(82, JOHAB); // Mac Johab (old)
+        FCHARSET_MAP.put(83, MAC_HEBREW); // Mac Hebrew
+        FCHARSET_MAP.put(84, MAC_ARABIC); // Mac Arabic
+        FCHARSET_MAP.put(85, MAC_GREEK); // Mac Greek
+        FCHARSET_MAP.put(86, MAC_TURKISH); // Mac Turkish
+        FCHARSET_MAP.put(87, MAC_THAI); // Mac Thai
+        FCHARSET_MAP.put(88, CP1250); // Mac East Europe
+        FCHARSET_MAP.put(89, CP1251); // Mac Russian
+
+        FCHARSET_MAP.put(128, MS932); // Shift JIS
+        FCHARSET_MAP.put(129, MS949); // Hangul
+        FCHARSET_MAP.put(130, MS1361); // Johab
+        FCHARSET_MAP.put(134, MS936); // GB2312
+        FCHARSET_MAP.put(136, MS950); // Big5
+        FCHARSET_MAP.put(161, CP1253); // Greek
+        FCHARSET_MAP.put(162, CP1254); // Turkish
+        FCHARSET_MAP.put(163, CP1258); // Vietnamese
+        FCHARSET_MAP.put(177, CP1255); // Hebrew
+        FCHARSET_MAP.put(178, CP1256); // Arabic
         // FCHARSET_MAP.put( 179, "" ); // Arabic Traditional
         // FCHARSET_MAP.put( 180, "" ); // Arabic user
         // FCHARSET_MAP.put( 181, "" ); // Hebrew user
-        FCHARSET_MAP.put(186, "cp1257"); // Baltic
+        FCHARSET_MAP.put(186, CP1257); // Baltic
 
-        FCHARSET_MAP.put(204, "cp1251"); // Russian
-        FCHARSET_MAP.put(222, "ms874"); // Thai
-        FCHARSET_MAP.put(238, "cp1250"); // Eastern European
-        FCHARSET_MAP.put(254, "cp437"); // PC 437
-        FCHARSET_MAP.put(255, "cp850"); // OEM
+        FCHARSET_MAP.put(204, CP1251); // Russian
+        FCHARSET_MAP.put(222, MS874); // Thai
+        FCHARSET_MAP.put(238, CP1250); // Eastern European
+        FCHARSET_MAP.put(254, CP437); // PC 437
+        FCHARSET_MAP.put(255, CP850); // OEM
     }
 
     // The RTF may specify the \ansicpgN charset in the
     // header; this maps the N to the corresponding Java
     // character set:
-
-    private static final Map<Integer, String> ANSICPG_MAP = new HashMap<Integer, String>();
+    private static final Map<Integer, Charset> ANSICPG_MAP =
+            new HashMap<Integer, Charset>();
     static {
-        ANSICPG_MAP.put(437, "CP437");   // US IBM
-        ANSICPG_MAP.put(708, "ISO-8859-6");   // Arabic (ASMO 708)
+        ANSICPG_MAP.put(437, CP4372);   // US IBM
+        ANSICPG_MAP.put(708, ISO_8859_6);   // Arabic (ASMO 708)
       
-        ANSICPG_MAP.put(709, "windows-709");  // Arabic (ASMO 449+, BCON V4)
-        ANSICPG_MAP.put(710, "windows-710");  // Arabic (transparent Arabic)
-        ANSICPG_MAP.put(710, "windows-711");  // Arabic (Nafitha Enhanced)
-        ANSICPG_MAP.put(710, "windows-720");  // Arabic (transparent ASMO)
-        ANSICPG_MAP.put(819, "CP819");  // Windows 3.1 (US & Western Europe)
-        ANSICPG_MAP.put(819, "CP819");  // Windows 3.1 (US & Western Europe)
-
-        ANSICPG_MAP.put(819, "CP819");  // Windows 3.1 (US & Western Europe)
-        ANSICPG_MAP.put(850, "CP850");  // IBM Multilingual
-        ANSICPG_MAP.put(852, "CP852");  // Eastern European
-        ANSICPG_MAP.put(860, "CP860");  // Portuguese
-        ANSICPG_MAP.put(862, "CP862");  // Hebrew
-        ANSICPG_MAP.put(863, "CP863");  // French Canadian
-        ANSICPG_MAP.put(864, "CP864");  // Arabic
-        ANSICPG_MAP.put(865, "CP865");  // Norwegian
-        ANSICPG_MAP.put(866, "CP866");  // Soviet Union
-        ANSICPG_MAP.put(874, "MS874");  // Thai
-        ANSICPG_MAP.put(932, "MS932");  // Japanese
-        ANSICPG_MAP.put(936, "MS936");  // Simplified Chinese
-        ANSICPG_MAP.put(949, "CP949");  // Korean
-        ANSICPG_MAP.put(950, "CP950");  // Traditional Chinese
-        ANSICPG_MAP.put(1250, "CP1250");  // Eastern European
-        ANSICPG_MAP.put(1251, "CP1251");  // Cyrillic
-        ANSICPG_MAP.put(1252, "CP1252");  // Western European
-        ANSICPG_MAP.put(1253, "CP1253");  // Greek
-        ANSICPG_MAP.put(1254, "CP1254");  // Turkish
-        ANSICPG_MAP.put(1255, "CP1255");  // Hebrew
-        ANSICPG_MAP.put(1256, "CP1256");  // Arabic
-        ANSICPG_MAP.put(1257, "CP1257");  // Baltic
-        ANSICPG_MAP.put(1258, "CP1258");  // Vietnamese
-        ANSICPG_MAP.put(1361, "x-Johab");  // Johab
-        ANSICPG_MAP.put(10000, "MacRoman");  // Mac Roman
-        ANSICPG_MAP.put(10001, "Shift_JIS");  // Mac Japan
-        ANSICPG_MAP.put(10004, "MacArabic");  // Mac Arabic
-        ANSICPG_MAP.put(10005, "MacHebrew");  // Mac Hebrew
-        ANSICPG_MAP.put(10006, "MacGreek");  // Mac Hebrew
-        ANSICPG_MAP.put(10007, "MacCyrillic");  // Mac Cyrillic
-        ANSICPG_MAP.put(10029, "x-MacCentralEurope");  // MAC Latin2
-        ANSICPG_MAP.put(10081, "MacTurkish");  // Mac Turkish
-        ANSICPG_MAP.put(57002, "x-ISCII91");   // Devanagari
+        ANSICPG_MAP.put(709, WINDOWS_709);  // Arabic (ASMO 449+, BCON V4)
+        ANSICPG_MAP.put(710, WINDOWS_710);  // Arabic (transparent Arabic)
+        ANSICPG_MAP.put(710, WINDOWS_711);  // Arabic (Nafitha Enhanced)
+        ANSICPG_MAP.put(710, WINDOWS_720);  // Arabic (transparent ASMO)
+        ANSICPG_MAP.put(819, CP819);  // Windows 3.1 (US & Western Europe)
+        ANSICPG_MAP.put(819, CP819);  // Windows 3.1 (US & Western Europe)
+
+        ANSICPG_MAP.put(819, CP819);  // Windows 3.1 (US & Western Europe)
+        ANSICPG_MAP.put(850, CP8502);  // IBM Multilingual
+        ANSICPG_MAP.put(852, CP852);  // Eastern European
+        ANSICPG_MAP.put(860, CP860);  // Portuguese
+        ANSICPG_MAP.put(862, CP862);  // Hebrew
+        ANSICPG_MAP.put(863, CP863);  // French Canadian
+        ANSICPG_MAP.put(864, CP864);  // Arabic
+        ANSICPG_MAP.put(865, CP865);  // Norwegian
+        ANSICPG_MAP.put(866, CP866);  // Soviet Union
+        ANSICPG_MAP.put(874, MS8742);  // Thai
+        ANSICPG_MAP.put(932, MS932);  // Japanese
+        ANSICPG_MAP.put(936, MS9362);  // Simplified Chinese
+        ANSICPG_MAP.put(949, CP949);  // Korean
+        ANSICPG_MAP.put(950, CP950);  // Traditional Chinese
+        ANSICPG_MAP.put(1250, CP12502);  // Eastern European
+        ANSICPG_MAP.put(1251, CP12512);  // Cyrillic
+        ANSICPG_MAP.put(1252, CP1252);  // Western European
+        ANSICPG_MAP.put(1253, CP12532);  // Greek
+        ANSICPG_MAP.put(1254, CP12542);  // Turkish
+        ANSICPG_MAP.put(1255, CP12552);  // Hebrew
+        ANSICPG_MAP.put(1256, CP12562);  // Arabic
+        ANSICPG_MAP.put(1257, CP12572);  // Baltic
+        ANSICPG_MAP.put(1258, CP12582);  // Vietnamese
+        ANSICPG_MAP.put(1361, X_JOHAB);  // Johab
+        ANSICPG_MAP.put(10000, MAC_ROMAN);  // Mac Roman
+        ANSICPG_MAP.put(10001, SHIFT_JIS);  // Mac Japan
+        ANSICPG_MAP.put(10004, MAC_ARABIC);  // Mac Arabic
+        ANSICPG_MAP.put(10005, MAC_HEBREW);  // Mac Hebrew
+        ANSICPG_MAP.put(10006, MAC_GREEK);  // Mac Hebrew
+        ANSICPG_MAP.put(10007, MAC_CYRILLIC);  // Mac Cyrillic
+        ANSICPG_MAP.put(10029, X_MAC_CENTRAL_EUROPE);  // MAC Latin2
+        ANSICPG_MAP.put(10081, MAC_TURKISH);  // Mac Turkish
+        ANSICPG_MAP.put(57002, X_ISCII91);   // Devanagari
 
         // TODO: in theory these other charsets are simple
         // shifts off of Devanagari, so we could impl that
         // here:
-        ANSICPG_MAP.put(57003, "windows-57003");   // Bengali
-        ANSICPG_MAP.put(57004, "windows-57004");   // Tamil
-        ANSICPG_MAP.put(57005, "windows-57005");   // Telugu
-        ANSICPG_MAP.put(57006, "windows-57006");   // Assamese
-        ANSICPG_MAP.put(57007, "windows-57007");   // Oriya
-        ANSICPG_MAP.put(57008, "windows-57008");   // Kannada
-        ANSICPG_MAP.put(57009, "windows-57009");   // Malayalam
-        ANSICPG_MAP.put(57010, "windows-57010");   // Gujariti
-        ANSICPG_MAP.put(57011, "windows-57011");   // Punjabi
+        ANSICPG_MAP.put(57003, WINDOWS_57003);   // Bengali
+        ANSICPG_MAP.put(57004, WINDOWS_57004);   // Tamil
+        ANSICPG_MAP.put(57005, WINDOWS_57005);   // Telugu
+        ANSICPG_MAP.put(57006, WINDOWS_57006);   // Assamese
+        ANSICPG_MAP.put(57007, WINDOWS_57007);   // Oriya
+        ANSICPG_MAP.put(57008, WINDOWS_57008);   // Kannada
+        ANSICPG_MAP.put(57009, WINDOWS_57009);   // Malayalam
+        ANSICPG_MAP.put(57010, WINDOWS_57010);   // Gujariti
+        ANSICPG_MAP.put(57011, WINDOWS_57011);   // Punjabi
     }
 
     public TextExtractor(XHTMLContentHandler out, Metadata metadata) {
@@ -625,15 +708,12 @@ final class TextExtractor {
     }
 
     private CharsetDecoder getDecoder() throws TikaException {
-        final String charset = getCharset();
-          
+        Charset charset = getCharset();
+
         // Common case: charset is same as last time, so
         // just reuse it:
         if (lastCharset == null || !charset.equals(lastCharset)) {
-            decoder = CharsetUtils.forName(charset).newDecoder();
-            if (decoder == null) {
-                throw new TikaException("cannot find decoder for charset=" + charset);
-            }
+            decoder = charset.newDecoder();
             decoder.onMalformedInput(CodingErrorAction.REPLACE);
             decoder.onUnmappableCharacter(CodingErrorAction.REPLACE);
             lastCharset = charset;
@@ -643,16 +723,15 @@ final class TextExtractor {
     }
 
     // Return current charset in-use
-    private String getCharset() throws TikaException {
+    private Charset getCharset() throws TikaException {
         // If a specific font (fN) was set, use its charset
         if (groupState.fontCharset != null) {
             return groupState.fontCharset;
         }
 
-        // Else, if global default font (defN) was set, use
-        // that
+        // Else, if global default font (defN) was set, use that one
         if (globalDefaultFont != -1 && !inHeader) {
-            final String cs = fontToCharset.get(globalDefaultFont);
+            Charset cs = fontToCharset.get(globalDefaultFont);
             if (cs != null) {
                 return cs;
             }
@@ -696,7 +775,7 @@ final class TextExtractor {
         if (inHeader) {
             if (equals("ansicpg")) {
                 // ANSI codepage
-                final String cs = ANSICPG_MAP.get(param);
+                Charset cs = ANSICPG_MAP.get(param);
                 if (cs != null) {
                     globalCharset = cs;
                 }
@@ -715,7 +794,7 @@ final class TextExtractor {
                         // Start new font definition
                         curFontID = param;
                     } else if (equals("fcharset")) {
-                        final String cs = FCHARSET_MAP.get(param);
+                        Charset cs = FCHARSET_MAP.get(param);
                         if (cs != null) {
                             fontToCharset.put(curFontID, cs);
                         }
@@ -748,7 +827,7 @@ final class TextExtractor {
                 }
             } else if (equals("f")) {
                 // Change current font
-                final String fontCharset = fontToCharset.get(param);
+                Charset fontCharset = fontToCharset.get(param);
 
                 // Push any buffered text before changing
                 // font:
@@ -811,13 +890,13 @@ final class TextExtractor {
     private void processControlWord() throws IOException, SAXException, TikaException {
         if (inHeader) {
             if (equals("ansi")) {
-                globalCharset = "cp1252";
+                globalCharset = WINDOWS_1252;
             } else if (equals("pca")) { 
-                globalCharset = "cp850";
+                globalCharset = CP850;
             } else if (equals("pc")) { 
-                globalCharset = "cp437";
+                globalCharset = CP437;
             } else if (equals("mac")) { 
-                globalCharset = "MacRoman";
+                globalCharset = MAC_ROMAN;
             }
 
             if (equals("colortbl") || equals("stylesheet") || equals("fonttbl")) {

Commit:
9ead13fb86b4476f79359bfc20735b2201c752ed
Jukka Zitting
jukka@apache.org
2012-07-08 10:07:00 +0000
TIKA-471: Avoid Charset name bottleneck when multiple threads are using HtmlParser
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/txt/UniversalEncodingDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/txt/UniversalEncodingDetector.java
index b2f4eb171..e6c48fb90 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/txt/UniversalEncodingDetector.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/txt/UniversalEncodingDetector.java
@@ -22,11 +22,6 @@ import java.nio.charset.Charset;
 
 import org.apache.tika.detect.EncodingDetector;
 import org.apache.tika.metadata.Metadata;
-import org.apache.tika.mime.MediaType;
-import org.apache.tika.utils.CharsetUtils;
-import org.mozilla.universalchardet.CharsetListener;
-import org.mozilla.universalchardet.Constants;
-import org.mozilla.universalchardet.UniversalDetector;
 
 public class UniversalEncodingDetector implements EncodingDetector {
 
@@ -40,69 +35,28 @@ public class UniversalEncodingDetector implements EncodingDetector {
             return null;
         }
 
-        Result result = new Result(metadata);
-        UniversalDetector detector = new UniversalDetector(result);
-
         input.mark(LOOKAHEAD);
-        byte[] b = new byte[BUFSIZE];
-        int n = 0;
-        int m = input.read(b);
-        while (m != -1 && n < LOOKAHEAD && !detector.isDone()) {
-            n += m;
-            detector.handleData(b, 0, m);
-            m = input.read(b, 0, Math.min(b.length, LOOKAHEAD - n));
-        }
-        input.reset();
-
-        detector.dataEnd();
-        return result.getCharset();
-    }
-
-    private static class Result implements CharsetListener {
-
-        private static final Charset DEFAULT_LATIN_ENCODING =
-                Charset.forName("ISO-8859-1");
-
-        private String hint = null;
-
-        private Charset charset = null;
-
-        public Result(Metadata metadata) {
-            MediaType type =
-                    MediaType.parse(metadata.get(Metadata.CONTENT_TYPE));
-            if (type != null) {
-                hint = type.getParameters().get("charset");
-            }
-            if (hint == null) {
-                hint = metadata.get(Metadata.CONTENT_ENCODING);
-            }
-        }
-
-        public void report(String charset) {
-            if (!Constants.CHARSET_WINDOWS_1252.equals(charset)) {
-                try {
-                    this.charset = CharsetUtils.forName(charset);
-                } catch (IllegalArgumentException e) {
-                    // ignore
-                }
-            } else {
-                if (hint != null) {
-                    try {
-                        this.charset =
-                                CharsetUtils.forName(CharsetUtils.clean(hint));
-                    } catch (IllegalArgumentException e) {
-                        // ignore
-                    }
-                } else {
-                    this.charset = DEFAULT_LATIN_ENCODING;
-                }
+        try {
+            UniversalEncodingListener listener =
+                    new UniversalEncodingListener(metadata);
+
+            byte[] b = new byte[BUFSIZE];
+            int n = 0;
+            int m = input.read(b);
+            while (m != -1 && n < LOOKAHEAD && !listener.isDone()) {
+                n += m;
+                listener.handleData(b, 0, m);
+                m = input.read(b, 0, Math.min(b.length, LOOKAHEAD - n));
             }
-        }
 
-        public Charset getCharset() {
-            return charset;
+            return listener.dataEnd();
+        } catch (IOException e) {
+            throw e;
+        } catch (Exception e) { // if juniversalchardet is not available
+            return null;
+        } finally {
+            input.reset();
         }
-
     }
 
 }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/txt/UniversalEncodingListener.java b/tika-parsers/src/main/java/org/apache/tika/parser/txt/UniversalEncodingListener.java
new file mode 100644
index 000000000..fdc601a12
--- /dev/null
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/txt/UniversalEncodingListener.java
@@ -0,0 +1,145 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.parser.txt;
+
+import java.nio.charset.Charset;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.mime.MediaType;
+import org.apache.tika.utils.CharsetUtils;
+import org.mozilla.universalchardet.CharsetListener;
+import org.mozilla.universalchardet.Constants;
+import org.mozilla.universalchardet.UniversalDetector;
+
+/**
+ * Helper class used by {@link UniversalEncodingDetector} to access the
+ * <code>juniversalchardet</code> detection logic.
+ */
+class UniversalEncodingListener implements CharsetListener {
+
+    private static final String CHARSET_ISO_8859_1 = "ISO-8859-1";
+
+    private static final String CHARSET_ISO_8859_15 = "ISO-8859-15";
+
+    private static Map<String, Charset> makeCC(String... names) {
+        Map<String, Charset> charsets = new HashMap<String, Charset>();
+        for (String name : names) {
+            try {
+                charsets.put(name, Charset.forName(name));
+            } catch (Exception e) {
+                // ignore
+            }
+        }
+        return charsets;
+    }
+
+    private static final Map<String, Charset> CONSTANT_CHARSETS = makeCC(
+            Constants.CHARSET_BIG5,
+            Constants.CHARSET_EUC_JP,
+            Constants.CHARSET_EUC_KR,
+            Constants.CHARSET_EUC_TW,
+            Constants.CHARSET_GB18030,
+            Constants.CHARSET_HZ_GB_2312, // not supported?
+            Constants.CHARSET_IBM855,
+            Constants.CHARSET_IBM866,
+            Constants.CHARSET_ISO_2022_CN,
+            Constants.CHARSET_ISO_2022_JP,
+            Constants.CHARSET_ISO_2022_KR,
+            CHARSET_ISO_8859_1,
+            Constants.CHARSET_ISO_8859_5,
+            Constants.CHARSET_ISO_8859_7,
+            Constants.CHARSET_ISO_8859_8,
+            CHARSET_ISO_8859_15,
+            Constants.CHARSET_KOI8_R,
+            Constants.CHARSET_MACCYRILLIC,
+            Constants.CHARSET_SHIFT_JIS,
+            Constants.CHARSET_UTF_16BE,
+            Constants.CHARSET_UTF_16LE,
+            Constants.CHARSET_UTF_32BE, // not supported?
+            Constants.CHARSET_UTF_32LE, // not supported?
+            Constants.CHARSET_UTF_8,
+            Constants.CHARSET_WINDOWS_1251,
+            Constants.CHARSET_WINDOWS_1252,
+            Constants.CHARSET_WINDOWS_1253,
+            Constants.CHARSET_WINDOWS_1255,
+            Constants.CHARSET_X_ISO_10646_UCS_4_2143, // not supported?
+            Constants.CHARSET_X_ISO_10646_UCS_4_3412); // not supported?
+
+    private static Charset getCharset(String name) {
+        Charset charset = CONSTANT_CHARSETS.get(name);
+        if (charset == null) {
+            try {
+                charset = CharsetUtils.forName(name);
+            } catch (Exception e) {
+                // ignore
+            }
+        }
+        return charset;
+    }
+
+    private final UniversalDetector detector = new UniversalDetector(this);
+
+    private String hint = null;
+
+    private Charset charset = null;
+
+    private boolean hasCR = false;
+
+    public UniversalEncodingListener(Metadata metadata) {
+        MediaType type = MediaType.parse(metadata.get(Metadata.CONTENT_TYPE));
+        if (type != null) {
+            hint = type.getParameters().get("charset");
+        }
+        if (hint == null) {
+            hint = metadata.get(Metadata.CONTENT_ENCODING);
+        }
+    }
+
+    public void report(String name) {
+        if (Constants.CHARSET_WINDOWS_1252.equals(name)) {
+            if (hint != null) {
+                // Use the encoding hint to distinguish between latin charsets
+                name = hint;
+            } else if (!hasCR) {
+                // If there are no CRLFs, it's more likely to be ISO-8859-1
+                name = CHARSET_ISO_8859_1;
+            }
+        }
+        this.charset = getCharset(name);
+    }
+
+    public boolean isDone() {
+        return detector.isDone();
+    }
+
+    public void handleData(byte[] buf, int offset, int length) {
+        for (int i = 0; !hasCR && i < length; i++) {
+            if (buf[offset + i] == '\r') {
+                hasCR = true;
+            }
+        }
+        detector.handleData(buf, offset, length);
+    }
+
+    public Charset dataEnd() {
+        detector.dataEnd();
+        return charset;
+    }
+
+}
\ No newline at end of file

Commit:
6621297537770ca9149e06ee2977483009f8860f
Jukka Zitting
jukka@apache.org
2012-07-08 00:34:16 +0000
TIKA-471: Avoid Charset name bottleneck when multiple threads are using HtmlParser
diff --git a/tika-core/src/main/java/org/apache/tika/config/ServiceLoader.java b/tika-core/src/main/java/org/apache/tika/config/ServiceLoader.java
index 619319139..0e025da13 100644
--- a/tika-core/src/main/java/org/apache/tika/config/ServiceLoader.java
+++ b/tika-core/src/main/java/org/apache/tika/config/ServiceLoader.java
@@ -22,6 +22,7 @@ import java.io.InputStream;
 import java.io.InputStreamReader;
 import java.net.URL;
 import java.util.ArrayList;
+import java.util.Collection;
 import java.util.Collections;
 import java.util.Enumeration;
 import java.util.HashMap;
@@ -242,14 +243,14 @@ public class ServiceLoader {
         List<T> providers = new ArrayList<T>();
 
         if (loader != null) {
-            Set<String> names = new HashSet<String>();
+            List<String> names = new ArrayList<String>();
 
             String serviceName = iface.getName();
             Enumeration<URL> resources =
                     findServiceResources("META-INF/services/" + serviceName);
             for (URL resource : Collections.list(resources)) {
                 try {
-                    names.addAll(getServiceClassNames(resource));
+                    collectServiceClassNames(resource, names);
                 } catch (IOException e) {
                     handler.handleLoadError(serviceName, e);
                 }
@@ -274,9 +275,8 @@ public class ServiceLoader {
 
     private static final Pattern WHITESPACE = Pattern.compile("\\s+");
 
-    private Set<String> getServiceClassNames(URL resource)
+    private void collectServiceClassNames(URL resource, Collection<String> names)
             throws IOException {
-        Set<String> names = new HashSet<String>();
         InputStream stream = resource.openStream();
         try {
             BufferedReader reader =
@@ -293,7 +293,6 @@ public class ServiceLoader {
         } finally {
             stream.close();
         }
-        return names;
     }
 
 }
diff --git a/tika-core/src/main/java/org/apache/tika/detect/AutoDetectReader.java b/tika-core/src/main/java/org/apache/tika/detect/AutoDetectReader.java
new file mode 100644
index 000000000..ff20551c1
--- /dev/null
+++ b/tika-core/src/main/java/org/apache/tika/detect/AutoDetectReader.java
@@ -0,0 +1,122 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.detect;
+
+import java.io.BufferedInputStream;
+import java.io.BufferedReader;
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.InputStreamReader;
+import java.nio.charset.Charset;
+import java.util.List;
+
+import org.apache.tika.config.ServiceLoader;
+import org.apache.tika.exception.TikaException;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.mime.MediaType;
+import org.apache.tika.utils.CharsetUtils;
+import org.xml.sax.InputSource;
+
+/**
+ * An input stream reader that automatically detects the character encoding
+ * to be used for converting bytes to characters.
+ *
+ * @since Apache Tika 1.2
+ */
+public class AutoDetectReader extends BufferedReader {
+
+    private static final ServiceLoader DEFAULT_LOADER =
+            new ServiceLoader(AutoDetectReader.class.getClassLoader());
+
+    private static Charset detect(
+            InputStream input, Metadata metadata,
+            List<EncodingDetector> detectors)
+            throws IOException, TikaException {
+        // Ask all given detectors for the character encoding
+        for (EncodingDetector detector : detectors) {
+            Charset charset = detector.detect(input, metadata);
+            if (charset != null) {
+                return charset;
+            }
+        }
+
+        // Try determining the encoding based on hints in document metadata
+        MediaType type = MediaType.parse(metadata.get(Metadata.CONTENT_TYPE));
+        if (type != null) {
+            String charset = type.getParameters().get("charset");
+            if (charset != null) {
+                try {
+                    return CharsetUtils.forName(charset);
+                } catch (IllegalArgumentException e) {
+                    // ignore
+                }
+            }
+        }
+
+        throw new TikaException(
+                "Failed to detect the character encoding of a document");
+    }
+
+    private final Charset charset;
+
+    private AutoDetectReader(InputStream stream, Charset charset)
+            throws IOException {
+        super(new InputStreamReader(stream, charset));
+        this.charset = charset;
+
+        // TIKA-240: Drop the BOM if present
+        mark(1);
+        if (read() != '\ufeff') { // zero-width no-break space
+            reset();
+        }
+    }
+
+    private AutoDetectReader(
+            BufferedInputStream stream, Metadata metadata,
+            List<EncodingDetector> detectors)
+            throws IOException, TikaException {
+        this(stream, detect(stream, metadata, detectors));
+    }
+
+    public AutoDetectReader(
+            InputStream stream, Metadata metadata,
+            ServiceLoader loader) throws IOException, TikaException {
+        this(new BufferedInputStream(stream), metadata,
+                loader.loadServiceProviders(EncodingDetector.class));
+    }
+
+    public AutoDetectReader(InputStream stream, Metadata metadata)
+            throws IOException, TikaException {
+        this(new BufferedInputStream(stream), metadata, DEFAULT_LOADER);
+    }
+
+    public AutoDetectReader(InputStream stream)
+            throws IOException, TikaException {
+        this(stream, new Metadata());
+    }
+
+    public Charset getCharset() {
+        return charset;
+    }
+
+    public InputSource asInputSource() {
+        InputSource source = new InputSource(this);
+        source.setEncoding(charset.name());
+        return source;
+    }
+
+}
diff --git a/tika-core/src/main/java/org/apache/tika/mime/MediaType.java b/tika-core/src/main/java/org/apache/tika/mime/MediaType.java
index 27c5e9ef8..5eb0cb277 100644
--- a/tika-core/src/main/java/org/apache/tika/mime/MediaType.java
+++ b/tika-core/src/main/java/org/apache/tika/mime/MediaType.java
@@ -229,15 +229,21 @@ public final class MediaType implements Comparable<MediaType>, Serializable {
         }
         return parameters;
     }
-    
+
+    /**
+     * Fuzzy unquoting mechanism that works also with somewhat malformed
+     * quotes.
+     *
+     * @param s string to unquote
+     * @return unquoted string
+     */
     private static String unquote(String s) {
-        if( s.startsWith("\"") && s.endsWith("\"")) {
-            return s.substring(1, s.length() - 1);
+        while (s.startsWith("\"") || s.startsWith("'")) {
+            s = s.substring(1);
+        }
+        while (s.endsWith("\"") || s.endsWith("'")) {
+            s = s.substring(0, s.length() - 1);
         }
-        if( s.startsWith("'") && s.endsWith("'")) {
-           return s.substring(1, s.length() - 1);
-       }
-
         return s;
     }
 
diff --git a/tika-core/src/test/java/org/apache/tika/mime/MediaTypeTest.java b/tika-core/src/test/java/org/apache/tika/mime/MediaTypeTest.java
index 3d7161793..a3dd4f89c 100644
--- a/tika-core/src/test/java/org/apache/tika/mime/MediaTypeTest.java
+++ b/tika-core/src/test/java/org/apache/tika/mime/MediaTypeTest.java
@@ -180,5 +180,22 @@ public class MediaTypeTest extends TestCase {
         assertEquals(0, type.getParameters().keySet().size());
     }
 
-    
+    /**
+     * TIKA-349
+     */
+    public void testOddParameters() {
+        assertEquals(
+                "text/html; charset=UTF-8",
+                MediaType.parse("text/html;; charset=UTF-8").toString());
+        assertEquals(
+                "text/html; charset=UTF-8",
+                MediaType.parse("text/html;; charset=UTF-8").toString());
+        assertEquals(
+                "text/html; charset=UTF-8",
+                MediaType.parse("text/html;; charset=\"UTF-8\"").toString());
+        assertEquals(
+                "text/html; charset=UTF-8",
+                MediaType.parse("text/html;; charset=\"UTF-8").toString());
+    }
+
 }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlEncodingDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlEncodingDetector.java
new file mode 100644
index 000000000..3727f7c7e
--- /dev/null
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlEncodingDetector.java
@@ -0,0 +1,87 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.parser.html;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.nio.ByteBuffer;
+import java.nio.CharBuffer;
+import java.nio.charset.Charset;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+import org.apache.tika.detect.EncodingDetector;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.mime.MediaType;
+import org.apache.tika.utils.CharsetUtils;
+
+/**
+ * Character encoding detector for determining the character encoding of a
+ * HTML document based on the potential charset parameter found in a
+ * Content-Type http-equiv meta tag somewhere near the beginning. Especially
+ * useful for determining the type among multiple closely related encodings
+ * (ISO-8859-*) for which other types of encoding detection are unreliable.
+ *
+ * @since Apache Tika 1.2
+ */
+public class HtmlEncodingDetector implements EncodingDetector {
+
+    // TIKA-357 - use bigger buffer for meta tag sniffing (was 4K)
+    private static final int META_TAG_BUFFER_SIZE = 8192;
+
+    private static final Pattern HTTP_EQUIV_PATTERN = Pattern.compile(
+            "(?is)<meta\\s+http-equiv\\s*=\\s*['\\\"]\\s*"
+            + "Content-Type['\\\"]\\s+content\\s*=\\s*['\\\"]"
+            + "([^'\\\"]+)['\\\"]");
+
+    private static final Charset ASCII = Charset.forName("US-ASCII");
+
+    public Charset detect(InputStream input, Metadata metadata)
+            throws IOException {
+        if (input == null) {
+            return null;
+        }
+
+        // Read enough of the text stream to capture possible meta tags
+        input.mark(META_TAG_BUFFER_SIZE);
+        byte[] buffer = new byte[META_TAG_BUFFER_SIZE];
+        int n = 0;
+        int m = input.read(buffer);
+        while (m != -1 && n < buffer.length) {
+            n += m;
+            m = input.read(buffer, n, buffer.length - n);
+        }
+        input.reset();
+
+        // Interpret the head as ASCII and try to spot a http-equiv setting
+        CharBuffer head = ASCII.decode(ByteBuffer.wrap(buffer, 0, n));
+        Matcher matcher = HTTP_EQUIV_PATTERN.matcher(head.toString());
+        if (matcher.find()) {
+            MediaType type = MediaType.parse(matcher.group(1));
+            if (type != null) {
+                String charset = type.getParameters().get("charset");
+                if (charset != null) {
+                    charset = CharsetUtils.clean(charset);
+                    return CharsetUtils.forName(charset);
+                }
+            }
+        }
+
+        return null;
+    }
+
+}
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlParser.java
index 91c926840..4be67e7d2 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlParser.java
@@ -16,30 +16,24 @@
  */
 package org.apache.tika.parser.html;
 
-import java.io.BufferedInputStream;
 import java.io.IOException;
 import java.io.InputStream;
-import java.io.InputStreamReader;
-import java.nio.charset.Charset;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashSet;
 import java.util.Set;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
 
+import org.apache.tika.config.ServiceLoader;
+import org.apache.tika.detect.AutoDetectReader;
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.io.CloseShieldInputStream;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.parser.AbstractParser;
 import org.apache.tika.parser.ParseContext;
-import org.apache.tika.parser.txt.DefaultEncodingDetector;
-import org.apache.tika.utils.CharsetUtils;
 import org.ccil.cowan.tagsoup.HTMLSchema;
 import org.ccil.cowan.tagsoup.Schema;
 import org.xml.sax.ContentHandler;
-import org.xml.sax.InputSource;
 import org.xml.sax.SAXException;
 
 /**
@@ -59,14 +53,8 @@ public class HtmlParser extends AbstractParser {
                 MediaType.application("vnd.wap.xhtml+xml"),
                 MediaType.application("x-asp"))));
 
-    // Use the widest, most common charset as our default.
-    private static final String DEFAULT_CHARSET = "windows-1252";
-    // TIKA-357 - use bigger buffer for meta tag sniffing (was 4K)
-    private static final int META_TAG_BUFFER_SIZE = 8192;
-    private static final Pattern HTTP_EQUIV_PATTERN = Pattern.compile(
-                    "(?is)<meta\\s+http-equiv\\s*=\\s*['\\\"]\\s*" +
-                    "Content-Type['\\\"]\\s+content\\s*=\\s*['\\\"]" +
-                    "([^'\\\"]+)['\\\"]");
+    private static final ServiceLoader LOADER =
+            new ServiceLoader(HtmlParser.class.getClassLoader());
 
     /**
      * HTML schema singleton used to amortize the heavy instantiation time.
@@ -77,92 +65,42 @@ public class HtmlParser extends AbstractParser {
         return SUPPORTED_TYPES;
     }
 
-    /**
-     * TIKA-332: Check for meta http-equiv tag with charset info in
-     * HTML content.
-     * <p>
-     * TODO: Move this into core, along with CharsetDetector
-     */ 
-    private String getEncoding(InputStream stream, Metadata metadata) throws IOException {
-        stream.mark(META_TAG_BUFFER_SIZE);
-        char[] buffer = new char[META_TAG_BUFFER_SIZE];
-        InputStreamReader isr = new InputStreamReader(stream, "us-ascii");
-        int bufferSize = isr.read(buffer);
-        stream.reset();
-
-        if (bufferSize != -1) {
-            String metaString = new String(buffer, 0, bufferSize);
-            Matcher m = HTTP_EQUIV_PATTERN.matcher(metaString);
-            if (m.find()) {
-                // TIKA-349: flexible handling of attributes
-                // We have one or more x or x=y attributes, separated by ';'
-                String[] attrs = m.group(1).split(";");
-                for (String attr : attrs) {
-                    String[] keyValue = attr.trim().split("=");
-                    if ((keyValue.length == 2) && keyValue[0].equalsIgnoreCase("charset")) {
-                        // TIKA-459: improve charset handling.
-                        String charset = CharsetUtils.clean(keyValue[1]);
-                        if (CharsetUtils.isSupported(charset)) {
-                            metadata.set(Metadata.CONTENT_ENCODING, charset);
-                            return charset;
-                        }
-                    }
-                }
-            }
-        }
-
-        // No (valid) charset in a meta http-equiv tag, use other heuristics
-        // to figure out the encoding
-        Charset charset = DefaultEncodingDetector.INSTANCE.detect(stream, metadata);
-        if (charset == null) {
-            try {
-                charset = CharsetUtils.forName(DEFAULT_CHARSET);
-            } catch (IllegalArgumentException e) {
-                charset = Charset.defaultCharset();
-            }
-        }
-        String encoding = charset.name();
-        metadata.set(Metadata.CONTENT_ENCODING, encoding);
-
-        return encoding;
-    }
-
     public void parse(
             InputStream stream, ContentHandler handler,
             Metadata metadata, ParseContext context)
             throws IOException, SAXException, TikaException {
-        // The getEncoding() method depends on the mark feature
-        if (!stream.markSupported()) {
-            stream = new BufferedInputStream(stream);
-        }
-
-        // Protect the stream from being closed by CyberNeko
-        // TODO: Is this still needed, given our use of TagSoup?
-        stream = new CloseShieldInputStream(stream);
-
-        // Prepare the input source using the encoding hint if available
-        InputSource source = new InputSource(stream); 
-        source.setEncoding(getEncoding(stream, metadata));
+        // Automatically detect the character encoding
+        AutoDetectReader reader = new AutoDetectReader(
+                new CloseShieldInputStream(stream), metadata, LOADER);
+        try {
+            if (metadata.get(Metadata.CONTENT_TYPE) == null) {
+                // TODO: Include charset
+                metadata.set(Metadata.CONTENT_TYPE, "text/html");
+            }
+            metadata.set(Metadata.CONTENT_ENCODING, reader.getCharset().name());
 
-        // Get the HTML mapper from the parse context
-        HtmlMapper mapper =
-            context.get(HtmlMapper.class, new HtmlParserMapper());
+            // Get the HTML mapper from the parse context
+            HtmlMapper mapper =
+                    context.get(HtmlMapper.class, new HtmlParserMapper());
 
-        // Parse the HTML document
-        org.ccil.cowan.tagsoup.Parser parser =
-            new org.ccil.cowan.tagsoup.Parser();
+            // Parse the HTML document
+            org.ccil.cowan.tagsoup.Parser parser =
+                    new org.ccil.cowan.tagsoup.Parser();
 
-        // TIKA-528: Reuse share schema to avoid heavy instantiation
-        parser.setProperty(
-                org.ccil.cowan.tagsoup.Parser.schemaProperty, HTML_SCHEMA);
-        // TIKA-599: Shared schema is thread-safe only if bogons are ignored
-        parser.setFeature(
-                org.ccil.cowan.tagsoup.Parser.ignoreBogonsFeature, true);
+            // TIKA-528: Reuse share schema to avoid heavy instantiation
+            parser.setProperty(
+                    org.ccil.cowan.tagsoup.Parser.schemaProperty, HTML_SCHEMA);
+            // TIKA-599: Shared schema is thread-safe only if bogons are ignored
+            parser.setFeature(
+                    org.ccil.cowan.tagsoup.Parser.ignoreBogonsFeature, true);
 
-        parser.setContentHandler(new XHTMLDowngradeHandler(
-                new HtmlHandler(mapper, handler, metadata)));
+            parser.setContentHandler(new XHTMLDowngradeHandler(
+                    new HtmlHandler(mapper, handler, metadata)));
 
-        parser.parse(source);
+            parser.parse(reader.asInputSource());
+        } finally {
+            reader.close();
+        }
     }
 
     /**
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/txt/DefaultEncodingDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/txt/DefaultEncodingDetector.java
deleted file mode 100644
index 4dc8d796a..000000000
--- a/tika-parsers/src/main/java/org/apache/tika/parser/txt/DefaultEncodingDetector.java
+++ /dev/null
@@ -1,69 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.tika.parser.txt;
-
-import java.io.IOException;
-import java.io.InputStream;
-import java.nio.charset.Charset;
-import java.util.List;
-
-import org.apache.tika.config.ServiceLoader;
-import org.apache.tika.detect.EncodingDetector;
-import org.apache.tika.metadata.Metadata;
-import org.apache.tika.mime.MediaType;
-import org.apache.tika.utils.CharsetUtils;
-
-public class DefaultEncodingDetector implements EncodingDetector {
-
-    public static final EncodingDetector INSTANCE =
-            new DefaultEncodingDetector(new ServiceLoader(
-                    DefaultEncodingDetector.class.getClassLoader()));
-
-    private final List<EncodingDetector> detectors;
-
-    public DefaultEncodingDetector(ServiceLoader loader) {
-        this.detectors =
-                loader.loadStaticServiceProviders(EncodingDetector.class);
-    }
-
-    public Charset detect(InputStream input, Metadata metadata)
-            throws IOException {
-        // Check all available detectors
-        for (EncodingDetector detector : detectors) {
-            Charset charset = detector.detect(input, metadata);
-            if (charset != null) {
-                return charset;
-            }
-        }
-
-        // Try determining the charset based on document metadata
-        MediaType type = MediaType.parse(metadata.get(Metadata.CONTENT_TYPE));
-        if (type != null) {
-            String charset = type.getParameters().get("charset");
-            if (charset != null) {
-                try {
-                    return CharsetUtils.forName(charset);
-                } catch (IllegalArgumentException e) {
-                    // ignore
-                }
-            }
-        }
-
-        return null;
-    }
-
-}
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/txt/TXTParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/txt/TXTParser.java
index 24c6549a7..83daaeca8 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/txt/TXTParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/txt/TXTParser.java
@@ -16,21 +16,20 @@
  */
 package org.apache.tika.parser.txt;
 
-import java.io.BufferedInputStream;
-import java.io.BufferedReader;
 import java.io.IOException;
 import java.io.InputStream;
-import java.io.InputStreamReader;
-import java.io.Reader;
-import java.nio.charset.Charset;
 import java.util.Collections;
 import java.util.Set;
 
+import org.apache.tika.config.ServiceLoader;
+import org.apache.tika.detect.AutoDetectReader;
 import org.apache.tika.exception.TikaException;
+import org.apache.tika.io.CloseShieldInputStream;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.parser.AbstractParser;
 import org.apache.tika.parser.ParseContext;
+import org.apache.tika.parser.html.HtmlParser;
 import org.apache.tika.sax.XHTMLContentHandler;
 import org.xml.sax.ContentHandler;
 import org.xml.sax.SAXException;
@@ -62,6 +61,9 @@ public class TXTParser extends AbstractParser {
     private static final Set<MediaType> SUPPORTED_TYPES =
         Collections.singleton(MediaType.TEXT_PLAIN);
 
+    private static final ServiceLoader LOADER =
+            new ServiceLoader(TXTParser.class.getClassLoader());
+
     public Set<MediaType> getSupportedTypes(ParseContext context) {
         return SUPPORTED_TYPES;
     }
@@ -70,47 +72,30 @@ public class TXTParser extends AbstractParser {
             InputStream stream, ContentHandler handler,
             Metadata metadata, ParseContext context)
             throws IOException, SAXException, TikaException {
-        // We need mark support for detecting the character encoding
-        stream = new BufferedInputStream(stream);
-
-        Charset charset =
-                DefaultEncodingDetector.INSTANCE.detect(stream, metadata);
-        if (charset != null) {
-            metadata.set(Metadata.CONTENT_ENCODING, charset.name());
-        } else {
-            throw new TikaException(
-                    "Text encoding could not be detected and no encoding"
-                    + " hint is available in document metadata");
-        }
+        // Automatically detect the character encoding
+        AutoDetectReader reader = new AutoDetectReader(
+                new CloseShieldInputStream(stream), metadata, LOADER);
+        try {
+            metadata.set(Metadata.CONTENT_TYPE, "text/plain"); // TODO: charset
+            metadata.set(Metadata.CONTENT_ENCODING, reader.getCharset().name());
 
-        // TIKA-341: Only stomp on content-type after we're done trying to
-        // use it to guess at the charset.
-        metadata.set(Metadata.CONTENT_TYPE, "text/plain");
+            XHTMLContentHandler xhtml =
+                    new XHTMLContentHandler(handler, metadata);
+            xhtml.startDocument();
 
-        Reader reader =
-                new BufferedReader(new InputStreamReader(stream, charset));
+            xhtml.startElement("p");
+            char[] buffer = new char[4096];
+            int n = reader.read(buffer);
+            while (n != -1) {
+                xhtml.characters(buffer, 0, n);
+                n = reader.read(buffer);
+            }
+            xhtml.endElement("p");
 
-        // TIKA-240: Drop the BOM when extracting plain text
-        reader.mark(1);
-        int bom = reader.read();
-        if (bom != '\ufeff') { // zero-width no-break space
-            reader.reset();
+            xhtml.endDocument();
+        } finally {
+            reader.close();
         }
-
-        XHTMLContentHandler xhtml =
-                new XHTMLContentHandler(handler, metadata);
-        xhtml.startDocument();
-
-        xhtml.startElement("p");
-        char[] buffer = new char[4096];
-        int n = reader.read(buffer);
-        while (n != -1) {
-            xhtml.characters(buffer, 0, n);
-            n = reader.read(buffer);
-        }
-        xhtml.endElement("p");
-
-        xhtml.endDocument();
     }
 
 }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/txt/UniversalEncodingDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/txt/UniversalEncodingDetector.java
index d7791bed8..b2f4eb171 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/txt/UniversalEncodingDetector.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/txt/UniversalEncodingDetector.java
@@ -22,6 +22,7 @@ import java.nio.charset.Charset;
 
 import org.apache.tika.detect.EncodingDetector;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.mime.MediaType;
 import org.apache.tika.utils.CharsetUtils;
 import org.mozilla.universalchardet.CharsetListener;
 import org.mozilla.universalchardet.Constants;
@@ -39,7 +40,7 @@ public class UniversalEncodingDetector implements EncodingDetector {
             return null;
         }
 
-        Result result = new Result();
+        Result result = new Result(metadata);
         UniversalDetector detector = new UniversalDetector(result);
 
         input.mark(LOOKAHEAD);
@@ -59,16 +60,42 @@ public class UniversalEncodingDetector implements EncodingDetector {
 
     private static class Result implements CharsetListener {
 
+        private static final Charset DEFAULT_LATIN_ENCODING =
+                Charset.forName("ISO-8859-1");
+
+        private String hint = null;
+
         private Charset charset = null;
 
-        public void report(String charset) {
-            if (Constants.CHARSET_WINDOWS_1252.equals(charset)) {
-                charset = "ISO-8859-1";
+        public Result(Metadata metadata) {
+            MediaType type =
+                    MediaType.parse(metadata.get(Metadata.CONTENT_TYPE));
+            if (type != null) {
+                hint = type.getParameters().get("charset");
+            }
+            if (hint == null) {
+                hint = metadata.get(Metadata.CONTENT_ENCODING);
             }
-            try {
-                this.charset = CharsetUtils.forName(charset);
-            } catch (IllegalArgumentException e) {
-                // ignore
+        }
+
+        public void report(String charset) {
+            if (!Constants.CHARSET_WINDOWS_1252.equals(charset)) {
+                try {
+                    this.charset = CharsetUtils.forName(charset);
+                } catch (IllegalArgumentException e) {
+                    // ignore
+                }
+            } else {
+                if (hint != null) {
+                    try {
+                        this.charset =
+                                CharsetUtils.forName(CharsetUtils.clean(hint));
+                    } catch (IllegalArgumentException e) {
+                        // ignore
+                    }
+                } else {
+                    this.charset = DEFAULT_LATIN_ENCODING;
+                }
             }
         }
 
diff --git a/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.detect.EncodingDetector b/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.detect.EncodingDetector
index e60217c3d..3933db5d9 100644
--- a/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.detect.EncodingDetector
+++ b/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.detect.EncodingDetector
@@ -13,5 +13,6 @@
 #  See the License for the specific language governing permissions and
 #  limitations under the License.
 
+org.apache.tika.parser.html.HtmlEncodingDetector
 org.apache.tika.parser.txt.UniversalEncodingDetector
 org.apache.tika.parser.txt.Icu4jEncodingDetector
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/html/HtmlParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/html/HtmlParserTest.java
index 7f7e28add..f5032eecd 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/html/HtmlParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/html/HtmlParserTest.java
@@ -243,7 +243,7 @@ public class HtmlParserTest extends TestCase {
             + "</head><body></body></html>";
         Metadata metadata = new Metadata();
         new HtmlParser().parse (
-                new ByteArrayInputStream(test.getBytes("UTF-8")),
+                new ByteArrayInputStream(test.getBytes("ISO-8859-1")),
                 new BodyContentHandler(),  metadata, new ParseContext());
         assertEquals("ISO-8859-1", metadata.get(Metadata.CONTENT_ENCODING));
     }
@@ -326,26 +326,26 @@ public class HtmlParserTest extends TestCase {
     public void testHttpEquivCharsetFunkyAttributes() throws Exception {
         String test1 =
             "<html><head><meta http-equiv=\"content-type\""
-            + " content=\"text/html; charset=ISO-8859-1; charset=iso-8859-1\" />"
+            + " content=\"text/html; charset=ISO-8859-15; charset=iso-8859-15\" />"
             + "<title>the name is \u00e1ndre</title>"
             + "</head><body></body></html>";
         Metadata metadata = new Metadata();
         new HtmlParser().parse (
-                new ByteArrayInputStream(test1.getBytes("UTF-8")),
+                new ByteArrayInputStream(test1.getBytes("ISO-8859-1")),
                 new BodyContentHandler(),  metadata, new ParseContext());
-        assertEquals("ISO-8859-1", metadata.get(Metadata.CONTENT_ENCODING));
+        assertEquals("ISO-8859-15", metadata.get(Metadata.CONTENT_ENCODING));
 
         // Some HTML pages have errors like ';;' versus '; ' as separator
         String test2 =
             "<html><head><meta http-equiv=\"content-type\""
-            + " content=\"text/html;;charset=ISO-8859-1\" />"
+            + " content=\"text/html;;charset=ISO-8859-15\" />"
             + "<title>the name is \u00e1ndre</title>"
             + "</head><body></body></html>";
         metadata = new Metadata();
         new HtmlParser().parse (
-                new ByteArrayInputStream(test2.getBytes("UTF-8")),
+                new ByteArrayInputStream(test2.getBytes("ISO-8859-1")),
                 new BodyContentHandler(),  metadata, new ParseContext());
-        assertEquals("ISO-8859-1", metadata.get(Metadata.CONTENT_ENCODING));
+        assertEquals("ISO-8859-15", metadata.get(Metadata.CONTENT_ENCODING));
     }
 
     /**
@@ -569,7 +569,7 @@ public class HtmlParserTest extends TestCase {
                 makeHtmlTransformer(sw), metadata, new ParseContext());
 
         String result = sw.toString();
-        
+
         // <meta> tag for Content-Type should exist, but nothing for Language
         assertTrue(Pattern.matches("(?s).*<meta name=\"Content-Type\" content=\"text/html; charset=utf-8\"/>.*$", result));
         assertFalse(Pattern.matches("(?s).*<meta name=\"Language\".*$", result));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/txt/TXTParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/txt/TXTParserTest.java
index 540537801..2267242b0 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/txt/TXTParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/txt/TXTParserTest.java
@@ -103,23 +103,23 @@ public class TXTParserTest extends TestCase {
      * @see <a href="https://issues.apache.org/jira/browse/TIKA-335">TIKA-335</a> 
      */
     public void testUseIncomingCharsetAsHint() throws Exception {
-        // Could be UTF-8 or ISO 8859-1 or ...
+        // Could be ISO 8859-1 or ISO 8859-15 or ...
         // u00e1 is latin small letter a with acute
         final String test2 = "the name is \u00e1ndre";
 
         Metadata metadata = new Metadata();
         parser.parse(
-                new ByteArrayInputStream(test2.getBytes("UTF-8")),
+                new ByteArrayInputStream(test2.getBytes("ISO-8859-1")),
                 new BodyContentHandler(),  metadata, new ParseContext());
         
-        assertEquals("UTF-8", metadata.get(Metadata.CONTENT_ENCODING));
+        assertEquals("ISO-8859-1", metadata.get(Metadata.CONTENT_ENCODING));
 
-        metadata.set(Metadata.CONTENT_ENCODING, "ISO-8859-1");
+        metadata.set(Metadata.CONTENT_ENCODING, "ISO-8859-15");
         parser.parse(
                 new ByteArrayInputStream(test2.getBytes("ISO-8859-1")),
                 new BodyContentHandler(),  metadata, new ParseContext());
-        
-        assertEquals("ISO-8859-1", metadata.get(Metadata.CONTENT_ENCODING));
+
+        assertEquals("ISO-8859-15", metadata.get(Metadata.CONTENT_ENCODING));
     }
 
     /**
@@ -128,24 +128,24 @@ public class TXTParserTest extends TestCase {
      * @see <a href="https://issues.apache.org/jira/browse/TIKA-341">TIKA-341</a> 
      */
     public void testUsingCharsetInContentTypeHeader() throws Exception {
-        // Could be UTF-8 or ISO 8859-1 or ...
+        // Could be ISO 8859-1 or ISO 8859-15 or ...
         // u00e1 is latin small letter a with acute
         final String test2 = "the name is \u00e1ndre";
 
         Metadata metadata = new Metadata();
         parser.parse(
-                new ByteArrayInputStream(test2.getBytes("UTF-8")),
+                new ByteArrayInputStream(test2.getBytes("ISO-8859-1")),
                 new BodyContentHandler(),  metadata, new ParseContext());
 
-        assertEquals("UTF-8", metadata.get(Metadata.CONTENT_ENCODING));
+        assertEquals("ISO-8859-1", metadata.get(Metadata.CONTENT_ENCODING));
 
         metadata = new Metadata();
-        metadata.set(Metadata.CONTENT_TYPE, "text/html; charset=ISO-8859-1");
+        metadata.set(Metadata.CONTENT_TYPE, "text/html; charset=ISO-8859-15");
         parser.parse(
                 new ByteArrayInputStream(test2.getBytes("ISO-8859-1")),
                 new BodyContentHandler(),  metadata, new ParseContext());
 
-        assertEquals("ISO-8859-1", metadata.get(Metadata.CONTENT_ENCODING));
+        assertEquals("ISO-8859-15", metadata.get(Metadata.CONTENT_ENCODING));
     }
 
     private void assertExtractText(String msg, String expected, byte[] input)

Commit:
929c8972a112ac75e5bec8120f0df5d7e5d5ec60
Jukka Zitting
jukka@apache.org
2012-07-07 21:30:54 +0000
TIKA-471: Avoid Charset name bottleneck when multiple threads are using HtmlParser
diff --git a/tika-core/src/main/java/org/apache/tika/detect/EncodingDetector.java b/tika-core/src/main/java/org/apache/tika/detect/EncodingDetector.java
new file mode 100644
index 000000000..458a23d08
--- /dev/null
+++ b/tika-core/src/main/java/org/apache/tika/detect/EncodingDetector.java
@@ -0,0 +1,57 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.detect;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.nio.charset.Charset;
+
+import org.apache.tika.metadata.Metadata;
+
+/**
+ * Character encoding detector. Implementations of this interface use
+ * various heuristics to detect the character encoding of a text document
+ * based on given input metadata or the first few bytes of the document stream.
+ *
+ * @since Apache Tika 0.4
+ */
+public interface EncodingDetector {
+
+    /**
+     * Detects the character encoding of the given text document, or
+     * <code>null</code> if the encoding of the document can not be detected.
+     * <p>
+     * If the document input stream is not available, then the first
+     * argument may be <code>null</code>. Otherwise the detector may
+     * read bytes from the start of the stream to help in encoding detection.
+     * The given stream is guaranteed to support the
+     * {@link InputStream#markSupported() mark feature} and the detector
+     * is expected to {@link InputStream#mark(int) mark} the stream before
+     * reading any bytes from it, and to {@link InputStream#reset() reset}
+     * the stream before returning. The stream must not be closed by the
+     * detector.
+     * <p>
+     * The given input metadata is only read, not modified, by the detector.
+     *
+     * @param input text document input stream, or <code>null</code>
+     * @param metadata input metadata for the document
+     * @return detected character encoding, or <code>null</code>
+     * @throws IOException if the document input stream could not be read
+     */
+    Charset detect(InputStream input, Metadata metadata) throws IOException;
+
+}
diff --git a/tika-core/src/main/java/org/apache/tika/detect/MagicDetector.java b/tika-core/src/main/java/org/apache/tika/detect/MagicDetector.java
index fff67f32e..753e04a41 100644
--- a/tika-core/src/main/java/org/apache/tika/detect/MagicDetector.java
+++ b/tika-core/src/main/java/org/apache/tika/detect/MagicDetector.java
@@ -36,6 +36,8 @@ import org.apache.tika.mime.MediaType;
  */
 public class MagicDetector implements Detector {
 
+    private static final Charset ISO_8859_1 = Charset.forName("ISO-8859-1");
+
     public static MagicDetector parse(
             MediaType mediaType,
             String type, String offset, String value, String mask) {
@@ -366,7 +368,7 @@ public class MagicDetector implements Detector {
                 Pattern p = Pattern.compile(new String(this.pattern));
 
                 ByteBuffer bb = ByteBuffer.wrap(buffer);
-                CharBuffer result = Charset.forName("ISO-8859-1").decode(bb);
+                CharBuffer result = ISO_8859_1.decode(bb);
                 Matcher m = p.matcher(result);
 
                 boolean match = false;
diff --git a/tika-core/src/main/java/org/apache/tika/utils/CharsetUtils.java b/tika-core/src/main/java/org/apache/tika/utils/CharsetUtils.java
index e1a093672..1088bcb22 100644
--- a/tika-core/src/main/java/org/apache/tika/utils/CharsetUtils.java
+++ b/tika-core/src/main/java/org/apache/tika/utils/CharsetUtils.java
@@ -21,11 +21,11 @@ import java.lang.reflect.Method;
 import java.nio.charset.Charset;
 import java.nio.charset.IllegalCharsetNameException;
 import java.util.HashMap;
+import java.util.Locale;
 import java.util.Map;
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 
-@SuppressWarnings("serial")
 public class CharsetUtils {
     private static final Pattern CHARSET_NAME_PATTERN = Pattern.compile("[ \\\"]*([^ >,;\\\"]+).*");
     private static final Pattern ISO_NAME_PATTERN = Pattern.compile("(?i).*8859-([\\d]+)");
@@ -34,17 +34,12 @@ public class CharsetUtils {
     
     // List of common invalid charset names that we can't fix using
     // pattern matching + heuristic
-    private static final Map<String, String> CHARSET_ALIASES = new HashMap<String, String>() {{
-        put("none", null);
-        put("no", null);
-        
-        put("iso-8851-1", "iso-8859-1");
-        
-        put("windows", "windows-1252");
-        
-        put("koi8r", "KOI8-R");
-    }};
-    
+    private static final Map<String, String> CHARSET_ALIASES =
+            new HashMap<String, String>();
+
+    private static final Map<String, Charset> STANDARD_CHARSETS =
+            new HashMap<String, Charset>();
+
     /**
      * Safely return whether <charsetName> is supported, without throwing exceptions
      * 
@@ -119,12 +114,24 @@ public class CharsetUtils {
     private static Method isSupportedICU;
 
     static {
+        CHARSET_ALIASES.put("none", null);
+        CHARSET_ALIASES.put("no", null);
+        CHARSET_ALIASES.put("iso-8851-1", "iso-8859-1");
+        CHARSET_ALIASES.put("windows", "windows-1252");
+        CHARSET_ALIASES.put("koi8r", "KOI8-R");
+
+        STANDARD_CHARSETS.put("US-ASCII", Charset.forName("US-ASCII"));
+        STANDARD_CHARSETS.put("ISO-8859-1", Charset.forName("ISO-8859-1"));
+        STANDARD_CHARSETS.put("UTF-8", Charset.forName("UTF-8"));
+        STANDARD_CHARSETS.put("UTF-16BE", Charset.forName("UTF-16BE"));
+        STANDARD_CHARSETS.put("UTF-16LE", Charset.forName("UTF-16LE"));
+        STANDARD_CHARSETS.put("UTF-16", Charset.forName("UTF-16"));
+
         // See if we can load the icu4j CharsetICU class
-        Class icuCharset = null;
+        Class<?> icuCharset = null;
         try  {
             icuCharset = CharsetUtils.class.getClassLoader().loadClass("com.ibm.icu.charset.CharsetICU");
-        } 
-        catch (ClassNotFoundException e)  {
+        }  catch (ClassNotFoundException e) {
         }
         if (icuCharset != null) {
             try {
@@ -146,6 +153,12 @@ public class CharsetUtils {
      *  if it is found on the classpath, else only uses
      *  JDK's builtin Charset.forName. */
     public static Charset forName(String name) {
+        Charset charset =
+                STANDARD_CHARSETS.get(name.toUpperCase(Locale.ENGLISH));
+        if (charset != null) {
+            return charset;
+        }
+
         if (getCharsetICU != null) {
             try {
                 Charset cs = (Charset) getCharsetICU.invoke(null, name);
@@ -156,6 +169,7 @@ public class CharsetUtils {
             } catch (IllegalAccessException iae) {
             }
         }
+
         return Charset.forName(name);
     }
 }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlParser.java
index fa56a03e6..91c926840 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlParser.java
@@ -113,16 +113,15 @@ public class HtmlParser extends AbstractParser {
 
         // No (valid) charset in a meta http-equiv tag, use other heuristics
         // to figure out the encoding
-        MediaType type =
-                DefaultEncodingDetector.INSTANCE.detect(stream, metadata);
-        String encoding = type.getParameters().get("charset");
-        if (encoding == null) {
-            if (Charset.isSupported(DEFAULT_CHARSET)) {
-                encoding = DEFAULT_CHARSET;
-            } else {
-                encoding = Charset.defaultCharset().name();
+        Charset charset = DefaultEncodingDetector.INSTANCE.detect(stream, metadata);
+        if (charset == null) {
+            try {
+                charset = CharsetUtils.forName(DEFAULT_CHARSET);
+            } catch (IllegalArgumentException e) {
+                charset = Charset.defaultCharset();
             }
         }
+        String encoding = charset.name();
         metadata.set(Metadata.CONTENT_ENCODING, encoding);
 
         return encoding;
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/txt/DefaultEncodingDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/txt/DefaultEncodingDetector.java
index 6b0fe2958..4dc8d796a 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/txt/DefaultEncodingDetector.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/txt/DefaultEncodingDetector.java
@@ -18,10 +18,14 @@ package org.apache.tika.parser.txt;
 
 import java.io.IOException;
 import java.io.InputStream;
+import java.nio.charset.Charset;
+import java.util.List;
 
 import org.apache.tika.config.ServiceLoader;
+import org.apache.tika.detect.EncodingDetector;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.mime.MediaType;
+import org.apache.tika.utils.CharsetUtils;
 
 public class DefaultEncodingDetector implements EncodingDetector {
 
@@ -29,22 +33,37 @@ public class DefaultEncodingDetector implements EncodingDetector {
             new DefaultEncodingDetector(new ServiceLoader(
                     DefaultEncodingDetector.class.getClassLoader()));
 
-    private final ServiceLoader loader;
+    private final List<EncodingDetector> detectors;
 
     public DefaultEncodingDetector(ServiceLoader loader) {
-        this.loader = loader;
+        this.detectors =
+                loader.loadStaticServiceProviders(EncodingDetector.class);
     }
 
-    public MediaType detect(InputStream input, Metadata metadata)
+    public Charset detect(InputStream input, Metadata metadata)
             throws IOException {
-        for (EncodingDetector detector
-                : loader.loadServiceProviders(EncodingDetector.class)) {
-            MediaType type = detector.detect(input, metadata);
-            if (!MediaType.OCTET_STREAM.equals(type)) {
-                return type;
+        // Check all available detectors
+        for (EncodingDetector detector : detectors) {
+            Charset charset = detector.detect(input, metadata);
+            if (charset != null) {
+                return charset;
             }
         }
-        return MediaType.OCTET_STREAM;
+
+        // Try determining the charset based on document metadata
+        MediaType type = MediaType.parse(metadata.get(Metadata.CONTENT_TYPE));
+        if (type != null) {
+            String charset = type.getParameters().get("charset");
+            if (charset != null) {
+                try {
+                    return CharsetUtils.forName(charset);
+                } catch (IllegalArgumentException e) {
+                    // ignore
+                }
+            }
+        }
+
+        return null;
     }
 
 }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/txt/EncodingDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/txt/EncodingDetector.java
deleted file mode 100644
index 731512eda..000000000
--- a/tika-parsers/src/main/java/org/apache/tika/parser/txt/EncodingDetector.java
+++ /dev/null
@@ -1,30 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.tika.parser.txt;
-
-import org.apache.tika.detect.Detector;
-
-/**
- * Interface for detecting the character encoding of a text document.
- * Implementation classes should respect the {@link Detector} contract
- * with the added precondition that the given document stream can be
- * expected to contain text instead of some non-text binary data.
- *
- * @since Tika 0.4
- */
-public interface EncodingDetector extends Detector {
-}
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/txt/Icu4jEncodingDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/txt/Icu4jEncodingDetector.java
index 019c33de7..92ca4431d 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/txt/Icu4jEncodingDetector.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/txt/Icu4jEncodingDetector.java
@@ -19,16 +19,20 @@ package org.apache.tika.parser.txt;
 import java.io.IOException;
 import java.io.InputStream;
 import java.nio.charset.Charset;
-import java.util.Collections;
 
+import org.apache.tika.detect.EncodingDetector;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.utils.CharsetUtils;
 
 public class Icu4jEncodingDetector implements EncodingDetector {
 
-    public MediaType detect(InputStream input, Metadata metadata)
+    public Charset detect(InputStream input, Metadata metadata)
             throws IOException {
+        if (input == null) {
+            return null;
+        }
+
         CharsetDetector detector = new CharsetDetector();
 
         String incomingCharset = metadata.get(Metadata.CONTENT_ENCODING);
@@ -52,14 +56,14 @@ public class Icu4jEncodingDetector implements EncodingDetector {
         detector.setText(input);
 
         for (CharsetMatch match : detector.detectAll()) {
-            if (Charset.isSupported(match.getName())) {
-                return new MediaType(
-                        MediaType.TEXT_PLAIN,
-                        Collections.singletonMap("charset", match.getName()));
+            try {
+                return CharsetUtils.forName(match.getName());
+            } catch (IllegalArgumentException e) {
+                // ignore
             }
         }
 
-        return MediaType.OCTET_STREAM;
+        return null;
     }
 
 }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/txt/TXTParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/txt/TXTParser.java
index e0b2c8793..24c6549a7 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/txt/TXTParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/txt/TXTParser.java
@@ -22,7 +22,7 @@ import java.io.IOException;
 import java.io.InputStream;
 import java.io.InputStreamReader;
 import java.io.Reader;
-import java.io.UnsupportedEncodingException;
+import java.nio.charset.Charset;
 import java.util.Collections;
 import java.util.Set;
 
@@ -73,11 +73,10 @@ public class TXTParser extends AbstractParser {
         // We need mark support for detecting the character encoding
         stream = new BufferedInputStream(stream);
 
-        MediaType type =
+        Charset charset =
                 DefaultEncodingDetector.INSTANCE.detect(stream, metadata);
-        String encoding = type.getParameters().get("charset");
-        if (encoding != null) {
-            metadata.set(Metadata.CONTENT_ENCODING, encoding);
+        if (charset != null) {
+            metadata.set(Metadata.CONTENT_ENCODING, charset.name());
         } else {
             throw new TikaException(
                     "Text encoding could not be detected and no encoding"
@@ -88,35 +87,30 @@ public class TXTParser extends AbstractParser {
         // use it to guess at the charset.
         metadata.set(Metadata.CONTENT_TYPE, "text/plain");
 
-        try {
-            Reader reader =
-                    new BufferedReader(new InputStreamReader(stream, encoding));
+        Reader reader =
+                new BufferedReader(new InputStreamReader(stream, charset));
 
-            // TIKA-240: Drop the BOM when extracting plain text
-            reader.mark(1);
-            int bom = reader.read();
-            if (bom != '\ufeff') { // zero-width no-break space
-                reader.reset();
-            }
+        // TIKA-240: Drop the BOM when extracting plain text
+        reader.mark(1);
+        int bom = reader.read();
+        if (bom != '\ufeff') { // zero-width no-break space
+            reader.reset();
+        }
 
-            XHTMLContentHandler xhtml =
+        XHTMLContentHandler xhtml =
                 new XHTMLContentHandler(handler, metadata);
-            xhtml.startDocument();
-
-            xhtml.startElement("p");
-            char[] buffer = new char[4096];
-            int n = reader.read(buffer);
-            while (n != -1) {
-                xhtml.characters(buffer, 0, n);
-                n = reader.read(buffer);
-            }
-            xhtml.endElement("p");
+        xhtml.startDocument();
 
-            xhtml.endDocument();
-        } catch (UnsupportedEncodingException e) {
-            throw new TikaException(
-                    "Unsupported text encoding: " + encoding, e);
+        xhtml.startElement("p");
+        char[] buffer = new char[4096];
+        int n = reader.read(buffer);
+        while (n != -1) {
+            xhtml.characters(buffer, 0, n);
+            n = reader.read(buffer);
         }
+        xhtml.endElement("p");
+
+        xhtml.endDocument();
     }
 
 }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/txt/UniversalEncodingDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/txt/UniversalEncodingDetector.java
index cb3417ca4..d7791bed8 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/txt/UniversalEncodingDetector.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/txt/UniversalEncodingDetector.java
@@ -18,10 +18,11 @@ package org.apache.tika.parser.txt;
 
 import java.io.IOException;
 import java.io.InputStream;
-import java.util.Collections;
+import java.nio.charset.Charset;
 
+import org.apache.tika.detect.EncodingDetector;
 import org.apache.tika.metadata.Metadata;
-import org.apache.tika.mime.MediaType;
+import org.apache.tika.utils.CharsetUtils;
 import org.mozilla.universalchardet.CharsetListener;
 import org.mozilla.universalchardet.Constants;
 import org.mozilla.universalchardet.UniversalDetector;
@@ -32,54 +33,47 @@ public class UniversalEncodingDetector implements EncodingDetector {
 
     private static final int LOOKAHEAD = 16 * BUFSIZE;
 
-    public MediaType detect(InputStream input, Metadata metadata)
+    public Charset detect(InputStream input, Metadata metadata)
             throws IOException {
         if (input == null) {
-            return MediaType.OCTET_STREAM;
+            return null;
         }
 
         Result result = new Result();
         UniversalDetector detector = new UniversalDetector(result);
 
         input.mark(LOOKAHEAD);
-        try {
-            byte[] b = new byte[BUFSIZE];
-            int n = 0;
-            int m = input.read(b);
-            while (m != -1 && n < LOOKAHEAD && !detector.isDone()) {
-                n += m;
-                detector.handleData(b, 0, m);
-                m = input.read(b, 0, Math.min(b.length, LOOKAHEAD - n));
-            }
-        } finally {
-            input.reset();
+        byte[] b = new byte[BUFSIZE];
+        int n = 0;
+        int m = input.read(b);
+        while (m != -1 && n < LOOKAHEAD && !detector.isDone()) {
+            n += m;
+            detector.handleData(b, 0, m);
+            m = input.read(b, 0, Math.min(b.length, LOOKAHEAD - n));
         }
+        input.reset();
 
         detector.dataEnd();
-
-        return result.getType();
+        return result.getCharset();
     }
 
     private static class Result implements CharsetListener {
 
-        private String charset = null;
+        private Charset charset = null;
 
         public void report(String charset) {
             if (Constants.CHARSET_WINDOWS_1252.equals(charset)) {
-                this.charset = "ISO-8859-1";
-            } else {
-                this.charset = charset;
+                charset = "ISO-8859-1";
+            }
+            try {
+                this.charset = CharsetUtils.forName(charset);
+            } catch (IllegalArgumentException e) {
+                // ignore
             }
         }
 
-        public MediaType getType() {
-            if (charset != null) {
-                return new MediaType(
-                        MediaType.TEXT_PLAIN,
-                        Collections.singletonMap("charset", charset));
-            } else {
-                return MediaType.OCTET_STREAM;
-            }
+        public Charset getCharset() {
+            return charset;
         }
 
     }
diff --git a/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.parser.txt.EncodingDetector b/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.detect.EncodingDetector
similarity index 100%
rename from tika-parsers/src/main/resources/META-INF/services/org.apache.tika.parser.txt.EncodingDetector
rename to tika-parsers/src/main/resources/META-INF/services/org.apache.tika.detect.EncodingDetector

Commit:
8756776cd711c78f7cbe9d2fd7688bbc97ae290c
Jukka Zitting
jukka@apache.org
2012-07-07 20:13:46 +0000
TIKA-322: Improve encoding detection speed and accuracy
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlParser.java
index ffaf5c42b..fa56a03e6 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlParser.java
@@ -34,8 +34,7 @@ import org.apache.tika.metadata.Metadata;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.parser.AbstractParser;
 import org.apache.tika.parser.ParseContext;
-import org.apache.tika.parser.txt.CharsetDetector;
-import org.apache.tika.parser.txt.CharsetMatch;
+import org.apache.tika.parser.txt.DefaultEncodingDetector;
 import org.apache.tika.utils.CharsetUtils;
 import org.ccil.cowan.tagsoup.HTMLSchema;
 import org.ccil.cowan.tagsoup.Schema;
@@ -102,70 +101,29 @@ public class HtmlParser extends AbstractParser {
                     String[] keyValue = attr.trim().split("=");
                     if ((keyValue.length == 2) && keyValue[0].equalsIgnoreCase("charset")) {
                         // TIKA-459: improve charset handling.
-                    	String charset = CharsetUtils.clean(keyValue[1]);
-                    	if (CharsetUtils.isSupported(charset)) {
-                    	    metadata.set(Metadata.CONTENT_ENCODING, charset);
-                    	    return charset;
-                    	}
+                        String charset = CharsetUtils.clean(keyValue[1]);
+                        if (CharsetUtils.isSupported(charset)) {
+                            metadata.set(Metadata.CONTENT_ENCODING, charset);
+                            return charset;
+                        }
                     }
                 }
             }
         }
 
-        // No (valid) charset in a meta http-equiv tag, see if it's in the passed content-encoding
-        // hint, or the passed content-type hint.
-        CharsetDetector detector = new CharsetDetector();
-        String incomingCharset = metadata.get(Metadata.CONTENT_ENCODING);
-        String incomingType = metadata.get(Metadata.CONTENT_TYPE);
-        if (incomingCharset == null && incomingType != null) {
-            // TIKA-341: Use charset in content-type
-            MediaType mt = MediaType.parse(incomingType);
-            if (mt != null) {
-                String charset = mt.getParameters().get("charset");
-                if ((charset != null) && Charset.isSupported(charset)) {
-                    incomingCharset = charset;
-                }
-            }
-        }
-
-        if (incomingCharset != null) {
-            detector.setDeclaredEncoding(incomingCharset);
-        }
-
-        // TIKA-341 without enabling input filtering (stripping of tags) the
-        // short HTML tests don't work well.
-        detector.enableInputFilter(true);
-        detector.setText(stream);
-        for (CharsetMatch match : detector.detectAll()) {
-            if (Charset.isSupported(match.getName())) {
-                metadata.set(Metadata.CONTENT_ENCODING, match.getName());
-
-                // TIKA-339: Don't set language, as it's typically not a very good
-                // guess, and it can create ambiguity if another (better) language
-                // value is specified by a meta tag in the HTML (or via HTTP response
-                // header).
-                /*
-                String language = match.getLanguage();
-                if (language != null) {
-                    metadata.set(Metadata.CONTENT_LANGUAGE, match.getLanguage());
-                    metadata.set(TikaCoreProperties.LANGUAGE, match.getLanguage());
-                }
-                */
-                
-                break;
-            }
-        }
-
-        String encoding = metadata.get(Metadata.CONTENT_ENCODING);
+        // No (valid) charset in a meta http-equiv tag, use other heuristics
+        // to figure out the encoding
+        MediaType type =
+                DefaultEncodingDetector.INSTANCE.detect(stream, metadata);
+        String encoding = type.getParameters().get("charset");
         if (encoding == null) {
             if (Charset.isSupported(DEFAULT_CHARSET)) {
                 encoding = DEFAULT_CHARSET;
             } else {
                 encoding = Charset.defaultCharset().name();
             }
-            
-            metadata.set(Metadata.CONTENT_ENCODING, encoding);
         }
+        metadata.set(Metadata.CONTENT_ENCODING, encoding);
 
         return encoding;
     }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/txt/DefaultEncodingDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/txt/DefaultEncodingDetector.java
new file mode 100644
index 000000000..6b0fe2958
--- /dev/null
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/txt/DefaultEncodingDetector.java
@@ -0,0 +1,50 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.parser.txt;
+
+import java.io.IOException;
+import java.io.InputStream;
+
+import org.apache.tika.config.ServiceLoader;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.mime.MediaType;
+
+public class DefaultEncodingDetector implements EncodingDetector {
+
+    public static final EncodingDetector INSTANCE =
+            new DefaultEncodingDetector(new ServiceLoader(
+                    DefaultEncodingDetector.class.getClassLoader()));
+
+    private final ServiceLoader loader;
+
+    public DefaultEncodingDetector(ServiceLoader loader) {
+        this.loader = loader;
+    }
+
+    public MediaType detect(InputStream input, Metadata metadata)
+            throws IOException {
+        for (EncodingDetector detector
+                : loader.loadServiceProviders(EncodingDetector.class)) {
+            MediaType type = detector.detect(input, metadata);
+            if (!MediaType.OCTET_STREAM.equals(type)) {
+                return type;
+            }
+        }
+        return MediaType.OCTET_STREAM;
+    }
+
+}
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/txt/EncodingDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/txt/EncodingDetector.java
index 8d52aa676..731512eda 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/txt/EncodingDetector.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/txt/EncodingDetector.java
@@ -1,4 +1,4 @@
-/**
+/*
  * Licensed to the Apache Software Foundation (ASF) under one or more
  * contributor license agreements.  See the NOTICE file distributed with
  * this work for additional information regarding copyright ownership.
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/txt/Icu4jEncodingDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/txt/Icu4jEncodingDetector.java
index fe1633509..019c33de7 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/txt/Icu4jEncodingDetector.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/txt/Icu4jEncodingDetector.java
@@ -23,6 +23,7 @@ import java.util.Collections;
 
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.mime.MediaType;
+import org.apache.tika.utils.CharsetUtils;
 
 public class Icu4jEncodingDetector implements EncodingDetector {
 
@@ -41,9 +42,13 @@ public class Icu4jEncodingDetector implements EncodingDetector {
         }
 
         if (incomingCharset != null) {
-            detector.setDeclaredEncoding(incomingCharset);
+            detector.setDeclaredEncoding(CharsetUtils.clean(incomingCharset));
         }
 
+        // TIKA-341 without enabling input filtering (stripping of tags)
+        // short HTML tests don't work well
+        detector.enableInputFilter(true);
+
         detector.setText(input);
 
         for (CharsetMatch match : detector.detectAll()) {
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/txt/TXTParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/txt/TXTParser.java
index cdca48eca..e0b2c8793 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/txt/TXTParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/txt/TXTParser.java
@@ -26,7 +26,6 @@ import java.io.UnsupportedEncodingException;
 import java.util.Collections;
 import java.util.Set;
 
-import org.apache.tika.config.ServiceLoader;
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.mime.MediaType;
@@ -74,7 +73,8 @@ public class TXTParser extends AbstractParser {
         // We need mark support for detecting the character encoding
         stream = new BufferedInputStream(stream);
 
-        MediaType type = detectEncoding(stream, metadata);
+        MediaType type =
+                DefaultEncodingDetector.INSTANCE.detect(stream, metadata);
         String encoding = type.getParameters().get("charset");
         if (encoding != null) {
             metadata.set(Metadata.CONTENT_ENCODING, encoding);
@@ -119,18 +119,4 @@ public class TXTParser extends AbstractParser {
         }
     }
 
-    private MediaType detectEncoding(InputStream stream, Metadata metadata)
-            throws IOException {
-        ServiceLoader loader =
-                new ServiceLoader(TXTParser.class.getClassLoader());
-        for (EncodingDetector detector
-                : loader.loadServiceProviders(EncodingDetector.class)) {
-            MediaType type = detector.detect(stream, metadata);
-            if (!MediaType.OCTET_STREAM.equals(type)) {
-                return type;
-            }
-        }
-        return MediaType.OCTET_STREAM;
-    }
-
 }
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/html/HtmlParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/html/HtmlParserTest.java
index 881f575ee..7f7e28add 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/html/HtmlParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/html/HtmlParserTest.java
@@ -280,7 +280,7 @@ public class HtmlParserTest extends TestCase {
         metadata = new Metadata();
         metadata.set(Metadata.CONTENT_TYPE, "text/html; charset=ISO-8859-1");
         new HtmlParser().parse (
-                new ByteArrayInputStream(test.getBytes("UTF-8")),
+                new ByteArrayInputStream(test.getBytes("ISO-8859-1")),
                 new BodyContentHandler(),  metadata, new ParseContext());
         assertEquals("ISO-8859-1", metadata.get(Metadata.CONTENT_ENCODING));
     }
@@ -366,7 +366,7 @@ public class HtmlParserTest extends TestCase {
         metadata = new Metadata();
         metadata.set(Metadata.CONTENT_TYPE, "charset=ISO-8859-1;text/html");
         new HtmlParser().parse (
-                new ByteArrayInputStream(test.getBytes("UTF-8")),
+                new ByteArrayInputStream(test.getBytes("ISO-8859-1")),
                 new BodyContentHandler(),  metadata, new ParseContext());
         assertEquals("ISO-8859-1", metadata.get(Metadata.CONTENT_ENCODING));
     }

Commit:
6bc0537b260d826bbfc6cf04d06963b86e230d72
Jukka Zitting
jukka@apache.org
2012-07-07 19:22:01 +0000
TIKA-322: Improve encoding detection speed and accuracy
diff --git a/tika-app/src/main/appended-resources/META-INF/LICENSE b/tika-app/src/main/appended-resources/META-INF/LICENSE
index cd323bbca..a92cacb69 100644
--- a/tika-app/src/main/appended-resources/META-INF/LICENSE
+++ b/tika-app/src/main/appended-resources/META-INF/LICENSE
@@ -423,3 +423,475 @@ XMPCore library (xmpcore)
     LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
     NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
     SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+juniversalchardet library (juniversalchardet)
+
+                              MOZILLA PUBLIC LICENSE
+                                    Version 1.1
+
+                                  ---------------
+
+    1. Definitions.
+
+         1.0.1. "Commercial Use" means distribution or otherwise making the
+         Covered Code available to a third party.
+
+         1.1. "Contributor" means each entity that creates or contributes to
+         the creation of Modifications.
+
+         1.2. "Contributor Version" means the combination of the Original
+         Code, prior Modifications used by a Contributor, and the Modifications
+         made by that particular Contributor.
+
+         1.3. "Covered Code" means the Original Code or Modifications or the
+         combination of the Original Code and Modifications, in each case
+         including portions thereof.
+
+         1.4. "Electronic Distribution Mechanism" means a mechanism generally
+         accepted in the software development community for the electronic
+         transfer of data.
+
+         1.5. "Executable" means Covered Code in any form other than Source
+         Code.
+
+         1.6. "Initial Developer" means the individual or entity identified
+         as the Initial Developer in the Source Code notice required by Exhibit
+         A.
+
+         1.7. "Larger Work" means a work which combines Covered Code or
+         portions thereof with code not governed by the terms of this License.
+
+         1.8. "License" means this document.
+
+         1.8.1. "Licensable" means having the right to grant, to the maximum
+         extent possible, whether at the time of the initial grant or
+         subsequently acquired, any and all of the rights conveyed herein.
+
+         1.9. "Modifications" means any addition to or deletion from the
+         substance or structure of either the Original Code or any previous
+         Modifications. When Covered Code is released as a series of files, a
+         Modification is:
+              A. Any addition to or deletion from the contents of a file
+              containing Original Code or previous Modifications.
+
+              B. Any new file that contains any part of the Original Code or
+              previous Modifications.
+
+         1.10. "Original Code" means Source Code of computer software code
+         which is described in the Source Code notice required by Exhibit A as
+         Original Code, and which, at the time of its release under this
+         License is not already Covered Code governed by this License.
+
+         1.10.1. "Patent Claims" means any patent claim(s), now owned or
+         hereafter acquired, including without limitation,  method, process,
+         and apparatus claims, in any patent Licensable by grantor.
+
+         1.11. "Source Code" means the preferred form of the Covered Code for
+         making modifications to it, including all modules it contains, plus
+         any associated interface definition files, scripts used to control
+         compilation and installation of an Executable, or source code
+         differential comparisons against either the Original Code or another
+         well known, available Covered Code of the Contributor's choice. The
+         Source Code can be in a compressed or archival form, provided the
+         appropriate decompression or de-archiving software is widely available
+         for no charge.
+
+         1.12. "You" (or "Your")  means an individual or a legal entity
+         exercising rights under, and complying with all of the terms of, this
+         License or a future version of this License issued under Section 6.1.
+         For legal entities, "You" includes any entity which controls, is
+         controlled by, or is under common control with You. For purposes of
+         this definition, "control" means (a) the power, direct or indirect,
+         to cause the direction or management of such entity, whether by
+         contract or otherwise, or (b) ownership of more than fifty percent
+         (50%) of the outstanding shares or beneficial ownership of such
+         entity.
+
+    2. Source Code License.
+
+         2.1. The Initial Developer Grant.
+         The Initial Developer hereby grants You a world-wide, royalty-free,
+         non-exclusive license, subject to third party intellectual property
+         claims:
+              (a)  under intellectual property rights (other than patent or
+              trademark) Licensable by Initial Developer to use, reproduce,
+              modify, display, perform, sublicense and distribute the Original
+              Code (or portions thereof) with or without Modifications, and/or
+              as part of a Larger Work; and
+
+              (b) under Patents Claims infringed by the making, using or
+              selling of Original Code, to make, have made, use, practice,
+              sell, and offer for sale, and/or otherwise dispose of the
+              Original Code (or portions thereof).
+
+              (c) the licenses granted in this Section 2.1(a) and (b) are
+              effective on the date Initial Developer first distributes
+              Original Code under the terms of this License.
+
+              (d) Notwithstanding Section 2.1(b) above, no patent license is
+              granted: 1) for code that You delete from the Original Code; 2)
+              separate from the Original Code;  or 3) for infringements caused
+              by: i) the modification of the Original Code or ii) the
+              combination of the Original Code with other software or devices.
+
+         2.2. Contributor Grant.
+         Subject to third party intellectual property claims, each Contributor
+         hereby grants You a world-wide, royalty-free, non-exclusive license
+
+              (a)  under intellectual property rights (other than patent or
+              trademark) Licensable by Contributor, to use, reproduce, modify,
+              display, perform, sublicense and distribute the Modifications
+              created by such Contributor (or portions thereof) either on an
+              unmodified basis, with other Modifications, as Covered Code
+              and/or as part of a Larger Work; and
+
+              (b) under Patent Claims infringed by the making, using, or
+              selling of  Modifications made by that Contributor either alone
+              and/or in combination with its Contributor Version (or portions
+              of such combination), to make, use, sell, offer for sale, have
+              made, and/or otherwise dispose of: 1) Modifications made by that
+              Contributor (or portions thereof); and 2) the combination of
+              Modifications made by that Contributor with its Contributor
+              Version (or portions of such combination).
+
+              (c) the licenses granted in Sections 2.2(a) and 2.2(b) are
+              effective on the date Contributor first makes Commercial Use of
+              the Covered Code.
+
+              (d)    Notwithstanding Section 2.2(b) above, no patent license is
+              granted: 1) for any code that Contributor has deleted from the
+              Contributor Version; 2)  separate from the Contributor Version;
+              3)  for infringements caused by: i) third party modifications of
+              Contributor Version or ii)  the combination of Modifications made
+              by that Contributor with other software  (except as part of the
+              Contributor Version) or other devices; or 4) under Patent Claims
+              infringed by Covered Code in the absence of Modifications made by
+              that Contributor.
+
+    3. Distribution Obligations.
+
+         3.1. Application of License.
+         The Modifications which You create or to which You contribute are
+         governed by the terms of this License, including without limitation
+         Section 2.2. The Source Code version of Covered Code may be
+         distributed only under the terms of this License or a future version
+         of this License released under Section 6.1, and You must include a
+         copy of this License with every copy of the Source Code You
+         distribute. You may not offer or impose any terms on any Source Code
+         version that alters or restricts the applicable version of this
+         License or the recipients' rights hereunder. However, You may include
+         an additional document offering the additional rights described in
+         Section 3.5.
+
+         3.2. Availability of Source Code.
+         Any Modification which You create or to which You contribute must be
+         made available in Source Code form under the terms of this License
+         either on the same media as an Executable version or via an accepted
+         Electronic Distribution Mechanism to anyone to whom you made an
+         Executable version available; and if made available via Electronic
+         Distribution Mechanism, must remain available for at least twelve (12)
+         months after the date it initially became available, or at least six
+         (6) months after a subsequent version of that particular Modification
+         has been made available to such recipients. You are responsible for
+         ensuring that the Source Code version remains available even if the
+         Electronic Distribution Mechanism is maintained by a third party.
+
+         3.3. Description of Modifications.
+         You must cause all Covered Code to which You contribute to contain a
+         file documenting the changes You made to create that Covered Code and
+         the date of any change. You must include a prominent statement that
+         the Modification is derived, directly or indirectly, from Original
+         Code provided by the Initial Developer and including the name of the
+         Initial Developer in (a) the Source Code, and (b) in any notice in an
+         Executable version or related documentation in which You describe the
+         origin or ownership of the Covered Code.
+
+         3.4. Intellectual Property Matters
+              (a) Third Party Claims.
+              If Contributor has knowledge that a license under a third party's
+              intellectual property rights is required to exercise the rights
+              granted by such Contributor under Sections 2.1 or 2.2,
+              Contributor must include a text file with the Source Code
+              distribution titled "LEGAL" which describes the claim and the
+              party making the claim in sufficient detail that a recipient will
+              know whom to contact. If Contributor obtains such knowledge after
+              the Modification is made available as described in Section 3.2,
+              Contributor shall promptly modify the LEGAL file in all copies
+              Contributor makes available thereafter and shall take other steps
+              (such as notifying appropriate mailing lists or newsgroups)
+              reasonably calculated to inform those who received the Covered
+              Code that new knowledge has been obtained.
+
+              (b) Contributor APIs.
+              If Contributor's Modifications include an application programming
+              interface and Contributor has knowledge of patent licenses which
+              are reasonably necessary to implement that API, Contributor must
+              also include this information in the LEGAL file.
+
+                   (c)    Representations.
+              Contributor represents that, except as disclosed pursuant to
+              Section 3.4(a) above, Contributor believes that Contributor's
+              Modifications are Contributor's original creation(s) and/or
+              Contributor has sufficient rights to grant the rights conveyed by
+              this License.
+
+         3.5. Required Notices.
+         You must duplicate the notice in Exhibit A in each file of the Source
+         Code.  If it is not possible to put such notice in a particular Source
+         Code file due to its structure, then You must include such notice in a
+         location (such as a relevant directory) where a user would be likely
+         to look for such a notice.  If You created one or more Modification(s)
+         You may add your name as a Contributor to the notice described in
+         Exhibit A.  You must also duplicate this License in any documentation
+         for the Source Code where You describe recipients' rights or ownership
+         rights relating to Covered Code.  You may choose to offer, and to
+         charge a fee for, warranty, support, indemnity or liability
+         obligations to one or more recipients of Covered Code. However, You
+         may do so only on Your own behalf, and not on behalf of the Initial
+         Developer or any Contributor. You must make it absolutely clear than
+         any such warranty, support, indemnity or liability obligation is
+         offered by You alone, and You hereby agree to indemnify the Initial
+         Developer and every Contributor for any liability incurred by the
+         Initial Developer or such Contributor as a result of warranty,
+         support, indemnity or liability terms You offer.
+
+         3.6. Distribution of Executable Versions.
+         You may distribute Covered Code in Executable form only if the
+         requirements of Section 3.1-3.5 have been met for that Covered Code,
+         and if You include a notice stating that the Source Code version of
+         the Covered Code is available under the terms of this License,
+         including a description of how and where You have fulfilled the
+         obligations of Section 3.2. The notice must be conspicuously included
+         in any notice in an Executable version, related documentation or
+         collateral in which You describe recipients' rights relating to the
+         Covered Code. You may distribute the Executable version of Covered
+         Code or ownership rights under a license of Your choice, which may
+         contain terms different from this License, provided that You are in
+         compliance with the terms of this License and that the license for the
+         Executable version does not attempt to limit or alter the recipient's
+         rights in the Source Code version from the rights set forth in this
+         License. If You distribute the Executable version under a different
+         license You must make it absolutely clear that any terms which differ
+         from this License are offered by You alone, not by the Initial
+         Developer or any Contributor. You hereby agree to indemnify the
+         Initial Developer and every Contributor for any liability incurred by
+         the Initial Developer or such Contributor as a result of any such
+         terms You offer.
+
+         3.7. Larger Works.
+         You may create a Larger Work by combining Covered Code with other code
+         not governed by the terms of this License and distribute the Larger
+         Work as a single product. In such a case, You must make sure the
+         requirements of this License are fulfilled for the Covered Code.
+
+    4. Inability to Comply Due to Statute or Regulation.
+
+         If it is impossible for You to comply with any of the terms of this
+         License with respect to some or all of the Covered Code due to
+         statute, judicial order, or regulation then You must: (a) comply with
+         the terms of this License to the maximum extent possible; and (b)
+         describe the limitations and the code they affect. Such description
+         must be included in the LEGAL file described in Section 3.4 and must
+         be included with all distributions of the Source Code. Except to the
+         extent prohibited by statute or regulation, such description must be
+         sufficiently detailed for a recipient of ordinary skill to be able to
+         understand it.
+
+    5. Application of this License.
+
+         This License applies to code to which the Initial Developer has
+         attached the notice in Exhibit A and to related Covered Code.
+
+    6. Versions of the License.
+
+         6.1. New Versions.
+         Netscape Communications Corporation ("Netscape") may publish revised
+         and/or new versions of the License from time to time. Each version
+         will be given a distinguishing version number.
+
+         6.2. Effect of New Versions.
+         Once Covered Code has been published under a particular version of the
+         License, You may always continue to use it under the terms of that
+         version. You may also choose to use such Covered Code under the terms
+         of any subsequent version of the License published by Netscape. No one
+         other than Netscape has the right to modify the terms applicable to
+         Covered Code created under this License.
+
+         6.3. Derivative Works.
+         If You create or use a modified version of this License (which you may
+         only do in order to apply it to code which is not already Covered Code
+         governed by this License), You must (a) rename Your license so that
+         the phrases "Mozilla", "MOZILLAPL", "MOZPL", "Netscape",
+         "MPL", "NPL" or any confusingly similar phrase do not appear in your
+         license (except to note that your license differs from this License)
+         and (b) otherwise make it clear that Your version of the license
+         contains terms which differ from the Mozilla Public License and
+         Netscape Public License. (Filling in the name of the Initial
+         Developer, Original Code or Contributor in the notice described in
+         Exhibit A shall not of themselves be deemed to be modifications of
+         this License.)
+
+    7. DISCLAIMER OF WARRANTY.
+
+         COVERED CODE IS PROVIDED UNDER THIS LICENSE ON AN "AS IS" BASIS,
+         WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING,
+         WITHOUT LIMITATION, WARRANTIES THAT THE COVERED CODE IS FREE OF
+         DEFECTS, MERCHANTABLE, FIT FOR A PARTICULAR PURPOSE OR NON-INFRINGING.
+         THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE COVERED CODE
+         IS WITH YOU. SHOULD ANY COVERED CODE PROVE DEFECTIVE IN ANY RESPECT,
+         YOU (NOT THE INITIAL DEVELOPER OR ANY OTHER CONTRIBUTOR) ASSUME THE
+         COST OF ANY NECESSARY SERVICING, REPAIR OR CORRECTION. THIS DISCLAIMER
+         OF WARRANTY CONSTITUTES AN ESSENTIAL PART OF THIS LICENSE. NO USE OF
+         ANY COVERED CODE IS AUTHORIZED HEREUNDER EXCEPT UNDER THIS DISCLAIMER.
+
+    8. TERMINATION.
+
+         8.1.  This License and the rights granted hereunder will terminate
+         automatically if You fail to comply with terms herein and fail to cure
+         such breach within 30 days of becoming aware of the breach. All
+         sublicenses to the Covered Code which are properly granted shall
+         survive any termination of this License. Provisions which, by their
+         nature, must remain in effect beyond the termination of this License
+         shall survive.
+
+         8.2.  If You initiate litigation by asserting a patent infringement
+         claim (excluding declatory judgment actions) against Initial Developer
+         or a Contributor (the Initial Developer or Contributor against whom
+         You file such action is referred to as "Participant")  alleging that:
+
+         (a)  such Participant's Contributor Version directly or indirectly
+         infringes any patent, then any and all rights granted by such
+         Participant to You under Sections 2.1 and/or 2.2 of this License
+         shall, upon 60 days notice from Participant terminate prospectively,
+         unless if within 60 days after receipt of notice You either: (i)
+         agree in writing to pay Participant a mutually agreeable reasonable
+         royalty for Your past and future use of Modifications made by such
+         Participant, or (ii) withdraw Your litigation claim with respect to
+         the Contributor Version against such Participant.  If within 60 days
+         of notice, a reasonable royalty and payment arrangement are not
+         mutually agreed upon in writing by the parties or the litigation claim
+         is not withdrawn, the rights granted by Participant to You under
+         Sections 2.1 and/or 2.2 automatically terminate at the expiration of
+         the 60 day notice period specified above.
+
+         (b)  any software, hardware, or device, other than such Participant's
+         Contributor Version, directly or indirectly infringes any patent, then
+         any rights granted to You by such Participant under Sections 2.1(b)
+         and 2.2(b) are revoked effective as of the date You first made, used,
+         sold, distributed, or had made, Modifications made by that
+         Participant.
+
+         8.3.  If You assert a patent infringement claim against Participant
+         alleging that such Participant's Contributor Version directly or
+         indirectly infringes any patent where such claim is resolved (such as
+         by license or settlement) prior to the initiation of patent
+         infringement litigation, then the reasonable value of the licenses
+         granted by such Participant under Sections 2.1 or 2.2 shall be taken
+         into account in determining the amount or value of any payment or
+         license.
+
+         8.4.  In the event of termination under Sections 8.1 or 8.2 above,
+         all end user license agreements (excluding distributors and resellers)
+         which have been validly granted by You or any distributor hereunder
+         prior to termination shall survive termination.
+
+    9. LIMITATION OF LIABILITY.
+
+         UNDER NO CIRCUMSTANCES AND UNDER NO LEGAL THEORY, WHETHER TORT
+         (INCLUDING NEGLIGENCE), CONTRACT, OR OTHERWISE, SHALL YOU, THE INITIAL
+         DEVELOPER, ANY OTHER CONTRIBUTOR, OR ANY DISTRIBUTOR OF COVERED CODE,
+         OR ANY SUPPLIER OF ANY OF SUCH PARTIES, BE LIABLE TO ANY PERSON FOR
+         ANY INDIRECT, SPECIAL, INCIDENTAL, OR CONSEQUENTIAL DAMAGES OF ANY
+         CHARACTER INCLUDING, WITHOUT LIMITATION, DAMAGES FOR LOSS OF GOODWILL,
+         WORK STOPPAGE, COMPUTER FAILURE OR MALFUNCTION, OR ANY AND ALL OTHER
+         COMMERCIAL DAMAGES OR LOSSES, EVEN IF SUCH PARTY SHALL HAVE BEEN
+         INFORMED OF THE POSSIBILITY OF SUCH DAMAGES. THIS LIMITATION OF
+         LIABILITY SHALL NOT APPLY TO LIABILITY FOR DEATH OR PERSONAL INJURY
+         RESULTING FROM SUCH PARTY'S NEGLIGENCE TO THE EXTENT APPLICABLE LAW
+         PROHIBITS SUCH LIMITATION. SOME JURISDICTIONS DO NOT ALLOW THE
+         EXCLUSION OR LIMITATION OF INCIDENTAL OR CONSEQUENTIAL DAMAGES, SO
+         THIS EXCLUSION AND LIMITATION MAY NOT APPLY TO YOU.
+
+    10. U.S. GOVERNMENT END USERS.
+
+         The Covered Code is a "commercial item," as that term is defined in
+         48 C.F.R. 2.101 (Oct. 1995), consisting of "commercial computer
+         software" and "commercial computer software documentation," as such
+         terms are used in 48 C.F.R. 12.212 (Sept. 1995). Consistent with 48
+         C.F.R. 12.212 and 48 C.F.R. 227.7202-1 through 227.7202-4 (June 1995),
+         all U.S. Government End Users acquire Covered Code with only those
+         rights set forth herein.
+
+    11. MISCELLANEOUS.
+
+         This License represents the complete agreement concerning subject
+         matter hereof. If any provision of this License is held to be
+         unenforceable, such provision shall be reformed only to the extent
+         necessary to make it enforceable. This License shall be governed by
+         California law provisions (except to the extent applicable law, if
+         any, provides otherwise), excluding its conflict-of-law provisions.
+         With respect to disputes in which at least one party is a citizen of,
+         or an entity chartered or registered to do business in the United
+         States of America, any litigation relating to this License shall be
+         subject to the jurisdiction of the Federal Courts of the Northern
+         District of California, with venue lying in Santa Clara County,
+         California, with the losing party responsible for costs, including
+         without limitation, court costs and reasonable attorneys' fees and
+         expenses. The application of the United Nations Convention on
+         Contracts for the International Sale of Goods is expressly excluded.
+         Any law or regulation which provides that the language of a contract
+         shall be construed against the drafter shall not apply to this
+         License.
+
+    12. RESPONSIBILITY FOR CLAIMS.
+
+         As between Initial Developer and the Contributors, each party is
+         responsible for claims and damages arising, directly or indirectly,
+         out of its utilization of rights under this License and You agree to
+         work with Initial Developer and Contributors to distribute such
+         responsibility on an equitable basis. Nothing herein is intended or
+         shall be deemed to constitute any admission of liability.
+
+    13. MULTIPLE-LICENSED CODE.
+
+         Initial Developer may designate portions of the Covered Code as
+         "Multiple-Licensed".  "Multiple-Licensed" means that the Initial
+         Developer permits you to utilize portions of the Covered Code under
+         Your choice of the NPL or the alternative licenses, if any, specified
+         by the Initial Developer in the file described in Exhibit A.
+
+    EXHIBIT A -Mozilla Public License.
+
+         ``The contents of this file are subject to the Mozilla Public License
+         Version 1.1 (the "License"); you may not use this file except in
+         compliance with the License. You may obtain a copy of the License at
+         http://www.mozilla.org/MPL/
+
+         Software distributed under the License is distributed on an "AS IS"
+         basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
+         License for the specific language governing rights and limitations
+         under the License.
+
+         The Original Code is ______________________________________.
+
+         The Initial Developer of the Original Code is ________________________.
+         Portions created by ______________________ are Copyright (C) ______
+         _______________________. All Rights Reserved.
+
+         Contributor(s): ______________________________________.
+
+         Alternatively, the contents of this file may be used under the terms
+         of the _____ license (the  "[___] License"), in which case the
+         provisions of [______] License are applicable instead of those
+         above.  If you wish to allow use of your version of this file only
+         under the terms of the [____] License and not to allow others to use
+         your version of this file under the MPL, indicate your decision by
+         deleting  the provisions above and replace  them with the notice and
+         other provisions required by the [___] License.  If you do not delete
+         the provisions above, a recipient may use your version of this file
+         under either the MPL or the [___] License."
+
+         [NOTE: The text of this Exhibit A may differ slightly from the text of
+         the notices in the Source Code files of the Original Code. You should
+         use the text of this Exhibit A rather than the text found in the
+         Original Code Source Code for Your Modifications.]
diff --git a/tika-bundle/pom.xml b/tika-bundle/pom.xml
index a3a4b3915..6fd28e69f 100644
--- a/tika-bundle/pom.xml
+++ b/tika-bundle/pom.xml
@@ -119,7 +119,8 @@
               poi,poi-scratchpad,poi-ooxml,poi-ooxml-schemas,
               xmlbeans, dom4j,
               tagsoup,
-              asm, 
+              asm,
+              juniversalchardet,
               vorbis-java-core, vorbis-java-tika,
               isoparser, aspectjrt,
               metadata-extractor,
diff --git a/tika-bundle/src/main/appended-resources/META-INF/LICENSE b/tika-bundle/src/main/appended-resources/META-INF/LICENSE
index 86803f2e9..b8ee2cbdc 100644
--- a/tika-bundle/src/main/appended-resources/META-INF/LICENSE
+++ b/tika-bundle/src/main/appended-resources/META-INF/LICENSE
@@ -391,3 +391,475 @@ XZ compression library (xz)
     public domain. You can do whatever you want with these files.
 
     This software is provided "as is", without any warranty.
+
+juniversalchardet library (juniversalchardet)
+
+                              MOZILLA PUBLIC LICENSE
+                                    Version 1.1
+
+                                  ---------------
+
+    1. Definitions.
+
+         1.0.1. "Commercial Use" means distribution or otherwise making the
+         Covered Code available to a third party.
+
+         1.1. "Contributor" means each entity that creates or contributes to
+         the creation of Modifications.
+
+         1.2. "Contributor Version" means the combination of the Original
+         Code, prior Modifications used by a Contributor, and the Modifications
+         made by that particular Contributor.
+
+         1.3. "Covered Code" means the Original Code or Modifications or the
+         combination of the Original Code and Modifications, in each case
+         including portions thereof.
+
+         1.4. "Electronic Distribution Mechanism" means a mechanism generally
+         accepted in the software development community for the electronic
+         transfer of data.
+
+         1.5. "Executable" means Covered Code in any form other than Source
+         Code.
+
+         1.6. "Initial Developer" means the individual or entity identified
+         as the Initial Developer in the Source Code notice required by Exhibit
+         A.
+
+         1.7. "Larger Work" means a work which combines Covered Code or
+         portions thereof with code not governed by the terms of this License.
+
+         1.8. "License" means this document.
+
+         1.8.1. "Licensable" means having the right to grant, to the maximum
+         extent possible, whether at the time of the initial grant or
+         subsequently acquired, any and all of the rights conveyed herein.
+
+         1.9. "Modifications" means any addition to or deletion from the
+         substance or structure of either the Original Code or any previous
+         Modifications. When Covered Code is released as a series of files, a
+         Modification is:
+              A. Any addition to or deletion from the contents of a file
+              containing Original Code or previous Modifications.
+
+              B. Any new file that contains any part of the Original Code or
+              previous Modifications.
+
+         1.10. "Original Code" means Source Code of computer software code
+         which is described in the Source Code notice required by Exhibit A as
+         Original Code, and which, at the time of its release under this
+         License is not already Covered Code governed by this License.
+
+         1.10.1. "Patent Claims" means any patent claim(s), now owned or
+         hereafter acquired, including without limitation,  method, process,
+         and apparatus claims, in any patent Licensable by grantor.
+
+         1.11. "Source Code" means the preferred form of the Covered Code for
+         making modifications to it, including all modules it contains, plus
+         any associated interface definition files, scripts used to control
+         compilation and installation of an Executable, or source code
+         differential comparisons against either the Original Code or another
+         well known, available Covered Code of the Contributor's choice. The
+         Source Code can be in a compressed or archival form, provided the
+         appropriate decompression or de-archiving software is widely available
+         for no charge.
+
+         1.12. "You" (or "Your")  means an individual or a legal entity
+         exercising rights under, and complying with all of the terms of, this
+         License or a future version of this License issued under Section 6.1.
+         For legal entities, "You" includes any entity which controls, is
+         controlled by, or is under common control with You. For purposes of
+         this definition, "control" means (a) the power, direct or indirect,
+         to cause the direction or management of such entity, whether by
+         contract or otherwise, or (b) ownership of more than fifty percent
+         (50%) of the outstanding shares or beneficial ownership of such
+         entity.
+
+    2. Source Code License.
+
+         2.1. The Initial Developer Grant.
+         The Initial Developer hereby grants You a world-wide, royalty-free,
+         non-exclusive license, subject to third party intellectual property
+         claims:
+              (a)  under intellectual property rights (other than patent or
+              trademark) Licensable by Initial Developer to use, reproduce,
+              modify, display, perform, sublicense and distribute the Original
+              Code (or portions thereof) with or without Modifications, and/or
+              as part of a Larger Work; and
+
+              (b) under Patents Claims infringed by the making, using or
+              selling of Original Code, to make, have made, use, practice,
+              sell, and offer for sale, and/or otherwise dispose of the
+              Original Code (or portions thereof).
+
+              (c) the licenses granted in this Section 2.1(a) and (b) are
+              effective on the date Initial Developer first distributes
+              Original Code under the terms of this License.
+
+              (d) Notwithstanding Section 2.1(b) above, no patent license is
+              granted: 1) for code that You delete from the Original Code; 2)
+              separate from the Original Code;  or 3) for infringements caused
+              by: i) the modification of the Original Code or ii) the
+              combination of the Original Code with other software or devices.
+
+         2.2. Contributor Grant.
+         Subject to third party intellectual property claims, each Contributor
+         hereby grants You a world-wide, royalty-free, non-exclusive license
+
+              (a)  under intellectual property rights (other than patent or
+              trademark) Licensable by Contributor, to use, reproduce, modify,
+              display, perform, sublicense and distribute the Modifications
+              created by such Contributor (or portions thereof) either on an
+              unmodified basis, with other Modifications, as Covered Code
+              and/or as part of a Larger Work; and
+
+              (b) under Patent Claims infringed by the making, using, or
+              selling of  Modifications made by that Contributor either alone
+              and/or in combination with its Contributor Version (or portions
+              of such combination), to make, use, sell, offer for sale, have
+              made, and/or otherwise dispose of: 1) Modifications made by that
+              Contributor (or portions thereof); and 2) the combination of
+              Modifications made by that Contributor with its Contributor
+              Version (or portions of such combination).
+
+              (c) the licenses granted in Sections 2.2(a) and 2.2(b) are
+              effective on the date Contributor first makes Commercial Use of
+              the Covered Code.
+
+              (d)    Notwithstanding Section 2.2(b) above, no patent license is
+              granted: 1) for any code that Contributor has deleted from the
+              Contributor Version; 2)  separate from the Contributor Version;
+              3)  for infringements caused by: i) third party modifications of
+              Contributor Version or ii)  the combination of Modifications made
+              by that Contributor with other software  (except as part of the
+              Contributor Version) or other devices; or 4) under Patent Claims
+              infringed by Covered Code in the absence of Modifications made by
+              that Contributor.
+
+    3. Distribution Obligations.
+
+         3.1. Application of License.
+         The Modifications which You create or to which You contribute are
+         governed by the terms of this License, including without limitation
+         Section 2.2. The Source Code version of Covered Code may be
+         distributed only under the terms of this License or a future version
+         of this License released under Section 6.1, and You must include a
+         copy of this License with every copy of the Source Code You
+         distribute. You may not offer or impose any terms on any Source Code
+         version that alters or restricts the applicable version of this
+         License or the recipients' rights hereunder. However, You may include
+         an additional document offering the additional rights described in
+         Section 3.5.
+
+         3.2. Availability of Source Code.
+         Any Modification which You create or to which You contribute must be
+         made available in Source Code form under the terms of this License
+         either on the same media as an Executable version or via an accepted
+         Electronic Distribution Mechanism to anyone to whom you made an
+         Executable version available; and if made available via Electronic
+         Distribution Mechanism, must remain available for at least twelve (12)
+         months after the date it initially became available, or at least six
+         (6) months after a subsequent version of that particular Modification
+         has been made available to such recipients. You are responsible for
+         ensuring that the Source Code version remains available even if the
+         Electronic Distribution Mechanism is maintained by a third party.
+
+         3.3. Description of Modifications.
+         You must cause all Covered Code to which You contribute to contain a
+         file documenting the changes You made to create that Covered Code and
+         the date of any change. You must include a prominent statement that
+         the Modification is derived, directly or indirectly, from Original
+         Code provided by the Initial Developer and including the name of the
+         Initial Developer in (a) the Source Code, and (b) in any notice in an
+         Executable version or related documentation in which You describe the
+         origin or ownership of the Covered Code.
+
+         3.4. Intellectual Property Matters
+              (a) Third Party Claims.
+              If Contributor has knowledge that a license under a third party's
+              intellectual property rights is required to exercise the rights
+              granted by such Contributor under Sections 2.1 or 2.2,
+              Contributor must include a text file with the Source Code
+              distribution titled "LEGAL" which describes the claim and the
+              party making the claim in sufficient detail that a recipient will
+              know whom to contact. If Contributor obtains such knowledge after
+              the Modification is made available as described in Section 3.2,
+              Contributor shall promptly modify the LEGAL file in all copies
+              Contributor makes available thereafter and shall take other steps
+              (such as notifying appropriate mailing lists or newsgroups)
+              reasonably calculated to inform those who received the Covered
+              Code that new knowledge has been obtained.
+
+              (b) Contributor APIs.
+              If Contributor's Modifications include an application programming
+              interface and Contributor has knowledge of patent licenses which
+              are reasonably necessary to implement that API, Contributor must
+              also include this information in the LEGAL file.
+
+                   (c)    Representations.
+              Contributor represents that, except as disclosed pursuant to
+              Section 3.4(a) above, Contributor believes that Contributor's
+              Modifications are Contributor's original creation(s) and/or
+              Contributor has sufficient rights to grant the rights conveyed by
+              this License.
+
+         3.5. Required Notices.
+         You must duplicate the notice in Exhibit A in each file of the Source
+         Code.  If it is not possible to put such notice in a particular Source
+         Code file due to its structure, then You must include such notice in a
+         location (such as a relevant directory) where a user would be likely
+         to look for such a notice.  If You created one or more Modification(s)
+         You may add your name as a Contributor to the notice described in
+         Exhibit A.  You must also duplicate this License in any documentation
+         for the Source Code where You describe recipients' rights or ownership
+         rights relating to Covered Code.  You may choose to offer, and to
+         charge a fee for, warranty, support, indemnity or liability
+         obligations to one or more recipients of Covered Code. However, You
+         may do so only on Your own behalf, and not on behalf of the Initial
+         Developer or any Contributor. You must make it absolutely clear than
+         any such warranty, support, indemnity or liability obligation is
+         offered by You alone, and You hereby agree to indemnify the Initial
+         Developer and every Contributor for any liability incurred by the
+         Initial Developer or such Contributor as a result of warranty,
+         support, indemnity or liability terms You offer.
+
+         3.6. Distribution of Executable Versions.
+         You may distribute Covered Code in Executable form only if the
+         requirements of Section 3.1-3.5 have been met for that Covered Code,
+         and if You include a notice stating that the Source Code version of
+         the Covered Code is available under the terms of this License,
+         including a description of how and where You have fulfilled the
+         obligations of Section 3.2. The notice must be conspicuously included
+         in any notice in an Executable version, related documentation or
+         collateral in which You describe recipients' rights relating to the
+         Covered Code. You may distribute the Executable version of Covered
+         Code or ownership rights under a license of Your choice, which may
+         contain terms different from this License, provided that You are in
+         compliance with the terms of this License and that the license for the
+         Executable version does not attempt to limit or alter the recipient's
+         rights in the Source Code version from the rights set forth in this
+         License. If You distribute the Executable version under a different
+         license You must make it absolutely clear that any terms which differ
+         from this License are offered by You alone, not by the Initial
+         Developer or any Contributor. You hereby agree to indemnify the
+         Initial Developer and every Contributor for any liability incurred by
+         the Initial Developer or such Contributor as a result of any such
+         terms You offer.
+
+         3.7. Larger Works.
+         You may create a Larger Work by combining Covered Code with other code
+         not governed by the terms of this License and distribute the Larger
+         Work as a single product. In such a case, You must make sure the
+         requirements of this License are fulfilled for the Covered Code.
+
+    4. Inability to Comply Due to Statute or Regulation.
+
+         If it is impossible for You to comply with any of the terms of this
+         License with respect to some or all of the Covered Code due to
+         statute, judicial order, or regulation then You must: (a) comply with
+         the terms of this License to the maximum extent possible; and (b)
+         describe the limitations and the code they affect. Such description
+         must be included in the LEGAL file described in Section 3.4 and must
+         be included with all distributions of the Source Code. Except to the
+         extent prohibited by statute or regulation, such description must be
+         sufficiently detailed for a recipient of ordinary skill to be able to
+         understand it.
+
+    5. Application of this License.
+
+         This License applies to code to which the Initial Developer has
+         attached the notice in Exhibit A and to related Covered Code.
+
+    6. Versions of the License.
+
+         6.1. New Versions.
+         Netscape Communications Corporation ("Netscape") may publish revised
+         and/or new versions of the License from time to time. Each version
+         will be given a distinguishing version number.
+
+         6.2. Effect of New Versions.
+         Once Covered Code has been published under a particular version of the
+         License, You may always continue to use it under the terms of that
+         version. You may also choose to use such Covered Code under the terms
+         of any subsequent version of the License published by Netscape. No one
+         other than Netscape has the right to modify the terms applicable to
+         Covered Code created under this License.
+
+         6.3. Derivative Works.
+         If You create or use a modified version of this License (which you may
+         only do in order to apply it to code which is not already Covered Code
+         governed by this License), You must (a) rename Your license so that
+         the phrases "Mozilla", "MOZILLAPL", "MOZPL", "Netscape",
+         "MPL", "NPL" or any confusingly similar phrase do not appear in your
+         license (except to note that your license differs from this License)
+         and (b) otherwise make it clear that Your version of the license
+         contains terms which differ from the Mozilla Public License and
+         Netscape Public License. (Filling in the name of the Initial
+         Developer, Original Code or Contributor in the notice described in
+         Exhibit A shall not of themselves be deemed to be modifications of
+         this License.)
+
+    7. DISCLAIMER OF WARRANTY.
+
+         COVERED CODE IS PROVIDED UNDER THIS LICENSE ON AN "AS IS" BASIS,
+         WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING,
+         WITHOUT LIMITATION, WARRANTIES THAT THE COVERED CODE IS FREE OF
+         DEFECTS, MERCHANTABLE, FIT FOR A PARTICULAR PURPOSE OR NON-INFRINGING.
+         THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE COVERED CODE
+         IS WITH YOU. SHOULD ANY COVERED CODE PROVE DEFECTIVE IN ANY RESPECT,
+         YOU (NOT THE INITIAL DEVELOPER OR ANY OTHER CONTRIBUTOR) ASSUME THE
+         COST OF ANY NECESSARY SERVICING, REPAIR OR CORRECTION. THIS DISCLAIMER
+         OF WARRANTY CONSTITUTES AN ESSENTIAL PART OF THIS LICENSE. NO USE OF
+         ANY COVERED CODE IS AUTHORIZED HEREUNDER EXCEPT UNDER THIS DISCLAIMER.
+
+    8. TERMINATION.
+
+         8.1.  This License and the rights granted hereunder will terminate
+         automatically if You fail to comply with terms herein and fail to cure
+         such breach within 30 days of becoming aware of the breach. All
+         sublicenses to the Covered Code which are properly granted shall
+         survive any termination of this License. Provisions which, by their
+         nature, must remain in effect beyond the termination of this License
+         shall survive.
+
+         8.2.  If You initiate litigation by asserting a patent infringement
+         claim (excluding declatory judgment actions) against Initial Developer
+         or a Contributor (the Initial Developer or Contributor against whom
+         You file such action is referred to as "Participant")  alleging that:
+
+         (a)  such Participant's Contributor Version directly or indirectly
+         infringes any patent, then any and all rights granted by such
+         Participant to You under Sections 2.1 and/or 2.2 of this License
+         shall, upon 60 days notice from Participant terminate prospectively,
+         unless if within 60 days after receipt of notice You either: (i)
+         agree in writing to pay Participant a mutually agreeable reasonable
+         royalty for Your past and future use of Modifications made by such
+         Participant, or (ii) withdraw Your litigation claim with respect to
+         the Contributor Version against such Participant.  If within 60 days
+         of notice, a reasonable royalty and payment arrangement are not
+         mutually agreed upon in writing by the parties or the litigation claim
+         is not withdrawn, the rights granted by Participant to You under
+         Sections 2.1 and/or 2.2 automatically terminate at the expiration of
+         the 60 day notice period specified above.
+
+         (b)  any software, hardware, or device, other than such Participant's
+         Contributor Version, directly or indirectly infringes any patent, then
+         any rights granted to You by such Participant under Sections 2.1(b)
+         and 2.2(b) are revoked effective as of the date You first made, used,
+         sold, distributed, or had made, Modifications made by that
+         Participant.
+
+         8.3.  If You assert a patent infringement claim against Participant
+         alleging that such Participant's Contributor Version directly or
+         indirectly infringes any patent where such claim is resolved (such as
+         by license or settlement) prior to the initiation of patent
+         infringement litigation, then the reasonable value of the licenses
+         granted by such Participant under Sections 2.1 or 2.2 shall be taken
+         into account in determining the amount or value of any payment or
+         license.
+
+         8.4.  In the event of termination under Sections 8.1 or 8.2 above,
+         all end user license agreements (excluding distributors and resellers)
+         which have been validly granted by You or any distributor hereunder
+         prior to termination shall survive termination.
+
+    9. LIMITATION OF LIABILITY.
+
+         UNDER NO CIRCUMSTANCES AND UNDER NO LEGAL THEORY, WHETHER TORT
+         (INCLUDING NEGLIGENCE), CONTRACT, OR OTHERWISE, SHALL YOU, THE INITIAL
+         DEVELOPER, ANY OTHER CONTRIBUTOR, OR ANY DISTRIBUTOR OF COVERED CODE,
+         OR ANY SUPPLIER OF ANY OF SUCH PARTIES, BE LIABLE TO ANY PERSON FOR
+         ANY INDIRECT, SPECIAL, INCIDENTAL, OR CONSEQUENTIAL DAMAGES OF ANY
+         CHARACTER INCLUDING, WITHOUT LIMITATION, DAMAGES FOR LOSS OF GOODWILL,
+         WORK STOPPAGE, COMPUTER FAILURE OR MALFUNCTION, OR ANY AND ALL OTHER
+         COMMERCIAL DAMAGES OR LOSSES, EVEN IF SUCH PARTY SHALL HAVE BEEN
+         INFORMED OF THE POSSIBILITY OF SUCH DAMAGES. THIS LIMITATION OF
+         LIABILITY SHALL NOT APPLY TO LIABILITY FOR DEATH OR PERSONAL INJURY
+         RESULTING FROM SUCH PARTY'S NEGLIGENCE TO THE EXTENT APPLICABLE LAW
+         PROHIBITS SUCH LIMITATION. SOME JURISDICTIONS DO NOT ALLOW THE
+         EXCLUSION OR LIMITATION OF INCIDENTAL OR CONSEQUENTIAL DAMAGES, SO
+         THIS EXCLUSION AND LIMITATION MAY NOT APPLY TO YOU.
+
+    10. U.S. GOVERNMENT END USERS.
+
+         The Covered Code is a "commercial item," as that term is defined in
+         48 C.F.R. 2.101 (Oct. 1995), consisting of "commercial computer
+         software" and "commercial computer software documentation," as such
+         terms are used in 48 C.F.R. 12.212 (Sept. 1995). Consistent with 48
+         C.F.R. 12.212 and 48 C.F.R. 227.7202-1 through 227.7202-4 (June 1995),
+         all U.S. Government End Users acquire Covered Code with only those
+         rights set forth herein.
+
+    11. MISCELLANEOUS.
+
+         This License represents the complete agreement concerning subject
+         matter hereof. If any provision of this License is held to be
+         unenforceable, such provision shall be reformed only to the extent
+         necessary to make it enforceable. This License shall be governed by
+         California law provisions (except to the extent applicable law, if
+         any, provides otherwise), excluding its conflict-of-law provisions.
+         With respect to disputes in which at least one party is a citizen of,
+         or an entity chartered or registered to do business in the United
+         States of America, any litigation relating to this License shall be
+         subject to the jurisdiction of the Federal Courts of the Northern
+         District of California, with venue lying in Santa Clara County,
+         California, with the losing party responsible for costs, including
+         without limitation, court costs and reasonable attorneys' fees and
+         expenses. The application of the United Nations Convention on
+         Contracts for the International Sale of Goods is expressly excluded.
+         Any law or regulation which provides that the language of a contract
+         shall be construed against the drafter shall not apply to this
+         License.
+
+    12. RESPONSIBILITY FOR CLAIMS.
+
+         As between Initial Developer and the Contributors, each party is
+         responsible for claims and damages arising, directly or indirectly,
+         out of its utilization of rights under this License and You agree to
+         work with Initial Developer and Contributors to distribute such
+         responsibility on an equitable basis. Nothing herein is intended or
+         shall be deemed to constitute any admission of liability.
+
+    13. MULTIPLE-LICENSED CODE.
+
+         Initial Developer may designate portions of the Covered Code as
+         "Multiple-Licensed".  "Multiple-Licensed" means that the Initial
+         Developer permits you to utilize portions of the Covered Code under
+         Your choice of the NPL or the alternative licenses, if any, specified
+         by the Initial Developer in the file described in Exhibit A.
+
+    EXHIBIT A -Mozilla Public License.
+
+         ``The contents of this file are subject to the Mozilla Public License
+         Version 1.1 (the "License"); you may not use this file except in
+         compliance with the License. You may obtain a copy of the License at
+         http://www.mozilla.org/MPL/
+
+         Software distributed under the License is distributed on an "AS IS"
+         basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
+         License for the specific language governing rights and limitations
+         under the License.
+
+         The Original Code is ______________________________________.
+
+         The Initial Developer of the Original Code is ________________________.
+         Portions created by ______________________ are Copyright (C) ______
+         _______________________. All Rights Reserved.
+
+         Contributor(s): ______________________________________.
+
+         Alternatively, the contents of this file may be used under the terms
+         of the _____ license (the  "[___] License"), in which case the
+         provisions of [______] License are applicable instead of those
+         above.  If you wish to allow use of your version of this file only
+         under the terms of the [____] License and not to allow others to use
+         your version of this file under the MPL, indicate your decision by
+         deleting  the provisions above and replace  them with the notice and
+         other provisions required by the [___] License.  If you do not delete
+         the provisions above, a recipient may use your version of this file
+         under either the MPL or the [___] License."
+
+         [NOTE: The text of this Exhibit A may differ slightly from the text of
+         the notices in the Source Code files of the Original Code. You should
+         use the text of this Exhibit A rather than the text found in the
+         Original Code Source Code for Your Modifications.]
diff --git a/tika-parsers/pom.xml b/tika-parsers/pom.xml
index 18fb9fa81..a56b5dd21 100644
--- a/tika-parsers/pom.xml
+++ b/tika-parsers/pom.xml
@@ -180,6 +180,11 @@
       <artifactId>vorbis-java-core</artifactId>
       <version>${vorbis.version}</version>
     </dependency>
+    <dependency>
+      <groupId>com.googlecode.juniversalchardet</groupId>
+      <artifactId>juniversalchardet</artifactId>
+      <version>1.0.3</version>
+    </dependency>
 
     <!-- Test dependencies -->
     <dependency>
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/txt/EncodingDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/txt/EncodingDetector.java
new file mode 100644
index 000000000..8d52aa676
--- /dev/null
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/txt/EncodingDetector.java
@@ -0,0 +1,30 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.parser.txt;
+
+import org.apache.tika.detect.Detector;
+
+/**
+ * Interface for detecting the character encoding of a text document.
+ * Implementation classes should respect the {@link Detector} contract
+ * with the added precondition that the given document stream can be
+ * expected to contain text instead of some non-text binary data.
+ *
+ * @since Tika 0.4
+ */
+public interface EncodingDetector extends Detector {
+}
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/txt/Icu4jEncodingDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/txt/Icu4jEncodingDetector.java
new file mode 100644
index 000000000..fe1633509
--- /dev/null
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/txt/Icu4jEncodingDetector.java
@@ -0,0 +1,60 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.parser.txt;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.nio.charset.Charset;
+import java.util.Collections;
+
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.mime.MediaType;
+
+public class Icu4jEncodingDetector implements EncodingDetector {
+
+    public MediaType detect(InputStream input, Metadata metadata)
+            throws IOException {
+        CharsetDetector detector = new CharsetDetector();
+
+        String incomingCharset = metadata.get(Metadata.CONTENT_ENCODING);
+        String incomingType = metadata.get(Metadata.CONTENT_TYPE);
+        if (incomingCharset == null && incomingType != null) {
+            // TIKA-341: Use charset in content-type
+            MediaType mt = MediaType.parse(incomingType);
+            if (mt != null) {
+                incomingCharset = mt.getParameters().get("charset");
+            }
+        }
+
+        if (incomingCharset != null) {
+            detector.setDeclaredEncoding(incomingCharset);
+        }
+
+        detector.setText(input);
+
+        for (CharsetMatch match : detector.detectAll()) {
+            if (Charset.isSupported(match.getName())) {
+                return new MediaType(
+                        MediaType.TEXT_PLAIN,
+                        Collections.singletonMap("charset", match.getName()));
+            }
+        }
+
+        return MediaType.OCTET_STREAM;
+    }
+
+}
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/txt/TXTParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/txt/TXTParser.java
index b7d9d8008..cdca48eca 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/txt/TXTParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/txt/TXTParser.java
@@ -23,10 +23,10 @@ import java.io.InputStream;
 import java.io.InputStreamReader;
 import java.io.Reader;
 import java.io.UnsupportedEncodingException;
-import java.nio.charset.Charset;
 import java.util.Collections;
 import java.util.Set;
 
+import org.apache.tika.config.ServiceLoader;
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.mime.MediaType;
@@ -70,39 +70,15 @@ public class TXTParser extends AbstractParser {
     public void parse(
             InputStream stream, ContentHandler handler,
             Metadata metadata, ParseContext context)
-    throws IOException, SAXException, TikaException {
-
-        // CharsetDetector expects a stream to support marks
-        if (!stream.markSupported()) {
-            stream = new BufferedInputStream(stream);
-        }
-
-        // Detect the content encoding (the stream is reset to the beginning)
-        CharsetDetector detector = new CharsetDetector();
-        String incomingCharset = metadata.get(Metadata.CONTENT_ENCODING);
-        String incomingType = metadata.get(Metadata.CONTENT_TYPE);
-        if (incomingCharset == null && incomingType != null) {
-            // TIKA-341: Use charset in content-type
-            MediaType mt = MediaType.parse(incomingType);
-            if (mt != null) {
-                incomingCharset = mt.getParameters().get("charset");
-            }
-        }
-
-        if (incomingCharset != null) {
-            detector.setDeclaredEncoding(incomingCharset);
-        }
-
-        detector.setText(stream);
-        for (CharsetMatch match : detector.detectAll()) {
-            if (Charset.isSupported(match.getName())) {
-                metadata.set(Metadata.CONTENT_ENCODING, match.getName());
-                break;
-            }
-        }
-
-        String encoding = metadata.get(Metadata.CONTENT_ENCODING);
-        if (encoding == null) {
+            throws IOException, SAXException, TikaException {
+        // We need mark support for detecting the character encoding
+        stream = new BufferedInputStream(stream);
+
+        MediaType type = detectEncoding(stream, metadata);
+        String encoding = type.getParameters().get("charset");
+        if (encoding != null) {
+            metadata.set(Metadata.CONTENT_ENCODING, encoding);
+        } else {
             throw new TikaException(
                     "Text encoding could not be detected and no encoding"
                     + " hint is available in document metadata");
@@ -114,7 +90,7 @@ public class TXTParser extends AbstractParser {
 
         try {
             Reader reader =
-                new BufferedReader(new InputStreamReader(stream, encoding));
+                    new BufferedReader(new InputStreamReader(stream, encoding));
 
             // TIKA-240: Drop the BOM when extracting plain text
             reader.mark(1);
@@ -143,4 +119,18 @@ public class TXTParser extends AbstractParser {
         }
     }
 
+    private MediaType detectEncoding(InputStream stream, Metadata metadata)
+            throws IOException {
+        ServiceLoader loader =
+                new ServiceLoader(TXTParser.class.getClassLoader());
+        for (EncodingDetector detector
+                : loader.loadServiceProviders(EncodingDetector.class)) {
+            MediaType type = detector.detect(stream, metadata);
+            if (!MediaType.OCTET_STREAM.equals(type)) {
+                return type;
+            }
+        }
+        return MediaType.OCTET_STREAM;
+    }
+
 }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/txt/UniversalEncodingDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/txt/UniversalEncodingDetector.java
new file mode 100644
index 000000000..cb3417ca4
--- /dev/null
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/txt/UniversalEncodingDetector.java
@@ -0,0 +1,87 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.parser.txt;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.util.Collections;
+
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.mime.MediaType;
+import org.mozilla.universalchardet.CharsetListener;
+import org.mozilla.universalchardet.Constants;
+import org.mozilla.universalchardet.UniversalDetector;
+
+public class UniversalEncodingDetector implements EncodingDetector {
+
+    private static final int BUFSIZE = 1024;
+
+    private static final int LOOKAHEAD = 16 * BUFSIZE;
+
+    public MediaType detect(InputStream input, Metadata metadata)
+            throws IOException {
+        if (input == null) {
+            return MediaType.OCTET_STREAM;
+        }
+
+        Result result = new Result();
+        UniversalDetector detector = new UniversalDetector(result);
+
+        input.mark(LOOKAHEAD);
+        try {
+            byte[] b = new byte[BUFSIZE];
+            int n = 0;
+            int m = input.read(b);
+            while (m != -1 && n < LOOKAHEAD && !detector.isDone()) {
+                n += m;
+                detector.handleData(b, 0, m);
+                m = input.read(b, 0, Math.min(b.length, LOOKAHEAD - n));
+            }
+        } finally {
+            input.reset();
+        }
+
+        detector.dataEnd();
+
+        return result.getType();
+    }
+
+    private static class Result implements CharsetListener {
+
+        private String charset = null;
+
+        public void report(String charset) {
+            if (Constants.CHARSET_WINDOWS_1252.equals(charset)) {
+                this.charset = "ISO-8859-1";
+            } else {
+                this.charset = charset;
+            }
+        }
+
+        public MediaType getType() {
+            if (charset != null) {
+                return new MediaType(
+                        MediaType.TEXT_PLAIN,
+                        Collections.singletonMap("charset", charset));
+            } else {
+                return MediaType.OCTET_STREAM;
+            }
+        }
+
+    }
+
+}
diff --git a/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.parser.txt.EncodingDetector b/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.parser.txt.EncodingDetector
new file mode 100644
index 000000000..e60217c3d
--- /dev/null
+++ b/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.parser.txt.EncodingDetector
@@ -0,0 +1,17 @@
+#  Licensed to the Apache Software Foundation (ASF) under one or more
+#  contributor license agreements.  See the NOTICE file distributed with
+#  this work for additional information regarding copyright ownership.
+#  The ASF licenses this file to You under the Apache License, Version 2.0
+#  (the "License"); you may not use this file except in compliance with
+#  the License.  You may obtain a copy of the License at
+#
+#       http://www.apache.org/licenses/LICENSE-2.0
+#
+#  Unless required by applicable law or agreed to in writing, software
+#  distributed under the License is distributed on an "AS IS" BASIS,
+#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+#  See the License for the specific language governing permissions and
+#  limitations under the License.
+
+org.apache.tika.parser.txt.UniversalEncodingDetector
+org.apache.tika.parser.txt.Icu4jEncodingDetector
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/txt/TXTParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/txt/TXTParserTest.java
index b9e41d067..540537801 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/txt/TXTParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/txt/TXTParserTest.java
@@ -116,7 +116,7 @@ public class TXTParserTest extends TestCase {
 
         metadata.set(Metadata.CONTENT_ENCODING, "ISO-8859-1");
         parser.parse(
-                new ByteArrayInputStream(test2.getBytes("UTF-8")),
+                new ByteArrayInputStream(test2.getBytes("ISO-8859-1")),
                 new BodyContentHandler(),  metadata, new ParseContext());
         
         assertEquals("ISO-8859-1", metadata.get(Metadata.CONTENT_ENCODING));
@@ -142,7 +142,7 @@ public class TXTParserTest extends TestCase {
         metadata = new Metadata();
         metadata.set(Metadata.CONTENT_TYPE, "text/html; charset=ISO-8859-1");
         parser.parse(
-                new ByteArrayInputStream(test2.getBytes("UTF-8")),
+                new ByteArrayInputStream(test2.getBytes("ISO-8859-1")),
                 new BodyContentHandler(),  metadata, new ParseContext());
 
         assertEquals("ISO-8859-1", metadata.get(Metadata.CONTENT_ENCODING));

Commit:
0a472d2873be89b333247879fd03e95825ef7a5f
Jukka Zitting
jukka@apache.org
2012-07-07 16:04:16 +0000
TIKA-561: Support EMLX file detection
diff --git a/.gitattributes b/.gitattributes
index 4244bb0a5..c75b2a453 100644
--- a/.gitattributes
+++ b/.gitattributes
@@ -1 +1,2 @@
 tika-parsers/src/test/resources/test-documents/testARofText.ar eol=lf
+tika-parsers/src/test/resources/test-documents/testEMLX.emlx eol=lf
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index a779fd5b5..0e7b36b80 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -2480,6 +2480,23 @@
       <match value="\177ELF" type="string" offset="0" />
     </magic>
   </mime-type>
+
+  <mime-type type="message/x-emlx">
+    <magic priority="70">
+      <match value="\nRelay-Version:" type="string" offset="2:9"/>
+      <match value="\n#!\ rnews" type="string" offset="2:9"/>
+      <match value="\nN#!\ rnews" type="string" offset="2:9"/>
+      <match value="\nForward\ to" type="string" offset="2:9"/>
+      <match value="\nPipe\ to" type="string" offset="2:9"/>
+      <match value="\nReturn-Path:" type="string" offset="2:9"/>
+      <match value="\nFrom:" type="string" offset="2:9"/>
+      <match value="\nReceived:" type="string" offset="2:9"/>
+      <match value="\nMessage-ID:" type="string" offset="2:9"/>
+      <match value="\nDate:" type="string" offset="2:9"/>
+    </magic>
+    <glob pattern="*.emlx"/>
+  </mime-type>
+
   <mime-type type="application/x-object">
     <sub-class-of type="application/x-elf"/>
     <magic priority="50">
diff --git a/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java b/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
index 1f7befcd2..57bb4ca96 100644
--- a/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
+++ b/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
@@ -605,6 +605,10 @@ public class TestMimeTypes extends TestCase {
        assertTypeByData("application/zip","testKMZ.kmz");
    }
 
+    public void testEmlx() throws IOException {
+        assertTypeDetection("testEMLX.emlx", "message/x-emlx");
+    }
+
     private void assertType(String expected, String filename) throws Exception {
         InputStream stream = TestMimeTypes.class.getResourceAsStream(
                 "/test-documents/" + filename);
@@ -647,18 +651,24 @@ public class TestMimeTypes extends TestCase {
           stream.close();
        }
     }
-    
+
+    private void assertTypeDetection(String filename, String type)
+            throws IOException {
+        assertTypeDetection(filename, type, type, type);
+    }
+
     private void assertTypeDetection(String filename, String byName, String byData, 
             String byNameAndData) throws IOException {
         assertTypeByName(byName, filename);
         assertTypeByData(byData, filename);
         assertTypeByNameAndData(byNameAndData, filename);
     }
-    
+
     private void assertTypeByNameAndData(String expected, String filename)
         throws IOException {
        assertEquals(expected, getTypeByNameAndData(filename).toString());
     }
+
     private MediaType getTypeByNameAndData(String filename) throws IOException {
        InputStream stream = TestMimeTypes.class.getResourceAsStream(
              "/test-documents/" + filename);
diff --git a/tika-parsers/src/test/resources/test-documents/testEMLX.emlx b/tika-parsers/src/test/resources/test-documents/testEMLX.emlx
new file mode 100644
index 000000000..d9a7126fc
--- /dev/null
+++ b/tika-parsers/src/test/resources/test-documents/testEMLX.emlx
@@ -0,0 +1,55 @@
+1795
+From: "Julien Nioche (JIRA)" <jira@apache.org>
+To: dev@tika.apache.org
+Subject: [jira] Commented: (TIKA-461) RFC822 messages not parsed
+Reply-To: dev@tika.apache.org
+Delivered-To: mailing list dev@tika.apache.org
+Date: Mon, 6 Sep 2010 05:25:34 -0400 (EDT)
+In-Reply-To: <6089099.260231278600349994.JavaMail.jira@thor>
+MIME-Version: 1.0
+Content-Type: text/plain; charset=utf-8
+Content-Transfer-Encoding: 7bit
+X-JIRA-FingerPrint: 30527f35849b9dde25b450d4833f0394
+X-Virus-Checked: Checked by ClamAV on apache.org
+
+
+    [ https://issues.apache.org/jira/browse/TIKA-461?page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel&focusedCommentId=12906468#action_12906468 ] 
+
+Julien Nioche commented on TIKA-461:
+------------------------------------
+
+I'll have a look at mime4j and try to use it in Tika
+
+> RFC822 messages not parsed
+> --------------------------
+>
+>                 Key: TIKA-461
+>                 URL: https://issues.apache.org/jira/browse/TIKA-461
+>             Project: Tika
+>          Issue Type: Bug
+>          Components: parser
+>    Affects Versions: 0.7
+>            Reporter: Joshua Turner
+>            Assignee: Julien Nioche
+>
+> Presented with an RFC822 message exported from Thunderbird, AutodetectParser produces an empty body, and a Metadata containing only one key-value pair: "Content-Type=message/rfc822". Directly calling MboxParser likewise gives an empty body, but with two metadata pairs: "Content-Encoding=us-ascii Content-Type=application/mbox".
+> A quick peek at the source of MboxParser shows that the implementation is pretty naive. If the wiring can be sorted out, something like Apache James' mime4j might be a better bet.
+
+-- 
+This message is automatically generated by JIRA.
+-
+You can reply to this email to add a comment to the issue online.
+
+<?xml version="1.0" encoding="UTF-8"?>
+<!DOCTYPE plist PUBLIC "-//Apple Computer//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
+<plist version="1.0">
+<dict>
+	<key>flags</key>
+	<integer>0</integer>
+	<key>sender</key>
+	<string>"Julien Nioche (JIRA)" &lt;jira@apache.org&gt;</string>
+	<key>subject</key>
+	<string>[jira] Commented: (TIKA-461) RFC822 messages not parsed</string>
+	<key>to</key>
+	<string>dev@tika.apache.org</string></dict>
+</plist>

Commit:
3e2a65294894c61051034f049f034cde1322175a
Nick Burch
nick@apache.org
2012-07-07 12:07:46 +0000
TIKA-948 Add mime magic for ChemDraw .cdx files, then fix the Cli extraction test so it has the correct extension
diff --git a/tika-app/src/test/java/org/apache/tika/cli/TikaCLITest.java b/tika-app/src/test/java/org/apache/tika/cli/TikaCLITest.java
index 291d6d79d..be584c0af 100644
--- a/tika-app/src/test/java/org/apache/tika/cli/TikaCLITest.java
+++ b/tika-app/src/test/java/org/apache/tika/cli/TikaCLITest.java
@@ -185,8 +185,8 @@ public class TikaCLITest extends TestCase{
             
             TikaCLI.main(params);
             
-            // ChemDraw file, currently doesn't have the correct extension
-            File expected1 = new File(tempFile, "MBD002B040A.bin");
+            // ChemDraw file
+            File expected1 = new File(tempFile, "MBD002B040A.cdx");
             // OLE10Native
             File expected2 = new File(tempFile, "file5");
             // Image of one of the embedded resources
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index da163087a..a779fd5b5 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -3542,6 +3542,9 @@
   </mime-type>
 
   <mime-type type="chemical/x-cdx">
+    <magic priority="50">
+      <match value="VjCD0100" type="string" offset="0"/>
+    </magic>
     <glob pattern="*.cdx"/>
   </mime-type>
   <mime-type type="chemical/x-cif">

Commit:
f28f04af7e60ffc04550030c0c99e8c7dd931442
Nick Burch
nick@apache.org
2012-07-06 23:12:10 +0000
TIKA-948 Look up the file extension for the mimetype detected for embedded resources, and fix unit tests for this
diff --git a/tika-app/src/test/java/org/apache/tika/cli/TikaCLITest.java b/tika-app/src/test/java/org/apache/tika/cli/TikaCLITest.java
index ec1c1b2a3..291d6d79d 100644
--- a/tika-app/src/test/java/org/apache/tika/cli/TikaCLITest.java
+++ b/tika-app/src/test/java/org/apache/tika/cli/TikaCLITest.java
@@ -186,7 +186,7 @@ public class TikaCLITest extends TestCase{
             TikaCLI.main(params);
             
             // ChemDraw file, currently doesn't have the correct extension
-            File expected1 = new File(tempFile, "MBD002B040A.ole");
+            File expected1 = new File(tempFile, "MBD002B040A.bin");
             // OLE10Native
             File expected2 = new File(tempFile, "file5");
             // Image of one of the embedded resources
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/AbstractPOIFSExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/AbstractPOIFSExtractor.java
index 14c5af41b..4d1b00c0e 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/AbstractPOIFSExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/AbstractPOIFSExtractor.java
@@ -33,6 +33,9 @@ import org.apache.tika.extractor.ParsingEmbeddedDocumentExtractor;
 import org.apache.tika.io.TikaInputStream;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.mime.MediaType;
+import org.apache.tika.mime.MimeType;
+import org.apache.tika.mime.MimeTypeException;
+import org.apache.tika.mime.MimeTypes;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.parser.microsoft.OfficeParser.POIFSDocumentType;
 import org.apache.tika.parser.pkg.ZipContainerDetector;
@@ -42,6 +45,7 @@ import org.xml.sax.SAXException;
 abstract class AbstractPOIFSExtractor {
     private final EmbeddedDocumentExtractor extractor;
     private TikaConfig tikaConfig;
+    private MimeTypes mimeTypes;
     private Detector detector;
 
     protected AbstractPOIFSExtractor(ParseContext context) {
@@ -54,19 +58,29 @@ abstract class AbstractPOIFSExtractor {
         }
         
         tikaConfig = context.get(TikaConfig.class);
+        mimeTypes = context.get(MimeTypes.class);
         detector = context.get(Detector.class);
     }
     
-    protected Detector getDetector() {
-       if (detector != null) return detector;
-       
+    // Note - these cache, but avoid creating the default TikaConfig if not needed
+    protected TikaConfig getTikaConfig() {
        if (tikaConfig == null) {
           tikaConfig = TikaConfig.getDefaultConfig();
        }
+       return tikaConfig;
+    }
+    protected Detector getDetector() {
+       if (detector != null) return detector;
        
-       detector = tikaConfig.getDetector();
+       detector = getTikaConfig().getDetector();
        return detector;
     }
+    protected MimeTypes getMimeTypes() {
+       if (mimeTypes != null) return mimeTypes;
+       
+       mimeTypes = getTikaConfig().getMimeRepository();
+       return mimeTypes;
+    }
     
     protected void handleEmbeddedResource(TikaInputStream resource, String filename,
           String mediaType, XHTMLContentHandler xhtml, boolean outputHtml)
@@ -144,8 +158,17 @@ abstract class AbstractPOIFSExtractor {
                    
                    // Try to work out what it is
                    MediaType mediaType = getDetector().detect(embedded, new Metadata());
+                   String extension = type.getExtension();
+                   try {
+                      MimeType mimeType = getMimeTypes().forName(mediaType.toString());
+                      extension = mimeType.getExtension();
+                   } catch(MimeTypeException mte) {
+                      // No details on this type are known
+                   }
+                   
+                   // Record what we can do about it
                    metadata.set(Metadata.CONTENT_TYPE, mediaType.getType().toString());
-                   metadata.set(Metadata.RESOURCE_NAME_KEY, dir.getName() + '.' + type.getExtension());
+                   metadata.set(Metadata.RESOURCE_NAME_KEY, dir.getName() + extension);
                 } catch(Exception e) {
                    throw new TikaException("Invalid embedded resource", e);
                 }
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/POIContainerExtractionTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/POIContainerExtractionTest.java
index ab4af8b87..69ef7cdf2 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/POIContainerExtractionTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/POIContainerExtractionTest.java
@@ -236,8 +236,7 @@ public class POIContainerExtractionTest extends AbstractPOIContainerExtractionTe
        assertEquals(2, handler.mediaTypes.size());
        
        assertEquals("image1.emf", handler.filenames.get(0));
-       //assertEquals("_1402837031.pdf", handler.filenames.get(1)); // TODO Fix, TIKA-48
-       assertEquals("_1402837031.ole", handler.filenames.get(1)); // TODO Fix, TIKA-48
+       assertEquals("_1402837031.pdf", handler.filenames.get(1));
 
        assertEquals(TYPE_EMF, handler.mediaTypes.get(0)); // Icon of embedded pdf
        assertEquals(TYPE_PDF, handler.mediaTypes.get(1)); // The embedded PDF itself

Commit:
270853e9988c41d797b8102ab22236dca0a43cc2
Jukka Zitting
jukka@apache.org
2012-07-06 21:26:06 +0000
TIKA-951: Bundle activation policy for Eclipse
diff --git a/tika-bundle/pom.xml b/tika-bundle/pom.xml
index bccbdd67c..a3a4b3915 100644
--- a/tika-bundle/pom.xml
+++ b/tika-bundle/pom.xml
@@ -112,7 +112,6 @@
             <Bundle-Activator>
               org.apache.tika.parser.internal.Activator
             </Bundle-Activator>
-            <Bundle-ActivationPolicy>lazy</Bundle-ActivationPolicy>
             <Embed-Dependency>
               tika-parsers;inline=true,
               commons-compress, xz, commons-codec, commons-io,

Commit:
0ce21716c6dac44666489e5b0b88096813c7b180
Jukka Zitting
jukka@apache.org
2012-07-06 21:19:39 +0000
TIKA-951: Bundle activation policy for Eclipse
diff --git a/tika-bundle/pom.xml b/tika-bundle/pom.xml
index a3a4b3915..bccbdd67c 100644
--- a/tika-bundle/pom.xml
+++ b/tika-bundle/pom.xml
@@ -112,6 +112,7 @@
             <Bundle-Activator>
               org.apache.tika.parser.internal.Activator
             </Bundle-Activator>
+            <Bundle-ActivationPolicy>lazy</Bundle-ActivationPolicy>
             <Embed-Dependency>
               tika-parsers;inline=true,
               commons-compress, xz, commons-codec, commons-io,
diff --git a/tika-core/pom.xml b/tika-core/pom.xml
index 85dea3fa4..1c48d2cab 100644
--- a/tika-core/pom.xml
+++ b/tika-core/pom.xml
@@ -76,6 +76,7 @@
             <Bundle-Activator>
               org.apache.tika.config.TikaActivator
             </Bundle-Activator>
+            <Bundle-ActivationPolicy>lazy</Bundle-ActivationPolicy>
           </instructions>
         </configuration>
       </plugin>

Commit:
03fd5d5d325cc126cb203ed15e3c6e63e0207705
Nick Burch
nick@apache.org
2012-07-06 20:36:02 +0000
Fix the extraction test for the file type, and check for one additional file
diff --git a/tika-app/src/test/java/org/apache/tika/cli/TikaCLITest.java b/tika-app/src/test/java/org/apache/tika/cli/TikaCLITest.java
index 1510421ed..ec1c1b2a3 100644
--- a/tika-app/src/test/java/org/apache/tika/cli/TikaCLITest.java
+++ b/tika-app/src/test/java/org/apache/tika/cli/TikaCLITest.java
@@ -185,14 +185,20 @@ public class TikaCLITest extends TestCase{
             
             TikaCLI.main(params);
             
-            File expected1 = new File(tempFile, "MBD002B040A.wps");
+            // ChemDraw file, currently doesn't have the correct extension
+            File expected1 = new File(tempFile, "MBD002B040A.ole");
+            // OLE10Native
             File expected2 = new File(tempFile, "file5");
+            // Image of one of the embedded resources
+            File expected3 = new File(tempFile, "file0.emf");
             
             assertTrue(expected1.exists());
             assertTrue(expected2.exists());
+            assertTrue(expected3.exists());
             
             assertTrue(expected1.length()>0);
             assertTrue(expected2.length()>0);
+            assertTrue(expected3.length()>0);
         } finally {
             FileUtils.deleteDirectory(tempFile);
         }

Commit:
218352a1ce7de0881416eff741d832a1abc51f07
Nick Burch
nick@apache.org
2012-07-06 20:35:12 +0000
TIKA-948 Start to be able to correctly detect differnt things embedded in CompObj, such as PDF files, and also to be able to extract the contents
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/AbstractPOIFSExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/AbstractPOIFSExtractor.java
index 9707ae592..14c5af41b 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/AbstractPOIFSExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/AbstractPOIFSExtractor.java
@@ -25,6 +25,8 @@ import org.apache.poi.poifs.filesystem.DocumentInputStream;
 import org.apache.poi.poifs.filesystem.Entry;
 import org.apache.poi.poifs.filesystem.Ole10Native;
 import org.apache.poi.poifs.filesystem.Ole10NativeException;
+import org.apache.tika.config.TikaConfig;
+import org.apache.tika.detect.Detector;
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.extractor.EmbeddedDocumentExtractor;
 import org.apache.tika.extractor.ParsingEmbeddedDocumentExtractor;
@@ -38,8 +40,9 @@ import org.apache.tika.sax.XHTMLContentHandler;
 import org.xml.sax.SAXException;
 
 abstract class AbstractPOIFSExtractor {
-
     private final EmbeddedDocumentExtractor extractor;
+    private TikaConfig tikaConfig;
+    private Detector detector;
 
     protected AbstractPOIFSExtractor(ParseContext context) {
         EmbeddedDocumentExtractor ex = context.get(EmbeddedDocumentExtractor.class);
@@ -49,6 +52,20 @@ abstract class AbstractPOIFSExtractor {
         } else {
             this.extractor = ex;
         }
+        
+        tikaConfig = context.get(TikaConfig.class);
+        detector = context.get(Detector.class);
+    }
+    
+    protected Detector getDetector() {
+       if (detector != null) return detector;
+       
+       if (tikaConfig == null) {
+          tikaConfig = TikaConfig.getDefaultConfig();
+       }
+       
+       detector = tikaConfig.getDetector();
+       return detector;
     }
     
     protected void handleEmbeddedResource(TikaInputStream resource, String filename,
@@ -116,6 +133,22 @@ abstract class AbstractPOIFSExtractor {
                 } catch (Ole10NativeException ex) {
                     // Not a valid OLE10Native record, skip it
                 }
+            } else if (type == POIFSDocumentType.COMP_OBJ) {
+                try {
+                   // Grab the contents and process
+                   DocumentEntry contentsEntry = (DocumentEntry)dir.getEntry("CONTENTS");
+                   DocumentInputStream inp = new DocumentInputStream(contentsEntry);
+                   byte[] contents = new byte[contentsEntry.getSize()];
+                   inp.readFully(contents);
+                   embedded = TikaInputStream.get(contents);
+                   
+                   // Try to work out what it is
+                   MediaType mediaType = getDetector().detect(embedded, new Metadata());
+                   metadata.set(Metadata.CONTENT_TYPE, mediaType.getType().toString());
+                   metadata.set(Metadata.RESOURCE_NAME_KEY, dir.getName() + '.' + type.getExtension());
+                } catch(Exception e) {
+                   throw new TikaException("Invalid embedded resource", e);
+                }
             } else {
                 metadata.set(Metadata.CONTENT_TYPE, type.getType().toString());
                 metadata.set(Metadata.RESOURCE_NAME_KEY, dir.getName() + '.' + type.getExtension());
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java
index 0315f6a0b..9d23c6740 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java
@@ -76,7 +76,8 @@ public class OfficeParser extends AbstractParser {
 
     public enum POIFSDocumentType {
         WORKBOOK("xls", MediaType.application("vnd.ms-excel")),
-        OLE10_NATIVE("ole", MediaType.application("x-tika-msoffice-embedded")),
+        OLE10_NATIVE("ole", POIFSContainerDetector.OLE10_NATIVE),
+        COMP_OBJ("ole", POIFSContainerDetector.COMP_OBJ),
         WORDDOCUMENT("doc", MediaType.application("msword")),
         UNKNOWN("unknown", MediaType.application("x-tika-msoffice")),
         ENCRYPTED("ole", MediaType.application("x-tika-ooxml-protected")),
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java
index fc65e5eb3..f30fbc29b 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java
@@ -22,7 +22,9 @@ import java.io.IOException;
 import java.io.InputStream;
 import java.nio.channels.FileChannel;
 import java.util.Collections;
+import java.util.HashMap;
 import java.util.HashSet;
+import java.util.Map;
 import java.util.Set;
 import java.util.regex.Pattern;
 
@@ -58,6 +60,11 @@ public class POIFSContainerDetector implements Detector {
     private static final byte [] STAR_DRAW = new byte [] {
         0x53, 0x74, 0x61, 0x72, 0x44, 0x72, 0x61, 0x77
     };
+    
+    /** An ASCII String "Quill96" for Works Files */
+    private static final byte [] WORKS_QUILL96 = new byte[] {
+        0x51, 0x75, 0x69, 0x6c, 0x6c, 0x39, 0x36
+    };
 
     /** The OLE base file format */
     public static final MediaType OLE = application("x-tika-msoffice");
@@ -65,8 +72,14 @@ public class POIFSContainerDetector implements Detector {
     /** The protected OOXML base file format */
     public static final MediaType OOXML_PROTECTED = application("x-tika-ooxml-protected");
     
+    /** General embedded document type within an OLE2 container */
+    public static final MediaType GENERAL_EMBEDDED = application("x-tika-msoffice-embedded");
+    
     /** An OLE10 Native embedded document within another OLE2 document */
-    public static final MediaType OLE10_NATIVE = application("x-tika-msoffice-embedded");
+    public static final MediaType OLE10_NATIVE = new MediaType(GENERAL_EMBEDDED, format("ole10_native")); 
+    
+    /** Some other kind of embedded document, in a CompObj container within another OLE2 document */
+    public static final MediaType COMP_OBJ = new MediaType(GENERAL_EMBEDDED, format("comp_obj"));
 
     /** Microsoft Excel */
     public static final MediaType XLS = application("vnd.ms-excel");
@@ -110,6 +123,12 @@ public class POIFSContainerDetector implements Detector {
     /** Regexp for matching the MPP Project Data stream */
     private static final Pattern mppDataMatch = Pattern.compile("\\s\\s\\s\\d+");
     
+    private static Map<String,String> format(String format) {
+       Map<String, String> params = new HashMap<String, String>();
+       params.put("format", format);
+       return params;
+    }
+    
     public MediaType detect(InputStream input, Metadata metadata)
              throws IOException {
         // Check if we have access to the document
@@ -203,7 +222,7 @@ public class POIFSContainerDetector implements Detector {
                      */
                     return OLE;
                 } else {
-                    return processStarDrawOrImpress(root);
+                    return processCompObjFormatType(root);
                 }
             } else if (names.contains("WksSSWorkBook")) {
                 // This check has to be before names.contains("Workbook")
@@ -240,8 +259,20 @@ public class POIFSContainerDetector implements Detector {
                // Newer Works files
                return WPS;
             } else if (names.contains("CONTENTS") && names.contains("\u0001CompObj")) {
-               // Normally an older Works file
-               return WPS;
+               // CompObj is a general kind of OLE2 embedding, but this may be an old Works file
+               // If we have the Directory, check
+               if (root != null) {
+                  MediaType type = processCompObjFormatType(root);
+                  if (type == WPS) {
+                     return WPS;
+                  } else {
+                     // Assume it's a general CompObj embedded resource
+                     return COMP_OBJ;
+                  }
+               } else {
+                  // Assume it's a general CompObj embedded resource
+                  return COMP_OBJ;
+               }
             } else if (names.contains("CONTENTS")) {
                // CONTENTS without SPELLING nor CompObj normally means some sort
                //  of embedded non-office file inside an OLE2 document
@@ -276,7 +307,13 @@ public class POIFSContainerDetector implements Detector {
         return OLE;
     }
 
-    private static MediaType processStarDrawOrImpress(DirectoryEntry root) {
+    /**
+     * Is this one of the kinds of formats which uses CompObj to
+     *  store all of their data, eg Star Draw, Star Impress or
+     *  (older) Works?
+     * If not, it's likely an embedded resource
+     */
+    private static MediaType processCompObjFormatType(DirectoryEntry root) {
         try {
             Entry e = root.getEntry("\u0001CompObj");
             if (e != null && e.isDocumentEntry()) {
@@ -292,6 +329,8 @@ public class POIFSContainerDetector implements Detector {
                     return SDA;
                 } else if (arrayContains(bytes, STAR_IMPRESS)) {
                     return SDD;
+                } else if (arrayContains(bytes, WORKS_QUILL96)) {
+                   return WPS;
                 }
             } 
         } catch (Exception e) {
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/POIContainerExtractionTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/POIContainerExtractionTest.java
index 19819b353..ab4af8b87 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/POIContainerExtractionTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/POIContainerExtractionTest.java
@@ -230,6 +230,20 @@ public class POIContainerExtractionTest extends AbstractPOIContainerExtractionTe
        // TODO
        
        
+       // Word, with a non-office file (PDF)
+       handler = process("testWORD_embedded_pdf.doc", extractor, true);
+       assertEquals(2, handler.filenames.size());
+       assertEquals(2, handler.mediaTypes.size());
+       
+       assertEquals("image1.emf", handler.filenames.get(0));
+       //assertEquals("_1402837031.pdf", handler.filenames.get(1)); // TODO Fix, TIKA-48
+       assertEquals("_1402837031.ole", handler.filenames.get(1)); // TODO Fix, TIKA-48
+
+       assertEquals(TYPE_EMF, handler.mediaTypes.get(0)); // Icon of embedded pdf
+       assertEquals(TYPE_PDF, handler.mediaTypes.get(1)); // The embedded PDF itself
+       
+       
+       
        // Outlook with a text file and a word document
        handler = process("testMSG_att_doc.msg", extractor, true);
        assertEquals(2, handler.filenames.size());

Commit:
1543cb0f3d1b4877825a923faa1f0f3ae990c4f9
Nick Burch
nick@apache.org
2012-07-06 20:32:52 +0000
TIKA-948 There is more than one way to embed things in OLE2, so add subtypes for both
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 7d9761cf8..da163087a 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -3014,8 +3014,15 @@
 
   <mime-type type="application/x-tika-msoffice-embedded">
     <sub-class-of type="application/x-tika-msoffice"/>
+  </mime-type>
+  <mime-type type="application/x-tika-msoffice-embedded;format=ole10_native">
+    <sub-class-of type="application/x-tika-msoffice-embedded"/>
     <_comment>OLE10 Native Embedded Document</_comment>
   </mime-type>
+  <mime-type type="application/x-tika-msoffice-embedded;format=comp_obj">
+    <sub-class-of type="application/x-tika-msoffice-embedded"/>
+    <_comment>CompObj OLE2 Embedded Document</_comment>
+  </mime-type>
 
   <mime-type type="application/x-tika-msworks-spreadsheet">
     <glob pattern="*.xlr"/>

Commit:
843569ad2fd8065d5654f709d12869d8c515803e
Nick Burch
nick@apache.org
2012-07-06 16:44:40 +0000
Test file from TIKA-948
diff --git a/tika-parsers/src/test/resources/test-documents/testWORD_embedded_pdf.doc b/tika-parsers/src/test/resources/test-documents/testWORD_embedded_pdf.doc
new file mode 100644
index 000000000..75a4d9818
--- /dev/null
+++ b/tika-parsers/src/test/resources/test-documents/testWORD_embedded_pdf.doc
@@ -0,0 +1,5 @@
+
+Here is the pdf file:
+[pic]
+
+Bye Bye

Commit:
50f56b665e629a7c748b6286fe505be9ded0a707
Nick Burch
nick@apache.org
2012-07-04 15:08:04 +0000
TIKA-949 Mimetype entries for some zip-based process/mapping formats
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index e6ce50970..7d9761cf8 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -46,6 +46,13 @@
   <mime-type type="application/auth-policy+xml"/>
   <mime-type type="application/batch-smtp"/>
   <mime-type type="application/beep+xml"/>
+
+  <mime-type type="application/bizagi-modeler">
+    <_comment>BizAgi Process Modeler</_comment>
+    <sub-class-of type="application/zip"/>
+    <glob pattern="*.bpm"/>
+  </mime-type>
+
   <mime-type type="application/cals-1840"/>
   <mime-type type="application/ccxml+xml">
     <glob pattern="*.ccxml"/>
@@ -1205,6 +1212,17 @@
     <glob pattern="*.mif"/>
   </mime-type>
 
+  <mime-type type="application/vnd.mindjet.mindmanager">
+    <_comment>MindManager</_comment>
+    <sub-class-of type="application/zip"/>
+    <glob pattern="*.mmp"/>
+    <glob pattern="*.mmap"/>
+    <glob pattern="*.mmpt"/>
+    <glob pattern="*.mmat"/>
+    <glob pattern="*.mmmp"/>
+    <glob pattern="*.mmas"/>
+  </mime-type>
+
   <mime-type type="application/vnd.minisoft-hp3000-save"/>
   <mime-type type="application/vnd.mitsubishi.misty-guard.trustweb"/>
   <mime-type type="application/vnd.mobius.daf">
@@ -3051,6 +3069,14 @@
     <glob pattern="*.xpi"/>
   </mime-type>
 
+  <mime-type type="application/x-xmind">
+    <_comment>XMind Pro</_comment>
+    <sub-class-of type="application/zip"/>
+    <glob pattern="*.xmind"/>
+    <!-- .xmap is also used, but that extension is more common elsewhere -->
+<!-- <glob pattern="*.xmap"/> -->
+  </mime-type>
+
   <mime-type type="application/x-xz">
     <glob pattern="*.xz"/>
     <magic priority="50">

Commit:
5696d7b8d53a6e93a84a083371a5444855d7dfdb
Jukka Zitting
jukka@apache.org
2012-07-04 09:52:41 +0000
TIKA-756: XMP output from Tika CLI
diff --git a/tika-xmp/src/main/java/org/apache/tika/xmp/XMPMetadata.java b/tika-xmp/src/main/java/org/apache/tika/xmp/XMPMetadata.java
index 30cfad19d..e9a431cf1 100644
--- a/tika-xmp/src/main/java/org/apache/tika/xmp/XMPMetadata.java
+++ b/tika-xmp/src/main/java/org/apache/tika/xmp/XMPMetadata.java
@@ -13,10 +13,6 @@
  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  * See the License for the specific language governing permissions and
  * limitations under the License.
- *
- * IPTC Metadata Descriptions taken from the IPTC Photo Metadata (July 2010) 
- * standard. These parts Copyright 2010 International Press Telecommunications 
- * Council.
  */
 package org.apache.tika.xmp;
 
@@ -50,704 +46,629 @@ import com.adobe.xmp.options.SerializeOptions;
 import com.adobe.xmp.properties.XMPProperty;
 
 /**
- * Provides a conversion of the Metadata map from Tika to the XMP data model
- * by also providing the Metadata API for clients to ease transition.
- * But clients can also work directly on the XMP data model, by getting the XMPMeta 
- * reference from this class.
- * Usually the instance would be initialized by providing the Metadata object that
- * had been returned from Tika-core which populates the XMP data model with
- * all properties that can be converted.
- * 
+ * Provides a conversion of the Metadata map from Tika to the XMP data model by also providing the
+ * Metadata API for clients to ease transition. But clients can also work directly on the XMP data
+ * model, by getting the XMPMeta reference from this class. Usually the instance would be
+ * initialized by providing the Metadata object that had been returned from Tika-core which
+ * populates the XMP data model with all properties that can be converted.
+ *
  * This class is not serializable!
  */
 @SuppressWarnings("serial")
-public class XMPMetadata extends Metadata
-{
-	/** The XMP data */
-	private XMPMeta xmpData;
-	/** Use the XMP namespace registry implementation */
-	private static final XMPSchemaRegistry registry = XMPMetaFactory.getSchemaRegistry();
-
-	/**
-	 *  Initializes with an empty XMP packet 
-	 */
-    public XMPMetadata() 
-    {
-    	xmpData = XMPMetaFactory.create();
-    }
-    
-	/**
+public class XMPMetadata extends Metadata {
+    /** The XMP data */
+    private XMPMeta xmpData;
+    /** Use the XMP namespace registry implementation */
+    private static final XMPSchemaRegistry registry = XMPMetaFactory.getSchemaRegistry();
+
+    /**
+     * Initializes with an empty XMP packet
+     */
+    public XMPMetadata() {
+        xmpData = XMPMetaFactory.create();
+    }
+
+    /**
      * @see org.apache.tika.xmp.XMPMetadata(org.apache.tika.metadata.Metadata, java.lang.String)
-	 * But the mimetype is retrieved from the metadata map.
-	 */
-    public XMPMetadata (Metadata meta) throws TikaException
-    {
-    	this.xmpData = TikaToXMP.convert(meta);
+     * But the mimetype is retrieved from the metadata map.
+     */
+    public XMPMetadata(Metadata meta) throws TikaException {
+        this.xmpData = TikaToXMP.convert( meta );
     }
-    
+
     /**
-     * Initializes the data by converting the Metadata information to XMP.
-     * If a mimetype is provided, a specific converter can be used, that converts all
-     * available metadata. If there is no mimetype provided or no specific converter 
-     * available a generic conversion is done which will convert only those properties 
-     * that are in known namespaces and are using the correct prefixes
-     * 
-     * @param meta the Metadata information from Tika-core
-     * @param mimetype mimetype information
-     * @throws In case an error occured during conversion
+     * Initializes the data by converting the Metadata information to XMP. If a mimetype is
+     * provided, a specific converter can be used, that converts all available metadata. If there is
+     * no mimetype provided or no specific converter available a generic conversion is done which
+     * will convert only those properties that are in known namespaces and are using the correct
+     * prefixes
+     *
+     * @param meta
+     *            the Metadata information from Tika-core
+     * @param mimetype
+     *            mimetype information
+     * @throws In
+     *             case an error occured during conversion
      */
-    public XMPMetadata (Metadata meta, String mimetype) throws TikaException
-    {
-    	this.xmpData = TikaToXMP.convert(meta, mimetype);
+    public XMPMetadata(Metadata meta, String mimetype) throws TikaException {
+        this.xmpData = TikaToXMP.convert( meta, mimetype );
     }
-    
+
     /**
-     * @see org.apache.tika.xmp.XMPMetadata#process(org.apache.tika.metadata.Metadata, java.lang.String)
-	 * But the mimetype is retrieved from the metadata map.
-	 */
-    public void process(Metadata meta) throws TikaException
-    {  
-    	this.xmpData = TikaToXMP.convert(meta);
+     * @see org.apache.tika.xmp.XMPMetadata#process(org.apache.tika.metadata.Metadata,
+     *      java.lang.String)
+     *  But the mimetype is retrieved from the metadata map.
+     */
+    public void process(Metadata meta) throws TikaException {
+        this.xmpData = TikaToXMP.convert( meta );
     }
 
     /**
-     * Converts the Metadata information to XMP.
-     * If a mimetype is provided, a specific converter can be used, that converts all
-     * available metadata. If there is no mimetype provided or no specific converter 
-     * available a generic conversion is done which will convert only those properties 
-     * that are in known namespaces and are using the correct prefixes
-     * 
-     * @param meta the Metadata information from Tika-core
-     * @param mimetype mimetype information
-     * @throws In case an error occured during conversion
+     * Converts the Metadata information to XMP. If a mimetype is provided, a specific converter can
+     * be used, that converts all available metadata. If there is no mimetype provided or no
+     * specific converter available a generic conversion is done which will convert only those
+     * properties that are in known namespaces and are using the correct prefixes
+     *
+     * @param meta
+     *            the Metadata information from Tika-core
+     * @param mimetype
+     *            mimetype information
+     * @throws In
+     *             case an error occured during conversion
      */
-    public void process(Metadata meta, String mimetype) throws TikaException
-    {  
-    	this.xmpData = TikaToXMP.convert(meta, mimetype);
+    public void process(Metadata meta, String mimetype) throws TikaException {
+        this.xmpData = TikaToXMP.convert( meta, mimetype );
     }
 
-    
     /**
      * Provides direct access to the XMP data model, in case a client prefers to work directly on it
      * instead of using the Metadata API
+     *
      * @return the "internal" XMP data object
      */
-    public XMPMeta getXMPData() { return xmpData; }
+    public XMPMeta getXMPData() {
+        return xmpData;
+    }
 
-    
     // === Namespace Registry API === //
     /**
-	 * Register a namespace URI with a suggested prefix. It is not an error if
-	 * the URI is already registered, no matter what the prefix is. If the URI
-	 * is not registered but the suggested prefix is in use, a unique prefix is
-	 * created from the suggested one. The actual registeed prefix is always
-	 * returned. The function result tells if the registered prefix is the
-	 * suggested one.
-	 * <p>
-	 * Note: No checking is presently done on either the URI or the prefix.
-	 *
-	 * @param namespaceURI
-	 *            The URI for the namespace. Must be a valid XML URI.
-	 * @param suggestedPrefix
-	 *            The suggested prefix to be used if the URI is not yet
-	 *            registered. Must be a valid XML name.
-	 * @return Returns the registered prefix for this URI, is equal to the
-	 *         suggestedPrefix if the namespace hasn't been registered before,
-	 *         otherwise the existing prefix.
-	 * @throws XMPException If the parameters are not accordingly set
-	 */
-	public static String registerNamespace(String namespaceURI, String suggestedPrefix) throws XMPException
-	{
-		return registry.registerNamespace(namespaceURI, suggestedPrefix);
-	}
-
-	/**
-	 * Obtain the prefix for a registered namespace URI.
-	 * <p>
-	 * It is not an error if the namespace URI is not registered.
-	 *
-	 * @param namespaceURI
-	 *            The URI for the namespace. Must not be null or the empty
-	 *            string.
-	 * @return Returns the prefix registered for this namespace URI or null.
-	 */
-	public static String getNamespacePrefix(String namespaceURI)
-	{
-		return registry.getNamespacePrefix(namespaceURI);
-	}
-
-
-	/**
-	 * Obtain the URI for a registered namespace prefix.
-	 * <p>
-	 * It is not an error if the namespace prefix is not registered.
-	 *
-	 * @param namespacePrefix
-	 *            The prefix for the namespace. Must not be null or the empty
-	 *            string.
-	 * @return Returns the URI registered for this prefix or null.
-	 */
-	public static String getNamespaceURI(String namespacePrefix)
-	{
-		return registry.getNamespaceURI(namespacePrefix);
-	}
-
-
-	/**
-	 * @return Returns the registered prefix/namespace-pairs as map, where the keys are the
-	 *         namespaces and the values are the prefixes.
-	 */
-	@SuppressWarnings("unchecked")
-	public static Map<String, String> getNamespaces()
-	{
-		return registry.getNamespaces();
-	}
-
-
-	/**
-	 * @return Returns the registered namespace/prefix-pairs as map, where the keys are the
-	 *         prefixes and the values are the namespaces.
-	 */
-	@SuppressWarnings("unchecked")
-	public static Map<String, String> getPrefixes()
-	{
-		return registry.getPrefixes();
-	}
-
-	/**
-	 * Deletes a namespace from the registry.
-	 * <p>
-	 * Does nothing if the URI is not registered, or if the namespaceURI
-	 * parameter is null or the empty string.
-	 * <p>
-	 * Note: Not yet implemented.
-	 *
-	 * @param namespaceURI
-	 *            The URI for the namespace.
-	 */
-	public static void deleteNamespace(String namespaceURI)
-	{
-		registry.deleteNamespace(namespaceURI);
-	}
-	
-	
-	// === Metadata API === //
-	/**
-	 * @see org.apache.tika.xmp.XMPMetadata#isMultiValued(java.lang.String)
-	 */
-	@Override
-	public boolean isMultiValued(Property property) 
-	{
-		return this.isMultiValued(property.getName());
-	}
-
-	/**
-	 * Checks if the named property is an array.
-	 * @see org.apache.tika.metadata.Metadata#isMultiValued(java.lang.String)
-	 */
-	@Override
-	public boolean isMultiValued(String name)
-	{
-		checkKey(name);
-
-		String[] keyParts = splitKey(name);
-			
-		String ns = registry.getNamespaceURI(keyParts[0]);
-		if( ns != null )
-		{
-			try 
-			{
-				XMPProperty prop = xmpData.getProperty(ns, keyParts[1]);
-				
-				return prop.getOptions().isArray();
-			} 
-			catch (XMPException e) 
-			{
-				// Ignore
-			}
-		}
-		
-		return false;
-	}
-
-	/**
-	 * For XMP it is not clear what that API should return, therefor not implemented
-	 */
-	@Override
-	public String[] names() 
-	{
-		throw new UnsupportedOperationException("Not implemented");
-	}
-
-	/**
-	 * Returns the value of a simple property or the first one of an array. 
-	 * The given name must contain a namespace prefix of a registered namespace.
-	 * 
-	 * @see org.apache.tika.metadata.Metadata#get(java.lang.String)
-	 */
-	@Override
-	public String get(String name) 
-	{
-		checkKey(name);
-
-		String value = null;
-		String[] keyParts = splitKey(name);
-		
-		String ns = registry.getNamespaceURI(keyParts[0]);
-		if( ns != null )
-		{
-			try 
-			{
-				XMPProperty prop = xmpData.getProperty(ns, keyParts[1]);
-				
-				if( prop != null && prop.getOptions().isSimple() )
-				{
-					value = prop.getValue();
-				}
-				else if( prop != null && prop.getOptions().isArray() )
-				{
-					prop = xmpData.getArrayItem(ns, keyParts[1], 1);
-					value = prop.getValue();
-				}
-				// in all other cases, null is returned
-			} 
-			catch (XMPException e) 
-			{
-				// Ignore
-			}
-		}
-		
-		return value;
-	}
-
-	/**
-	 * @see org.apache.tika.xmp.XMPMetadata#get(java.lang.String)
-	 */
-	@Override
-	public String get(Property property) {
-		return this.get(property.getName());
-	}
-
-	/**
-	 * @see org.apache.tika.xmp.XMPMetadata#get(java.lang.String)
-	 */
-	@Override
-	public Integer getInt(Property property) 
-	{
-		Integer result = null;
-		
-		try 
-		{
-			result = new Integer(XMPUtils.convertToInteger(this.get(property.getName())));
-		} 
-		catch (XMPException e) 
-		{
-			//Ignore
-		}
-		
-		return result;
-	}
-
-	/**
-	 * @see org.apache.tika.xmp.XMPMetadata#get(java.lang.String)
-	 */
-	@Override
-	public Date getDate(Property property) 
-	{
-		Date result = null;
-		
-		try 
-		{
-			XMPDateTime xmpDate = XMPUtils.convertToDate(this.get(property.getName()));
-			if (xmpDate != null)
-			{
-				Calendar cal = xmpDate.getCalendar();
-				// TODO Timezone is currently lost
-				// need another solution that preserves the timezone
-				result = cal.getTime();
-			}
-		} 
-		catch (XMPException e) 
-		{
-			//Ignore
-		}
-		
-		return result;
-	}
-
-	/**
-	 * @see org.apache.tika.xmp.XMPMetadata#getValues(java.lang.String)
-	 */
-	@Override
-	public String[] getValues(Property property) 
-	{
-		return this.getValues(property.getName());
-	}
-
-	/**
-	 * Returns the value of a simple property or all if the property is an array and the elements are of simple type. 
-	 * The given name must contain a namespace prefix of a registered namespace.
-	 * @see org.apache.tika.metadata.Metadata#getValues(java.lang.String)
-	 */
-	@Override
-	public String[] getValues(String name) {
-		checkKey(name);
-
-		String[] value = null;
-		String[] keyParts = splitKey(name);
-		
-		String ns = registry.getNamespaceURI(keyParts[0]);
-		if( ns != null )
-		{
-			try
-			{
-				XMPProperty prop = xmpData.getProperty(ns, keyParts[1]);
-				
-				if( prop != null && prop.getOptions().isSimple() )
-				{
-					value = new String[1];
-					value[0] = prop.getValue();
-				}
-				else if( prop != null && prop.getOptions().isArray() )
-				{
-					int size = xmpData.countArrayItems(ns, keyParts[1]);
-					value = new String[size];
-					boolean onlySimpleChildren = true;
-					
-					for( int i = 0 ; i < size && onlySimpleChildren ; i++)
-					{
-						prop = xmpData.getArrayItem(ns, keyParts[1], i+1);
-						if( prop.getOptions().isSimple() )
-						{
-							value[i] = prop.getValue();
-						}
-						else
-						{
-							onlySimpleChildren = false;
-						}
-					}
-					
-					if( ! onlySimpleChildren )
-					{
-						value = null;
-					}
-				}
-				// in all other cases, null is returned
-			} 
-			catch (XMPException e) 
-			{
-				// Ignore
-			}
-		}
-		
-		return value;
-	}
-
-
-
-	/**
-	 * As this API could only possibly work for simple properties in XMP,
-	 * it just calls the set method, which replaces any existing value
-	 * @see org.apache.tika.metadata.Metadata#add(java.lang.String, java.lang.String)
-	 */
-	@Override
-	public void add(String name, String value) 
-	{
-		set(name, value);
-	}
-
-	/**
-	 * Sets the given property. If the property already exists, it is overwritten. 
-	 * Only simple properties that use a registered prefix are stored in the XMP.
-	 *  
-	 * @see org.apache.tika.metadata.Metadata#set(java.lang.String, java.lang.String)
-	 */
-	@Override
-	public void set(String name, String value) 
-	{
-		checkKey(name);
-		
-		String[] keyParts = splitKey(name);
-		
-		String ns = registry.getNamespaceURI(keyParts[0]);
-		if( ns != null )
-		{
-			try 
-			{
-				xmpData.setProperty(ns, keyParts[1], value);
-			} 
-			catch (XMPException e) 
-			{
-				// Ignore
-			}
-		}
-	}
-
-	/**
-	 * @see org.apache.tika.xmp.XMPMetadata#set(java.lang.String, java.lang.String)
-	 */
-	@Override
-	public void set(Property property, String value) 
-	{
-		this.set(property.getName(), value);
-	}
-	
-	/**
-	 * @see org.apache.tika.xmp.XMPMetadata#set(java.lang.String, java.lang.String)
-	 */
-	@Override
-	public void set(Property property, int value) 
-	{
-		// Can reuse the checks from the base class implementation which will call 
-		// the set(String, String) method in the end 
-		super.set(property, value);
-	}
-	
-	/**
-	 * @see org.apache.tika.xmp.XMPMetadata#set(java.lang.String, java.lang.String)
-	 */
-	@Override
-	public void set(Property property, double value) 
-	{
-		super.set(property, value);
-	}
-	
-	/**
-	 * @see org.apache.tika.xmp.XMPMetadata#set(java.lang.String, java.lang.String)
-	 */
-	@Override
-	public void set(Property property, Date date) 
-	{
-		super.set(property, date);
-	}
-	
-	/**
-	 * Sets array properties. If the property already exists, it is overwritten. 
-	 * Only array properties that use a registered prefix are stored in the XMP.
-	 * @see org.apache.tika.metadata.Metadata#set(org.apache.tika.metadata.Property, java.lang.String[])
-	 */
-	@Override
-	public void set(Property property, String[] values) 
-	{
-		checkKey(property.getName());
-	
-		if(	! property.isMultiValuePermitted() ) 
-		{
-            throw new PropertyTypeException("Property is not of an array type");
+     * Register a namespace URI with a suggested prefix. It is not an error if the URI is already
+     * registered, no matter what the prefix is. If the URI is not registered but the suggested
+     * prefix is in use, a unique prefix is created from the suggested one. The actual registeed
+     * prefix is always returned. The function result tells if the registered prefix is the
+     * suggested one.
+     * Note: No checking is presently done on either the URI or the prefix.
+     *
+     * @param namespaceURI
+     *            The URI for the namespace. Must be a valid XML URI.
+     * @param suggestedPrefix
+     *            The suggested prefix to be used if the URI is not yet registered. Must be a valid
+     *            XML name.
+     * @return Returns the registered prefix for this URI, is equal to the suggestedPrefix if the
+     *         namespace hasn't been registered before, otherwise the existing prefix.
+     * @throws XMPException
+     *             If the parameters are not accordingly set
+     */
+    public static String registerNamespace(String namespaceURI, String suggestedPrefix)
+            throws XMPException {
+        return registry.registerNamespace( namespaceURI, suggestedPrefix );
+    }
+
+    /**
+     * Obtain the prefix for a registered namespace URI.
+     * It is not an error if the namespace URI is not registered.
+     *
+     * @param namespaceURI
+     *            The URI for the namespace. Must not be null or the empty string.
+     * @return Returns the prefix registered for this namespace URI or null.
+     */
+    public static String getNamespacePrefix(String namespaceURI) {
+        return registry.getNamespacePrefix( namespaceURI );
+    }
+
+    /**
+     * Obtain the URI for a registered namespace prefix.
+     * It is not an error if the namespace prefix is not registered.
+     *
+     * @param namespacePrefix
+     *            The prefix for the namespace. Must not be null or the empty string.
+     * @return Returns the URI registered for this prefix or null.
+     */
+    public static String getNamespaceURI(String namespacePrefix) {
+        return registry.getNamespaceURI( namespacePrefix );
+    }
+
+    /**
+     * @return Returns the registered prefix/namespace-pairs as map, where the keys are the
+     *         namespaces and the values are the prefixes.
+     */
+    @SuppressWarnings("unchecked")
+    public static Map<String, String> getNamespaces() {
+        return registry.getNamespaces();
+    }
+
+    /**
+     * @return Returns the registered namespace/prefix-pairs as map, where the keys are the prefixes
+     *         and the values are the namespaces.
+     */
+    @SuppressWarnings("unchecked")
+    public static Map<String, String> getPrefixes() {
+        return registry.getPrefixes();
+    }
+
+    /**
+     * Deletes a namespace from the registry.
+     * <p>
+     * Does nothing if the URI is not registered, or if the namespaceURI parameter is null or the
+     * empty string.
+     * <p>
+     * Note: Not yet implemented.
+     *
+     * @param namespaceURI
+     *            The URI for the namespace.
+     */
+    public static void deleteNamespace(String namespaceURI) {
+        registry.deleteNamespace( namespaceURI );
+    }
+
+    // === Metadata API === //
+    /**
+     * @see org.apache.tika.xmp.XMPMetadata#isMultiValued(java.lang.String)
+     */
+    @Override
+    public boolean isMultiValued(Property property) {
+        return this.isMultiValued( property.getName() );
+    }
+
+    /**
+     * Checks if the named property is an array.
+     *
+     * @see org.apache.tika.metadata.Metadata#isMultiValued(java.lang.String)
+     */
+    @Override
+    public boolean isMultiValued(String name) {
+        checkKey( name );
+
+        String[] keyParts = splitKey( name );
+
+        String ns = registry.getNamespaceURI( keyParts[0] );
+        if (ns != null) {
+            try {
+                XMPProperty prop = xmpData.getProperty( ns, keyParts[1] );
+
+                return prop.getOptions().isArray();
+            }
+            catch (XMPException e) {
+                // Ignore
+            }
         }
-		
-		String[] keyParts = splitKey(property.getName());
-		
-		String ns = registry.getNamespaceURI(keyParts[0]);
-		if( ns != null )
-		{
-			try 
-			{
-				int arrayType = tikaToXMPArrayType(property.getPrimaryProperty().getPropertyType());
-				xmpData.setProperty(ns, keyParts[1], null, new PropertyOptions(arrayType));
-				
-				for( String value : values )
-				{
-					xmpData.appendArrayItem(ns, keyParts[1], value);
-				}
-			} 
-			catch (XMPException e) 
-			{
-				// Ignore
-			}
-		}
-	}
-	
-	/**
-	 * It will set all simple and array properties that have QName keys in registered namespaces.
-	 * @see org.apache.tika.metadata.Metadata#setAll(java.util.Properties)
-	 */
-	@Override
-	public void setAll(Properties properties) 
-	{
-		@SuppressWarnings("unchecked")
-		Enumeration<String> names = (Enumeration<String>) properties.propertyNames();
-        
-		while (names.hasMoreElements()) 
-		{
+
+        return false;
+    }
+
+    /**
+     * For XMP it is not clear what that API should return, therefor not implemented
+     */
+    @Override
+    public String[] names() {
+        throw new UnsupportedOperationException( "Not implemented" );
+    }
+
+    /**
+     * Returns the value of a simple property or the first one of an array. The given name must
+     * contain a namespace prefix of a registered namespace.
+     *
+     * @see org.apache.tika.metadata.Metadata#get(java.lang.String)
+     */
+    @Override
+    public String get(String name) {
+        checkKey( name );
+
+        String value = null;
+        String[] keyParts = splitKey( name );
+
+        String ns = registry.getNamespaceURI( keyParts[0] );
+        if (ns != null) {
+            try {
+                XMPProperty prop = xmpData.getProperty( ns, keyParts[1] );
+
+                if (prop != null && prop.getOptions().isSimple()) {
+                    value = prop.getValue();
+                }
+                else if (prop != null && prop.getOptions().isArray()) {
+                    prop = xmpData.getArrayItem( ns, keyParts[1], 1 );
+                    value = prop.getValue();
+                }
+                // in all other cases, null is returned
+            }
+            catch (XMPException e) {
+                // Ignore
+            }
+        }
+
+        return value;
+    }
+
+    /**
+     * @see org.apache.tika.xmp.XMPMetadata#get(java.lang.String)
+     */
+    @Override
+    public String get(Property property) {
+        return this.get( property.getName() );
+    }
+
+    /**
+     * @see org.apache.tika.xmp.XMPMetadata#get(java.lang.String)
+     */
+    @Override
+    public Integer getInt(Property property) {
+        Integer result = null;
+
+        try {
+            result = new Integer( XMPUtils.convertToInteger( this.get( property.getName() ) ) );
+        }
+        catch (XMPException e) {
+            // Ignore
+        }
+
+        return result;
+    }
+
+    /**
+     * @see org.apache.tika.xmp.XMPMetadata#get(java.lang.String)
+     */
+    @Override
+    public Date getDate(Property property) {
+        Date result = null;
+
+        try {
+            XMPDateTime xmpDate = XMPUtils.convertToDate( this.get( property.getName() ) );
+            if (xmpDate != null) {
+                Calendar cal = xmpDate.getCalendar();
+                // TODO Timezone is currently lost
+                // need another solution that preserves the timezone
+                result = cal.getTime();
+            }
+        }
+        catch (XMPException e) {
+            // Ignore
+        }
+
+        return result;
+    }
+
+    /**
+     * @see org.apache.tika.xmp.XMPMetadata#getValues(java.lang.String)
+     */
+    @Override
+    public String[] getValues(Property property) {
+        return this.getValues( property.getName() );
+    }
+
+    /**
+     * Returns the value of a simple property or all if the property is an array and the elements
+     * are of simple type. The given name must contain a namespace prefix of a registered namespace.
+     *
+     * @see org.apache.tika.metadata.Metadata#getValues(java.lang.String)
+     */
+    @Override
+    public String[] getValues(String name) {
+        checkKey( name );
+
+        String[] value = null;
+        String[] keyParts = splitKey( name );
+
+        String ns = registry.getNamespaceURI( keyParts[0] );
+        if (ns != null) {
+            try {
+                XMPProperty prop = xmpData.getProperty( ns, keyParts[1] );
+
+                if (prop != null && prop.getOptions().isSimple()) {
+                    value = new String[1];
+                    value[0] = prop.getValue();
+                }
+                else if (prop != null && prop.getOptions().isArray()) {
+                    int size = xmpData.countArrayItems( ns, keyParts[1] );
+                    value = new String[size];
+                    boolean onlySimpleChildren = true;
+
+                    for (int i = 0; i < size && onlySimpleChildren; i++) {
+                        prop = xmpData.getArrayItem( ns, keyParts[1], i + 1 );
+                        if (prop.getOptions().isSimple()) {
+                            value[i] = prop.getValue();
+                        }
+                        else {
+                            onlySimpleChildren = false;
+                        }
+                    }
+
+                    if (!onlySimpleChildren) {
+                        value = null;
+                    }
+                }
+                // in all other cases, null is returned
+            }
+            catch (XMPException e) {
+                // Ignore
+            }
+        }
+
+        return value;
+    }
+
+    /**
+     * As this API could only possibly work for simple properties in XMP, it just calls the set
+     * method, which replaces any existing value
+     *
+     * @see org.apache.tika.metadata.Metadata#add(java.lang.String, java.lang.String)
+     */
+    @Override
+    public void add(String name, String value) {
+        set( name, value );
+    }
+
+    /**
+     * Sets the given property. If the property already exists, it is overwritten. Only simple
+     * properties that use a registered prefix are stored in the XMP.
+     *
+     * @see org.apache.tika.metadata.Metadata#set(java.lang.String, java.lang.String)
+     */
+    @Override
+    public void set(String name, String value) {
+        checkKey( name );
+
+        String[] keyParts = splitKey( name );
+
+        String ns = registry.getNamespaceURI( keyParts[0] );
+        if (ns != null) {
+            try {
+                xmpData.setProperty( ns, keyParts[1], value );
+            }
+            catch (XMPException e) {
+                // Ignore
+            }
+        }
+    }
+
+    /**
+     * @see org.apache.tika.xmp.XMPMetadata#set(java.lang.String, java.lang.String)
+     */
+    @Override
+    public void set(Property property, String value) {
+        this.set( property.getName(), value );
+    }
+
+    /**
+     * @see org.apache.tika.xmp.XMPMetadata#set(java.lang.String, java.lang.String)
+     */
+    @Override
+    public void set(Property property, int value) {
+        // Can reuse the checks from the base class implementation which will call
+        // the set(String, String) method in the end
+        super.set( property, value );
+    }
+
+    /**
+     * @see org.apache.tika.xmp.XMPMetadata#set(java.lang.String, java.lang.String)
+     */
+    @Override
+    public void set(Property property, double value) {
+        super.set( property, value );
+    }
+
+    /**
+     * @see org.apache.tika.xmp.XMPMetadata#set(java.lang.String, java.lang.String)
+     */
+    @Override
+    public void set(Property property, Date date) {
+        super.set( property, date );
+    }
+
+    /**
+     * Sets array properties. If the property already exists, it is overwritten. Only array
+     * properties that use a registered prefix are stored in the XMP.
+     *
+     * @see org.apache.tika.metadata.Metadata#set(org.apache.tika.metadata.Property,
+     *      java.lang.String[])
+     */
+    @Override
+    public void set(Property property, String[] values) {
+        checkKey( property.getName() );
+
+        if (!property.isMultiValuePermitted()) {
+            throw new PropertyTypeException( "Property is not of an array type" );
+        }
+
+        String[] keyParts = splitKey( property.getName() );
+
+        String ns = registry.getNamespaceURI( keyParts[0] );
+        if (ns != null) {
+            try {
+                int arrayType = tikaToXMPArrayType( property.getPrimaryProperty().getPropertyType() );
+                xmpData.setProperty( ns, keyParts[1], null, new PropertyOptions( arrayType ) );
+
+                for (String value : values) {
+                    xmpData.appendArrayItem( ns, keyParts[1], value );
+                }
+            }
+            catch (XMPException e) {
+                // Ignore
+            }
+        }
+    }
+
+    /**
+     * It will set all simple and array properties that have QName keys in registered namespaces.
+     *
+     * @see org.apache.tika.metadata.Metadata#setAll(java.util.Properties)
+     */
+    @Override
+    public void setAll(Properties properties) {
+        @SuppressWarnings("unchecked")
+        Enumeration<String> names = (Enumeration<String>) properties.propertyNames();
+
+        while (names.hasMoreElements()) {
             String name = names.nextElement();
-            Property property = Property.get(name);
-            if( property == null )
-            {
-            	throw new PropertyTypeException("Unknown property: " + name);
+            Property property = Property.get( name );
+            if (property == null) {
+                throw new PropertyTypeException( "Unknown property: " + name );
+            }
+
+            String value = properties.getProperty( name );
+
+            if (property.isMultiValuePermitted()) {
+                this.set( property, new String[] { value } );
             }
-            
-            String value = properties.getProperty(name);
-            
-            if( property.isMultiValuePermitted() )
-            {
-            	this.set(property,  new String[] { value });
+            else {
+                this.set( property, value );
             }
-            else
-            {
-            	this.set(property, value);
+        }
+    }
+
+    /**
+     * @see org.apache.tika.xmp.XMPMetadata#remove(java.lang.String)
+     */
+    public void remove(Property property) {
+        this.remove( property.getName() );
+    }
+
+    /**
+     * Removes the given property from the XMP data. If it is a complex property the whole subtree
+     * is removed
+     *
+     * @see org.apache.tika.metadata.Metadata#remove(java.lang.String)
+     */
+    @Override
+    public void remove(String name) {
+        checkKey( name );
+
+        String[] keyParts = splitKey( name );
+
+        String ns = registry.getNamespaceURI( keyParts[0] );
+        if (ns != null) {
+            xmpData.deleteProperty( ns, keyParts[1] );
+        }
+    }
+
+    /**
+     * Returns the number of top-level namespaces
+     */
+    @Override
+    public int size() {
+        int size = 0;
+
+        try {
+            // Get an iterator for the XMP packet, starting at the top level schema nodes
+            XMPIterator nsIter = xmpData.iterator( new IteratorOptions().setJustChildren( true )
+                    .setOmitQualifiers( true ) );
+            // iterate all top level namespaces
+            while (nsIter.hasNext()) {
+                nsIter.next();
+                size++;
             }
         }
-	}
-
-
-	/**
-	 * @see org.apache.tika.xmp.XMPMetadata#remove(java.lang.String)
-	 */
-	public void remove(Property property) 
-	{
-		this.remove(property.getName());
-	}
-	
-	/**
-	 * Removes the given property from the XMP data. 
-	 * If it is a complex property the whole subtree is removed
-	 * @see org.apache.tika.metadata.Metadata#remove(java.lang.String)
-	 */
-	@Override
-	public void remove(String name) 
-	{
-		checkKey(name);
-		
-		String[] keyParts = splitKey(name);
-			
-		String ns = registry.getNamespaceURI(keyParts[0]);
-		if( ns != null )
-		{
-			xmpData.deleteProperty(ns, keyParts[1]);
-		}
-	}
-	
-	/**
-	 * Returns the number of top-level namespaces
-	 */
-	@Override
-	public int size() 
-	{
-		int size = 0;
-
-		try 
-		{
-			// Get an iterator for the XMP packet, starting at the top level schema nodes
-			XMPIterator nsIter = xmpData.iterator( new IteratorOptions().setJustChildren(true).setOmitQualifiers(true) );
-			// iterate all top level namespaces
-			while (nsIter.hasNext())
-			{
-				nsIter.next();
-				size++;
-			}
-		} 
-		catch (XMPException e) 
-		{
-			// ignore
-		}
-		
-		return size;
-	}
-
-	/**
-	 * This method is not implemented, yet. It is very tedious to check for semantic equality of XMP packets
-	 */
-	@Override
-	public boolean equals(Object o) 
-	{
-		throw new UnsupportedOperationException("Not implemented");
-	}
-
-	/**
-	 * Serializes the XMP data in compact form without packet wrapper
-	 * @see org.apache.tika.metadata.Metadata#toString()
-	 */
-	@Override
-	public String toString() 
-	{
-		String result = null;
-		try 
-		{
-			result = XMPMetaFactory.serializeToString(xmpData, new SerializeOptions().setOmitPacketWrapper(true).setUseCompactFormat(true));
-		} 
-		catch (XMPException e) 
-		{
-			// ignore
-		}
-		return result;
-	}
-
-	// The XMP object is not serializable!
-	private void readObject(ObjectInputStream ois) throws ClassNotFoundException, IOException 
-	{
-		throw new NotSerializableException();
-	}
-
-	// The XMP object is not serializable!
-	private void writeObject(ObjectOutputStream ois) throws IOException 
-	{
-		throw new NotSerializableException();
-	}
-
-	/**
-	 * Checks if the given key is a valid QName with a known standard namespace prefix
-	 * 
-	 * @param key
-	 *            the key to check
-	 * @return true if the key is valid otherwise false
-	 */
-	private void checkKey(String key) throws PropertyTypeException
-	{
-		if( key == null || key.length() == 0 )
-		{
-			throw new PropertyTypeException("Key must not be null");
-		}
-		
-		String[] keyParts = splitKey(key);
-		if( keyParts == null )
-		{
-			throw new PropertyTypeException("Key must be a QName in the form prefix:localName");
-		}
-
-		if( registry.getNamespaceURI(keyParts[0]) == null )
-		{
-			throw new PropertyTypeException("Key does not use a registered Namespace prefix");
-		}
-	}
-	
-	/**
-	 * Split the given key at the namespace prefix delimiter
-	 * @param key the key to split
-	 * @return prefix and local name of the property or null if the key did not
-	 * contain a delimiter or too much of them
-	 */
-	private String[] splitKey(String key)
-	{
-		String[] keyParts = key.split(Metadata.NAMESPACE_PREFIX_DELIMITER);
-		if (keyParts.length > 0 && keyParts.length <= 2)
-		{
-			return keyParts;
-		}
-		
-		return null;
-	}// checkKeyPrefix
-
-	/**
-	 * Convert Tika array types to XMP array types
-	 * @param type
-	 * @return
-	 */
-	private int tikaToXMPArrayType(PropertyType type)
-	{
-		int result = 0;
-		switch(type)
-		{
-			case BAG:
-				result = PropertyOptions.ARRAY;
-				break;
-			case SEQ:
-				result = PropertyOptions.ARRAY_ORDERED;
-				break;
-			case ALT:
-				result = PropertyOptions.ARRAY_ALTERNATE;
-				break;
-		}
-		return result;
-	}
+        catch (XMPException e) {
+            // ignore
+        }
+
+        return size;
+    }
+
+    /**
+     * This method is not implemented, yet. It is very tedious to check for semantic equality of XMP
+     * packets
+     */
+    @Override
+    public boolean equals(Object o) {
+        throw new UnsupportedOperationException( "Not implemented" );
+    }
+
+    /**
+     * Serializes the XMP data in compact form without packet wrapper
+     *
+     * @see org.apache.tika.metadata.Metadata#toString()
+     */
+    @Override
+    public String toString() {
+        String result = null;
+        try {
+            result = XMPMetaFactory.serializeToString( xmpData, new SerializeOptions()
+                    .setOmitPacketWrapper( true ).setUseCompactFormat( true ) );
+        }
+        catch (XMPException e) {
+            // ignore
+        }
+        return result;
+    }
+
+    // The XMP object is not serializable!
+    private void readObject(ObjectInputStream ois) throws ClassNotFoundException, IOException {
+        throw new NotSerializableException();
+    }
+
+    // The XMP object is not serializable!
+    private void writeObject(ObjectOutputStream ois) throws IOException {
+        throw new NotSerializableException();
+    }
+
+    /**
+     * Checks if the given key is a valid QName with a known standard namespace prefix
+     *
+     * @param key
+     *            the key to check
+     * @return true if the key is valid otherwise false
+     */
+    private void checkKey(String key) throws PropertyTypeException {
+        if (key == null || key.length() == 0) {
+            throw new PropertyTypeException( "Key must not be null" );
+        }
+
+        String[] keyParts = splitKey( key );
+        if (keyParts == null) {
+            throw new PropertyTypeException( "Key must be a QName in the form prefix:localName" );
+        }
+
+        if (registry.getNamespaceURI( keyParts[0] ) == null) {
+            throw new PropertyTypeException( "Key does not use a registered Namespace prefix" );
+        }
+    }
+
+    /**
+     * Split the given key at the namespace prefix delimiter
+     *
+     * @param key
+     *            the key to split
+     * @return prefix and local name of the property or null if the key did not contain a delimiter
+     *         or too much of them
+     */
+    private String[] splitKey(String key) {
+        String[] keyParts = key.split( Metadata.NAMESPACE_PREFIX_DELIMITER );
+        if (keyParts.length > 0 && keyParts.length <= 2) {
+            return keyParts;
+        }
+
+        return null;
+    }// checkKeyPrefix
+
+    /**
+     * Convert Tika array types to XMP array types
+     *
+     * @param type
+     * @return
+     */
+    private int tikaToXMPArrayType(PropertyType type) {
+        int result = 0;
+        switch (type) {
+            case BAG:
+                result = PropertyOptions.ARRAY;
+                break;
+            case SEQ:
+                result = PropertyOptions.ARRAY_ORDERED;
+                break;
+            case ALT:
+                result = PropertyOptions.ARRAY_ALTERNATE;
+                break;
+        }
+        return result;
+    }
 }
diff --git a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/AbstractConverter.java b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/AbstractConverter.java
index 121404d73..1d3753bda 100644
--- a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/AbstractConverter.java
+++ b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/AbstractConverter.java
@@ -13,10 +13,6 @@
  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  * See the License for the specific language governing permissions and
  * limitations under the License.
- *
- * IPTC Metadata Descriptions taken from the IPTC Photo Metadata (July 2010) 
- * standard. These parts Copyright 2010 International Press Telecommunications 
- * Council.
  */
 package org.apache.tika.xmp.convert;
 
@@ -35,165 +31,174 @@ import com.adobe.xmp.XMPUtils;
 import com.adobe.xmp.options.PropertyOptions;
 
 /**
- * Base class for Tika Metadata to XMP converter which provides some needed
- * common functionality.
+ * Base class for Tika Metadata to XMP converter which provides some needed common functionality.
  */
-public abstract class AbstractConverter implements ITikaToXMPConverter
-{
-	private Metadata metadata;
-	protected XMPMeta meta;
-
-	abstract public XMPMeta process(Metadata metadata) throws XMPException;
-	
-	/**
-	 * Every Converter has to provide information about namespaces
-	 * that are used additionally to the core set of XMP namespaces.
-	 * 
-	 * @return the additional namespace information
-	 */
-	abstract protected Set<Namespace> getAdditionalNamespaces();
-	
-	public AbstractConverter() throws TikaException
-	{
-		meta = XMPMetaFactory.create();
-		metadata = new Metadata();
-		registerNamespaces(getAdditionalNamespaces());
-	}
-
-	public void setMetadata(Metadata metadata)
-	{
-		this.metadata = metadata;
-	}
-
-	public XMPMeta getXMPMeta()
-	{
-		return meta;
-	}
-
-	// --- utility methods used by sub-classes ---
-	
-	/** 
-	 * Registers a number <code>Namespace</code> information with XMPCore.
-	 * Any already registered namespace is not registered again.
-	 * 
-	 * @param namespaces the list of namespaces to be registered
-	 * @throws TikaException in case a namespace oculd not be registered
-	 */
-	protected void registerNamespaces(Set<Namespace> namespaces) throws TikaException
-	{
-		XMPSchemaRegistry registry = XMPMetaFactory.getSchemaRegistry();
-
-		for( Namespace namespace : namespaces)
-		{
-			// Any already registered namespace is not registered again
-			try 
-			{
-				registry.registerNamespace(namespace.uri, namespace.prefix);
-			} 
-			catch (XMPException e) 
-			{
-				throw new TikaException("Namespace needed by converter could not be registiered with XMPCore", e);
-			}
-		}
-	}
-	
-	/**
-	 * @see AbstractConverter#createProperty(String, String, String);
-	 */
-	protected void createProperty(Property metadataProperty, String ns, String propertyName) throws XMPException
-	{
-		createProperty(metadataProperty.getName(), ns, propertyName);
-	}
-
-	/**
-	 * Creates a simple property.
-	 * @param tikaKey Key in the Tika metadata map
-	 * @param ns namespace the property should be created in
-	 * @param propertyName name of the property
-	 * @throws XMPException if the property could not be created
-	 */
-	protected void createProperty(String tikaKey, String ns, String propertyName) throws XMPException
-	{
-		String value = metadata.get(tikaKey);
-		if (value != null  &&  value.length() > 0)
-		{
-			meta.setProperty(ns, propertyName, value);
-		}
-	}
-
-	/**
-	 * @see AbstractConverter#createLangAltProperty(String, String, String);
-	 */
-	protected void createLangAltProperty(Property metadataProperty, String ns, String propertyName) throws XMPException
-	{
-		createLangAltProperty(metadataProperty.getName(), ns, propertyName);
-	}
-	
-	/**
-	 * Creates a language alternative property in the x-default language
-	 * @param tikaKey Key in the Tika metadata map
-	 * @param ns namespace the property should be created in
-	 * @param propertyName name of the property
-	 * @throws XMPException if the property could not be created
-	 */
-	protected void createLangAltProperty(String tikaKey, String ns, String propertyName) throws XMPException
-	{
-		String value = metadata.get(tikaKey);
-		if (value != null  &&  value.length() > 0)
-		{
-			meta.setLocalizedText(ns, propertyName, null, XMPConst.X_DEFAULT, value);
-		}
-	}
-
-	protected void createArrayProperty(Property metadataProperty, String nsDc, String arrayProperty, int arrayType) throws XMPException
-	{
-		createArrayProperty(metadataProperty.getName(), nsDc, arrayProperty, arrayType);
-	}
-	
-	/**
-	 * Creates an array property from a list of values.
-	 * @param tikaKey Key in the Tika metadata map
-	 * @param ns namespace the property should be created in
-	 * @param propertyName name of the property
-	 * @param arrayType depicts which kind of array shall be created
-	 * @throws XMPException if the property could not be created
-	 */
-	protected void createArrayProperty(String tikaKey, String ns, String propertyName, int arrayType) throws XMPException
-	{
-		String[] values = metadata.getValues(tikaKey);
-		if (values != null)
-		{
-			meta.setProperty(ns, propertyName, null, new PropertyOptions(arrayType));
-			for( String value : values )
-			{
-				meta.appendArrayItem( ns, propertyName, value );
-			}
-		}
-	}
-	
-	protected void createCommaSeparatedArray(Property metadataProperty, String nsDc, String arrayProperty, int arrayType) throws XMPException
-	{
-		createCommaSeparatedArray(metadataProperty.getName(), nsDc, arrayProperty, arrayType);
-	}
-	
-	/**
-	 * Creates an array property from a comma separated list.
-	 * @param tikaKey Key in the Tika metadata map
-	 * @param ns namespace the property should be created in
-	 * @param propertyName name of the property
-	 * @param arrayType depicts which kind of array shall be created
-	 * @throws XMPException if the property could not be created
-	 */
-	protected void createCommaSeparatedArray(String tikaKey, String ns, String propertyName, int arrayType) throws XMPException
-	{
-		String value = metadata.get(tikaKey);
-		if (value != null  &&  value.length() > 0)
-		{
-			XMPUtils.separateArrayItems(meta, ns, propertyName, value, new PropertyOptions(arrayType), false);
-		}
-	}
-
-
-
+public abstract class AbstractConverter implements ITikaToXMPConverter {
+    private Metadata metadata;
+    protected XMPMeta meta;
+
+    abstract public XMPMeta process(Metadata metadata) throws XMPException;
+
+    /**
+     * Every Converter has to provide information about namespaces that are used additionally to the
+     * core set of XMP namespaces.
+     *
+     * @return the additional namespace information
+     */
+    abstract protected Set<Namespace> getAdditionalNamespaces();
+
+    public AbstractConverter() throws TikaException {
+        meta = XMPMetaFactory.create();
+        metadata = new Metadata();
+        registerNamespaces( getAdditionalNamespaces() );
+    }
+
+    public void setMetadata(Metadata metadata) {
+        this.metadata = metadata;
+    }
+
+    public XMPMeta getXMPMeta() {
+        return meta;
+    }
+
+    // --- utility methods used by sub-classes ---
+
+    /**
+     * Registers a number <code>Namespace</code> information with XMPCore. Any already registered
+     * namespace is not registered again.
+     *
+     * @param namespaces
+     *            the list of namespaces to be registered
+     * @throws TikaException
+     *             in case a namespace oculd not be registered
+     */
+    protected void registerNamespaces(Set<Namespace> namespaces) throws TikaException {
+        XMPSchemaRegistry registry = XMPMetaFactory.getSchemaRegistry();
+
+        for (Namespace namespace : namespaces) {
+            // Any already registered namespace is not registered again
+            try {
+                registry.registerNamespace( namespace.uri, namespace.prefix );
+            }
+            catch (XMPException e) {
+                throw new TikaException(
+                        "Namespace needed by converter could not be registiered with XMPCore", e );
+            }
+        }
+    }
+
+    /**
+     * @see AbstractConverter#createProperty(String, String, String);
+     */
+    protected void createProperty(Property metadataProperty, String ns, String propertyName)
+            throws XMPException {
+        createProperty( metadataProperty.getName(), ns, propertyName );
+    }
+
+    /**
+     * Creates a simple property.
+     *
+     * @param tikaKey
+     *            Key in the Tika metadata map
+     * @param ns
+     *            namespace the property should be created in
+     * @param propertyName
+     *            name of the property
+     * @throws XMPException
+     *             if the property could not be created
+     */
+    protected void createProperty(String tikaKey, String ns, String propertyName)
+            throws XMPException {
+        String value = metadata.get( tikaKey );
+        if (value != null && value.length() > 0) {
+            meta.setProperty( ns, propertyName, value );
+        }
+    }
+
+    /**
+     * @see AbstractConverter#createLangAltProperty(String, String, String);
+     */
+    protected void createLangAltProperty(Property metadataProperty, String ns, String propertyName)
+            throws XMPException {
+        createLangAltProperty( metadataProperty.getName(), ns, propertyName );
+    }
+
+    /**
+     * Creates a language alternative property in the x-default language
+     *
+     * @param tikaKey
+     *            Key in the Tika metadata map
+     * @param ns
+     *            namespace the property should be created in
+     * @param propertyName
+     *            name of the property
+     * @throws XMPException
+     *             if the property could not be created
+     */
+    protected void createLangAltProperty(String tikaKey, String ns, String propertyName)
+            throws XMPException {
+        String value = metadata.get( tikaKey );
+        if (value != null && value.length() > 0) {
+            meta.setLocalizedText( ns, propertyName, null, XMPConst.X_DEFAULT, value );
+        }
+    }
+
+    protected void createArrayProperty(Property metadataProperty, String nsDc,
+            String arrayProperty, int arrayType) throws XMPException {
+        createArrayProperty( metadataProperty.getName(), nsDc, arrayProperty, arrayType );
+    }
+
+    /**
+     * Creates an array property from a list of values.
+     *
+     * @param tikaKey
+     *            Key in the Tika metadata map
+     * @param ns
+     *            namespace the property should be created in
+     * @param propertyName
+     *            name of the property
+     * @param arrayType
+     *            depicts which kind of array shall be created
+     * @throws XMPException
+     *             if the property could not be created
+     */
+    protected void createArrayProperty(String tikaKey, String ns, String propertyName, int arrayType)
+            throws XMPException {
+        String[] values = metadata.getValues( tikaKey );
+        if (values != null) {
+            meta.setProperty( ns, propertyName, null, new PropertyOptions( arrayType ) );
+            for (String value : values) {
+                meta.appendArrayItem( ns, propertyName, value );
+            }
+        }
+    }
+
+    protected void createCommaSeparatedArray(Property metadataProperty, String nsDc,
+            String arrayProperty, int arrayType) throws XMPException {
+        createCommaSeparatedArray( metadataProperty.getName(), nsDc, arrayProperty, arrayType );
+    }
+
+    /**
+     * Creates an array property from a comma separated list.
+     *
+     * @param tikaKey
+     *            Key in the Tika metadata map
+     * @param ns
+     *            namespace the property should be created in
+     * @param propertyName
+     *            name of the property
+     * @param arrayType
+     *            depicts which kind of array shall be created
+     * @throws XMPException
+     *             if the property could not be created
+     */
+    protected void createCommaSeparatedArray(String tikaKey, String ns, String propertyName,
+            int arrayType) throws XMPException {
+        String value = metadata.get( tikaKey );
+        if (value != null && value.length() > 0) {
+            XMPUtils.separateArrayItems( meta, ns, propertyName, value, new PropertyOptions(
+                    arrayType ), false );
+        }
+    }
 
 }
diff --git a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/GenericConverter.java b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/GenericConverter.java
index 83fe83762..a2781ef08 100644
--- a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/GenericConverter.java
+++ b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/GenericConverter.java
@@ -13,10 +13,6 @@
  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  * See the License for the specific language governing permissions and
  * limitations under the License.
- *
- * IPTC Metadata Descriptions taken from the IPTC Photo Metadata (July 2010) 
- * standard. These parts Copyright 2010 International Press Telecommunications 
- * Council.
  */
 package org.apache.tika.xmp.convert;
 
@@ -38,79 +34,71 @@ import com.adobe.xmp.XMPSchemaRegistry;
 import com.adobe.xmp.options.PropertyOptions;
 
 /**
- * Trys to convert as much of the properties in the <code>Metadata</code> map
- * to XMP namespaces. only those properties will be cnverted where the name contains 
- * a prefix and this prefix correlates with a "known" prefix for a standard namespace.
- * For example "dc:title" would be mapped to the "title" property in the DublinCore namespace.
+ * Trys to convert as much of the properties in the <code>Metadata</code> map to XMP namespaces.
+ * only those properties will be cnverted where the name contains a prefix and this prefix
+ * correlates with a "known" prefix for a standard namespace. For example "dc:title" would be mapped
+ * to the "title" property in the DublinCore namespace.
  */
-public class GenericConverter extends AbstractConverter 
-{
-	public GenericConverter() throws TikaException 
-	{
-		super();
-	}
+public class GenericConverter extends AbstractConverter {
+    public GenericConverter() throws TikaException {
+        super();
+    }
+
+    @Override
+    public XMPMeta process(Metadata metadata) throws XMPException {
+        setMetadata( metadata );
+        XMPSchemaRegistry registry = XMPMetaFactory.getSchemaRegistry();
+
+        String[] keys = metadata.names();
+        for (String key : keys) {
+            String[] keyParts = key.split( Metadata.NAMESPACE_PREFIX_DELIMITER );
+            if (keyParts.length > 0 && keyParts.length <= 2) {
+                String uri = registry.getNamespaceURI( keyParts[0] );
+
+                if (uri != null) {
+                    // Tika properties where the type differs from the XMP specification
+                    if (key.equals( DublinCore.TITLE.getName() )
+                            || key.equals( DublinCore.DESCRIPTION.getName() )
+                            || key.equals( XMPRights.USAGE_TERMS.getName() )) {
+                        createLangAltProperty( key, uri, keyParts[1] );
+                    }
+                    else if (key.equals( DublinCore.CREATOR.getName() )) {
+                        createArrayProperty( key, uri, keyParts[1], PropertyOptions.ARRAY_ORDERED );
+                    }
+                    else {
+                        PropertyType type = Property.getPropertyType( key );
+                        if (type != null) {
+                            switch (type) {
+                                case SIMPLE:
+                                    createProperty( key, uri, keyParts[1] );
+                                    break;
+                                case BAG:
+                                    createArrayProperty( key, uri, keyParts[1],
+                                            PropertyOptions.ARRAY );
+                                    break;
+                                case SEQ:
+                                    createArrayProperty( key, uri, keyParts[1],
+                                            PropertyOptions.ARRAY_ORDERED );
+                                    break;
+                                case ALT:
+                                    createArrayProperty( key, uri, keyParts[1],
+                                            PropertyOptions.ARRAY_ALTERNATE );
+                                    break;
+                            // TODO Add support for structs and lang-alts, but those types are
+                            // currently not used in Tika
+                            }
+                        }
+                    }
+                }
+            } // ignore keys that are not qualified
+        }
 
-	@Override
-	public XMPMeta process(Metadata metadata) throws XMPException 
-	{
-		setMetadata(metadata);
-		XMPSchemaRegistry registry = XMPMetaFactory.getSchemaRegistry();
-		
-		String [] keys = metadata.names();
-		for( String key : keys)
-		{
-			String[] keyParts = key.split(Metadata.NAMESPACE_PREFIX_DELIMITER);
-			if (keyParts.length > 0 && keyParts.length <= 2)
-			{
-				String uri = registry.getNamespaceURI(keyParts[0]);
-				
-				if( uri != null )
-				{
-					// Tika properties where the type differs from the XMP specification
-					if( key.equals(DublinCore.TITLE.getName()) || 
-						key.equals(DublinCore.DESCRIPTION.getName()) || 
-						key.equals(XMPRights.USAGE_TERMS.getName()) )
-					{
-						createLangAltProperty(key, uri, keyParts[1]);
-					}
-					else if( key.equals(DublinCore.CREATOR.getName()) )
-					{
-						createArrayProperty(key, uri, keyParts[1], PropertyOptions.ARRAY_ORDERED);
-					}
-					else
-					{
-						PropertyType type = Property.getPropertyType(key);
-						if( type != null )
-						{
-							switch( type )
-							{
-								case SIMPLE:
-									createProperty(key, uri, keyParts[1]);
-									break;
-								case BAG:
-									createArrayProperty(key, uri, keyParts[1], PropertyOptions.ARRAY);
-									break;
-								case SEQ:
-									createArrayProperty(key, uri, keyParts[1], PropertyOptions.ARRAY_ORDERED);
-									break;
-								case ALT:
-									createArrayProperty(key, uri, keyParts[1], PropertyOptions.ARRAY_ALTERNATE);
-									break;
-								// TODO Add support for structs and lang-alts, but those types are currently not used in Tika
-							}
-						}
-					}
-				}
-			} // ignore keys that are not qualified
-		}
-				
-		return getXMPMeta();
-	}
+        return getXMPMeta();
+    }
 
-	@Override
-	public Set<Namespace> getAdditionalNamespaces() 
-	{
-		// no additional namespaces needed
-		return Collections.unmodifiableSet(new HashSet<Namespace>());
-	}
+    @Override
+    public Set<Namespace> getAdditionalNamespaces() {
+        // no additional namespaces needed
+        return Collections.unmodifiableSet( new HashSet<Namespace>() );
+    }
 }
diff --git a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/ITikaToXMPConverter.java b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/ITikaToXMPConverter.java
index e86fe0117..8edd403cd 100644
--- a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/ITikaToXMPConverter.java
+++ b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/ITikaToXMPConverter.java
@@ -13,10 +13,6 @@
  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  * See the License for the specific language governing permissions and
  * limitations under the License.
- *
- * IPTC Metadata Descriptions taken from the IPTC Photo Metadata (July 2010) 
- * standard. These parts Copyright 2010 International Press Telecommunications 
- * Council.
  */
 package org.apache.tika.xmp.convert;
 
@@ -28,15 +24,16 @@ import com.adobe.xmp.XMPMeta;
 /**
  * Interface for the specific <code>Metadata</code> to XMP converters
  */
-public interface ITikaToXMPConverter 
-{
-	/**
-	 * Converts a Tika {@link Metadata}-object into an {@link XMPMeta} containing 
-	 * the useful properties.
-	 * 
-	 * @param metadata a Tika Metadata object
-	 * @return Returns an XMPMeta object.
-	 * @throws XMPException If an error occurs during the creation of the XMP object.
-	 */
-	XMPMeta process(Metadata metadata) throws XMPException;	
+public interface ITikaToXMPConverter {
+    /**
+     * Converts a Tika {@link Metadata}-object into an {@link XMPMeta} containing the useful
+     * properties.
+     *
+     * @param metadata
+     *            a Tika Metadata object
+     * @return Returns an XMPMeta object.
+     * @throws XMPException
+     *             If an error occurs during the creation of the XMP object.
+     */
+    XMPMeta process(Metadata metadata) throws XMPException;
 }
diff --git a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/MSOfficeBinaryConverter.java b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/MSOfficeBinaryConverter.java
index 2e0b55b7b..1edc6b5f3 100644
--- a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/MSOfficeBinaryConverter.java
+++ b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/MSOfficeBinaryConverter.java
@@ -13,10 +13,6 @@
  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  * See the License for the specific language governing permissions and
  * limitations under the License.
- *
- * IPTC Metadata Descriptions taken from the IPTC Photo Metadata (July 2010) 
- * standard. These parts Copyright 2010 International Press Telecommunications 
- * Council.
  */
 package org.apache.tika.xmp.convert;
 
@@ -27,7 +23,6 @@ import java.util.Set;
 
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.metadata.HttpHeaders;
-import org.apache.tika.metadata.MSOffice;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.Office;
 import org.apache.tika.metadata.OfficeOpenXMLCore;
@@ -42,56 +37,57 @@ import com.adobe.xmp.options.PropertyOptions;
 /**
  * Tika to XMP mapping for the binary MS formats Word (.doc), Excel (.xls) and PowerPoint (.ppt).
  */
-public class MSOfficeBinaryConverter extends AbstractConverter
-{
-	 public MSOfficeBinaryConverter() throws TikaException 
-	 {
-		super();
-	}
+public class MSOfficeBinaryConverter extends AbstractConverter {
+    public MSOfficeBinaryConverter() throws TikaException {
+        super();
+    }
+
+    protected static final Set<Namespace> ADDITIONAL_NAMESPACES = Collections
+            .unmodifiableSet( new HashSet<Namespace>( Arrays.asList( new Namespace(
+                    OfficeOpenXMLCore.NAMESPACE_URI, OfficeOpenXMLCore.PREFIX ), new Namespace(
+                    OfficeOpenXMLExtended.NAMESPACE_URI, OfficeOpenXMLExtended.PREFIX ) ) ) );
+
+    /**
+     * @throws XMPException
+     *             Forwards XMP errors
+     * @see XMPFilesProcessor.MSOfficeXMLConverter.onverter#process(Metadata)
+     */
+    public XMPMeta process(Metadata metadata) throws XMPException {
+        super.setMetadata( metadata );
 
-	protected static final Set<Namespace> ADDITIONAL_NAMESPACES =
-		        Collections.unmodifiableSet(new HashSet<Namespace>(Arrays.asList(
-		        		new Namespace(OfficeOpenXMLCore.NAMESPACE_URI, OfficeOpenXMLCore.PREFIX),
-		        		new Namespace(OfficeOpenXMLExtended.NAMESPACE_URI, OfficeOpenXMLExtended.PREFIX)
-		        		)));
-		        		
-	/**
-	 * @throws XMPException Forwards XMP errors
-	 * @see XMPFilesProcessor.MSOfficeXMLConverter.onverter#process(Metadata)
-	 */
-	public XMPMeta process(Metadata metadata) throws XMPException
-	{
-		super.setMetadata(metadata);
+        // For all formats, Tika uses the same keys
+        createProperty( HttpHeaders.CONTENT_TYPE, XMPConst.NS_DC, "format" );
+        createProperty( OfficeOpenXMLExtended.APPLICATION, XMPConst.NS_XMP, "CreatorTool" );
+        createCommaSeparatedArray( TikaCoreProperties.CREATOR, XMPConst.NS_DC, "creator",
+                PropertyOptions.ARRAY_ORDERED );
+        createProperty( OfficeOpenXMLCore.CATEGORY, XMPConst.NS_IPTCCORE, "intellectualGenre" );
+        createProperty( TikaCoreProperties.CREATED, XMPConst.NS_XMP, "CreateDate" );
+        createProperty( Office.CHARACTER_COUNT, OfficeOpenXMLExtended.NAMESPACE_URI, "Characters" );
+        createProperty( TikaCoreProperties.COMMENTS, XMPConst.NS_PDFX, "Comments" );
+        createProperty( OfficeOpenXMLExtended.COMPANY, OfficeOpenXMLExtended.NAMESPACE_URI,
+                "Company" );
+        createCommaSeparatedArray( TikaCoreProperties.KEYWORDS, XMPConst.NS_DC, "subject",
+                PropertyOptions.ARRAY );
+        createLangAltProperty( TikaCoreProperties.DESCRIPTION, XMPConst.NS_DC, "description" );
+        createProperty( TikaCoreProperties.LANGUAGE, OfficeOpenXMLCore.NAMESPACE_URI, "language" );
+        createProperty( TikaCoreProperties.PRINT_DATE, OfficeOpenXMLCore.NAMESPACE_URI,
+                "lastPrinted" );
+        createProperty( TikaCoreProperties.MODIFIED, XMPConst.NS_XMP, "ModifyDate" );
+        createProperty( Office.PAGE_COUNT, XMPConst.TYPE_PAGEDFILE, "NPages" );
+        createProperty( OfficeOpenXMLCore.REVISION, OfficeOpenXMLCore.NAMESPACE_URI, "revision" );
+        createProperty( Office.SLIDE_COUNT, OfficeOpenXMLExtended.NAMESPACE_URI, "Pages" );
+        createProperty( OfficeOpenXMLExtended.TEMPLATE, OfficeOpenXMLExtended.NAMESPACE_URI,
+                "Template" );
+        createLangAltProperty( TikaCoreProperties.TITLE, XMPConst.NS_DC, "title" );
+        createProperty( Office.WORD_COUNT, OfficeOpenXMLExtended.NAMESPACE_URI, "Words" );
+        // Not mapped: (MSOffice) Edit-Time ???
+        // Not mapped: (MSOffice) Last-Author ???
+        // not mapped: (MSOffice) Security ???
 
-		// For all formats, Tika uses the same keys 
-		createProperty(HttpHeaders.CONTENT_TYPE, XMPConst.NS_DC, "format");
-		createProperty(OfficeOpenXMLExtended.APPLICATION, XMPConst.NS_XMP, "CreatorTool");
-		createCommaSeparatedArray(TikaCoreProperties.CREATOR, XMPConst.NS_DC, "creator", PropertyOptions.ARRAY_ORDERED);
-		createProperty(OfficeOpenXMLCore.CATEGORY, XMPConst.NS_IPTCCORE, "intellectualGenre");
-		createProperty(TikaCoreProperties.CREATED, XMPConst.NS_XMP, "CreateDate");
-		createProperty(Office.CHARACTER_COUNT, OfficeOpenXMLExtended.NAMESPACE_URI, "Characters");
-		createProperty(TikaCoreProperties.COMMENTS, XMPConst.NS_PDFX, "Comments");
-		createProperty(OfficeOpenXMLExtended.COMPANY, OfficeOpenXMLExtended.NAMESPACE_URI, "Company");
-		createCommaSeparatedArray(TikaCoreProperties.KEYWORDS, XMPConst.NS_DC, "subject", PropertyOptions.ARRAY);
-		createLangAltProperty(TikaCoreProperties.DESCRIPTION, XMPConst.NS_DC, "description");
-		createProperty(TikaCoreProperties.LANGUAGE, OfficeOpenXMLCore.NAMESPACE_URI, "language");
-		createProperty(TikaCoreProperties.PRINT_DATE, OfficeOpenXMLCore.NAMESPACE_URI, "lastPrinted");
-		createProperty(TikaCoreProperties.MODIFIED, XMPConst.NS_XMP, "ModifyDate");
-		createProperty(Office.PAGE_COUNT, XMPConst.TYPE_PAGEDFILE, "NPages");
-		createProperty(OfficeOpenXMLCore.REVISION, OfficeOpenXMLCore.NAMESPACE_URI, "revision");
-		createProperty(Office.SLIDE_COUNT, OfficeOpenXMLExtended.NAMESPACE_URI, "Pages");
-		createProperty(OfficeOpenXMLExtended.TEMPLATE, OfficeOpenXMLExtended.NAMESPACE_URI, "Template");
-		createLangAltProperty(TikaCoreProperties.TITLE, XMPConst.NS_DC, "title");
-		createProperty(Office.WORD_COUNT, OfficeOpenXMLExtended.NAMESPACE_URI, "Words");
-		// Not mapped: (MSOffice) Edit-Time 	???
-		// Not mapped:	(MSOffice) Last-Author 	???
-		// not mapped: (MSOffice) Security 	???
-		
-		return super.getXMPMeta();
-	}
+        return super.getXMPMeta();
+    }
 
-	protected Set<Namespace> getAdditionalNamespaces() 
-	{
-		return ADDITIONAL_NAMESPACES;
-	}
+    protected Set<Namespace> getAdditionalNamespaces() {
+        return ADDITIONAL_NAMESPACES;
+    }
 }
diff --git a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/MSOfficeXMLConverter.java b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/MSOfficeXMLConverter.java
index 2bf9c69c2..600e69ca7 100644
--- a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/MSOfficeXMLConverter.java
+++ b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/MSOfficeXMLConverter.java
@@ -13,10 +13,6 @@
  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  * See the License for the specific language governing permissions and
  * limitations under the License.
- *
- * IPTC Metadata Descriptions taken from the IPTC Photo Metadata (July 2010) 
- * standard. These parts Copyright 2010 International Press Telecommunications 
- * Council.
  */
 package org.apache.tika.xmp.convert;
 
@@ -39,87 +35,91 @@ import com.adobe.xmp.XMPMeta;
 import com.adobe.xmp.options.PropertyOptions;
 
 /**
- * Tika to XMP mapping for the Office Open XML formats Word (.docx), Excel (.xlsx) and PowerPoint (.pptx).
+ * Tika to XMP mapping for the Office Open XML formats Word (.docx), Excel (.xlsx) and PowerPoint
+ * (.pptx).
  */
-public class MSOfficeXMLConverter extends AbstractConverter 
-{
-	protected static final Set<Namespace> ADDITIONAL_NAMESPACES =
-	        Collections.unmodifiableSet(new HashSet<Namespace>(Arrays.asList(
-	        		new Namespace(OfficeOpenXMLCore.NAMESPACE_URI, OfficeOpenXMLCore.PREFIX),
-	        		new Namespace(OfficeOpenXMLExtended.NAMESPACE_URI, OfficeOpenXMLExtended.PREFIX)
-	        		)));
-	
-	public MSOfficeXMLConverter() throws TikaException 
-	{
-		super();
-	}
-
-	@Override
-	public XMPMeta process(Metadata metadata) throws XMPException 
-	{
-		super.setMetadata(metadata);
-		
-		createProperty(HttpHeaders.CONTENT_TYPE, XMPConst.NS_DC, "format");
-		
-		// Core Properties
-		createProperty(OfficeOpenXMLCore.CATEGORY, XMPConst.NS_IPTCCORE, "intellectualGenre");
-		createProperty(OfficeOpenXMLCore.CONTENT_STATUS, OfficeOpenXMLCore.NAMESPACE_URI, "contentStatus");
-		createProperty(TikaCoreProperties.CREATED, XMPConst.NS_XMP, "CreateDate");
-		createCommaSeparatedArray(TikaCoreProperties.CREATOR, XMPConst.NS_DC, "creator", PropertyOptions.ARRAY_ORDERED);
-		createProperty(TikaCoreProperties.COMMENTS, XMPConst.NS_PDFX, "Comments");
-		createProperty(TikaCoreProperties.IDENTIFIER, XMPConst.NS_DC, "identifier");
-		createCommaSeparatedArray(TikaCoreProperties.KEYWORDS, XMPConst.NS_DC, "subject", PropertyOptions.ARRAY); 
-		createLangAltProperty(TikaCoreProperties.DESCRIPTION, XMPConst.NS_DC, "description"); 
-		createProperty(TikaCoreProperties.LANGUAGE, XMPConst.NS_DC, "language");
-		createProperty(TikaCoreProperties.MODIFIER, OfficeOpenXMLCore.NAMESPACE_URI, "lastModifiedBy");
-		createProperty(TikaCoreProperties.PRINT_DATE, OfficeOpenXMLCore.NAMESPACE_URI, "lastPrinted");
-		createProperty(TikaCoreProperties.MODIFIED, XMPConst.NS_XMP, "ModifyDate");
-		createProperty(OfficeOpenXMLCore.REVISION, OfficeOpenXMLCore.NAMESPACE_URI, "revision");
-		createLangAltProperty(TikaCoreProperties.TITLE, XMPConst.NS_DC, "title");
-		createProperty(OfficeOpenXMLCore.VERSION, OfficeOpenXMLCore.NAMESPACE_URI, "version");
-		
-		// Extended Properties
-		
-		// Put both App name and version in xmp:CreatorTool 
-		String creatorTool = "";
-		String value = metadata.get(OfficeOpenXMLExtended.APPLICATION);
-		if (value != null  &&  value.length() > 0)
-		{
-			creatorTool = value;
-
-			value = metadata.get(OfficeOpenXMLExtended.APP_VERSION);
-			if (value != null  &&  value.length() > 0)
-			{
-				creatorTool += " " + value;
-			}
-		}
-		
-		if( creatorTool.length() > 0 )
-		{
-			meta.setProperty(XMPConst.NS_XMP, "CreatorTool", creatorTool);
-		}
-		
-		createProperty(Office.CHARACTER_COUNT, OfficeOpenXMLExtended.NAMESPACE_URI, "Characters");
-		createProperty(Office.CHARACTER_COUNT_WITH_SPACES, OfficeOpenXMLExtended.NAMESPACE_URI, "CharactersWithSpaces");
-		createProperty(TikaCoreProperties.PUBLISHER, OfficeOpenXMLExtended.NAMESPACE_URI, "Company");
-		createProperty(Office.LINE_COUNT, OfficeOpenXMLExtended.NAMESPACE_URI, "Lines");
-		createProperty(OfficeOpenXMLExtended.MANAGER, OfficeOpenXMLExtended.NAMESPACE_URI, "Manager");
-		createProperty(OfficeOpenXMLExtended.NOTES, OfficeOpenXMLExtended.NAMESPACE_URI, "Notes");
-		createProperty(Office.PAGE_COUNT, XMPConst.TYPE_PAGEDFILE, "NPages");
-		createProperty(Office.PARAGRAPH_COUNT, OfficeOpenXMLExtended.NAMESPACE_URI, "Paragraphs");
-		createProperty(OfficeOpenXMLExtended.PRESENTATION_FORMAT, OfficeOpenXMLExtended.NAMESPACE_URI, "PresentationFormat");
-		createProperty(Office.SLIDE_COUNT, OfficeOpenXMLExtended.NAMESPACE_URI, "Slides");
-		createProperty(OfficeOpenXMLExtended.TEMPLATE, OfficeOpenXMLExtended.NAMESPACE_URI, "Template");
-		createProperty(OfficeOpenXMLExtended.TOTAL_TIME, OfficeOpenXMLExtended.NAMESPACE_URI, "TotalTime");
-		createProperty(Office.WORD_COUNT, OfficeOpenXMLExtended.NAMESPACE_URI, "Words");
-		
-		return super.getXMPMeta();
-	}
-
-	@Override
-	protected Set<Namespace> getAdditionalNamespaces() 
-	{
-		return ADDITIONAL_NAMESPACES;
-	}
+public class MSOfficeXMLConverter extends AbstractConverter {
+    protected static final Set<Namespace> ADDITIONAL_NAMESPACES = Collections
+            .unmodifiableSet( new HashSet<Namespace>( Arrays.asList( new Namespace(
+                    OfficeOpenXMLCore.NAMESPACE_URI, OfficeOpenXMLCore.PREFIX ), new Namespace(
+                    OfficeOpenXMLExtended.NAMESPACE_URI, OfficeOpenXMLExtended.PREFIX ) ) ) );
+
+    public MSOfficeXMLConverter() throws TikaException {
+        super();
+    }
+
+    @Override
+    public XMPMeta process(Metadata metadata) throws XMPException {
+        super.setMetadata( metadata );
+
+        createProperty( HttpHeaders.CONTENT_TYPE, XMPConst.NS_DC, "format" );
+
+        // Core Properties
+        createProperty( OfficeOpenXMLCore.CATEGORY, XMPConst.NS_IPTCCORE, "intellectualGenre" );
+        createProperty( OfficeOpenXMLCore.CONTENT_STATUS, OfficeOpenXMLCore.NAMESPACE_URI,
+                "contentStatus" );
+        createProperty( TikaCoreProperties.CREATED, XMPConst.NS_XMP, "CreateDate" );
+        createCommaSeparatedArray( TikaCoreProperties.CREATOR, XMPConst.NS_DC, "creator",
+                PropertyOptions.ARRAY_ORDERED );
+        createProperty( TikaCoreProperties.COMMENTS, XMPConst.NS_PDFX, "Comments" );
+        createProperty( TikaCoreProperties.IDENTIFIER, XMPConst.NS_DC, "identifier" );
+        createCommaSeparatedArray( TikaCoreProperties.KEYWORDS, XMPConst.NS_DC, "subject",
+                PropertyOptions.ARRAY );
+        createLangAltProperty( TikaCoreProperties.DESCRIPTION, XMPConst.NS_DC, "description" );
+        createProperty( TikaCoreProperties.LANGUAGE, XMPConst.NS_DC, "language" );
+        createProperty( TikaCoreProperties.MODIFIER, OfficeOpenXMLCore.NAMESPACE_URI,
+                "lastModifiedBy" );
+        createProperty( TikaCoreProperties.PRINT_DATE, OfficeOpenXMLCore.NAMESPACE_URI,
+                "lastPrinted" );
+        createProperty( TikaCoreProperties.MODIFIED, XMPConst.NS_XMP, "ModifyDate" );
+        createProperty( OfficeOpenXMLCore.REVISION, OfficeOpenXMLCore.NAMESPACE_URI, "revision" );
+        createLangAltProperty( TikaCoreProperties.TITLE, XMPConst.NS_DC, "title" );
+        createProperty( OfficeOpenXMLCore.VERSION, OfficeOpenXMLCore.NAMESPACE_URI, "version" );
+
+        // Extended Properties
+
+        // Put both App name and version in xmp:CreatorTool
+        String creatorTool = "";
+        String value = metadata.get( OfficeOpenXMLExtended.APPLICATION );
+        if (value != null && value.length() > 0) {
+            creatorTool = value;
+
+            value = metadata.get( OfficeOpenXMLExtended.APP_VERSION );
+            if (value != null && value.length() > 0) {
+                creatorTool += " " + value;
+            }
+        }
+
+        if (creatorTool.length() > 0) {
+            meta.setProperty( XMPConst.NS_XMP, "CreatorTool", creatorTool );
+        }
+
+        createProperty( Office.CHARACTER_COUNT, OfficeOpenXMLExtended.NAMESPACE_URI, "Characters" );
+        createProperty( Office.CHARACTER_COUNT_WITH_SPACES, OfficeOpenXMLExtended.NAMESPACE_URI,
+                "CharactersWithSpaces" );
+        createProperty( TikaCoreProperties.PUBLISHER, OfficeOpenXMLExtended.NAMESPACE_URI,
+                "Company" );
+        createProperty( Office.LINE_COUNT, OfficeOpenXMLExtended.NAMESPACE_URI, "Lines" );
+        createProperty( OfficeOpenXMLExtended.MANAGER, OfficeOpenXMLExtended.NAMESPACE_URI,
+                "Manager" );
+        createProperty( OfficeOpenXMLExtended.NOTES, OfficeOpenXMLExtended.NAMESPACE_URI, "Notes" );
+        createProperty( Office.PAGE_COUNT, XMPConst.TYPE_PAGEDFILE, "NPages" );
+        createProperty( Office.PARAGRAPH_COUNT, OfficeOpenXMLExtended.NAMESPACE_URI, "Paragraphs" );
+        createProperty( OfficeOpenXMLExtended.PRESENTATION_FORMAT,
+                OfficeOpenXMLExtended.NAMESPACE_URI, "PresentationFormat" );
+        createProperty( Office.SLIDE_COUNT, OfficeOpenXMLExtended.NAMESPACE_URI, "Slides" );
+        createProperty( OfficeOpenXMLExtended.TEMPLATE, OfficeOpenXMLExtended.NAMESPACE_URI,
+                "Template" );
+        createProperty( OfficeOpenXMLExtended.TOTAL_TIME, OfficeOpenXMLExtended.NAMESPACE_URI,
+                "TotalTime" );
+        createProperty( Office.WORD_COUNT, OfficeOpenXMLExtended.NAMESPACE_URI, "Words" );
+
+        return super.getXMPMeta();
+    }
+
+    @Override
+    protected Set<Namespace> getAdditionalNamespaces() {
+        return ADDITIONAL_NAMESPACES;
+    }
 
 }
diff --git a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/Namespace.java b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/Namespace.java
index 10a2e5551..cd8bcc6c8 100644
--- a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/Namespace.java
+++ b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/Namespace.java
@@ -13,24 +13,18 @@
  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  * See the License for the specific language governing permissions and
  * limitations under the License.
- *
- * IPTC Metadata Descriptions taken from the IPTC Photo Metadata (July 2010) 
- * standard. These parts Copyright 2010 International Press Telecommunications 
- * Council.
  */
 package org.apache.tika.xmp.convert;
 
 /**
  * Utility class to hold namespace information.
  */
-public class Namespace 
-{
-	public String uri;
-	public String prefix;
+public class Namespace {
+    public String uri;
+    public String prefix;
 
-	public Namespace(String uri, String prefix) 
-	{
-		this.uri = uri;
-		this.prefix = prefix;
-	}
+    public Namespace(String uri, String prefix) {
+        this.uri = uri;
+        this.prefix = prefix;
+    }
 }
diff --git a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/OpenDocumentConverter.java b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/OpenDocumentConverter.java
index 5c8adb1bd..f43236bf5 100644
--- a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/OpenDocumentConverter.java
+++ b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/OpenDocumentConverter.java
@@ -13,10 +13,6 @@
  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  * See the License for the specific language governing permissions and
  * limitations under the License.
- *
- * IPTC Metadata Descriptions taken from the IPTC Photo Metadata (July 2010) 
- * standard. These parts Copyright 2010 International Press Telecommunications 
- * Council.
  */
 package org.apache.tika.xmp.convert;
 
@@ -39,65 +35,63 @@ import com.adobe.xmp.XMPMeta;
 import com.adobe.xmp.options.PropertyOptions;
 
 /**
- * Tika to XMP mapping for the Open Document formats:
- * Text (.odt), Spreatsheet (.ods), Graphics (.odg) and Presentation (.odp).
+ * Tika to XMP mapping for the Open Document formats: Text (.odt), Spreatsheet (.ods), Graphics
+ * (.odg) and Presentation (.odp).
  */
-public class OpenDocumentConverter extends AbstractConverter
-{
-	protected static final Set<Namespace> ADDITIONAL_NAMESPACES =
-	        Collections.unmodifiableSet(new HashSet<Namespace>(Arrays.asList(
-	        		new Namespace(Office.NAMESPACE_URI_DOC_META, Office.PREFIX_DOC_META)
-	        		)));
-	
-	public OpenDocumentConverter() throws TikaException 
-	{
-		super();
-	}
+public class OpenDocumentConverter extends AbstractConverter {
+    protected static final Set<Namespace> ADDITIONAL_NAMESPACES = Collections
+            .unmodifiableSet( new HashSet<Namespace>( Arrays.asList( new Namespace(
+                    Office.NAMESPACE_URI_DOC_META, Office.PREFIX_DOC_META ) ) ) );
+
+    public OpenDocumentConverter() throws TikaException {
+        super();
+    }
+
+    /**
+     * @throws XMPException
+     *             Forwards XMP errors
+     * @see XMPFilesProcessor.onverter#process(Metadata)
+     */
+    @Override
+    public XMPMeta process(Metadata metadata) throws XMPException {
+        super.setMetadata( metadata );
+
+        createProperty( HttpHeaders.CONTENT_TYPE, XMPConst.NS_DC, "format" );
 
-	/**
-	 * @throws XMPException Forwards XMP errors
-	 * @see XMPFilesProcessor.onverter#process(Metadata)
-	 */
-	@Override
-	public XMPMeta process(Metadata metadata) throws XMPException
-	{
-		super.setMetadata(metadata);
+        createProperty( Office.CHARACTER_COUNT, Office.NAMESPACE_URI_DOC_META, "character-count" );
+        createProperty( TikaCoreProperties.CREATED, XMPConst.NS_XMP, "CreateDate" );
+        createCommaSeparatedArray( TikaCoreProperties.CREATOR, XMPConst.NS_DC, "creator",
+                PropertyOptions.ARRAY_ORDERED );
+        createProperty( TikaCoreProperties.MODIFIED, XMPConst.NS_XMP, "ModifyDate" );
+        createProperty( TikaCoreProperties.COMMENTS, XMPConst.NS_PDFX, "Comments" );
+        createCommaSeparatedArray( TikaCoreProperties.KEYWORDS, XMPConst.NS_DC, "subject",
+                PropertyOptions.ARRAY );
+        createLangAltProperty( TikaCoreProperties.DESCRIPTION, XMPConst.NS_DC, "description" );
+        createProperty( MSOffice.EDIT_TIME, Office.NAMESPACE_URI_DOC_META, "editing-duration" );
+        createProperty( "editing-cycles", Office.NAMESPACE_URI_DOC_META, "editing-cycles" );
+        createProperty( "generator", XMPConst.NS_XMP, "CreatorTool" );
+        createProperty( Office.IMAGE_COUNT, Office.NAMESPACE_URI_DOC_META, "image-count" );
+        createProperty( "initial-creator", Office.NAMESPACE_URI_DOC_META, "initial-creator" );
+        createProperty( Office.OBJECT_COUNT, Office.NAMESPACE_URI_DOC_META, "object-count" );
+        createProperty( PagedText.N_PAGES, XMPConst.TYPE_PAGEDFILE, "NPages" );
+        createProperty( Office.PARAGRAPH_COUNT, Office.NAMESPACE_URI_DOC_META, "paragraph-count" );
+        createProperty( Office.TABLE_COUNT, Office.NAMESPACE_URI_DOC_META, "table-count" );
+        createLangAltProperty( TikaCoreProperties.TITLE, XMPConst.NS_DC, "title" );
+        createProperty( Office.WORD_COUNT, Office.NAMESPACE_URI_DOC_META, "word-count" );
 
-		createProperty(HttpHeaders.CONTENT_TYPE, XMPConst.NS_DC, "format");
-		
-		createProperty(Office.CHARACTER_COUNT, Office.NAMESPACE_URI_DOC_META, "character-count");
-		createProperty(TikaCoreProperties.CREATED, XMPConst.NS_XMP, "CreateDate");
-		createCommaSeparatedArray(TikaCoreProperties.CREATOR, XMPConst.NS_DC, "creator", PropertyOptions.ARRAY_ORDERED);
-		createProperty(TikaCoreProperties.MODIFIED, XMPConst.NS_XMP, "ModifyDate");
-		createProperty(TikaCoreProperties.COMMENTS, XMPConst.NS_PDFX, "Comments");
-		createCommaSeparatedArray(TikaCoreProperties.KEYWORDS, XMPConst.NS_DC, "subject", PropertyOptions.ARRAY);
-		createLangAltProperty(TikaCoreProperties.DESCRIPTION, XMPConst.NS_DC, "description");
-		createProperty(MSOffice.EDIT_TIME, Office.NAMESPACE_URI_DOC_META, "editing-duration");
-		createProperty("editing-cycles", Office.NAMESPACE_URI_DOC_META, "editing-cycles");
-		createProperty("generator", XMPConst.NS_XMP, "CreatorTool");
-		createProperty(Office.IMAGE_COUNT, Office.NAMESPACE_URI_DOC_META, "image-count");
-		createProperty("initial-creator", Office.NAMESPACE_URI_DOC_META, "initial-creator");
-		createProperty(Office.OBJECT_COUNT, Office.NAMESPACE_URI_DOC_META, "object-count");
-		createProperty(PagedText.N_PAGES, XMPConst.TYPE_PAGEDFILE, "NPages");
-		createProperty(Office.PARAGRAPH_COUNT, Office.NAMESPACE_URI_DOC_META, "paragraph-count");
-		createProperty(Office.TABLE_COUNT, Office.NAMESPACE_URI_DOC_META, "table-count");
-		createLangAltProperty(TikaCoreProperties.TITLE, XMPConst.NS_DC, "title");
-		createProperty(Office.WORD_COUNT, Office.NAMESPACE_URI_DOC_META, "word-count");
+        // duplicate properties not mapped:
+        // nbImg | 0
+        // nbObject | 0
+        // nbPage | 1
+        // nbPara | 3
+        // nbTab | 0
+        // nbWord | 5
 
-		// duplicate properties not mapped:
-		//		nbImg | 0
-		//		nbObject | 0
-		//		nbPage | 1
-		//		nbPara | 3
-		//		nbTab | 0
-		//		nbWord | 5
-		
-		return super.getXMPMeta();
-	}
+        return super.getXMPMeta();
+    }
 
-	@Override
-	protected Set<Namespace> getAdditionalNamespaces() 
-	{
-		return ADDITIONAL_NAMESPACES;
-	}
+    @Override
+    protected Set<Namespace> getAdditionalNamespaces() {
+        return ADDITIONAL_NAMESPACES;
+    }
 }
diff --git a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/RTFConverter.java b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/RTFConverter.java
index 0cd630277..19d7b503d 100644
--- a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/RTFConverter.java
+++ b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/RTFConverter.java
@@ -13,10 +13,6 @@
  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  * See the License for the specific language governing permissions and
  * limitations under the License.
- *
- * IPTC Metadata Descriptions taken from the IPTC Photo Metadata (July 2010) 
- * standard. These parts Copyright 2010 International Press Telecommunications 
- * Council.
  */
 package org.apache.tika.xmp.convert;
 
@@ -26,7 +22,6 @@ import java.util.HashSet;
 import java.util.Set;
 
 import org.apache.tika.exception.TikaException;
-import org.apache.tika.metadata.ClimateForcast;
 import org.apache.tika.metadata.HttpHeaders;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.OfficeOpenXMLCore;
@@ -41,41 +36,41 @@ import com.adobe.xmp.options.PropertyOptions;
 /**
  * Tika to XMP mapping for the RTF format.
  */
-public class RTFConverter extends AbstractConverter
-{
-	protected static final Set<Namespace> ADDITIONAL_NAMESPACES =
-	        Collections.unmodifiableSet(new HashSet<Namespace>(Arrays.asList(
-	        		new Namespace(OfficeOpenXMLExtended.NAMESPACE_URI, OfficeOpenXMLExtended.PREFIX)
-	        		)));
-	
-	public RTFConverter() throws TikaException 
-	{
-		super();
-	}
+public class RTFConverter extends AbstractConverter {
+    protected static final Set<Namespace> ADDITIONAL_NAMESPACES = Collections
+            .unmodifiableSet( new HashSet<Namespace>( Arrays.asList( new Namespace(
+                    OfficeOpenXMLExtended.NAMESPACE_URI, OfficeOpenXMLExtended.PREFIX ) ) ) );
+
+    public RTFConverter() throws TikaException {
+        super();
+    }
+
+    @Override
+    public XMPMeta process(Metadata metadata) throws XMPException {
+        setMetadata( metadata );
+
+        createProperty( HttpHeaders.CONTENT_TYPE, XMPConst.NS_DC, "format" );
 
-	@Override
-	public XMPMeta process(Metadata metadata) throws XMPException
-	{
-		setMetadata(metadata);
-		
-		createProperty(HttpHeaders.CONTENT_TYPE, XMPConst.NS_DC, "format");
+        createCommaSeparatedArray( TikaCoreProperties.CREATOR, XMPConst.NS_DC, "creator",
+                PropertyOptions.ARRAY_ORDERED );
+        createLangAltProperty( TikaCoreProperties.TITLE, XMPConst.NS_DC, "title" );
+        createLangAltProperty( TikaCoreProperties.DESCRIPTION, XMPConst.NS_DC, "description" );
+        createCommaSeparatedArray( TikaCoreProperties.KEYWORDS, XMPConst.NS_DC, "subject",
+                PropertyOptions.ARRAY );
+        createProperty( OfficeOpenXMLCore.CATEGORY, XMPConst.NS_IPTCCORE, "intellectualGenre" );
+        createProperty( OfficeOpenXMLExtended.TEMPLATE, OfficeOpenXMLExtended.NAMESPACE_URI,
+                "Template" );
+        createProperty( TikaCoreProperties.COMMENTS, XMPConst.NS_PDFX, "Comments" );
+        createProperty( OfficeOpenXMLExtended.COMPANY, OfficeOpenXMLExtended.NAMESPACE_URI,
+                "Company" );
+        createProperty( OfficeOpenXMLExtended.MANAGER, OfficeOpenXMLExtended.NAMESPACE_URI,
+                "Manager" );
 
-		createCommaSeparatedArray(TikaCoreProperties.CREATOR, XMPConst.NS_DC, "creator", PropertyOptions.ARRAY_ORDERED);
-		createLangAltProperty(TikaCoreProperties.TITLE, XMPConst.NS_DC, "title");
-		createLangAltProperty(TikaCoreProperties.DESCRIPTION, XMPConst.NS_DC, "description");
-		createCommaSeparatedArray(TikaCoreProperties.KEYWORDS, XMPConst.NS_DC, "subject", PropertyOptions.ARRAY);
-		createProperty(OfficeOpenXMLCore.CATEGORY, XMPConst.NS_IPTCCORE, "intellectualGenre");
-		createProperty(OfficeOpenXMLExtended.TEMPLATE, OfficeOpenXMLExtended.NAMESPACE_URI, "Template");
-		createProperty(TikaCoreProperties.COMMENTS, XMPConst.NS_PDFX, "Comments");
-		createProperty(OfficeOpenXMLExtended.COMPANY, OfficeOpenXMLExtended.NAMESPACE_URI, "Company");
-		createProperty(OfficeOpenXMLExtended.MANAGER, OfficeOpenXMLExtended.NAMESPACE_URI, "Manager");
-				
-		return getXMPMeta();
-	}
+        return getXMPMeta();
+    }
 
-	@Override
-	protected Set<Namespace> getAdditionalNamespaces() 
-	{
-		return ADDITIONAL_NAMESPACES;
-	}
+    @Override
+    protected Set<Namespace> getAdditionalNamespaces() {
+        return ADDITIONAL_NAMESPACES;
+    }
 }
diff --git a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/TikaToXMP.java b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/TikaToXMP.java
index 7d4501dab..b0079e1dd 100644
--- a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/TikaToXMP.java
+++ b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/TikaToXMP.java
@@ -13,10 +13,6 @@
  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  * See the License for the specific language governing permissions and
  * limitations under the License.
- *
- * IPTC Metadata Descriptions taken from the IPTC Photo Metadata (July 2010) 
- * standard. These parts Copyright 2010 International Press Telecommunications 
- * Council.
  */
 package org.apache.tika.xmp.convert;
 
@@ -38,188 +34,169 @@ import com.adobe.xmp.XMPException;
 import com.adobe.xmp.XMPMeta;
 import com.adobe.xmp.XMPMetaFactory;
 
-public class TikaToXMP
-{
-	/** 
-	 * Map from mimetype to converter class 
-	 * Must only be accessed through <code>getConverterMap</code>
-	 */
-	private static Map<MediaType, Class<? extends ITikaToXMPConverter>> converterMap;		
-
-	// --- public API implementation---
-	
-	public TikaToXMP() 
-	{
-		// Nothing to do
-	}
-	
-
-	/**
-	 * @see ITikaToXMP#convert(Metadata, String)
-	 * But the mimetype is retrieved from the metadata map.
-	 */
-	public static XMPMeta convert(Metadata tikaMetadata) throws TikaException 
-	{
-		if( tikaMetadata == null )
-		{
-			throw new IllegalArgumentException("Metadata parameter must not be null");
-		}
-		
-		String mimetype = tikaMetadata.get(Metadata.CONTENT_TYPE);
-		if(mimetype == null)
-		{
-			mimetype = tikaMetadata.get(TikaCoreProperties.FORMAT);
-		}
-		
-		return convert(tikaMetadata, mimetype);
-	}
-
-
-	/**
-	 * Convert the given Tika metadata map to XMP object.
-	 * If a mimetype is provided in the Metadata map, a specific converter can be used, that converts all
-     * available metadata.
-     * If there is no mimetype provided or no specific converter available a generic conversion is done
-     * which will convert only those properties that are in known namespaces and are using the correct prefixes.
-	 *
-	 * @param tikaMetadata the Metadata map from Tika
-	 * @param mimetype depicts the format's converter to use
-	 * @return XMP object
-	 * @throws TikaException
-	 */
-	public static XMPMeta convert(Metadata tikaMetadata, String mimetype) throws TikaException 
-	{
-		if( tikaMetadata == null )
-		{
-			throw new IllegalArgumentException("Metadata parameter must not be null");
-		}
-		
-		ITikaToXMPConverter converter = null;
-		
-		if( isConverterAvailable(mimetype) )
-		{
-			converter = getConverter(mimetype);
-		}
-		else
-		{
-			converter = new GenericConverter();
-		}
-		
-		XMPMeta xmp = null;
-		
-		if( converter != null )
-		{
-			try 
-			{
-				xmp = converter.process(tikaMetadata);
-			} 
-			catch (XMPException e) 
-			{
-				throw new TikaException("Tika metadata could not be converted to XMP", e);
-			}
-		}
-		else
-		{
-			xmp = XMPMetaFactory.create(); // empty packet
-		}
-		
-		return xmp;
-	}
-
-	/** 
-	 * Check if there is a converter available which allows to convert the
-	 * Tika metadata to XMP
-	 * @param mimetype the Mimetype
-	 * @return true if the Metadata object can be converted or false if not
-	 */
-	public static boolean isConverterAvailable(String mimetype) 
-	{
-		MediaType type = MediaType.parse(mimetype);
-		
-        if (type != null) 
-        {
-        	return (getConverterMap().get(type) != null);
+public class TikaToXMP {
+    /**
+     * Map from mimetype to converter class Must only be accessed through
+     * <code>getConverterMap</code>
+     */
+    private static Map<MediaType, Class<? extends ITikaToXMPConverter>> converterMap;
+
+    // --- public API implementation---
+
+    public TikaToXMP() {
+        // Nothing to do
+    }
+
+    /**
+     * @see ITikaToXMP#convert(Metadata, String) But the mimetype is retrieved from the metadata
+     *      map.
+     */
+    public static XMPMeta convert(Metadata tikaMetadata) throws TikaException {
+        if (tikaMetadata == null) {
+            throw new IllegalArgumentException( "Metadata parameter must not be null" );
+        }
+
+        String mimetype = tikaMetadata.get( Metadata.CONTENT_TYPE );
+        if (mimetype == null) {
+            mimetype = tikaMetadata.get( TikaCoreProperties.FORMAT );
+        }
+
+        return convert( tikaMetadata, mimetype );
+    }
+
+    /**
+     * Convert the given Tika metadata map to XMP object. If a mimetype is provided in the Metadata
+     * map, a specific converter can be used, that converts all available metadata. If there is no
+     * mimetype provided or no specific converter available a generic conversion is done which will
+     * convert only those properties that are in known namespaces and are using the correct
+     * prefixes.
+     *
+     * @param tikaMetadata
+     *            the Metadata map from Tika
+     * @param mimetype
+     *            depicts the format's converter to use
+     * @return XMP object
+     * @throws TikaException
+     */
+    public static XMPMeta convert(Metadata tikaMetadata, String mimetype) throws TikaException {
+        if (tikaMetadata == null) {
+            throw new IllegalArgumentException( "Metadata parameter must not be null" );
+        }
+
+        ITikaToXMPConverter converter = null;
+
+        if (isConverterAvailable( mimetype )) {
+            converter = getConverter( mimetype );
+        }
+        else {
+            converter = new GenericConverter();
+        }
+
+        XMPMeta xmp = null;
+
+        if (converter != null) {
+            try {
+                xmp = converter.process( tikaMetadata );
+            }
+            catch (XMPException e) {
+                throw new TikaException( "Tika metadata could not be converted to XMP", e );
+            }
+        }
+        else {
+            xmp = XMPMetaFactory.create(); // empty packet
+        }
+
+        return xmp;
+    }
+
+    /**
+     * Check if there is a converter available which allows to convert the Tika metadata to XMP
+     *
+     * @param mimetype
+     *            the Mimetype
+     * @return true if the Metadata object can be converted or false if not
+     */
+    public static boolean isConverterAvailable(String mimetype) {
+        MediaType type = MediaType.parse( mimetype );
+
+        if (type != null) {
+            return (getConverterMap().get( type ) != null);
         }
-        
+
         return false;
-	}
-	
-	/**
-	 * Retrieve a specific converter according to the mimetype
-	 * @param mimetype the Mimetype
-	 * @return the converter or null, if none exists
-	 * @throws TikaException
-	 */
-	public static ITikaToXMPConverter getConverter(String mimetype) throws TikaException 
-	{
-		if( mimetype == null )
-		{
-			throw new IllegalArgumentException("mimetype must not be null");
-		}
-		
-		ITikaToXMPConverter converter = null;
-		
-		MediaType type = MediaType.parse(mimetype);
-		
-        if (type != null) 
-        {
-			Class<? extends ITikaToXMPConverter> clazz = getConverterMap().get( type );
-			if (clazz != null)
-			{
-				try
-				{
-					converter = clazz.newInstance();
-				}
-				catch (Exception e)
-				{
-					throw new TikaException("TikaToXMP converter class cannot be instantiated for mimetype: " + type.toString(), e);
-				}
-			}
+    }
+
+    /**
+     * Retrieve a specific converter according to the mimetype
+     *
+     * @param mimetype
+     *            the Mimetype
+     * @return the converter or null, if none exists
+     * @throws TikaException
+     */
+    public static ITikaToXMPConverter getConverter(String mimetype) throws TikaException {
+        if (mimetype == null) {
+            throw new IllegalArgumentException( "mimetype must not be null" );
+        }
+
+        ITikaToXMPConverter converter = null;
+
+        MediaType type = MediaType.parse( mimetype );
+
+        if (type != null) {
+            Class<? extends ITikaToXMPConverter> clazz = getConverterMap().get( type );
+            if (clazz != null) {
+                try {
+                    converter = clazz.newInstance();
+                }
+                catch (Exception e) {
+                    throw new TikaException(
+                            "TikaToXMP converter class cannot be instantiated for mimetype: "
+                                    + type.toString(), e );
+                }
+            }
         }
-        
+
         return converter;
-	}
-
-	// --- Private methods ---
-	
-	private static Map<MediaType, Class<? extends ITikaToXMPConverter>> getConverterMap()
-	{
-		if( converterMap == null )
-		{
-			converterMap = new HashMap<MediaType, Class<? extends ITikaToXMPConverter>>();
-			initialize();
-		}
-		return converterMap;
-	}
-	
-	
-	/**
-	 * Initializes the map with supported converters.
-	 */
-	private static void initialize()
-	{
-		// No particular parsing context is needed
-		ParseContext parseContext = new ParseContext();
-		
-		// MS Office Binary File Format
-		addConverter(new OfficeParser().getSupportedTypes(parseContext), MSOfficeBinaryConverter.class);
-		
-		// Rich Text Format
-		addConverter(new RTFParser().getSupportedTypes(parseContext), RTFConverter.class);
-
-		// MS Open XML Format
-		addConverter(new OOXMLParser().getSupportedTypes(parseContext), MSOfficeXMLConverter.class);
-		
-		// Open document format
-		addConverter(new OpenDocumentParser().getSupportedTypes(parseContext), OpenDocumentConverter.class);
-	}
-	
-	
-	private static void addConverter(Set<MediaType> supportedTypes, Class<? extends ITikaToXMPConverter> converter)
-	{
-		for( MediaType type : supportedTypes )
-		{
-			getConverterMap().put(type, converter);
-		}
-	}
+    }
+
+    // --- Private methods ---
+
+    private static Map<MediaType, Class<? extends ITikaToXMPConverter>> getConverterMap() {
+        if (converterMap == null) {
+            converterMap = new HashMap<MediaType, Class<? extends ITikaToXMPConverter>>();
+            initialize();
+        }
+        return converterMap;
+    }
+
+    /**
+     * Initializes the map with supported converters.
+     */
+    private static void initialize() {
+        // No particular parsing context is needed
+        ParseContext parseContext = new ParseContext();
+
+        // MS Office Binary File Format
+        addConverter( new OfficeParser().getSupportedTypes( parseContext ),
+                MSOfficeBinaryConverter.class );
+
+        // Rich Text Format
+        addConverter( new RTFParser().getSupportedTypes( parseContext ), RTFConverter.class );
+
+        // MS Open XML Format
+        addConverter( new OOXMLParser().getSupportedTypes( parseContext ),
+                MSOfficeXMLConverter.class );
+
+        // Open document format
+        addConverter( new OpenDocumentParser().getSupportedTypes( parseContext ),
+                OpenDocumentConverter.class );
+    }
+
+    private static void addConverter(Set<MediaType> supportedTypes,
+            Class<? extends ITikaToXMPConverter> converter) {
+        for (MediaType type : supportedTypes) {
+            getConverterMap().put( type, converter );
+        }
+    }
 }
diff --git a/tika-xmp/src/test/java/org/apache/tika/xmp/TikaToXMPTest.java b/tika-xmp/src/test/java/org/apache/tika/xmp/TikaToXMPTest.java
index 4ef489db2..eb2196415 100644
--- a/tika-xmp/src/test/java/org/apache/tika/xmp/TikaToXMPTest.java
+++ b/tika-xmp/src/test/java/org/apache/tika/xmp/TikaToXMPTest.java
@@ -13,10 +13,6 @@
  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  * See the License for the specific language governing permissions and
  * limitations under the License.
- *
- * IPTC Metadata Descriptions taken from the IPTC Photo Metadata (July 2010) 
- * standard. These parts Copyright 2010 International Press Telecommunications 
- * Council.
  */
 package org.apache.tika.xmp;
 
@@ -46,198 +42,182 @@ import com.adobe.xmp.properties.XMPProperty;
 /**
  * Tests the Tika <code>Metadata</code> to XMP conversion functionatlity
  */
-public class TikaToXMPTest 
-{
-	private Metadata tikaMetadata;
-	
-	private static final String OOXML_MIMETYPE = "application/vnd.openxmlformats-officedocument.wordprocessingml.document";
-	private static final String GENERIC_MIMETYPE = "generic/mimetype";
-	
-	// --- Set up ---
-	@Before
-	public void setup()
-	{
-		tikaMetadata = new Metadata();
-	}
-	
-	private void setupOOXMLMetadata(Metadata metadata)
-	{
-		// simple property
-		metadata.set(TikaCoreProperties.LANGUAGE, "language");
-		// language alternative
-		metadata.set(TikaCoreProperties.TITLE, "title");
-		// comma separated array
-		metadata.set(TikaCoreProperties.KEYWORDS, "keyword1,keyword2");
-		// OOXML specific simple prop
-		metadata.set(TikaCoreProperties.MODIFIER, "lastModifiedBy");
-	}
-	
-	private void checkOOXMLMetadata(XMPMeta xmp) throws XMPException
-	{
-		// check simple property
-		XMPProperty prop = xmp.getProperty(XMPConst.NS_DC, "language");
-		assertNotNull(prop);
-		assertEquals("language", prop.getValue());
-		
-		// check lang alt
-		prop = xmp.getLocalizedText(XMPConst.NS_DC, "title", null, XMPConst.X_DEFAULT);
-		assertNotNull(prop);
-		assertEquals("title", prop.getValue());
-		
-		// check array
-		prop = xmp.getArrayItem(XMPConst.NS_DC, "subject", 1);
-		assertNotNull(prop);
-		assertEquals("keyword1", prop.getValue());
-		prop = xmp.getArrayItem(XMPConst.NS_DC, "subject", 2);
-		assertNotNull(prop);
-		assertEquals("keyword2", prop.getValue());
-		
-		// check OOXML specific simple property
-		prop = xmp.getProperty(OfficeOpenXMLCore.NAMESPACE_URI, "lastModifiedBy");
-		assertNotNull(prop);
-		assertEquals("lastModifiedBy", prop.getValue());
-	}
-	
-	
-	// --- TESTS ---
-	@Test
-	public void convert_OOXMLMetadataWithMimetype_everythingConverted() throws XMPException, TikaException 
-	{
-		setupOOXMLMetadata(tikaMetadata);
-		tikaMetadata.set(Metadata.CONTENT_TYPE, OOXML_MIMETYPE);
-
-		XMPMeta xmp = TikaToXMP.convert(tikaMetadata);
-		
-		checkOOXMLMetadata(xmp);
-	}
-
-	
-	@Test
-	public void convert_OOXMLMetadataWithExtraMimetype_everythingConverted() throws XMPException, TikaException 
-	{
-		setupOOXMLMetadata(tikaMetadata);
-		
-		XMPMeta xmp = TikaToXMP.convert(tikaMetadata, OOXML_MIMETYPE);
-		
-		checkOOXMLMetadata(xmp);
-	}
-
-
-	@Test
-	public void convert_OOXMLMetadataWithoutMimetype_onlyGeneralMetadataconverted() throws XMPException, TikaException 
-	{
-		setupOOXMLMetadata(tikaMetadata);
-		
-		XMPMeta xmp = TikaToXMP.convert(tikaMetadata, null);
-		
-		// general metadata is converted
-		// check simple property
-		XMPProperty prop = xmp.getProperty(XMPConst.NS_DC, "language");
-		assertNotNull(prop);
-		assertEquals("language", prop.getValue());
-		
-		// check lang alt
-		prop = xmp.getLocalizedText(XMPConst.NS_DC, "title", null, XMPConst.X_DEFAULT);
-		assertNotNull(prop);
-		assertEquals("title", prop.getValue());
-		
-		// OOXML one is not, the namespace has also not been registiered as the converter has not been used
-		XMPMetaFactory.getSchemaRegistry().registerNamespace(OfficeOpenXMLCore.NAMESPACE_URI, OfficeOpenXMLCore.PREFIX);
-		prop = xmp.getProperty(OfficeOpenXMLCore.NAMESPACE_URI, "lastModifiedBy");
-		assertNull(prop);
-	}
-	
-	
-	@Test
-	public void convert_genericMetadataAllQualified_allConverted() throws XMPException, TikaException 
-	{
-		// simple property
-		tikaMetadata.set(TikaCoreProperties.FORMAT, GENERIC_MIMETYPE);
-		// language alternative
-		tikaMetadata.set(TikaCoreProperties.TITLE, "title");
-		// array
-		tikaMetadata.set(TikaCoreProperties.KEYWORDS, new String[] {"keyword1", "keyword2"});
-		
-		
-		XMPMeta xmp = TikaToXMP.convert(tikaMetadata, null);
-		
-		// check simple property
-		XMPProperty prop = xmp.getProperty(XMPConst.NS_DC, "format");
-		assertNotNull(prop);
-		assertEquals(GENERIC_MIMETYPE, prop.getValue());
-		
-		// check lang alt
-		prop = xmp.getLocalizedText(XMPConst.NS_DC, "title", null, XMPConst.X_DEFAULT);
-		assertNotNull(prop);
-		assertEquals("title", prop.getValue());
-		
-		// check array
-		prop = xmp.getArrayItem(XMPConst.NS_DC, "subject", 1);
-		assertNotNull(prop);
-		assertEquals("keyword1", prop.getValue());
-		prop = xmp.getArrayItem(XMPConst.NS_DC, "subject", 2);
-		assertNotNull(prop);
-		assertEquals("keyword2", prop.getValue());
-	}
-	
-	
-	@Test
-	public void convert_wrongGenericMetadata_notConverted() throws XMPException, TikaException 
-	{
-		// unknown prefix
-		tikaMetadata.set("unknown:key", "unknownPrefixValue");
-		// not qualified key
-		tikaMetadata.set("wrongKey", "wrongKeyValue");
-		
-		XMPMeta xmp = TikaToXMP.convert(tikaMetadata, null);
-		
-		// XMP is empty
-		XMPIterator iter = xmp.iterator();
-		assertFalse(iter.hasNext());
-	}
-	
-	@Test(expected=IllegalArgumentException.class)
-	public void convert_nullInput_throw() throws TikaException 
-	{
-		TikaToXMP.convert(null);
-	}
-	
-	@Test
-	public void isConverterAvailable_availableMime_true() 
-	{
-		assertTrue(TikaToXMP.isConverterAvailable(OOXML_MIMETYPE));
-	}
-
-	@Test
-	public void isConverterAvailable_noAvailableMime_false() 
-	{
-		assertFalse(TikaToXMP.isConverterAvailable(GENERIC_MIMETYPE));
-	}
-	
-	@Test
-	public void isConverterAvailable_nullInput_false() 
-	{
-		assertFalse(TikaToXMP.isConverterAvailable(null));
-	}
-	
-	@Test
-	public void getConverter_ConverterAvailable_class() throws TikaException
-	{
-		ITikaToXMPConverter converter = TikaToXMP.getConverter(OOXML_MIMETYPE);
-		assertNotNull(converter);
-		assertTrue(converter instanceof MSOfficeXMLConverter);
-	}
-
-	@Test
-	public void getConverter_noConverterAvailable_null() throws TikaException 
-	{
-		ITikaToXMPConverter converter = TikaToXMP.getConverter(GENERIC_MIMETYPE);
-		assertNull(converter);
-	}
-	
-	@Test(expected=IllegalArgumentException.class)
-	public void getConverter_nullInput_throw() throws TikaException 
-	{
-		TikaToXMP.getConverter(null);
-	}
+public class TikaToXMPTest {
+    private Metadata tikaMetadata;
+
+    private static final String OOXML_MIMETYPE = "application/vnd.openxmlformats-officedocument.wordprocessingml.document";
+    private static final String GENERIC_MIMETYPE = "generic/mimetype";
+
+    // --- Set up ---
+    @Before
+    public void setup() {
+        tikaMetadata = new Metadata();
+    }
+
+    private void setupOOXMLMetadata(Metadata metadata) {
+        // simple property
+        metadata.set( TikaCoreProperties.LANGUAGE, "language" );
+        // language alternative
+        metadata.set( TikaCoreProperties.TITLE, "title" );
+        // comma separated array
+        metadata.set( TikaCoreProperties.KEYWORDS, "keyword1,keyword2" );
+        // OOXML specific simple prop
+        metadata.set( TikaCoreProperties.MODIFIER, "lastModifiedBy" );
+    }
+
+    private void checkOOXMLMetadata(XMPMeta xmp) throws XMPException {
+        // check simple property
+        XMPProperty prop = xmp.getProperty( XMPConst.NS_DC, "language" );
+        assertNotNull( prop );
+        assertEquals( "language", prop.getValue() );
+
+        // check lang alt
+        prop = xmp.getLocalizedText( XMPConst.NS_DC, "title", null, XMPConst.X_DEFAULT );
+        assertNotNull( prop );
+        assertEquals( "title", prop.getValue() );
+
+        // check array
+        prop = xmp.getArrayItem( XMPConst.NS_DC, "subject", 1 );
+        assertNotNull( prop );
+        assertEquals( "keyword1", prop.getValue() );
+        prop = xmp.getArrayItem( XMPConst.NS_DC, "subject", 2 );
+        assertNotNull( prop );
+        assertEquals( "keyword2", prop.getValue() );
+
+        // check OOXML specific simple property
+        prop = xmp.getProperty( OfficeOpenXMLCore.NAMESPACE_URI, "lastModifiedBy" );
+        assertNotNull( prop );
+        assertEquals( "lastModifiedBy", prop.getValue() );
+    }
+
+    // --- TESTS ---
+    @Test
+    public void convert_OOXMLMetadataWithMimetype_everythingConverted() throws XMPException,
+            TikaException {
+        setupOOXMLMetadata( tikaMetadata );
+        tikaMetadata.set( Metadata.CONTENT_TYPE, OOXML_MIMETYPE );
+
+        XMPMeta xmp = TikaToXMP.convert( tikaMetadata );
+
+        checkOOXMLMetadata( xmp );
+    }
+
+    @Test
+    public void convert_OOXMLMetadataWithExtraMimetype_everythingConverted() throws XMPException,
+            TikaException {
+        setupOOXMLMetadata( tikaMetadata );
+
+        XMPMeta xmp = TikaToXMP.convert( tikaMetadata, OOXML_MIMETYPE );
+
+        checkOOXMLMetadata( xmp );
+    }
+
+    @Test
+    public void convert_OOXMLMetadataWithoutMimetype_onlyGeneralMetadataconverted()
+            throws XMPException, TikaException {
+        setupOOXMLMetadata( tikaMetadata );
+
+        XMPMeta xmp = TikaToXMP.convert( tikaMetadata, null );
+
+        // general metadata is converted
+        // check simple property
+        XMPProperty prop = xmp.getProperty( XMPConst.NS_DC, "language" );
+        assertNotNull( prop );
+        assertEquals( "language", prop.getValue() );
+
+        // check lang alt
+        prop = xmp.getLocalizedText( XMPConst.NS_DC, "title", null, XMPConst.X_DEFAULT );
+        assertNotNull( prop );
+        assertEquals( "title", prop.getValue() );
+
+        // OOXML one is not, the namespace has also not been registiered as the converter has not
+        // been used
+        XMPMetaFactory.getSchemaRegistry().registerNamespace( OfficeOpenXMLCore.NAMESPACE_URI,
+                OfficeOpenXMLCore.PREFIX );
+        prop = xmp.getProperty( OfficeOpenXMLCore.NAMESPACE_URI, "lastModifiedBy" );
+        assertNull( prop );
+    }
+
+    @Test
+    public void convert_genericMetadataAllQualified_allConverted() throws XMPException,
+            TikaException {
+        // simple property
+        tikaMetadata.set( TikaCoreProperties.FORMAT, GENERIC_MIMETYPE );
+        // language alternative
+        tikaMetadata.set( TikaCoreProperties.TITLE, "title" );
+        // array
+        tikaMetadata.set( TikaCoreProperties.KEYWORDS, new String[] { "keyword1", "keyword2" } );
+
+        XMPMeta xmp = TikaToXMP.convert( tikaMetadata, null );
+
+        // check simple property
+        XMPProperty prop = xmp.getProperty( XMPConst.NS_DC, "format" );
+        assertNotNull( prop );
+        assertEquals( GENERIC_MIMETYPE, prop.getValue() );
+
+        // check lang alt
+        prop = xmp.getLocalizedText( XMPConst.NS_DC, "title", null, XMPConst.X_DEFAULT );
+        assertNotNull( prop );
+        assertEquals( "title", prop.getValue() );
+
+        // check array
+        prop = xmp.getArrayItem( XMPConst.NS_DC, "subject", 1 );
+        assertNotNull( prop );
+        assertEquals( "keyword1", prop.getValue() );
+        prop = xmp.getArrayItem( XMPConst.NS_DC, "subject", 2 );
+        assertNotNull( prop );
+        assertEquals( "keyword2", prop.getValue() );
+    }
+
+    @Test
+    public void convert_wrongGenericMetadata_notConverted() throws XMPException, TikaException {
+        // unknown prefix
+        tikaMetadata.set( "unknown:key", "unknownPrefixValue" );
+        // not qualified key
+        tikaMetadata.set( "wrongKey", "wrongKeyValue" );
+
+        XMPMeta xmp = TikaToXMP.convert( tikaMetadata, null );
+
+        // XMP is empty
+        XMPIterator iter = xmp.iterator();
+        assertFalse( iter.hasNext() );
+    }
+
+    @Test(expected = IllegalArgumentException.class)
+    public void convert_nullInput_throw() throws TikaException {
+        TikaToXMP.convert( null );
+    }
+
+    @Test
+    public void isConverterAvailable_availableMime_true() {
+        assertTrue( TikaToXMP.isConverterAvailable( OOXML_MIMETYPE ) );
+    }
+
+    @Test
+    public void isConverterAvailable_noAvailableMime_false() {
+        assertFalse( TikaToXMP.isConverterAvailable( GENERIC_MIMETYPE ) );
+    }
+
+    @Test
+    public void isConverterAvailable_nullInput_false() {
+        assertFalse( TikaToXMP.isConverterAvailable( null ) );
+    }
+
+    @Test
+    public void getConverter_ConverterAvailable_class() throws TikaException {
+        ITikaToXMPConverter converter = TikaToXMP.getConverter( OOXML_MIMETYPE );
+        assertNotNull( converter );
+        assertTrue( converter instanceof MSOfficeXMLConverter );
+    }
+
+    @Test
+    public void getConverter_noConverterAvailable_null() throws TikaException {
+        ITikaToXMPConverter converter = TikaToXMP.getConverter( GENERIC_MIMETYPE );
+        assertNull( converter );
+    }
+
+    @Test(expected = IllegalArgumentException.class)
+    public void getConverter_nullInput_throw() throws TikaException {
+        TikaToXMP.getConverter( null );
+    }
 }
diff --git a/tika-xmp/src/test/java/org/apache/tika/xmp/XMPMetadataTest.java b/tika-xmp/src/test/java/org/apache/tika/xmp/XMPMetadataTest.java
index 9be050fbf..95804d119 100644
--- a/tika-xmp/src/test/java/org/apache/tika/xmp/XMPMetadataTest.java
+++ b/tika-xmp/src/test/java/org/apache/tika/xmp/XMPMetadataTest.java
@@ -13,10 +13,6 @@
  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  * See the License for the specific language governing permissions and
  * limitations under the License.
- *
- * IPTC Metadata Descriptions taken from the IPTC Photo Metadata (July 2010) 
- * standard. These parts Copyright 2010 International Press Telecommunications 
- * Council.
  */
 package org.apache.tika.xmp;
 
@@ -41,245 +37,218 @@ import com.adobe.xmp.XMPMeta;
 import com.adobe.xmp.XMPUtils;
 import com.adobe.xmp.properties.XMPProperty;
 
-public class XMPMetadataTest 
-{
-	private Metadata tikaMetadata;
-	private XMPMetadata xmpMeta;
-	
-	private static final String GENERIC_MIMETYPE = "generic/mimetype";
-	
-	// --- SETUP ---
-	@Before
-	public void setUp() throws Exception 
-	{
-	    XMPMetadata.registerNamespace(DublinCore.NAMESPACE_URI_DC_TERMS, DublinCore.PREFIX_DC_TERMS);
-		xmpMeta = new XMPMetadata();
-		tikaMetadata = new Metadata();
-		setupMetadata(tikaMetadata);
-	}
-
-	private void setupMetadata(Metadata metadata)
-	{
-		// simple property
-		metadata.set(TikaCoreProperties.FORMAT, GENERIC_MIMETYPE);
-		// language alternative
-		metadata.set(TikaCoreProperties.TITLE, "title");
-		// array
-		metadata.set(TikaCoreProperties.KEYWORDS, new String[] {"keyword1", "keyword2"});
-		// date
-		metadata.set(TikaCoreProperties.MODIFIED,"2001-01-01T01:01" );
-		// int simple property
-		metadata.set(Property.internalInteger("xmp:Integer"), "2");
-	}
-	
-	// --- HELPER ---
-	private void checkArrayValues(String[] values, String baseValue)
-	{
-		int i = 1;
-		for(String value : values)
-		{
-			assertEquals(baseValue+i, value);
-			i++;
-		}
-	}
-	
-	
-	// --- TESTS ---
-	@Test
-	public void process_genericConversion_ok() throws TikaException, XMPException
-	{
-		xmpMeta.process(tikaMetadata, GENERIC_MIMETYPE);
-		
-		XMPMeta xmp = xmpMeta.getXMPData();
-		
-		// check simple property
-		XMPProperty prop = xmp.getProperty(XMPConst.NS_DC, "format");
-		assertNotNull(prop);
-		assertEquals(GENERIC_MIMETYPE, prop.getValue());
-		
-		// check lang alt
-		prop = xmp.getLocalizedText(XMPConst.NS_DC, "title", null, XMPConst.X_DEFAULT);
-		assertNotNull(prop);
-		assertEquals("title", prop.getValue());
-		
-		// check array
-		prop = xmp.getArrayItem(XMPConst.NS_DC, "subject", 1);
-		assertNotNull(prop);
-		assertEquals("keyword1", prop.getValue());
-		prop = xmp.getArrayItem(XMPConst.NS_DC, "subject", 2);
-		assertNotNull(prop);
-		assertEquals("keyword2", prop.getValue());
-	}
-	
-	@Test
-	public void isMultiValued_multiProp_true() throws TikaException 
-	{
-		xmpMeta.process(tikaMetadata);
-		
-		assertTrue(xmpMeta.isMultiValued(TikaCoreProperties.KEYWORDS));
-	}
-
-	@Test
-	public void isMultiValued_simpleProp_false() throws TikaException 
-	{
-		xmpMeta.process(tikaMetadata);
-		
-		assertFalse(xmpMeta.isMultiValued(TikaCoreProperties.FORMAT));
-	}
-
-	@Test
-	public void get_simpleProp_valueReturned() throws TikaException 
-	{
-		xmpMeta.process(tikaMetadata);
-		
-		assertEquals(GENERIC_MIMETYPE, xmpMeta.get(TikaCoreProperties.FORMAT));
-	}
-
-	@Test
-	public void get_arrayProp_firstValueReturned() throws TikaException 
-	{
-		xmpMeta.process(tikaMetadata);
-		
-		assertEquals("keyword1", xmpMeta.get(TikaCoreProperties.KEYWORDS));
-	}
-
-	@Test
-	public void get_notExistingProp_null() throws TikaException 
-	{
-		assertNull(xmpMeta.get(TikaCoreProperties.FORMAT));
-	}
-	
-	@Test(expected=PropertyTypeException.class)
-	public void get_nullInput_throw() 
-	{
-		String notInitialized = null;
-		xmpMeta.get(notInitialized);
-	}
-	
-	@Test(expected=PropertyTypeException.class)
-	public void get_notQualifiedKey_throw() 
-	{
-		xmpMeta.get("wrongKey");
-	}
-	
-	@Test(expected=PropertyTypeException.class)
-	public void get_unknownPrefixKey_throw() 
-	{
-		xmpMeta.get("unknown:key");
-	}
-	
-	@Test
-	public void getInt_IntegerProperty_valueReturned() throws TikaException 
-	{
-		xmpMeta.process(tikaMetadata);
-		
-		assertEquals(new Integer(2), xmpMeta.getInt(Property.get("xmp:Integer")));
-	}
-
-	@Test
-	public void getDate_DateProperty_valueReturned()  throws TikaException, XMPException 
-	{
-		xmpMeta.process(tikaMetadata);
-		
-		Date date = XMPUtils.convertToDate("2001-01-01T01:01").getCalendar().getTime();
-		assertTrue(date.equals(xmpMeta.getDate(TikaCoreProperties.MODIFIED)));
-	}
-
-	@Test
-	public void getValues_arrayProperty_allElementsReturned() throws TikaException 
-	{
-		xmpMeta.process(tikaMetadata);
-		
-		String[] values = xmpMeta.getValues(TikaCoreProperties.KEYWORDS);
-		assertEquals(2, values.length);
-		
-		checkArrayValues(values, "keyword");
-	}
-
-	@Test
-	public void testSetAll() 
-	{
-		Properties props = new Properties();
-		props.put(TikaCoreProperties.FORMAT.getName(), "format");
-		props.put(TikaCoreProperties.KEYWORDS.getName(), "keyword");
-		
-		xmpMeta.setAll(props);
-		
-		assertEquals("format", xmpMeta.get(TikaCoreProperties.FORMAT));
-		
-		String[] values = xmpMeta.getValues(TikaCoreProperties.KEYWORDS);
-		assertEquals(1, values.length);
-		
-		assertEquals("keyword", values[0]);
-	}
-
-	@Test
-	public void set_simpleProp_ok() 
-	{
-		xmpMeta.set(TikaCoreProperties.FORMAT, GENERIC_MIMETYPE);
-		
-		assertEquals(GENERIC_MIMETYPE, xmpMeta.get(TikaCoreProperties.FORMAT));
-	}
-	
-	@Test(expected=PropertyTypeException.class)
-	public void set_nullInput_throw() 
-	{
-		String notInitialized = null;
-		xmpMeta.set(notInitialized,"value");
-	}
-	
-	@Test(expected=PropertyTypeException.class)
-	public void set_notQualifiedKey_throw() 
-	{
-		xmpMeta.set("wrongKey","value");
-	}
-	
-	@Test(expected=PropertyTypeException.class)
-	public void set_unknownPrefixKey_throw() 
-	{
-		xmpMeta.set("unknown:key","value");
-	}
-
-	@Test
-	public void set_arrayProperty_ok() 
-	{
-		xmpMeta.set(TikaCoreProperties.KEYWORDS, new String[] {"keyword1", "keyword2"});
-
-		String[] values = xmpMeta.getValues(TikaCoreProperties.KEYWORDS);
-		assertEquals(2, values.length);
-		
-		checkArrayValues(values, "keyword");
-	}
-
-	@Test(expected=PropertyTypeException.class)
-	public void set_simplePropWithMultipleValues_throw() 
-	{
-		xmpMeta.set(TikaCoreProperties.FORMAT,new String[] {"value1", "value2"});
-	}
-	
-
-	@Test
-	public void remove_existingProperty_propertyRemoved() throws TikaException 
-	{
-		xmpMeta.process(tikaMetadata);
-		
-		assertNotNull(xmpMeta.get(TikaCoreProperties.FORMAT));
-		
-		xmpMeta.remove(TikaCoreProperties.FORMAT);
-		
-		assertNull(xmpMeta.get(TikaCoreProperties.FORMAT));
-	}
-
-	@Test
-	public void size_numberOfNamespacesReturned() throws TikaException
-	{
-		xmpMeta.process(tikaMetadata);
-		
-		assertEquals(3, xmpMeta.size());
-		
-		xmpMeta.set(XMPRights.OWNER, "owner");
-		
-		assertEquals(4, xmpMeta.size());
-	}
+public class XMPMetadataTest {
+    private Metadata tikaMetadata;
+    private XMPMetadata xmpMeta;
+
+    private static final String GENERIC_MIMETYPE = "generic/mimetype";
+
+    // --- SETUP ---
+    @Before
+    public void setUp() throws Exception {
+        XMPMetadata.registerNamespace( DublinCore.NAMESPACE_URI_DC_TERMS,
+                DublinCore.PREFIX_DC_TERMS );
+        xmpMeta = new XMPMetadata();
+        tikaMetadata = new Metadata();
+        setupMetadata( tikaMetadata );
+    }
+
+    private void setupMetadata(Metadata metadata) {
+        // simple property
+        metadata.set( TikaCoreProperties.FORMAT, GENERIC_MIMETYPE );
+        // language alternative
+        metadata.set( TikaCoreProperties.TITLE, "title" );
+        // array
+        metadata.set( TikaCoreProperties.KEYWORDS, new String[] { "keyword1", "keyword2" } );
+        // date
+        metadata.set( TikaCoreProperties.MODIFIED, "2001-01-01T01:01" );
+        // int simple property
+        metadata.set( Property.internalInteger( "xmp:Integer" ), "2" );
+    }
+
+    // --- HELPER ---
+    private void checkArrayValues(String[] values, String baseValue) {
+        int i = 1;
+        for (String value : values) {
+            assertEquals( baseValue + i, value );
+            i++;
+        }
+    }
+
+    // --- TESTS ---
+    @Test
+    public void process_genericConversion_ok() throws TikaException, XMPException {
+        xmpMeta.process( tikaMetadata, GENERIC_MIMETYPE );
+
+        XMPMeta xmp = xmpMeta.getXMPData();
+
+        // check simple property
+        XMPProperty prop = xmp.getProperty( XMPConst.NS_DC, "format" );
+        assertNotNull( prop );
+        assertEquals( GENERIC_MIMETYPE, prop.getValue() );
+
+        // check lang alt
+        prop = xmp.getLocalizedText( XMPConst.NS_DC, "title", null, XMPConst.X_DEFAULT );
+        assertNotNull( prop );
+        assertEquals( "title", prop.getValue() );
+
+        // check array
+        prop = xmp.getArrayItem( XMPConst.NS_DC, "subject", 1 );
+        assertNotNull( prop );
+        assertEquals( "keyword1", prop.getValue() );
+        prop = xmp.getArrayItem( XMPConst.NS_DC, "subject", 2 );
+        assertNotNull( prop );
+        assertEquals( "keyword2", prop.getValue() );
+    }
+
+    @Test
+    public void isMultiValued_multiProp_true() throws TikaException {
+        xmpMeta.process( tikaMetadata );
+
+        assertTrue( xmpMeta.isMultiValued( TikaCoreProperties.KEYWORDS ) );
+    }
+
+    @Test
+    public void isMultiValued_simpleProp_false() throws TikaException {
+        xmpMeta.process( tikaMetadata );
+
+        assertFalse( xmpMeta.isMultiValued( TikaCoreProperties.FORMAT ) );
+    }
+
+    @Test
+    public void get_simpleProp_valueReturned() throws TikaException {
+        xmpMeta.process( tikaMetadata );
+
+        assertEquals( GENERIC_MIMETYPE, xmpMeta.get( TikaCoreProperties.FORMAT ) );
+    }
+
+    @Test
+    public void get_arrayProp_firstValueReturned() throws TikaException {
+        xmpMeta.process( tikaMetadata );
+
+        assertEquals( "keyword1", xmpMeta.get( TikaCoreProperties.KEYWORDS ) );
+    }
+
+    @Test
+    public void get_notExistingProp_null() throws TikaException {
+        assertNull( xmpMeta.get( TikaCoreProperties.FORMAT ) );
+    }
+
+    @Test(expected = PropertyTypeException.class)
+    public void get_nullInput_throw() {
+        String notInitialized = null;
+        xmpMeta.get( notInitialized );
+    }
+
+    @Test(expected = PropertyTypeException.class)
+    public void get_notQualifiedKey_throw() {
+        xmpMeta.get( "wrongKey" );
+    }
+
+    @Test(expected = PropertyTypeException.class)
+    public void get_unknownPrefixKey_throw() {
+        xmpMeta.get( "unknown:key" );
+    }
+
+    @Test
+    public void getInt_IntegerProperty_valueReturned() throws TikaException {
+        xmpMeta.process( tikaMetadata );
+
+        assertEquals( new Integer( 2 ), xmpMeta.getInt( Property.get( "xmp:Integer" ) ) );
+    }
+
+    @Test
+    public void getDate_DateProperty_valueReturned() throws TikaException, XMPException {
+        xmpMeta.process( tikaMetadata );
+
+        Date date = XMPUtils.convertToDate( "2001-01-01T01:01" ).getCalendar().getTime();
+        assertTrue( date.equals( xmpMeta.getDate( TikaCoreProperties.MODIFIED ) ) );
+    }
+
+    @Test
+    public void getValues_arrayProperty_allElementsReturned() throws TikaException {
+        xmpMeta.process( tikaMetadata );
+
+        String[] values = xmpMeta.getValues( TikaCoreProperties.KEYWORDS );
+        assertEquals( 2, values.length );
+
+        checkArrayValues( values, "keyword" );
+    }
+
+    @Test
+    public void testSetAll() {
+        Properties props = new Properties();
+        props.put( TikaCoreProperties.FORMAT.getName(), "format" );
+        props.put( TikaCoreProperties.KEYWORDS.getName(), "keyword" );
+
+        xmpMeta.setAll( props );
+
+        assertEquals( "format", xmpMeta.get( TikaCoreProperties.FORMAT ) );
+
+        String[] values = xmpMeta.getValues( TikaCoreProperties.KEYWORDS );
+        assertEquals( 1, values.length );
+
+        assertEquals( "keyword", values[0] );
+    }
+
+    @Test
+    public void set_simpleProp_ok() {
+        xmpMeta.set( TikaCoreProperties.FORMAT, GENERIC_MIMETYPE );
+
+        assertEquals( GENERIC_MIMETYPE, xmpMeta.get( TikaCoreProperties.FORMAT ) );
+    }
+
+    @Test(expected = PropertyTypeException.class)
+    public void set_nullInput_throw() {
+        String notInitialized = null;
+        xmpMeta.set( notInitialized, "value" );
+    }
+
+    @Test(expected = PropertyTypeException.class)
+    public void set_notQualifiedKey_throw() {
+        xmpMeta.set( "wrongKey", "value" );
+    }
+
+    @Test(expected = PropertyTypeException.class)
+    public void set_unknownPrefixKey_throw() {
+        xmpMeta.set( "unknown:key", "value" );
+    }
+
+    @Test
+    public void set_arrayProperty_ok() {
+        xmpMeta.set( TikaCoreProperties.KEYWORDS, new String[] { "keyword1", "keyword2" } );
+
+        String[] values = xmpMeta.getValues( TikaCoreProperties.KEYWORDS );
+        assertEquals( 2, values.length );
+
+        checkArrayValues( values, "keyword" );
+    }
+
+    @Test(expected = PropertyTypeException.class)
+    public void set_simplePropWithMultipleValues_throw() {
+        xmpMeta.set( TikaCoreProperties.FORMAT, new String[] { "value1", "value2" } );
+    }
+
+    @Test
+    public void remove_existingProperty_propertyRemoved() throws TikaException {
+        xmpMeta.process( tikaMetadata );
+
+        assertNotNull( xmpMeta.get( TikaCoreProperties.FORMAT ) );
+
+        xmpMeta.remove( TikaCoreProperties.FORMAT );
+
+        assertNull( xmpMeta.get( TikaCoreProperties.FORMAT ) );
+    }
+
+    @Test
+    public void size_numberOfNamespacesReturned() throws TikaException {
+        xmpMeta.process( tikaMetadata );
+
+        assertEquals( 3, xmpMeta.size() );
+
+        xmpMeta.set( XMPRights.OWNER, "owner" );
+
+        assertEquals( 4, xmpMeta.size() );
+    }
 
 }

Commit:
0b9fc00f4f2c1f22556d5635d55bcce5a96f0907
Jukka Zitting
jukka@apache.org
2012-07-03 15:03:47 +0000
TIKA-756: XMP output from Tika CLI
diff --git a/pom.xml b/pom.xml
index c2ac30c47..283cdc29a 100644
--- a/pom.xml
+++ b/pom.xml
@@ -48,6 +48,7 @@
     <module>tika-parent</module>
     <module>tika-core</module>
     <module>tika-parsers</module>
+    <module>tika-xmp</module>
     <module>tika-app</module>
     <module>tika-bundle</module>
     <module>tika-server</module>
@@ -88,15 +89,6 @@
   </build>
 
   <profiles>
-    <profile>
-      <id>java6</id>
-      <activation>
-        <jdk>[1.6,)</jdk>
-      </activation>
-      <modules>
-        <module>tika-xmp</module>
-      </modules>
-    </profile>
     <profile>
       <id>apache-release</id>
       <properties>
diff --git a/tika-xmp/pom.xml b/tika-xmp/pom.xml
index 26ee6e5d2..a1f5df992 100644
--- a/tika-xmp/pom.xml
+++ b/tika-xmp/pom.xml
@@ -74,7 +74,7 @@
     <dependency>
       <groupId>com.adobe.xmp</groupId>
       <artifactId>xmpcore</artifactId>
-      <version>5.1.1</version>
+      <version>5.1.2</version>
     </dependency>
     <dependency>
       <groupId>junit</groupId>

Commit:
196a61f19cdd8c78339412c8e084b74c3390ad42
Jukka Zitting
jukka@apache.org
2012-07-03 08:48:25 +0000
TIKA-773: .NET version of Tika
diff --git a/tika-dotnet/.gitignore b/tika-dotnet/.gitignore
deleted file mode 100644
index 8b7111121..000000000
--- a/tika-dotnet/.gitignore
+++ /dev/null
@@ -1,2 +0,0 @@
-Tika.sln.cache
-obj

Commit:
07a1590839bff6f16ac19b031a26e128141e19a2
Ray Gauss II
rgauss@apache.org
2012-07-03 03:14:39 +0000
TIKA-930: Consolidation of Some Tika Core Properties    - Added the Dublin Core Terms namespace and prefix
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/DublinCore.java b/tika-core/src/main/java/org/apache/tika/metadata/DublinCore.java
index 1a3ae1096..46fa52bc5 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/DublinCore.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/DublinCore.java
@@ -23,8 +23,10 @@ package org.apache.tika.metadata;
  */
 public interface DublinCore {
 
-	public static final String NAMESPACE_URI_DC = "http://purl.org/dc/elements/1.1/";
-	public static final String PREFIX_DC = "dc";
+    public static final String NAMESPACE_URI_DC = "http://purl.org/dc/elements/1.1/";
+    public static final String NAMESPACE_URI_DC_TERMS = "http://purl.org/dc/terms/";
+    public static final String PREFIX_DC = "dc";
+    public static final String PREFIX_DC_TERMS = "dcterms";
 
     /**
      * Typically, Format may include the media-type or dimensions of the
@@ -52,7 +54,7 @@ public interface DublinCore {
      * Date on which the resource was changed.
      */
 	Property MODIFIED = Property.internalDate(
-			PREFIX_DC + Metadata.NAMESPACE_PREFIX_DELIMITER + "modified");
+		PREFIX_DC_TERMS + Metadata.NAMESPACE_PREFIX_DELIMITER + "modified");
 
     /**
      * An entity responsible for making contributions to the content of the
@@ -60,7 +62,7 @@ public interface DublinCore {
      * or a service. Typically, the name of a Contributor should be used to
      * indicate the entity.
      */
-	Property CONTRIBUTOR = Property.internalText(
+	Property CONTRIBUTOR = Property.internalTextBag(
     		PREFIX_DC + Metadata.NAMESPACE_PREFIX_DELIMITER + "contributor");
 
     /**
@@ -81,9 +83,15 @@ public interface DublinCore {
      * Examples of a Creator include a person, an organisation, or a service.
      * Typically, the name of a Creator should be used to indicate the entity.
      */
-	Property CREATOR = Property.internalText(
+	Property CREATOR = Property.internalTextBag(
     		PREFIX_DC + Metadata.NAMESPACE_PREFIX_DELIMITER + "creator");
 
+    /**
+     * Date of creation of the resource.
+     */
+        Property CREATED = Property.internalDate(
+                PREFIX_DC_TERMS + Metadata.NAMESPACE_PREFIX_DELIMITER + "created");
+
     /**
      * A date associated with an event in the life cycle of the resource.
      * Typically, Date will be associated with the creation or availability of
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/MSOffice.java b/tika-core/src/main/java/org/apache/tika/metadata/MSOffice.java
index 4b49cac85..886aa4300 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/MSOffice.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/MSOffice.java
@@ -26,7 +26,7 @@ public interface MSOffice {
 
     @Deprecated String KEYWORDS = "Keywords";
 
-    String COMMENTS = "Comments";
+    @Deprecated String COMMENTS = "Comments";
 
     @Deprecated String LAST_AUTHOR = "Last-Author";
 
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/OfficeOpenXMLCore.java b/tika-core/src/main/java/org/apache/tika/metadata/OfficeOpenXMLCore.java
index 5f33f1fd3..1a803b819 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/OfficeOpenXMLCore.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/OfficeOpenXMLCore.java
@@ -67,4 +67,10 @@ public interface OfficeOpenXMLCore
      */
     Property VERSION = Property.externalText(
     		PREFIX + Metadata.NAMESPACE_PREFIX_DELIMITER + "version");
+    
+    /**
+     * The document's subject.
+     */
+    Property SUBJECT = Property.externalText(
+                PREFIX + Metadata.NAMESPACE_PREFIX_DELIMITER + "subject");
 }
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/OfficeOpenXMLExtended.java b/tika-core/src/main/java/org/apache/tika/metadata/OfficeOpenXMLExtended.java
index 330a83006..b7b0264d0 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/OfficeOpenXMLExtended.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/OfficeOpenXMLExtended.java
@@ -30,9 +30,11 @@ package org.apache.tika.metadata;
  */
 public interface OfficeOpenXMLExtended 
 {
-	String NAMESPACE_URI = "http://schemas.openxmlformats.org/officeDocument/2006/extended-properties/";
-	String PREFIX = "extended-properties";
-	
+    String NAMESPACE_URI = "http://schemas.openxmlformats.org/officeDocument/2006/extended-properties/";
+    String WORD_PROCESSING_NAMESPACE_URI = "http://schemas.openxmlformats.org/wordprocessingml/2006/main";
+    String PREFIX = "extended-properties";
+    String WORD_PROCESSING_PREFIX = "w";
+
     Property TEMPLATE = Property.externalText(
     		PREFIX + Metadata.NAMESPACE_PREFIX_DELIMITER + "Template");
     
@@ -62,4 +64,7 @@ public interface OfficeOpenXMLExtended
     
     Property DOC_SECURITY = Property.externalInteger(
     		PREFIX + Metadata.NAMESPACE_PREFIX_DELIMITER + "DocSecurity");
+    
+    Property COMMENTS = Property.externalTextBag(
+            WORD_PROCESSING_PREFIX + Metadata.NAMESPACE_PREFIX_DELIMITER + "comments");
 }
\ No newline at end of file
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/TikaCoreProperties.java b/tika-core/src/main/java/org/apache/tika/metadata/TikaCoreProperties.java
index 320baf7c9..9e1105288 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/TikaCoreProperties.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/TikaCoreProperties.java
@@ -64,24 +64,21 @@ public interface TikaCoreProperties {
     * @see DublinCore#CREATOR
     */
     public static final Property CREATOR = Property.composite(DublinCore.CREATOR, 
-            new Property[] { Property.internalText(Metadata.CREATOR) });
+            new Property[] { 
+                Office.AUTHOR,
+                Property.internalTextBag(Metadata.CREATOR),
+                Property.internalTextBag(Metadata.AUTHOR)
+            });
     
     /**
-     * @see Office#INITIAL_AUTHOR
-     */
-    public static final Property INITIAL_AUTHOR = Office.INITIAL_AUTHOR;
-
-    /**
-     * @see Office#AUTHOR
+     * @see Office#LAST_AUTHOR
      */
-    public static final Property AUTHOR = Property.composite(Office.AUTHOR,
-          new Property[] { Property.internalText(MSOffice.AUTHOR) });
-
+     public static final Property MODIFIER = Office.LAST_AUTHOR;
+    
     /**
-     * @see Office#LAST_AUTHOR
+     * @see XMP#CREATOR_TOOL
      */
-    public static final Property LAST_AUTHOR = Property.composite(Office.LAST_AUTHOR,
-            new Property[] { Property.internalText(MSOffice.LAST_AUTHOR) });
+     public static final Property CREATOR_TOOL = XMP.CREATOR_TOOL;
     
    /**
     * @see DublinCore#LANGUAGE
@@ -136,42 +133,48 @@ public interface TikaCoreProperties {
      
     /**
      * @see DublinCore#SUBJECT
-     */
-    public static final Property SUBJECT = Property.composite(DublinCore.SUBJECT, 
-            new Property[] { Property.internalText(Metadata.SUBJECT) });
-      
-    /**
      * @see Office#KEYWORDS
      */
-    public static final Property KEYWORDS = Property.composite(Office.KEYWORDS,
-            new Property[] { Property.internalTextBag(MSOffice.KEYWORDS) });
-
+    public static final Property KEYWORDS = Property.composite(DublinCore.SUBJECT,
+            new Property[] { 
+                Office.KEYWORDS, 
+                Property.internalTextBag(MSOffice.KEYWORDS),
+                Property.internalTextBag(Metadata.SUBJECT)
+            });
     
     // Date related properties
     
-    /**
-     * @see DublinCore#DATE
-     */
-     public static final Property DATE = Property.composite(DublinCore.DATE, 
-             new Property[] { Metadata.DATE });
-     
-    /**
-     * @see DublinCore#MODIFIED
-     */
-     public static final Property MODIFIED = Property.composite(DublinCore.MODIFIED, 
-             new Property[] { Property.internalText(Metadata.MODIFIED), Property.internalText("Last-Modified") });
+     /** 
+      * @see DublinCore#DATE 
+      * @see Office#CREATION_DATE 
+      */
+     public static final Property CREATED = Property.composite(DublinCore.CREATED,
+             new Property[] { 
+                     Office.CREATION_DATE, 
+                     MSOffice.CREATION_DATE, 
+                     Metadata.DATE
+             });
      
-     /** @see Office#CREATION_DATE */
-     public static final Property CREATION_DATE = Property.composite(Office.CREATION_DATE,
-             new Property[] { MSOffice.CREATION_DATE });
-
-     /** @see Office#SAVE_DATE */
-     public static final Property SAVE_DATE = Property.composite(Office.SAVE_DATE,
-             new Property[] { MSOffice.LAST_SAVED });
+     /** 
+      * @see DublinCore#MODIFIED
+      * @see Office#SAVE_DATE 
+      */
+     public static final Property MODIFIED = Property.composite(DublinCore.MODIFIED,
+             new Property[] { 
+                     Office.SAVE_DATE, 
+                     MSOffice.LAST_SAVED, 
+                     Property.internalText(Metadata.MODIFIED),
+                     Property.internalText("Last-Modified")
+             });
      
      /** @see Office#PRINT_DATE */
      public static final Property PRINT_DATE = Property.composite(Office.PRINT_DATE, 
              new Property[] { MSOffice.LAST_PRINTED });
+     
+     /**
+      * @see XMP#METADATA_DATE
+      */
+     public static final Property METADATA_DATE = XMP.METADATA_DATE;
     
      
     // Geographic related properties
@@ -190,4 +193,56 @@ public interface TikaCoreProperties {
      * @see Geographic#ALTITUDE
      */
     public static final Property ALTITUDE = Geographic.ALTITUDE;
+    
+    
+    // Comment and rating properties
+    
+    /**
+     * @see XMP#RATING
+     */
+    public static final Property RATING = XMP.RATING;
+    
+    /** 
+     * @see OfficeOpenXMLExtended#COMMENTS 
+     */
+    public static final Property COMMENTS = Property.composite(OfficeOpenXMLExtended.COMMENTS, 
+            new Property[] { 
+                Property.internalTextBag(ClimateForcast.COMMENT),
+                Property.internalTextBag(MSOffice.COMMENTS)
+            });
+    
+    // TODO: Remove transition properties in Tika 2.0
+    
+    /** 
+     * @see DublinCore#SUBJECT 
+     * @deprecated use TikaCoreProperties#KEYWORDS
+     */
+    @Deprecated
+    public static final Property TRANSITION_KEYWORDS_TO_DC_SUBJECT = Property.composite(DublinCore.SUBJECT, 
+            new Property[] { Property.internalTextBag(MSOffice.KEYWORDS) });
+    
+    /** 
+     * @see OfficeOpenXMLExtended#COMMENTS 
+     * @deprecated use TikaCoreProperties#DESCRIPTION
+     */
+    @Deprecated
+    public static final Property TRANSITION_SUBJECT_TO_DC_DESCRIPTION = Property.composite(DublinCore.DESCRIPTION, 
+            new Property[] { Property.internalText(Metadata.SUBJECT) });
+    
+    /** 
+     * @see DublinCore#TITLE 
+     * @deprecated use TikaCoreProperties#TITLE
+     */
+    @Deprecated
+    public static final Property TRANSITION_SUBJECT_TO_DC_TITLE = Property.composite(DublinCore.TITLE, 
+            new Property[] { Property.internalText(Metadata.SUBJECT) });
+    
+    /** 
+     * @see OfficeOpenXMLCore#SUBJECT 
+     * @deprecated use OfficeOpenXMLCore#SUBJECT
+     */
+    @Deprecated
+    public static final Property TRANSITION_SUBJECT_TO_OO_SUBJECT = Property.composite(OfficeOpenXMLCore.SUBJECT, 
+            new Property[] { Property.internalText(Metadata.SUBJECT) });
+    
 }
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/XMP.java b/tika-core/src/main/java/org/apache/tika/metadata/XMP.java
index 9101dfd06..0f8c7fce6 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/XMP.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/XMP.java
@@ -23,7 +23,7 @@ public interface XMP {
     String PREFIX = "xmp";
 
     /** The xmp prefix followed by the colon delimiter */
-    String PREFIX_ = PREFIX + ":";
+    String PREFIX_ = PREFIX + Metadata.NAMESPACE_PREFIX_DELIMITER;
 
     /**
      * The date and time the resource was created. For a digital file, this need not
diff --git a/tika-core/src/test/java/org/apache/tika/metadata/TestMetadata.java b/tika-core/src/test/java/org/apache/tika/metadata/TestMetadata.java
index 253380de6..8ab4529a1 100644
--- a/tika-core/src/test/java/org/apache/tika/metadata/TestMetadata.java
+++ b/tika-core/src/test/java/org/apache/tika/metadata/TestMetadata.java
@@ -234,7 +234,7 @@ public class TestMetadata extends TestCase {
             fail("Shouldn't be able to set a multi valued property as an int");
         } catch(PropertyTypeException e) {}
         try {
-            meta.set(TikaCoreProperties.CREATION_DATE, 1);
+            meta.set(TikaCoreProperties.CREATED, 1);
             fail("Shouldn't be able to set a date property as an int");
         } catch(PropertyTypeException e) {}
         
@@ -252,7 +252,7 @@ public class TestMetadata extends TestCase {
         meta.set(Metadata.IMAGE_WIDTH, 22);
         assertEquals(22, meta.getInt(Metadata.IMAGE_WIDTH).intValue());
         assertEquals(null, meta.getInt(Metadata.BITS_PER_SAMPLE));
-        assertEquals(null, meta.getInt(TikaCoreProperties.CREATION_DATE));
+        assertEquals(null, meta.getInt(TikaCoreProperties.CREATED));
     }
     
     /**
@@ -264,8 +264,8 @@ public class TestMetadata extends TestCase {
         long hour = 60 * 60 * 1000; 
         
         // Isn't initially set, will get null back
-        assertEquals(null, meta.get(TikaCoreProperties.CREATION_DATE));
-        assertEquals(null, meta.getInt(TikaCoreProperties.CREATION_DATE));
+        assertEquals(null, meta.get(TikaCoreProperties.CREATED));
+        assertEquals(null, meta.getInt(TikaCoreProperties.CREATED));
         
         // Can only set as a single valued date
         try {
@@ -278,52 +278,52 @@ public class TestMetadata extends TestCase {
         } catch(PropertyTypeException e) {}
         
         // Can set it and retrieve it
-        meta.set(TikaCoreProperties.CREATION_DATE, new Date(1000));
-        assertEquals("1970-01-01T00:00:01Z", meta.get(TikaCoreProperties.CREATION_DATE));
-        assertEquals(1000, meta.getDate(TikaCoreProperties.CREATION_DATE).getTime());
+        meta.set(TikaCoreProperties.CREATED, new Date(1000));
+        assertEquals("1970-01-01T00:00:01Z", meta.get(TikaCoreProperties.CREATED));
+        assertEquals(1000, meta.getDate(TikaCoreProperties.CREATED).getTime());
         
         // If you save a non date value, you get null
-        meta.set(TikaCoreProperties.CREATION_DATE, "INVALID");
-        assertEquals("INVALID", meta.get(TikaCoreProperties.CREATION_DATE));
-        assertEquals(null, meta.getDate(TikaCoreProperties.CREATION_DATE));
+        meta.set(TikaCoreProperties.CREATED, "INVALID");
+        assertEquals("INVALID", meta.get(TikaCoreProperties.CREATED));
+        assertEquals(null, meta.getDate(TikaCoreProperties.CREATED));
         
         // If you try to retrieve a non simple date value, you get null
-        meta.set(TikaCoreProperties.CREATION_DATE, new Date(1000));
-        assertEquals(1000, meta.getDate(TikaCoreProperties.CREATION_DATE).getTime());
+        meta.set(TikaCoreProperties.CREATED, new Date(1000));
+        assertEquals(1000, meta.getDate(TikaCoreProperties.CREATED).getTime());
         assertEquals(null, meta.getInt(Metadata.BITS_PER_SAMPLE));
-        assertEquals(null, meta.getInt(TikaCoreProperties.CREATION_DATE));
+        assertEquals(null, meta.getInt(TikaCoreProperties.CREATED));
         
         // Our format doesn't include milliseconds
         // This means things get rounded 
-        meta.set(TikaCoreProperties.CREATION_DATE, new Date(1050));
-        assertEquals("1970-01-01T00:00:01Z", meta.get(TikaCoreProperties.CREATION_DATE));
-        assertEquals(1000, meta.getDate(TikaCoreProperties.CREATION_DATE).getTime());
+        meta.set(TikaCoreProperties.CREATED, new Date(1050));
+        assertEquals("1970-01-01T00:00:01Z", meta.get(TikaCoreProperties.CREATED));
+        assertEquals(1000, meta.getDate(TikaCoreProperties.CREATED).getTime());
         
         // We can accept a number of different ISO-8601 variants
-        meta.set(TikaCoreProperties.CREATION_DATE, "1970-01-01T00:00:01Z");
-        assertEquals(1000, meta.getDate(TikaCoreProperties.CREATION_DATE).getTime());
+        meta.set(TikaCoreProperties.CREATED, "1970-01-01T00:00:01Z");
+        assertEquals(1000, meta.getDate(TikaCoreProperties.CREATED).getTime());
         
-        meta.set(TikaCoreProperties.CREATION_DATE, "1970-01-01 00:00:01Z");
-        assertEquals(1000, meta.getDate(TikaCoreProperties.CREATION_DATE).getTime());
+        meta.set(TikaCoreProperties.CREATED, "1970-01-01 00:00:01Z");
+        assertEquals(1000, meta.getDate(TikaCoreProperties.CREATED).getTime());
         
-        meta.set(TikaCoreProperties.CREATION_DATE, "1970-01-01T01:00:01+01:00");
-        assertEquals(1000, meta.getDate(TikaCoreProperties.CREATION_DATE).getTime());
+        meta.set(TikaCoreProperties.CREATED, "1970-01-01T01:00:01+01:00");
+        assertEquals(1000, meta.getDate(TikaCoreProperties.CREATED).getTime());
         
-        meta.set(TikaCoreProperties.CREATION_DATE, "1970-01-01 01:00:01+01:00");
-        assertEquals(1000, meta.getDate(TikaCoreProperties.CREATION_DATE).getTime());
+        meta.set(TikaCoreProperties.CREATED, "1970-01-01 01:00:01+01:00");
+        assertEquals(1000, meta.getDate(TikaCoreProperties.CREATED).getTime());
         
-        meta.set(TikaCoreProperties.CREATION_DATE, "1970-01-01T12:00:01+12:00");
-        assertEquals(1000, meta.getDate(TikaCoreProperties.CREATION_DATE).getTime());
+        meta.set(TikaCoreProperties.CREATED, "1970-01-01T12:00:01+12:00");
+        assertEquals(1000, meta.getDate(TikaCoreProperties.CREATED).getTime());
         
-        meta.set(TikaCoreProperties.CREATION_DATE, "1969-12-31T12:00:01-12:00");
-        assertEquals(1000, meta.getDate(TikaCoreProperties.CREATION_DATE).getTime());
+        meta.set(TikaCoreProperties.CREATED, "1969-12-31T12:00:01-12:00");
+        assertEquals(1000, meta.getDate(TikaCoreProperties.CREATED).getTime());
         
         // Dates without times, come in at midday UTC
-        meta.set(TikaCoreProperties.CREATION_DATE, "1970-01-01");
-        assertEquals(12*hour, meta.getDate(TikaCoreProperties.CREATION_DATE).getTime());
+        meta.set(TikaCoreProperties.CREATED, "1970-01-01");
+        assertEquals(12*hour, meta.getDate(TikaCoreProperties.CREATED).getTime());
         
-        meta.set(TikaCoreProperties.CREATION_DATE, "1970:01:01");
-        assertEquals(12*hour, meta.getDate(TikaCoreProperties.CREATION_DATE).getTime());
+        meta.set(TikaCoreProperties.CREATED, "1970:01:01");
+        assertEquals(12*hour, meta.getDate(TikaCoreProperties.CREATED).getTime());
     }
     
     /**
@@ -333,9 +333,9 @@ public class TestMetadata extends TestCase {
     public void testGetSetDateUnspecifiedTimezone() {
         Metadata meta = new Metadata();    
         
-        meta.set(TikaCoreProperties.DATE, "1970-01-01T00:00:01");
+        meta.set(TikaCoreProperties.CREATED, "1970-01-01T00:00:01");
         assertEquals("should return string without time zone specifier because zone is not known",
-        		"1970-01-01T00:00:01", meta.get(TikaCoreProperties.DATE));
+        		"1970-01-01T00:00:01", meta.get(TikaCoreProperties.CREATED));
     }
     
     /**
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/dwg/DWGParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/dwg/DWGParser.java
index fe5f36ee0..5f8fcace2 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/dwg/DWGParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/dwg/DWGParser.java
@@ -55,11 +55,11 @@ public class DWGParser extends AbstractParser {
     /** The order of the fields in the header */
     private static final Property[] HEADER_PROPERTIES_ENTRIES = {
         TikaCoreProperties.TITLE, 
-        TikaCoreProperties.SUBJECT,
-        TikaCoreProperties.AUTHOR,
-        TikaCoreProperties.KEYWORDS,
-        Property.internalText(Metadata.COMMENTS),
-        TikaCoreProperties.LAST_AUTHOR,
+        TikaCoreProperties.TRANSITION_SUBJECT_TO_DC_DESCRIPTION,
+        TikaCoreProperties.CREATOR,
+        TikaCoreProperties.TRANSITION_KEYWORDS_TO_DC_SUBJECT,
+        TikaCoreProperties.COMMENTS,
+        TikaCoreProperties.MODIFIER,
         null, // Unknown?
         TikaCoreProperties.RELATION, // Hyperlink
     };
@@ -69,12 +69,12 @@ public class DWGParser extends AbstractParser {
        null, 
        TikaCoreProperties.RELATION, // 0x01
        TikaCoreProperties.TITLE,    // 0x02
-       TikaCoreProperties.SUBJECT,  // 0x03
-       TikaCoreProperties.AUTHOR,   // 0x04
+       TikaCoreProperties.TRANSITION_SUBJECT_TO_DC_DESCRIPTION,  // 0x03
+       TikaCoreProperties.CREATOR,   // 0x04
        null,
-       Property.internalText(Metadata.COMMENTS),// 0x06 
-       TikaCoreProperties.KEYWORDS,    // 0x07
-       TikaCoreProperties.LAST_AUTHOR, // 0x08
+       TikaCoreProperties.COMMENTS,// 0x06 
+       TikaCoreProperties.TRANSITION_KEYWORDS_TO_DC_SUBJECT,    // 0x07
+       TikaCoreProperties.MODIFIER, // 0x08
    };
 
     private static final String HEADER_2000_PROPERTIES_MARKER_STR =
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/font/TrueTypeParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/font/TrueTypeParser.java
index d295f57b8..f355beaad 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/font/TrueTypeParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/font/TrueTypeParser.java
@@ -66,7 +66,7 @@ public class TrueTypeParser extends AbstractParser {
         }
 
         metadata.set(Metadata.CONTENT_TYPE, TYPE.toString());
-        metadata.set(TikaCoreProperties.DATE, font.getHeader().getCreated().getTime());
+        metadata.set(TikaCoreProperties.CREATED, font.getHeader().getCreated().getTime());
         metadata.set(
                 TikaCoreProperties.MODIFIED,
                 font.getHeader().getModified().getTime());
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/image/ImageMetadataExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/image/ImageMetadataExtractor.java
index 6a01c404d..6ad56d919 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/image/ImageMetadataExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/image/ImageMetadataExtractor.java
@@ -31,6 +31,7 @@ import java.util.regex.Pattern;
 
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.metadata.Geographic;
+import org.apache.tika.metadata.IPTC;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.Property;
 import org.apache.tika.metadata.TikaCoreProperties;
@@ -277,7 +278,7 @@ public class ImageMetadataExtractor {
         }
         public void handle(Directory directory, Metadata metadata) throws MetadataException {
             if (directory.containsTag(JpegCommentDirectory.TAG_JPEG_COMMENT)) {
-                metadata.add(Metadata.COMMENT, directory.getString(JpegCommentDirectory.TAG_JPEG_COMMENT));
+                metadata.add(TikaCoreProperties.COMMENTS, directory.getString(JpegCommentDirectory.TAG_JPEG_COMMENT));
             }
         }
     }
@@ -416,16 +417,16 @@ public class ImageMetadataExtractor {
                 // Unless we have GPS time we don't know the time zone so date must be set
                 // as ISO 8601 datetime without timezone suffix (no Z or +/-)
                 String datetimeNoTimeZone = DATE_UNSPECIFIED_TZ.format(original); // Same time zone as Metadata Extractor uses
-                metadata.set(TikaCoreProperties.DATE, datetimeNoTimeZone);
+                metadata.set(TikaCoreProperties.CREATED, datetimeNoTimeZone);
                 metadata.set(Metadata.ORIGINAL_DATE, datetimeNoTimeZone);
             }
             if (directory.containsTag(ExifDirectory.TAG_DATETIME)) {
                 Date datetime = directory.getDate(ExifDirectory.TAG_DATETIME);
                 String datetimeNoTimeZone = DATE_UNSPECIFIED_TZ.format(datetime);
-                metadata.set(Metadata.LAST_MODIFIED, datetimeNoTimeZone);
+                metadata.set(TikaCoreProperties.MODIFIED, datetimeNoTimeZone);
                 // If Date/Time Original does not exist this might be creation date
                 if (original == null) {
-                    metadata.set(TikaCoreProperties.DATE, datetimeNoTimeZone);
+                    metadata.set(TikaCoreProperties.CREATED, datetimeNoTimeZone);
                 }
             }
         }
@@ -444,7 +445,7 @@ public class ImageMetadataExtractor {
             if (directory.containsTag(IptcDirectory.TAG_KEYWORDS)) {
                 String[] keywords = directory.getStringArray(IptcDirectory.TAG_KEYWORDS);
                 for (String k : keywords) {
-                    metadata.add(Metadata.KEYWORDS, k);
+                    metadata.add(TikaCoreProperties.KEYWORDS, k);
                 }
             }
             if (directory.containsTag(IptcDirectory.TAG_HEADLINE)) {
@@ -453,7 +454,8 @@ public class ImageMetadataExtractor {
                 metadata.set(TikaCoreProperties.TITLE, directory.getString(IptcDirectory.TAG_OBJECT_NAME));
             }
             if (directory.containsTag(IptcDirectory.TAG_BY_LINE)) {
-                metadata.set(TikaCoreProperties.AUTHOR, directory.getString(IptcDirectory.TAG_BY_LINE));
+                metadata.set(TikaCoreProperties.CREATOR, directory.getString(IptcDirectory.TAG_BY_LINE));
+                metadata.set(IPTC.CREATOR, directory.getString(IptcDirectory.TAG_BY_LINE));
             }
             if (directory.containsTag(IptcDirectory.TAG_CAPTION)) {
                 metadata.set(TikaCoreProperties.DESCRIPTION,
@@ -481,7 +483,7 @@ public class ImageMetadataExtractor {
                             latitude > 0) {
                         latitude *= -1;
                     }
-                    metadata.set(Metadata.LATITUDE, LAT_LONG_FORMAT.format(latitude)); 
+                    metadata.set(TikaCoreProperties.LATITUDE, LAT_LONG_FORMAT.format(latitude)); 
                 }
             }
 
@@ -494,7 +496,7 @@ public class ImageMetadataExtractor {
                             longitude > 0) {
                         longitude *= -1;
                     }
-                    metadata.set(Metadata.LONGITUDE, LAT_LONG_FORMAT.format(longitude));
+                    metadata.set(TikaCoreProperties.LONGITUDE, LAT_LONG_FORMAT.format(longitude));
                 }
             }
         }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/image/ImageParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/image/ImageParser.java
index bba76dd27..d84c5ac06 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/image/ImageParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/image/ImageParser.java
@@ -34,6 +34,7 @@ import org.apache.tika.exception.TikaException;
 import org.apache.tika.io.CloseShieldInputStream;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.Property;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.parser.AbstractParser;
 import org.apache.tika.parser.ParseContext;
@@ -104,8 +105,8 @@ public class ImageParser extends AbstractParser {
                 
                 // Translate certain Metadata tags from the ImageIO
                 //  specific namespace into the general Tika one
-                setIfPresent(metadata, "CommentExtensions CommentExtension", Metadata.COMMENTS);
-                setIfPresent(metadata, "markerSequence com", Metadata.COMMENTS);
+                setIfPresent(metadata, "CommentExtensions CommentExtension", TikaCoreProperties.COMMENTS);
+                setIfPresent(metadata, "markerSequence com", TikaCoreProperties.COMMENTS);
                 setIfPresent(metadata, "Data BitsPerSample", Metadata.BITS_PER_SAMPLE);
             } catch (IIOException e) {
                 // TIKA-619: There is a known bug in the Sun API when dealing with GIF images
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/image/xmp/JempboxExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/image/xmp/JempboxExtractor.java
index c1e7b360d..d3a2f53c0 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/image/xmp/JempboxExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/image/xmp/JempboxExtractor.java
@@ -70,7 +70,7 @@ public class JempboxExtractor {
                 if (dc.getSubjects() != null && dc.getSubjects().size() > 0) {
                     Iterator<String> keywords = dc.getSubjects().iterator();
                     while (keywords.hasNext()) {
-                        metadata.add(TikaCoreProperties.SUBJECT, keywords.next());
+                        metadata.add(TikaCoreProperties.KEYWORDS, keywords.next());
                     }
                     // TODO should we set KEYWORDS too?
                     // All tested photo managers set the same in Iptc.Application2.Keywords and Xmp.dc.subject
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/iptc/IptcAnpaParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/iptc/IptcAnpaParser.java
index b1661bcf1..652f3dbe8 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/iptc/IptcAnpaParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/iptc/IptcAnpaParser.java
@@ -771,9 +771,9 @@ public class IptcAnpaParser implements Parser {
       // in other consuming applications, like Lucene
       metadata.set(Metadata.CONTENT_TYPE,  clean("text/anpa-1312"));
       metadata.set(TikaCoreProperties.TITLE,         clean(properties.get("title")));
-      metadata.set(TikaCoreProperties.SUBJECT,       clean(properties.get("subject")));
-      metadata.set(TikaCoreProperties.AUTHOR,        clean(properties.get("author")));
-      metadata.set(TikaCoreProperties.CREATION_DATE, clean(properties.get("created")));
+      metadata.set(TikaCoreProperties.KEYWORDS,       clean(properties.get("subject")));
+      metadata.set(TikaCoreProperties.CREATOR,        clean(properties.get("author")));
+      metadata.set(TikaCoreProperties.CREATED, clean(properties.get("created")));
       metadata.set(TikaCoreProperties.MODIFIED,      clean(properties.get("modified")));
       metadata.set(TikaCoreProperties.SOURCE,      clean(properties.get("source")));
 //      metadata.set(TikaCoreProperties.PUBLISHER,     clean(properties.get("publisher")));
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/KeynoteContentHandler.java b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/KeynoteContentHandler.java
index c19394923..c60f9555e 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/KeynoteContentHandler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/KeynoteContentHandler.java
@@ -96,7 +96,7 @@ class KeynoteContentHandler extends DefaultHandler {
         } else if (inMetaDataTitle && "key:string".equals(qName)) {
             metadata.set(TikaCoreProperties.TITLE, attributes.getValue("sfa:string"));
         } else if (inMetaDataAuthors && "key:string".equals(qName)) {
-            metadata.add(TikaCoreProperties.AUTHOR, attributes.getValue("sfa:string"));
+            metadata.add(TikaCoreProperties.CREATOR, attributes.getValue("sfa:string"));
         } else if (inSlide && "sf:tabular-model".equals(qName)) {
             tableId = attributes.getValue("sfa:ID");
             xhtml.startElement("table");
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/NumbersContentHandler.java b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/NumbersContentHandler.java
index b8c7b4fda..abacd57fd 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/NumbersContentHandler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/NumbersContentHandler.java
@@ -209,11 +209,14 @@ class NumbersContentHandler extends DefaultHandler {
 
     private Property resolveMetadataKey(String localName) {
         if ("authors".equals(localName)) {
-            return TikaCoreProperties.AUTHOR;
+            return TikaCoreProperties.CREATOR;
         }
         if ("title".equals(localName)) {
             return TikaCoreProperties.TITLE;
         }
+        if ("comment".equals(localName)) {
+            return TikaCoreProperties.COMMENTS;
+        }
         return Property.internalText(localName);
     }
 }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/PagesContentHandler.java b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/PagesContentHandler.java
index f73b4c9e0..1bab802e1 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/PagesContentHandler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/PagesContentHandler.java
@@ -265,11 +265,11 @@ class PagesContentHandler extends DefaultHandler {
     private Object resolveMetaDataKey(String metaDataLocalName) {
         Object metaDataKey = metaDataLocalName;
         if ("sf:authors".equals(metaDataQName)) {
-            metaDataKey = TikaCoreProperties.AUTHOR;
+            metaDataKey = TikaCoreProperties.CREATOR;
         } else if ("sf:title".equals(metaDataQName)) {
             metaDataKey = TikaCoreProperties.TITLE;
         } else if ("sl:SLCreationDateProperty".equals(metaDataQName)) {
-            metaDataKey = TikaCoreProperties.CREATION_DATE;
+            metaDataKey = TikaCoreProperties.CREATED;
         } else if ("sl:SLLastModifiedDateProperty".equals(metaDataQName)) {
             metaDataKey = Metadata.LAST_MODIFIED;
         } else if ("sl:language".equals(metaDataQName)) {
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mail/MailContentHandler.java b/tika-parsers/src/main/java/org/apache/tika/parser/mail/MailContentHandler.java
index c9193b9be..a1b829d6d 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mail/MailContentHandler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mail/MailContentHandler.java
@@ -167,7 +167,7 @@ class MailContentHandler implements ContentHandler {
                     for (int i = 0; i < mailboxList.size(); i++) {
                         String from = getDisplayString(mailboxList.get(i));
                         metadata.add(Metadata.MESSAGE_FROM, from);
-                        metadata.add(TikaCoreProperties.AUTHOR, from);
+                        metadata.add(TikaCoreProperties.CREATOR, from);
                     }
                 } else {
                     String from = stripOutFieldPrefix(field, "From:");
@@ -178,10 +178,10 @@ class MailContentHandler implements ContentHandler {
                         from = from.substring(0, from.length() - 1);
                     }
                     metadata.add(Metadata.MESSAGE_FROM, from);
-                    metadata.add(TikaCoreProperties.AUTHOR, from);
+                    metadata.add(TikaCoreProperties.CREATOR, from);
                 }
             } else if (fieldname.equalsIgnoreCase("Subject")) {
-                metadata.add(TikaCoreProperties.SUBJECT,
+                metadata.add(TikaCoreProperties.TRANSITION_SUBJECT_TO_DC_TITLE,
                         ((UnstructuredField) parsedField).getValue());
             } else if (fieldname.equalsIgnoreCase("To")) {
                 processAddressList(parsedField, "To:", Metadata.MESSAGE_TO);
@@ -191,8 +191,7 @@ class MailContentHandler implements ContentHandler {
                 processAddressList(parsedField, "Bcc:", Metadata.MESSAGE_BCC);
             } else if (fieldname.equalsIgnoreCase("Date")) {
                 DateTimeField dateField = (DateTimeField) parsedField;
-                metadata.set(TikaCoreProperties.DATE, dateField.getDate());
-                metadata.set(Metadata.CREATION_DATE, dateField.getDate());
+                metadata.set(TikaCoreProperties.CREATED, dateField.getDate());
             }
         } catch (RuntimeException me) {
             if (strictParsing) {
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mbox/MboxParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/mbox/MboxParser.java
index ca5e3e989..fb8b41af3 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mbox/MboxParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mbox/MboxParser.java
@@ -198,7 +198,6 @@ public class MboxParser extends AbstractParser {
         String headerContent = headerMatcher.group(2);
 
         if (headerTag.equalsIgnoreCase("From")) {
-            metadata.add(TikaCoreProperties.AUTHOR, headerContent);
             metadata.set(TikaCoreProperties.CREATOR, headerContent);
         } else if (headerTag.equalsIgnoreCase("To") ||
         	headerTag.equalsIgnoreCase("Cc") ||
@@ -218,13 +217,13 @@ public class MboxParser extends AbstractParser {
             }
             metadata.add(property, headerContent);
         } else if (headerTag.equalsIgnoreCase("Subject")) {
-            metadata.add(TikaCoreProperties.SUBJECT, headerContent);
-            metadata.set(TikaCoreProperties.TITLE, headerContent);
+            // TODO Move to title in Tika 2.0
+            metadata.add(TikaCoreProperties.TRANSITION_SUBJECT_TO_DC_TITLE, 
+                    headerContent);
         } else if (headerTag.equalsIgnoreCase("Date")) {
             try {
                 Date date = parseDate(headerContent);
-                metadata.set(TikaCoreProperties.DATE, date);
-                metadata.set(Metadata.CREATION_DATE, date);
+                metadata.set(TikaCoreProperties.CREATED, date);
             } catch (ParseException e) {
                 // ignoring date because format was not understood
             }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OutlookExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OutlookExtractor.java
index 3d0fdb902..eda5f4870 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OutlookExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OutlookExtractor.java
@@ -97,14 +97,16 @@ public class OutlookExtractor extends AbstractPOIFSExtractor {
            String subject = msg.getSubject();
            String from = msg.getDisplayFrom();
    
-           metadata.set(TikaCoreProperties.AUTHOR, from);
+           metadata.set(TikaCoreProperties.CREATOR, from);
            metadata.set(Metadata.MESSAGE_FROM, from);
            metadata.set(Metadata.MESSAGE_TO, msg.getDisplayTo());
            metadata.set(Metadata.MESSAGE_CC, msg.getDisplayCC());
            metadata.set(Metadata.MESSAGE_BCC, msg.getDisplayBCC());
            
            metadata.set(TikaCoreProperties.TITLE, subject);
-           metadata.set(TikaCoreProperties.SUBJECT, msg.getConversationTopic());
+           // TODO: Move to description in Tika 2.0
+           metadata.set(TikaCoreProperties.TRANSITION_SUBJECT_TO_DC_DESCRIPTION, 
+                   msg.getConversationTopic());
            
            try {
            for(String recipientAddress : msg.getRecipientEmailAddressList()) {
@@ -116,9 +118,8 @@ public class OutlookExtractor extends AbstractPOIFSExtractor {
            // Date - try two ways to find it
            // First try via the proper chunk
            if(msg.getMessageDate() != null) {
-              metadata.set(TikaCoreProperties.DATE, msg.getMessageDate().getTime());
-              metadata.set(Metadata.CREATION_DATE, msg.getMessageDate().getTime());
-              metadata.set(Metadata.LAST_SAVED, msg.getMessageDate().getTime());
+              metadata.set(TikaCoreProperties.CREATED, msg.getMessageDate().getTime());
+              metadata.set(TikaCoreProperties.MODIFIED, msg.getMessageDate().getTime());
            } else {
               try {
                  // Failing that try via the raw headers 
@@ -131,14 +132,12 @@ public class OutlookExtractor extends AbstractPOIFSExtractor {
                             // See if we can parse it as a normal mail date
                             try {
                                Date d = MboxParser.parseDate(date);
-                               metadata.set(TikaCoreProperties.DATE, d);
-                               metadata.set(Metadata.CREATION_DATE, d);
-                               metadata.set(Metadata.LAST_SAVED, d);
+                               metadata.set(TikaCoreProperties.CREATED, d);
+                               metadata.set(TikaCoreProperties.MODIFIED, d);
                             } catch(ParseException e) {
                                // Store it as-is, and hope for the best...
-                               metadata.set(TikaCoreProperties.DATE, date);
-                               metadata.set(Metadata.CREATION_DATE, date);
-                               metadata.set(Metadata.LAST_SAVED, date);
+                               metadata.set(TikaCoreProperties.CREATED, date);
+                               metadata.set(TikaCoreProperties.MODIFIED, date);
                             }
                             break;
                         }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/SummaryExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/SummaryExtractor.java
index 73b47fa0f..d04424b2f 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/SummaryExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/SummaryExtractor.java
@@ -96,16 +96,17 @@ class SummaryExtractor {
 
     private void parse(SummaryInformation summary) {
         set(TikaCoreProperties.TITLE, summary.getTitle());
-        set(TikaCoreProperties.AUTHOR, summary.getAuthor());
+        set(TikaCoreProperties.CREATOR, summary.getAuthor());
         set(TikaCoreProperties.KEYWORDS, summary.getKeywords());
-        set(TikaCoreProperties.SUBJECT, summary.getSubject());
-        set(TikaCoreProperties.LAST_AUTHOR, summary.getLastAuthor());
-        set(Metadata.COMMENTS, summary.getComments());
+        // TODO Move to OO subject in Tika 2.0
+        set(TikaCoreProperties.TRANSITION_SUBJECT_TO_OO_SUBJECT, summary.getSubject());
+        set(TikaCoreProperties.MODIFIER, summary.getLastAuthor());
+        set(TikaCoreProperties.COMMENTS, summary.getComments());
         set(OfficeOpenXMLExtended.TEMPLATE, summary.getTemplate());
         set(OfficeOpenXMLExtended.APPLICATION, summary.getApplicationName());
         set(OfficeOpenXMLCore.REVISION, summary.getRevNumber());
-        set(TikaCoreProperties.CREATION_DATE, summary.getCreateDateTime());
-        set(TikaCoreProperties.SAVE_DATE, summary.getLastSaveDateTime());
+        set(TikaCoreProperties.CREATED, summary.getCreateDateTime());
+        set(TikaCoreProperties.MODIFIED, summary.getLastSaveDateTime());
         set(TikaCoreProperties.PRINT_DATE, summary.getLastPrinted());
         set(Metadata.EDIT_TIME, summary.getEditTime());
         set(OfficeOpenXMLExtended.DOC_SECURITY, summary.getSecurity());
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/TNEFParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/TNEFParser.java
index bc8525061..48c48be48 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/TNEFParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/TNEFParser.java
@@ -82,7 +82,8 @@ public class TNEFParser extends AbstractParser {
        // Set the message subject if known
        String subject = msg.getSubject();
        if(subject != null && subject.length() > 0) {
-          metadata.set(TikaCoreProperties.SUBJECT, subject);
+          // TODO: Move to title in Tika 2.0
+          metadata.set(TikaCoreProperties.TRANSITION_SUBJECT_TO_DC_TITLE, subject);
        }
        
        // Recurse into the message body RTF
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java
index 52045375b..e7344bb3a 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java
@@ -70,14 +70,10 @@ public class MetadataExtractor {
         addProperty(metadata, OfficeOpenXMLCore.CATEGORY, propsHolder.getCategoryProperty());
         addProperty(metadata, OfficeOpenXMLCore.CONTENT_STATUS, propsHolder
                 .getContentStatusProperty());
-        addProperty(metadata, TikaCoreProperties.DATE, propsHolder
-                .getCreatedProperty());
-        addProperty(metadata, TikaCoreProperties.CREATION_DATE, propsHolder
+        addProperty(metadata, TikaCoreProperties.CREATED, propsHolder
                 .getCreatedProperty());
         addProperty(metadata, TikaCoreProperties.CREATOR, propsHolder
                 .getCreatorProperty());
-        addProperty(metadata, TikaCoreProperties.AUTHOR, propsHolder
-                .getCreatorProperty());
         addProperty(metadata, TikaCoreProperties.DESCRIPTION, propsHolder
                 .getDescriptionProperty());
         addProperty(metadata, TikaCoreProperties.IDENTIFIER, propsHolder
@@ -86,7 +82,7 @@ public class MetadataExtractor {
                 .getKeywordsProperty());
         addProperty(metadata, TikaCoreProperties.LANGUAGE, propsHolder
                 .getLanguageProperty());
-        addProperty(metadata, TikaCoreProperties.LAST_AUTHOR, propsHolder
+        addProperty(metadata, TikaCoreProperties.MODIFIER, propsHolder
                 .getLastModifiedByProperty());
         addProperty(metadata, TikaCoreProperties.PRINT_DATE, propsHolder
                 .getLastPrintedProperty());
@@ -96,8 +92,9 @@ public class MetadataExtractor {
               .getModifiedProperty());
         addProperty(metadata, OfficeOpenXMLCore.REVISION, propsHolder
                 .getRevisionProperty());
-        addProperty(metadata, TikaCoreProperties.SUBJECT, propsHolder
-                .getSubjectProperty());
+        // TODO: Move to OO subject in Tika 2.0
+        addProperty(metadata, TikaCoreProperties.TRANSITION_SUBJECT_TO_OO_SUBJECT, 
+                propsHolder.getSubjectProperty());
         addProperty(metadata, TikaCoreProperties.TITLE, propsHolder.getTitleProperty());
         addProperty(metadata, OfficeOpenXMLCore.VERSION, propsHolder.getVersionProperty());
         
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/Mp3Parser.java b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/Mp3Parser.java
index 3fde7946a..aee35671c 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/Mp3Parser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/Mp3Parser.java
@@ -73,7 +73,7 @@ public class Mp3Parser extends AbstractParser {
            CompositeTagHandler tag = new CompositeTagHandler(audioAndTags.tags);
 
            metadata.set(TikaCoreProperties.TITLE, tag.getTitle());
-           metadata.set(TikaCoreProperties.AUTHOR, tag.getArtist());
+           metadata.set(TikaCoreProperties.CREATOR, tag.getArtist());
            metadata.set(XMPDM.ARTIST, tag.getArtist());
            metadata.set(XMPDM.COMPOSER, tag.getComposer());
            metadata.set(XMPDM.ALBUM, tag.getAlbum());
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java b/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java
index 13088a6ca..fb474d31d 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java
@@ -185,7 +185,7 @@ public class MP4Parser extends AbstractParser {
            TrackHeaderBox header = track.getTrackHeaderBox();
            // Get the creation and modification dates
            metadata.set(
-                 TikaCoreProperties.CREATION_DATE, 
+                 TikaCoreProperties.CREATED, 
                  MP4TimeToDate(header.getCreationTime())
            );
            metadata.set(
@@ -229,7 +229,7 @@ public class MP4Parser extends AbstractParser {
 
               // Artist
               AppleArtistBox artist = getOrNull(apple, AppleArtistBox.class);
-              addMetadata(TikaCoreProperties.AUTHOR, metadata, artist);
+              addMetadata(TikaCoreProperties.CREATOR, metadata, artist);
               addMetadata(XMPDM.ARTIST, metadata, artist);
               
               // Album
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/odf/OpenDocumentMetaParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/odf/OpenDocumentMetaParser.java
index 2bada243f..776775b39 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/odf/OpenDocumentMetaParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/odf/OpenDocumentMetaParser.java
@@ -16,28 +16,36 @@
  */
 package org.apache.tika.parser.odf;
 
+import java.io.IOException;
+import java.io.InputStream;
+
+import org.apache.tika.exception.TikaException;
+import org.apache.tika.metadata.DublinCore;
 import org.apache.tika.metadata.MSOffice;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.Office;
+import org.apache.tika.metadata.OfficeOpenXMLCore;
 import org.apache.tika.metadata.PagedText;
 import org.apache.tika.metadata.Property;
 import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.parser.xml.AttributeDependantMetadataHandler;
 import org.apache.tika.parser.xml.AttributeMetadataHandler;
-import org.apache.tika.parser.xml.DcXMLParser;
+import org.apache.tika.parser.xml.ElementMetadataHandler;
 import org.apache.tika.parser.xml.MetadataHandler;
+import org.apache.tika.parser.xml.XMLParser;
 import org.apache.tika.sax.TeeContentHandler;
 import org.apache.tika.sax.xpath.CompositeMatcher;
 import org.apache.tika.sax.xpath.Matcher;
 import org.apache.tika.sax.xpath.MatchingContentHandler;
 import org.apache.tika.sax.xpath.XPathParser;
 import org.xml.sax.ContentHandler;
+import org.xml.sax.SAXException;
 
 /**
  * Parser for OpenDocument <code>meta.xml</code> files.
  */
-public class OpenDocumentMetaParser extends DcXMLParser {
+public class OpenDocumentMetaParser extends XMLParser {
     /**
      * Serial version UID
      */
@@ -45,7 +53,23 @@ public class OpenDocumentMetaParser extends DcXMLParser {
    
     private static final String META_NS = "urn:oasis:names:tc:opendocument:xmlns:meta:1.0"; 
     private static final XPathParser META_XPATH = new XPathParser("meta", META_NS);
-
+    
+    /** 
+     * @see OfficeOpenXMLCore#SUBJECT 
+     * @deprecated use OfficeOpenXMLCore#SUBJECT
+     */
+    @Deprecated
+    private static final Property TRANSITION_INITIAL_CREATOR_TO_INITIAL_AUTHOR = 
+        Property.composite(Office.INITIAL_AUTHOR, 
+            new Property[] { Property.externalText("initial-creator") });
+    
+    private static ContentHandler getDublinCoreHandler(
+            Metadata metadata, Property property, String element) {
+        return new ElementMetadataHandler(
+                DublinCore.NAMESPACE_URI_DC, element,
+                metadata, property);
+    }
+    
     private static ContentHandler getMeta(
             ContentHandler ch, Metadata md, Property property, String element) {
         Matcher matcher = new CompositeMatcher(
@@ -86,16 +110,36 @@ public class OpenDocumentMetaParser extends DcXMLParser {
   }
 
     protected ContentHandler getContentHandler(ContentHandler ch, Metadata md, ParseContext context) {
+        // We can no longer extend DcXMLParser due to the handling of dc:subject and dc:date
         // Process the Dublin Core Attributes 
-        ch = super.getContentHandler(ch, md, context);
+        ch = new TeeContentHandler(super.getContentHandler(ch, md, context),
+                getDublinCoreHandler(md, TikaCoreProperties.TITLE, "title"),
+                getDublinCoreHandler(md, TikaCoreProperties.CREATOR, "creator"),
+                getDublinCoreHandler(md, TikaCoreProperties.DESCRIPTION, "description"),
+                getDublinCoreHandler(md, TikaCoreProperties.PUBLISHER, "publisher"),
+                getDublinCoreHandler(md, TikaCoreProperties.CONTRIBUTOR, "contributor"),
+                getDublinCoreHandler(md, TikaCoreProperties.TYPE, "type"),
+                getDublinCoreHandler(md, TikaCoreProperties.FORMAT, "format"),
+                getDublinCoreHandler(md, TikaCoreProperties.IDENTIFIER, "identifier"),
+                getDublinCoreHandler(md, TikaCoreProperties.LANGUAGE, "language"),
+                getDublinCoreHandler(md, TikaCoreProperties.RIGHTS, "rights"));
         
         // Process the OO Meta Attributes
-        ch = getMeta(ch, md, TikaCoreProperties.CREATION_DATE, "creation-date");
-        ch = getMeta(ch, md, TikaCoreProperties.KEYWORDS, "keyword");
+        ch = getMeta(ch, md, TikaCoreProperties.CREATED, "creation-date");
+        // ODF uses dc:date for modified
+        ch = new TeeContentHandler(ch, new ElementMetadataHandler(
+                DublinCore.NAMESPACE_URI_DC, "date",
+                md, TikaCoreProperties.MODIFIED));
+        
+        // ODF uses dc:subject for description
+        ch = new TeeContentHandler(ch, new ElementMetadataHandler(
+                DublinCore.NAMESPACE_URI_DC, "subject",
+                md, TikaCoreProperties.TRANSITION_SUBJECT_TO_OO_SUBJECT));
+        ch = getMeta(ch, md, TikaCoreProperties.TRANSITION_KEYWORDS_TO_DC_SUBJECT, "keyword");
         
         ch = getMeta(ch, md, Property.externalText(MSOffice.EDIT_TIME), "editing-duration");        
         ch = getMeta(ch, md, Property.externalText("editing-cycles"), "editing-cycles");
-        ch = getMeta(ch, md, Property.externalText("initial-creator"), "initial-creator");
+        ch = getMeta(ch, md, TRANSITION_INITIAL_CREATOR_TO_INITIAL_AUTHOR, "initial-creator");
         ch = getMeta(ch, md, Property.externalText("generator"), "generator");
         
         // Process the user defined Meta Attributes
@@ -135,5 +179,19 @@ public class OpenDocumentMetaParser extends DcXMLParser {
         ch = new NSNormalizerContentHandler(ch);
         return ch;
     }
-
+    
+    @Override
+    public void parse(
+            InputStream stream, ContentHandler handler,
+            Metadata metadata, ParseContext context)
+            throws IOException, SAXException, TikaException {
+        super.parse(stream, handler, metadata, context);
+        // Copy subject to description for OO2
+        String odfSubject = metadata.get(OfficeOpenXMLCore.SUBJECT);
+        if (odfSubject != null && !odfSubject.equals("") && 
+                (metadata.get(TikaCoreProperties.DESCRIPTION) == null || metadata.get(TikaCoreProperties.DESCRIPTION).equals(""))) {
+            metadata.set(TikaCoreProperties.DESCRIPTION, odfSubject);
+        }
+    }
+    
 }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java
index 6940cc73d..976ab963a 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java
@@ -212,15 +212,17 @@ public class PDFParser extends AbstractParser {
         PDDocumentInformation info = document.getDocumentInformation();
         metadata.set(PagedText.N_PAGES, document.getNumberOfPages());
         addMetadata(metadata, TikaCoreProperties.TITLE, info.getTitle());
-        addMetadata(metadata, TikaCoreProperties.AUTHOR, info.getAuthor());
-        addMetadata(metadata, TikaCoreProperties.CREATOR, info.getCreator());
+        addMetadata(metadata, TikaCoreProperties.CREATOR, info.getAuthor());
+        addMetadata(metadata, TikaCoreProperties.CREATOR_TOOL, info.getCreator());
         addMetadata(metadata, TikaCoreProperties.KEYWORDS, info.getKeywords());
         addMetadata(metadata, "producer", info.getProducer());
-        addMetadata(metadata, TikaCoreProperties.SUBJECT, info.getSubject());
+        // TODO: Move to description in Tika 2.0
+        addMetadata(metadata, TikaCoreProperties.TRANSITION_SUBJECT_TO_OO_SUBJECT, info.getSubject());
         addMetadata(metadata, "trapped", info.getTrapped());
         try {
+            // TODO Remove these in Tika 2.0
             addMetadata(metadata, "created", info.getCreationDate());
-            addMetadata(metadata, TikaCoreProperties.CREATION_DATE, info.getCreationDate());
+            addMetadata(metadata, TikaCoreProperties.CREATED, info.getCreationDate());
         } catch (IOException e) {
             // Invalid date format, just ignore
         }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/prt/PRTParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/prt/PRTParser.java
index 09a192277..bf0941d79 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/prt/PRTParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/prt/PRTParser.java
@@ -85,8 +85,7 @@ public class PRTParser extends AbstractParser {
           String formattedDate = dateStr.substring(0, 4) + "-" + dateStr.substring(4,6) +
              "-" + dateStr.substring(6,8) + "T" + dateStr.substring(8,10) + ":" +
              dateStr.substring(10, 12) + ":00";
-          metadata.set(Metadata.CREATION_DATE, formattedDate);
-          metadata.set(TikaCoreProperties.DATE, formattedDate);
+          metadata.set(TikaCoreProperties.CREATED, formattedDate);
        }
        metadata.set(Metadata.CONTENT_TYPE, PRT_MIME_TYPE);
        
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/rtf/TextExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/rtf/TextExtractor.java
index 16ea68c93..7aab4b803 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/rtf/TextExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/rtf/TextExtractor.java
@@ -34,6 +34,7 @@ import org.apache.tika.exception.TikaException;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.OfficeOpenXMLCore;
 import org.apache.tika.metadata.OfficeOpenXMLExtended;
+import org.apache.tika.metadata.Property;
 import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.sax.XHTMLContentHandler;
 import org.apache.tika.utils.CharsetUtils;
@@ -95,7 +96,7 @@ final class TextExtractor {
 
     // Non null if we are processing metadata (title,
     // keywords, etc.) inside the info group:
-    private String nextMetaData;
+    private Property nextMetaData;
     private boolean inParagraph;
 
     // Non-zero if we are processing inside a field destination:
@@ -828,23 +829,24 @@ final class TextExtractor {
                 // \printim, \version, \nofpages, \nofwords,
                 // \nofchars, etc.
                 if (equals("author")) {
-                    nextMetaData = TikaCoreProperties.AUTHOR.getName();
+                    nextMetaData = TikaCoreProperties.CREATOR;
                 } else if (equals("title")) {
-                    nextMetaData = TikaCoreProperties.TITLE.getName();
+                    nextMetaData = TikaCoreProperties.TITLE;
                 } else if (equals("subject")) {
-                    nextMetaData = TikaCoreProperties.SUBJECT.getName();
+                    // TODO: Move to OO subject in Tika 2.0
+                    nextMetaData = TikaCoreProperties.TRANSITION_SUBJECT_TO_OO_SUBJECT;
                 } else if (equals("keywords")) {
-                    nextMetaData = TikaCoreProperties.KEYWORDS.getName();
+                    nextMetaData = TikaCoreProperties.TRANSITION_KEYWORDS_TO_DC_SUBJECT;
                 } else if (equals("category")) {
-                    nextMetaData = OfficeOpenXMLCore.CATEGORY.getName();
+                    nextMetaData = OfficeOpenXMLCore.CATEGORY;
                 } else if (equals("comment")) {
-                    nextMetaData = Metadata.COMMENT;
+                    nextMetaData = TikaCoreProperties.COMMENTS;
                 } else if (equals("company")) {
-                    nextMetaData = OfficeOpenXMLExtended.COMPANY.getName();
+                    nextMetaData = OfficeOpenXMLExtended.COMPANY;
                 } else if (equals("manager")) {
-                    nextMetaData = OfficeOpenXMLExtended.MANAGER.getName();
+                    nextMetaData = OfficeOpenXMLExtended.MANAGER;
                 } else if (equals("template")) {
-                    nextMetaData = OfficeOpenXMLExtended.TEMPLATE.getName();
+                    nextMetaData = OfficeOpenXMLExtended.TEMPLATE;
                 }
             }
 
@@ -1064,7 +1066,11 @@ final class TextExtractor {
 
         if (inHeader) {
             if (nextMetaData != null) {
-                metadata.add(nextMetaData, pendingBuffer.toString());
+                if (nextMetaData.isMultiValuePermitted()) {
+                    metadata.add(nextMetaData, pendingBuffer.toString());
+                } else {
+                    metadata.set(nextMetaData, pendingBuffer.toString());
+                }
                 nextMetaData = null;
             }
             pendingBuffer.setLength(0);
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/xml/DcXMLParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/xml/DcXMLParser.java
index 57bfb346b..5999773e1 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/xml/DcXMLParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/xml/DcXMLParser.java
@@ -16,6 +16,7 @@
  */
 package org.apache.tika.parser.xml;
 
+import org.apache.tika.metadata.DublinCore;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.Property;
 import org.apache.tika.metadata.TikaCoreProperties;
@@ -34,7 +35,7 @@ public class DcXMLParser extends XMLParser {
     private static ContentHandler getDublinCoreHandler(
             Metadata metadata, Property property, String element) {
         return new ElementMetadataHandler(
-                "http://purl.org/dc/elements/1.1/", element,
+                DublinCore.NAMESPACE_URI_DC, element,
                 metadata, property);
     }
 
@@ -43,12 +44,12 @@ public class DcXMLParser extends XMLParser {
         return new TeeContentHandler(
                 super.getContentHandler(handler, metadata, context),
                 getDublinCoreHandler(metadata, TikaCoreProperties.TITLE, "title"),
-                getDublinCoreHandler(metadata, TikaCoreProperties.SUBJECT, "subject"),
+                getDublinCoreHandler(metadata, TikaCoreProperties.KEYWORDS, "subject"),
                 getDublinCoreHandler(metadata, TikaCoreProperties.CREATOR, "creator"),
                 getDublinCoreHandler(metadata, TikaCoreProperties.DESCRIPTION, "description"),
                 getDublinCoreHandler(metadata, TikaCoreProperties.PUBLISHER, "publisher"),
                 getDublinCoreHandler(metadata, TikaCoreProperties.CONTRIBUTOR, "contributor"),
-                getDublinCoreHandler(metadata, TikaCoreProperties.DATE, "date"),
+                getDublinCoreHandler(metadata, TikaCoreProperties.CREATED, "date"),
                 getDublinCoreHandler(metadata, TikaCoreProperties.TYPE, "type"),
                 getDublinCoreHandler(metadata, TikaCoreProperties.FORMAT, "format"),
                 getDublinCoreHandler(metadata, TikaCoreProperties.IDENTIFIER, "identifier"),
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/dwg/DWGParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/dwg/DWGParserTest.java
index 1ddd7dc1e..bf9f0c60f 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/dwg/DWGParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/dwg/DWGParserTest.java
@@ -79,13 +79,15 @@ public class DWGParserTest extends TestCase {
             assertEquals("The quick brown fox jumps over the lazy dog", 
                     metadata.get(TikaCoreProperties.TITLE));
             assertEquals("Gym class featuring a brown fox and lazy dog",
-                    metadata.get(TikaCoreProperties.SUBJECT));
+                    metadata.get(TikaCoreProperties.DESCRIPTION));
+            assertEquals("Gym class featuring a brown fox and lazy dog",
+                    metadata.get(Metadata.SUBJECT));
             assertEquals("Nevin Nollop",
-                    metadata.get(TikaCoreProperties.AUTHOR));
+                    metadata.get(TikaCoreProperties.CREATOR));
             assertEquals("Pangram, fox, dog",
                     metadata.get(TikaCoreProperties.KEYWORDS));
             assertEquals("Lorem ipsum",
-                    metadata.get(Metadata.COMMENTS).substring(0,11));
+                    metadata.get(TikaCoreProperties.COMMENTS).substring(0,11));
             assertEquals("http://www.alfresco.com",
                     metadata.get(TikaCoreProperties.RELATION));
             
@@ -113,10 +115,11 @@ public class DWGParserTest extends TestCase {
             assertEquals("image/vnd.dwg", metadata.get(Metadata.CONTENT_TYPE));
             
             assertNull(metadata.get(TikaCoreProperties.TITLE));
-            assertNull(metadata.get(TikaCoreProperties.SUBJECT));
-            assertNull(metadata.get(TikaCoreProperties.AUTHOR));
+            assertNull(metadata.get(TikaCoreProperties.DESCRIPTION));
+            assertNull(metadata.get(Metadata.SUBJECT));
+            assertNull(metadata.get(TikaCoreProperties.CREATOR));
             assertNull(metadata.get(TikaCoreProperties.KEYWORDS));
-            assertNull(metadata.get(Metadata.COMMENTS));
+            assertNull(metadata.get(TikaCoreProperties.COMMENTS));
             assertNull(metadata.get(TikaCoreProperties.RELATION));
 
             String content = handler.toString();
@@ -137,15 +140,17 @@ public class DWGParserTest extends TestCase {
             assertEquals("Test Title", 
                     metadata.get(TikaCoreProperties.TITLE));
             assertEquals("Test Subject",
-                    metadata.get(TikaCoreProperties.SUBJECT));
+                    metadata.get(TikaCoreProperties.DESCRIPTION));
+            assertEquals("Test Subject",
+                    metadata.get(Metadata.SUBJECT));
             assertEquals("My Author",
-                    metadata.get(TikaCoreProperties.AUTHOR));
+                    metadata.get(TikaCoreProperties.CREATOR));
             assertEquals("My keyword1, MyKeyword2",
                     metadata.get(TikaCoreProperties.KEYWORDS));
             assertEquals("This is a comment",
-                    metadata.get(Metadata.COMMENTS));
+                    metadata.get(TikaCoreProperties.COMMENTS));
             assertEquals("bejanpol",
-                    metadata.get(Metadata.LAST_AUTHOR));
+                    metadata.get(TikaCoreProperties.MODIFIER));
             assertEquals("http://mycompany/drawings",
                     metadata.get(TikaCoreProperties.RELATION));
             assertEquals("MyCustomPropertyValue",
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/image/ImageMetadataExtractorTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/image/ImageMetadataExtractorTest.java
index 7c3e02570..1aa5ac3b8 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/image/ImageMetadataExtractorTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/image/ImageMetadataExtractorTest.java
@@ -66,7 +66,8 @@ public class ImageMetadataExtractorTest extends TestCase {
         Metadata metadata = new Metadata();
         
         new ImageMetadataExtractor.ExifHandler().handle(exif, metadata);
-        assertEquals("Should be ISO date without time zone", "2000-01-01T00:00:00", metadata.get(TikaCoreProperties.DATE));
+        assertEquals("Should be ISO date without time zone", "2000-01-01T00:00:00", 
+                metadata.get(TikaCoreProperties.CREATED));
     }
 
     public void testExifHandlerParseDateFallback() throws MetadataException {
@@ -77,7 +78,8 @@ public class ImageMetadataExtractorTest extends TestCase {
         Metadata metadata = new Metadata();
         
         new ImageMetadataExtractor.ExifHandler().handle(exif, metadata);
-        assertEquals("Should try EXIF Date/Time if Original is not set", "1999-01-01T00:00:00", metadata.get(TikaCoreProperties.DATE));
+        assertEquals("Should try EXIF Date/Time if Original is not set", "1999-01-01T00:00:00", 
+                metadata.get(TikaCoreProperties.CREATED));
     }
     
     public void testExifHandlerParseDateError() throws MetadataException {
@@ -88,7 +90,8 @@ public class ImageMetadataExtractorTest extends TestCase {
         Metadata metadata = new Metadata();
         
         new ImageMetadataExtractor.ExifHandler().handle(exif, metadata);
-        assertEquals("Parsing should proceed without date", null, metadata.get(TikaCoreProperties.DATE));
+        assertEquals("Parsing should proceed without date", null, 
+                metadata.get(TikaCoreProperties.CREATED));
     }
     
     public void testCopyUnknownFieldsHandler() throws MetadataException {
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/image/ImageParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/image/ImageParserTest.java
index a275ed0a9..51263e059 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/image/ImageParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/image/ImageParserTest.java
@@ -19,6 +19,7 @@ package org.apache.tika.parser.image;
 import java.io.InputStream;
 
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.parser.Parser;
 import org.xml.sax.helpers.DefaultHandler;
@@ -77,7 +78,7 @@ public class ImageParserTest extends TestCase {
         
         assertEquals("100", metadata.get(Metadata.IMAGE_WIDTH));
         assertEquals("75", metadata.get(Metadata.IMAGE_LENGTH));
-        assertEquals("Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.", metadata.get(Metadata.COMMENTS));
+        assertEquals("Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.", metadata.get(TikaCoreProperties.COMMENTS));
     }
 
     public void testJPEG() throws Exception {
@@ -112,7 +113,7 @@ public class ImageParserTest extends TestCase {
         
         assertEquals("100", metadata.get(Metadata.IMAGE_WIDTH));
         assertEquals("75", metadata.get(Metadata.IMAGE_LENGTH));
-        assertEquals("Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.", metadata.get(Metadata.COMMENTS));
+        assertEquals("Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.", metadata.get(TikaCoreProperties.COMMENTS));
     }
 
     public void testPNG() throws Exception {
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/image/MetadataFieldsTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/image/MetadataFieldsTest.java
index 968e1e250..d811a6297 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/image/MetadataFieldsTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/image/MetadataFieldsTest.java
@@ -26,7 +26,7 @@ public class MetadataFieldsTest extends TestCase {
     public void testIsMetadataField() {
         assertFalse(MetadataFields.isMetadataField("random string that is not a field"));
         assertFalse(MetadataFields.isMetadataField("xyz"));
-        assertTrue(MetadataFields.isMetadataField(TikaCoreProperties.SUBJECT));
+        assertTrue(MetadataFields.isMetadataField(TikaCoreProperties.KEYWORDS));
         assertTrue(MetadataFields.isMetadataField(TIFF.F_NUMBER.getName()));
     }
 
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/image/TiffParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/image/TiffParserTest.java
index 6eeadc7e7..daa1a7cdf 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/image/TiffParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/image/TiffParserTest.java
@@ -54,7 +54,10 @@ public class TiffParserTest extends TestCase {
         assertEquals("3", metadata.get(Metadata.SAMPLES_PER_PIXEL));
         
         // Embedded XMP
-        List<String> subject = Arrays.asList(metadata.getValues(TikaCoreProperties.SUBJECT));
+        List<String> keywords = Arrays.asList(metadata.getValues(TikaCoreProperties.KEYWORDS));
+        assertTrue("got " + keywords, keywords.contains("cat"));
+        assertTrue("got " + keywords, keywords.contains("garden"));
+        List<String> subject = Arrays.asList(metadata.getValues(Metadata.SUBJECT));
         assertTrue("got " + subject, subject.contains("cat"));
         assertTrue("got " + subject, subject.contains("garden"));
     }
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/image/xmp/JempboxExtractorTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/image/xmp/JempboxExtractorTest.java
index af0a72e38..84e86ecfe 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/image/xmp/JempboxExtractorTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/image/xmp/JempboxExtractorTest.java
@@ -38,7 +38,7 @@ public class JempboxExtractorTest extends TestCase {
         metadata.set(TikaCoreProperties.DESCRIPTION, "old description");
         metadata.set(TikaCoreProperties.CREATOR, "previous author");
         // ... or kept in case the field is multi-value
-        metadata.add(TikaCoreProperties.SUBJECT, "oldkeyword");
+        metadata.add(TikaCoreProperties.KEYWORDS, "oldkeyword");
         
         JempboxExtractor extractor = new JempboxExtractor(metadata);
         extractor.parse(stream);
@@ -47,12 +47,18 @@ public class JempboxExtractorTest extends TestCase {
         assertEquals("Tosteberga \u00C4ngar", metadata.get(TikaCoreProperties.TITLE));
         assertEquals("Bird site in north eastern Sk\u00E5ne, Sweden.\n(new line)", metadata.get(TikaCoreProperties.DESCRIPTION));
         assertEquals("Some Tourist", metadata.get(TikaCoreProperties.CREATOR));
-        Collection<String> keywords = Arrays.asList(metadata.getValues(TikaCoreProperties.SUBJECT));  
+        Collection<String> keywords = Arrays.asList(metadata.getValues(TikaCoreProperties.KEYWORDS));  
         assertTrue(keywords.contains("oldkeyword"));
         assertTrue(keywords.contains("grazelands"));
         assertTrue(keywords.contains("nature reserve"));
         assertTrue(keywords.contains("bird watching"));
         assertTrue(keywords.contains("coast"));
+        Collection<String> subject = Arrays.asList(metadata.getValues(Metadata.SUBJECT));  
+        assertTrue(subject.contains("oldkeyword"));
+        assertTrue(subject.contains("grazelands"));
+        assertTrue(subject.contains("nature reserve"));
+        assertTrue(subject.contains("bird watching"));
+        assertTrue(subject.contains("coast"));
     }
 
     public void testParseJpegPhotoshop() throws IOException, TikaException {
@@ -66,7 +72,7 @@ public class JempboxExtractorTest extends TestCase {
         assertEquals("Tosteberga \u00C4ngar", metadata.get(TikaCoreProperties.TITLE));
         assertEquals("Bird site in north eastern Sk\u00E5ne, Sweden.\n(new line)", metadata.get(TikaCoreProperties.DESCRIPTION));
         assertEquals("Some Tourist", metadata.get(TikaCoreProperties.CREATOR));
-        Collection<String> keywords = Arrays.asList(metadata.getValues(TikaCoreProperties.SUBJECT));  
+        Collection<String> keywords = Arrays.asList(metadata.getValues(TikaCoreProperties.KEYWORDS));  
         assertTrue(keywords.contains("bird watching"));
         assertTrue(keywords.contains("coast"));
     }
@@ -80,7 +86,7 @@ public class JempboxExtractorTest extends TestCase {
         
         // XnViewMp fields not understood by Jempbox
         assertEquals("Bird site in north eastern Sk\u00E5ne, Sweden.\n(new line)", metadata.get(TikaCoreProperties.DESCRIPTION));
-        Collection<String> keywords = Arrays.asList(metadata.getValues(TikaCoreProperties.SUBJECT));
+        Collection<String> keywords = Arrays.asList(metadata.getValues(TikaCoreProperties.KEYWORDS));
         assertTrue(keywords.contains("coast"));
         assertTrue(keywords.contains("nature reserve"));
     }
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
index 440672cbb..8bc2013ec 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
@@ -59,7 +59,7 @@ public class IWorkParserTest extends TestCase {
         assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.CONTENT_TYPE));
         assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.SLIDE_COUNT.getName()));
 //        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Office.SLIDE_COUNT.getName()));
-        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(TikaCoreProperties.AUTHOR.getName()));
+        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(TikaCoreProperties.CREATOR.getName()));
         assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(TikaCoreProperties.TITLE.getName()));
         
         // Check the metadata values
@@ -67,7 +67,7 @@ public class IWorkParserTest extends TestCase {
         assertEquals("3", metadata.get(Metadata.SLIDE_COUNT));
         assertEquals("1024", metadata.get(KeynoteContentHandler.PRESENTATION_WIDTH));
         assertEquals("768", metadata.get(KeynoteContentHandler.PRESENTATION_HEIGHT));
-        assertEquals("Tika user", metadata.get(TikaCoreProperties.AUTHOR));
+        assertEquals("Tika user", metadata.get(TikaCoreProperties.CREATOR));
         assertEquals("Apache tika", metadata.get(TikaCoreProperties.TITLE));
 
         String content = handler.toString();
@@ -150,14 +150,14 @@ public class IWorkParserTest extends TestCase {
         List<String> metadataKeys = Arrays.asList(metadata.names());
         assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.CONTENT_TYPE));
         assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.PAGE_COUNT.getName()));
-        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(TikaCoreProperties.AUTHOR.getName()));
+        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(TikaCoreProperties.CREATOR.getName()));
         assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(TikaCoreProperties.TITLE.getName()));
         assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.LAST_MODIFIED.getName()));
         assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.LANGUAGE));
         
         // Check the metadata values
         assertEquals("application/vnd.apple.pages", metadata.get(Metadata.CONTENT_TYPE));
-        assertEquals("Tika user", metadata.get(TikaCoreProperties.AUTHOR));
+        assertEquals("Tika user", metadata.get(TikaCoreProperties.CREATOR));
         assertEquals("Apache tika", metadata.get(TikaCoreProperties.TITLE));
         assertEquals("2010-05-09T21:34:38+0200", metadata.get(Metadata.CREATION_DATE));
         assertEquals("2010-05-09T23:50:36+0200", metadata.get(Metadata.LAST_MODIFIED));
@@ -214,16 +214,16 @@ public class IWorkParserTest extends TestCase {
         List<String> metadataKeys = Arrays.asList(metadata.names());
         assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.CONTENT_TYPE));
         assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.PAGE_COUNT.getName()));
-        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(TikaCoreProperties.AUTHOR.getName()));
-        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.COMMENT));
+        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(TikaCoreProperties.CREATOR.getName()));
+        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(TikaCoreProperties.COMMENTS.getName()));
         assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.TITLE));
         assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(TikaCoreProperties.TITLE.getName()));
         
         // Check the metadata values
         assertEquals("2", metadata.get(Metadata.PAGE_COUNT));
-        assertEquals("Tika User", metadata.get(TikaCoreProperties.AUTHOR));
+        assertEquals("Tika User", metadata.get(TikaCoreProperties.CREATOR));
         assertEquals("Account checking", metadata.get(TikaCoreProperties.TITLE));
-        assertEquals("a comment", metadata.get(Metadata.COMMENT));
+        assertEquals("a comment", metadata.get(TikaCoreProperties.COMMENTS));
 
         String content = handler.toString();
         assertTrue(content.contains("Category"));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/jpeg/JpegParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/jpeg/JpegParserTest.java
index f5e249562..411c35822 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/jpeg/JpegParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/jpeg/JpegParserTest.java
@@ -66,12 +66,17 @@ public class JpegParserTest extends TestCase {
         // Common tags
         //assertEquals("2009-10-02T23:02:49", metadata.get(Metadata.LAST_MODIFIED));
         assertEquals("Date/Time Original for when the photo was taken, unspecified time zone",
-                "2009-08-11T09:09:45", metadata.get(TikaCoreProperties.DATE));
-        List<String> keywords = Arrays.asList(metadata.getValues(TikaCoreProperties.SUBJECT));
+                "2009-08-11T09:09:45", metadata.get(TikaCoreProperties.CREATED));
+        List<String> keywords = Arrays.asList(metadata.getValues(TikaCoreProperties.KEYWORDS));
         assertTrue("'canon-55-250' expected in " + keywords, keywords.contains("canon-55-250"));
         assertTrue("'moscow-birds' expected in " + keywords, keywords.contains("moscow-birds")); 
         assertTrue("'serbor' expected in " + keywords, keywords.contains("serbor"));
         assertFalse(keywords.contains("canon-55-250 moscow-birds serbor"));
+        List<String> subject = Arrays.asList(metadata.getValues(Metadata.SUBJECT));
+        assertTrue("'canon-55-250' expected in " + subject, subject.contains("canon-55-250"));
+        assertTrue("'moscow-birds' expected in " + subject, subject.contains("moscow-birds")); 
+        assertTrue("'serbor' expected in " + subject, subject.contains("serbor"));
+        assertFalse(subject.contains("canon-55-250 moscow-birds serbor"));
     }
 
     /**
@@ -109,11 +114,12 @@ public class JpegParserTest extends TestCase {
         
         // Common tags
         assertEquals("Date/Time Original for when the photo was taken, unspecified time zone",
-                "2009-08-11T09:09:45", metadata.get(TikaCoreProperties.DATE));
+                "2009-08-11T09:09:45", metadata.get(TikaCoreProperties.CREATED));
         assertEquals("This image has different Date/Time than Date/Time Original, so it is probably modification date",
                 "2009-10-02T23:02:49", metadata.get(Metadata.LAST_MODIFIED));
         assertEquals("Date/Time Original should be stored in EXIF field too",
                 "2009-08-11T09:09:45", metadata.get(TIFF.ORIGINAL_DATE));
+        assertEquals("canon-55-250", metadata.getValues(TikaCoreProperties.KEYWORDS)[0]);
         assertEquals("canon-55-250", metadata.getValues(Metadata.KEYWORDS)[0]);
     }
 
@@ -144,7 +150,6 @@ public class JpegParserTest extends TestCase {
         // embedded comments with non-ascii characters
         assertEquals("Tosteberga \u00C4ngar", metadata.get(TikaCoreProperties.TITLE));
         assertEquals("Bird site in north eastern Sk\u00E5ne, Sweden.\n(new line)", metadata.get(TikaCoreProperties.DESCRIPTION));
-        assertEquals("Some Tourist", metadata.get(TikaCoreProperties.AUTHOR));
         assertEquals("Some Tourist", metadata.get(TikaCoreProperties.CREATOR)); // Dublin Core
         // xmp handles spaces in keywords, returns "bird watching, nature reserve, coast, grazelands"
         // but we have to replace them with underscore
@@ -152,7 +157,7 @@ public class JpegParserTest extends TestCase {
         List<String> keywords = Arrays.asList(metadata.getValues(Metadata.KEYWORDS));
         assertTrue(keywords.contains("coast"));
         assertTrue(keywords.contains("bird watching"));
-        assertEquals(keywords, Arrays.asList(metadata.getValues(TikaCoreProperties.SUBJECT)));
+        assertEquals(keywords, Arrays.asList(metadata.getValues(TikaCoreProperties.KEYWORDS)));
         
         // Core EXIF/TIFF tags
         assertEquals("103", metadata.get(Metadata.IMAGE_WIDTH));
@@ -184,7 +189,9 @@ public class JpegParserTest extends TestCase {
         assertEquals("Tosteberga \u00C4ngar", metadata.get(TikaCoreProperties.TITLE));
         assertEquals("Bird site in north eastern Sk\u00E5ne, Sweden.\n(new line)", metadata.get(TikaCoreProperties.DESCRIPTION));
         assertEquals("Some Tourist", metadata.get(TikaCoreProperties.CREATOR));
-        List<String> subject = Arrays.asList(metadata.getValues(TikaCoreProperties.SUBJECT));
+        List<String> keywords = Arrays.asList(metadata.getValues(TikaCoreProperties.KEYWORDS));
+        assertTrue("got " + keywords, keywords.contains("bird watching")); 
+        List<String> subject = Arrays.asList(metadata.getValues(Metadata.SUBJECT));
         assertTrue("got " + subject, subject.contains("bird watching")); 
     }
     
@@ -200,7 +207,7 @@ public class JpegParserTest extends TestCase {
         assertEquals("Bird site in north eastern Sk\u00E5ne, Sweden.\n(new line)", metadata.get(TikaCoreProperties.DESCRIPTION));
         // xmp handles spaces in keywords, returns "bird watching, nature reserve, coast, grazelands"
         // but we have to replace them with underscore
-        String[] subject = metadata.getValues(TikaCoreProperties.SUBJECT);
+        String[] subject = metadata.getValues(TikaCoreProperties.KEYWORDS);
         List<String> keywords = Arrays.asList(subject);
         assertTrue("'coast'" + " not in " + keywords, keywords.contains("coast"));
         assertTrue("'nature reserve'" + " not in " + keywords, keywords.contains("nature reserve"));     
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/mail/RFC822ParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/mail/RFC822ParserTest.java
index 5d53ec126..46658899d 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/mail/RFC822ParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/mail/RFC822ParserTest.java
@@ -59,8 +59,11 @@ public class RFC822ParserTest extends TestCase {
             verify(handler, never()).endElement(XHTMLContentHandler.XHTML, "div", "div");
             verify(handler).endDocument();
             //note no leading spaces, and no quotes
-            assertEquals("Julien Nioche (JIRA) <jira@apache.org>", metadata.get(TikaCoreProperties.AUTHOR));
-            assertEquals("[jira] Commented: (TIKA-461) RFC822 messages not parsed", metadata.get(TikaCoreProperties.SUBJECT));
+            assertEquals("Julien Nioche (JIRA) <jira@apache.org>", metadata.get(TikaCoreProperties.CREATOR));
+            assertEquals("[jira] Commented: (TIKA-461) RFC822 messages not parsed", 
+                    metadata.get(TikaCoreProperties.TITLE));
+            assertEquals("[jira] Commented: (TIKA-461) RFC822 messages not parsed", 
+                    metadata.get(Metadata.SUBJECT));
         } catch (Exception e) {
             fail("Exception thrown: " + e.getMessage());
         }
@@ -147,8 +150,12 @@ public class RFC822ParserTest extends TestCase {
             parser.parse(stream, handler, metadata, new ParseContext());
             //tests correct decoding of internationalized headers, both
             //quoted-printable (Q) and Base64 (B).
-            assertEquals("Keld J\u00F8rn Simonsen <keld@dkuug.dk>", metadata.get(TikaCoreProperties.AUTHOR));
-            assertEquals("If you can read this you understand the example.", metadata.get(TikaCoreProperties.SUBJECT));
+            assertEquals("Keld J\u00F8rn Simonsen <keld@dkuug.dk>", 
+                    metadata.get(TikaCoreProperties.CREATOR));
+            assertEquals("If you can read this you understand the example.", 
+                    metadata.get(TikaCoreProperties.TITLE));
+            assertEquals("If you can read this you understand the example.", 
+                    metadata.get(Metadata.SUBJECT));
         } catch (Exception e) {
             fail("Exception thrown: " + e.getMessage());
         }
@@ -165,8 +172,12 @@ public class RFC822ParserTest extends TestCase {
        ContentHandler handler = mock(DefaultHandler.class);
 
        parser.parse(stream, handler, metadata, new ParseContext());
-       assertEquals("Saved by Windows Internet Explorer 7", metadata.get(TikaCoreProperties.AUTHOR));
-       assertEquals("Air Permit Programs | Air & Radiation | US EPA", metadata.get(TikaCoreProperties.SUBJECT));
+       assertEquals("Saved by Windows Internet Explorer 7", 
+               metadata.get(TikaCoreProperties.CREATOR));
+       assertEquals("Air Permit Programs | Air & Radiation | US EPA", 
+               metadata.get(TikaCoreProperties.TITLE));
+       assertEquals("Air Permit Programs | Air & Radiation | US EPA", 
+               metadata.get(Metadata.SUBJECT));
     }
 
     /**
@@ -199,7 +210,7 @@ public class RFC822ParserTest extends TestCase {
         context.set(MimeConfig.class, config);
         parser.parse(
                 new ByteArrayInputStream(data), handler, metadata, context);
-        assertEquals(name.trim(), metadata.get(TikaCoreProperties.AUTHOR));
+        assertEquals(name.trim(), metadata.get(TikaCoreProperties.CREATOR));
     }
     
     /**
@@ -212,16 +223,17 @@ public class RFC822ParserTest extends TestCase {
        ContentHandler handler = new BodyContentHandler();
 
        parser.parse(stream, handler, metadata, new ParseContext());
-       assertEquals(true, metadata.isMultiValued(TikaCoreProperties.AUTHOR));
-       assertEquals("xyz", metadata.getValues(TikaCoreProperties.AUTHOR)[0]);
-       assertEquals("abc", metadata.getValues(TikaCoreProperties.AUTHOR)[1]);
+       assertEquals(true, metadata.isMultiValued(TikaCoreProperties.CREATOR));
+       assertEquals("xyz", metadata.getValues(TikaCoreProperties.CREATOR)[0]);
+       assertEquals("abc", metadata.getValues(TikaCoreProperties.CREATOR)[1]);
        assertEquals(true, metadata.isMultiValued(Metadata.MESSAGE_FROM));
        assertEquals("xyz", metadata.getValues(Metadata.MESSAGE_FROM)[0]);
        assertEquals("abc", metadata.getValues(Metadata.MESSAGE_FROM)[1]);
        assertEquals(true, metadata.isMultiValued(Metadata.MESSAGE_TO));
        assertEquals("abc", metadata.getValues(Metadata.MESSAGE_TO)[0]);
        assertEquals("def", metadata.getValues(Metadata.MESSAGE_TO)[1]);
-       assertEquals("abcd", metadata.get(TikaCoreProperties.SUBJECT));
+       assertEquals("abcd", metadata.get(TikaCoreProperties.TITLE));
+       assertEquals("abcd", metadata.get(Metadata.SUBJECT));
        assertTrue(handler.toString().contains("bar biz bat"));
     }
 
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/mbox/MboxParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/mbox/MboxParserTest.java
index 982f8874e..bbba0844c 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/mbox/MboxParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/mbox/MboxParserTest.java
@@ -71,13 +71,13 @@ public class MboxParserTest extends TestCase {
             verify(handler).endDocument();
 
             assertEquals("subject", metadata.get(TikaCoreProperties.TITLE));
-            assertEquals("subject", metadata.get(TikaCoreProperties.SUBJECT));
-            assertEquals("<author@domain.com>", metadata.get(TikaCoreProperties.AUTHOR));
+            assertEquals("subject", metadata.get(Metadata.SUBJECT));
+            assertEquals("<author@domain.com>", metadata.get(Metadata.AUTHOR));
             assertEquals("<author@domain.com>", metadata.get(TikaCoreProperties.CREATOR));
             assertEquals(null, metadata.get(Metadata.MESSAGE_RECIPIENT_ADDRESS));
             assertEquals("<name@domain.com>", metadata.get("MboxParser-return-path"));
             assertEquals("Should be ISO date in UTC, converted from 'Tue, 9 Jun 2009 23:58:45 -0400'", 
-                    "2009-06-10T03:58:45Z", metadata.get(TikaCoreProperties.DATE));
+                    "2009-06-10T03:58:45Z", metadata.get(TikaCoreProperties.CREATED));
         } catch (Exception e) {
             fail("Exception thrown: " + e.getMessage());
         }
@@ -134,9 +134,10 @@ public class MboxParserTest extends TestCase {
         try {
             parser.parse(stream, handler, metadata, new ParseContext());
 
+            // TODO: Remove subject and author in Tika 2.0
+            assertEquals("Re: question about when shuffle/sort start working", metadata.get(Metadata.SUBJECT));
             assertEquals("Re: question about when shuffle/sort start working", metadata.get(TikaCoreProperties.TITLE));
-            assertEquals("Re: question about when shuffle/sort start working", metadata.get(TikaCoreProperties.SUBJECT));
-            assertEquals("Jothi Padmanabhan <jothipn@yahoo-inc.com>", metadata.get(TikaCoreProperties.AUTHOR));
+            assertEquals("Jothi Padmanabhan <jothipn@yahoo-inc.com>", metadata.get(Metadata.AUTHOR));
             assertEquals("Jothi Padmanabhan <jothipn@yahoo-inc.com>", metadata.get(TikaCoreProperties.CREATOR));
             assertEquals("core-user@hadoop.apache.org", metadata.get(Metadata.MESSAGE_RECIPIENT_ADDRESS));
             
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ExcelParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ExcelParserTest.java
index 782564675..bd10ff9cf 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ExcelParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ExcelParserTest.java
@@ -48,13 +48,14 @@ public class ExcelParserTest extends TestCase {
                     "application/vnd.ms-excel",
                     metadata.get(Metadata.CONTENT_TYPE));
             assertEquals("Simple Excel document", metadata.get(TikaCoreProperties.TITLE));
-            assertEquals("Keith Bennett", metadata.get(TikaCoreProperties.AUTHOR));
+            assertEquals("Keith Bennett", metadata.get(TikaCoreProperties.CREATOR));
+            assertEquals("Keith Bennett", metadata.get(Metadata.AUTHOR));
             
             // Mon Oct 01 17:13:56 BST 2007
-            assertEquals("2007-10-01T16:13:56Z", metadata.get(TikaCoreProperties.CREATION_DATE));
+            assertEquals("2007-10-01T16:13:56Z", metadata.get(TikaCoreProperties.CREATED));
             
             // Mon Oct 01 17:31:43 BST 2007
-            assertEquals("2007-10-01T16:31:43Z", metadata.get(TikaCoreProperties.SAVE_DATE));
+            assertEquals("2007-10-01T16:31:43Z", metadata.get(TikaCoreProperties.MODIFIED));
             
             String content = handler.toString();
             assertTrue(content.contains("Sample Excel Worksheet"));
@@ -281,10 +282,10 @@ public class ExcelParserTest extends TestCase {
        }
        
        assertEquals("application/vnd.ms-excel", metadata.get(Metadata.CONTENT_TYPE));
-       assertEquals("",                     metadata.get(TikaCoreProperties.AUTHOR));
-       assertEquals("",                     metadata.get(TikaCoreProperties.LAST_AUTHOR));
-       assertEquals("2011-08-22T13:45:54Z", metadata.get(TikaCoreProperties.SAVE_DATE));
-       assertEquals("2006-09-12T15:06:44Z", metadata.get(TikaCoreProperties.CREATION_DATE));
+       assertEquals("",                     metadata.get(TikaCoreProperties.CREATOR));
+       assertEquals("",                     metadata.get(TikaCoreProperties.MODIFIER));
+       assertEquals("2011-08-22T13:45:54Z", metadata.get(TikaCoreProperties.MODIFIED));
+       assertEquals("2006-09-12T15:06:44Z", metadata.get(TikaCoreProperties.CREATED));
        assertEquals("Microsoft Excel",      metadata.get(OfficeOpenXMLExtended.APPLICATION));
        assertEquals("true",                 metadata.get("custom:myCustomBoolean"));
        assertEquals("3",                    metadata.get("custom:myCustomNumber"));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/OutlookParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/OutlookParserTest.java
index d9b397447..d49f0187f 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/OutlookParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/OutlookParserTest.java
@@ -65,12 +65,15 @@ public class OutlookParserTest extends TestCase {
                 metadata.get(Metadata.MESSAGE_RECIPIENT_ADDRESS));
         assertEquals(
                 "L'\u00C9quipe Microsoft Outlook Express",
-                metadata.get(TikaCoreProperties.AUTHOR));
+                metadata.get(TikaCoreProperties.CREATOR));
+        assertEquals(
+                "L'\u00C9quipe Microsoft Outlook Express",
+                metadata.get(Metadata.AUTHOR));
         
         // Stored as Thu, 5 Apr 2007 09:26:06 -0700
         assertEquals(
                 "2007-04-05T16:26:06Z",
-                metadata.get(TikaCoreProperties.DATE));
+                metadata.get(TikaCoreProperties.CREATED));
 
         String content = handler.toString();
         assertTrue(content.contains(""));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PowerPointParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PowerPointParserTest.java
index bd4dcfb64..036ee68e4 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PowerPointParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PowerPointParserTest.java
@@ -22,6 +22,7 @@ import java.util.Locale;
 import org.apache.tika.TikaTest;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.Office;
+import org.apache.tika.metadata.OfficeOpenXMLCore;
 import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.sax.BodyContentHandler;
@@ -41,7 +42,8 @@ public class PowerPointParserTest extends TikaTest {
                     "application/vnd.ms-powerpoint",
                     metadata.get(Metadata.CONTENT_TYPE));
             assertEquals("Sample Powerpoint Slide", metadata.get(TikaCoreProperties.TITLE));
-            assertEquals("Keith Bennett", metadata.get(TikaCoreProperties.AUTHOR));
+            assertEquals("Keith Bennett", metadata.get(TikaCoreProperties.CREATOR));
+            assertEquals("Keith Bennett", metadata.get(Metadata.AUTHOR));
             String content = handler.toString();
             assertTrue(content.contains("Sample Powerpoint Slide"));
             assertTrue(content.contains("Powerpoint X for Mac"));
@@ -106,7 +108,10 @@ public class PowerPointParserTest extends TikaTest {
 
         assertContains("Subject is here", content);
         assertEquals("Subject is here",
-                     metadata.get(TikaCoreProperties.SUBJECT));
+                     metadata.get(OfficeOpenXMLCore.SUBJECT));
+        // TODO: Remove subject in Tika 2.0
+        assertEquals("Subject is here",
+                     metadata.get(Metadata.SUBJECT));
 
         assertContains("Suddenly some Japanese text:", content);
         // Special version of (GHQ)
@@ -199,10 +204,10 @@ public class PowerPointParserTest extends TikaTest {
        }
        
        assertEquals("application/vnd.ms-powerpoint", metadata.get(Metadata.CONTENT_TYPE));
-       assertEquals("JOUVIN ETIENNE",       metadata.get(TikaCoreProperties.AUTHOR));
-       assertEquals("EJ04325S",             metadata.get(TikaCoreProperties.LAST_AUTHOR));
-       assertEquals("2011-08-22T13:32:58Z", metadata.get(TikaCoreProperties.SAVE_DATE));
-       assertEquals("2011-08-22T13:30:53Z", metadata.get(TikaCoreProperties.CREATION_DATE));
+       assertEquals("JOUVIN ETIENNE",       metadata.get(TikaCoreProperties.CREATOR));
+       assertEquals("EJ04325S",             metadata.get(TikaCoreProperties.MODIFIER));
+       assertEquals("2011-08-22T13:32:58Z", metadata.get(TikaCoreProperties.MODIFIED));
+       assertEquals("2011-08-22T13:30:53Z", metadata.get(TikaCoreProperties.CREATED));
        assertEquals("1",                    metadata.get(Office.SLIDE_COUNT));
        assertEquals("3",                    metadata.get(Office.WORD_COUNT));
        assertEquals("Test extraction properties pptx", metadata.get(TikaCoreProperties.TITLE));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ProjectParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ProjectParserTest.java
index 396bfbd4b..81616d423 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ProjectParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ProjectParserTest.java
@@ -66,18 +66,19 @@ public class ProjectParserTest extends TestCase {
                metadata.get(Metadata.CONTENT_TYPE));
        
        assertEquals("The quick brown fox jumps over the lazy dog", metadata.get(TikaCoreProperties.TITLE));
-       assertEquals("Gym class featuring a brown fox and lazy dog", metadata.get(TikaCoreProperties.SUBJECT));
-       assertEquals("Nevin Nollop", metadata.get(TikaCoreProperties.AUTHOR));
-       assertEquals("", metadata.get(TikaCoreProperties.LAST_AUTHOR));
+       assertEquals("Gym class featuring a brown fox and lazy dog", metadata.get(OfficeOpenXMLCore.SUBJECT));
+       assertEquals("Gym class featuring a brown fox and lazy dog", metadata.get(Metadata.SUBJECT));
+       assertEquals("Nevin Nollop", metadata.get(TikaCoreProperties.CREATOR));
+       assertEquals("", metadata.get(TikaCoreProperties.MODIFIER));
        assertEquals("Pangram, fox, dog", metadata.get(TikaCoreProperties.KEYWORDS));
-       assertEquals("Comment Vulpes vulpes comment", metadata.get(Metadata.COMMENTS));
+       assertEquals("Comment Vulpes vulpes comment", metadata.get(TikaCoreProperties.COMMENTS));
        
        assertEquals("Category1", metadata.get(OfficeOpenXMLCore.CATEGORY));
        assertEquals("Mr Burns", metadata.get(OfficeOpenXMLExtended.MANAGER));
        assertEquals("CompanyA", metadata.get(OfficeOpenXMLExtended.COMPANY));
        
-       assertEquals("2011-11-24T10:58:00Z", metadata.get(TikaCoreProperties.CREATION_DATE));
-       assertEquals("2011-11-24T11:31:00Z", metadata.get(TikaCoreProperties.SAVE_DATE));
+       assertEquals("2011-11-24T10:58:00Z", metadata.get(TikaCoreProperties.CREATED));
+       assertEquals("2011-11-24T11:31:00Z", metadata.get(TikaCoreProperties.MODIFIED));
        
        // Custom Project metadata is present with prefix
        assertEquals("0%", metadata.get("custom:% Complete"));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PublisherParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PublisherParserTest.java
index 27de34f11..e31dc5433 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PublisherParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PublisherParserTest.java
@@ -40,7 +40,8 @@ public class PublisherParserTest extends TestCase {
                     "application/x-mspublisher",
                     metadata.get(Metadata.CONTENT_TYPE));
             assertEquals(null, metadata.get(TikaCoreProperties.TITLE));
-            assertEquals("Nick Burch", metadata.get(TikaCoreProperties.AUTHOR));
+            assertEquals("Nick Burch", metadata.get(TikaCoreProperties.CREATOR));
+            assertEquals("Nick Burch", metadata.get(Metadata.AUTHOR));
             String content = handler.toString();
             assertTrue(content.contains("0123456789"));
             assertTrue(content.contains("abcdef"));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/TNEFParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/TNEFParserTest.java
index a155259e3..e2e4ab1ca 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/TNEFParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/TNEFParserTest.java
@@ -55,7 +55,8 @@ public class TNEFParserTest extends AbstractPOIContainerExtractionTest {
       TNEFParser tnef = new TNEFParser();
       tnef.parse(stream, handler, metadata, new ParseContext());
       
-      assertEquals("This is a test message", metadata.get(TikaCoreProperties.SUBJECT));
+      assertEquals("This is a test message", metadata.get(TikaCoreProperties.TITLE));
+      assertEquals("This is a test message", metadata.get(Metadata.SUBJECT));
    }
    
     /**
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/VisioParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/VisioParserTest.java
index 0b5507028..b7ae9a33c 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/VisioParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/VisioParserTest.java
@@ -40,7 +40,7 @@ public class VisioParserTest extends TestCase {
                     "application/vnd.visio",
                     metadata.get(Metadata.CONTENT_TYPE));
             assertEquals("", metadata.get(TikaCoreProperties.TITLE));
-            assertEquals("Hogwarts", metadata.get(TikaCoreProperties.AUTHOR));
+            assertEquals("Hogwarts", metadata.get(TikaCoreProperties.CREATOR));
             String content = handler.toString();
             assertTrue(content.contains("Some random text, on a page"));
         } finally {
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/WordParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/WordParserTest.java
index ad9853fe0..41afcd5a4 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/WordParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/WordParserTest.java
@@ -28,6 +28,7 @@ import javax.xml.transform.stream.StreamResult;
 import org.apache.tika.TikaTest;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.Office;
+import org.apache.tika.metadata.OfficeOpenXMLCore;
 import org.apache.tika.metadata.OfficeOpenXMLExtended;
 import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.ParseContext;
@@ -49,7 +50,8 @@ public class WordParserTest extends TikaTest {
                     "application/msword",
                     metadata.get(Metadata.CONTENT_TYPE));
             assertEquals("Sample Word Document", metadata.get(TikaCoreProperties.TITLE));
-            assertEquals("Keith Bennett", metadata.get(TikaCoreProperties.AUTHOR));
+            assertEquals("Keith Bennett", metadata.get(TikaCoreProperties.CREATOR));
+            assertEquals("Keith Bennett", metadata.get(Metadata.AUTHOR));
             assertTrue(handler.toString().contains("Sample Word Document"));
         } finally {
             input.close();
@@ -118,7 +120,8 @@ public class WordParserTest extends TikaTest {
                      "application/msword",
                      metadata.get(Metadata.CONTENT_TYPE));
         assertEquals("Sample Word Document", metadata.get(TikaCoreProperties.TITLE));
-        assertEquals("Keith Bennett", metadata.get(TikaCoreProperties.AUTHOR));
+        assertEquals("Keith Bennett", metadata.get(TikaCoreProperties.CREATOR));
+        assertEquals("Keith Bennett", metadata.get(Metadata.AUTHOR));
         assertTrue(xml.contains("Sample Word Document"));
 
         // Check that custom headings came through
@@ -180,8 +183,10 @@ public class WordParserTest extends TikaTest {
                     "application/msword",
                     metadata.get(Metadata.CONTENT_TYPE));
             assertEquals("The quick brown fox jumps over the lazy dog", metadata.get(TikaCoreProperties.TITLE));
-            assertEquals("Gym class featuring a brown fox and lazy dog", metadata.get(TikaCoreProperties.SUBJECT));
-            assertEquals("Nevin Nollop", metadata.get(TikaCoreProperties.AUTHOR));
+            assertEquals("Gym class featuring a brown fox and lazy dog", metadata.get(OfficeOpenXMLCore.SUBJECT));
+            assertEquals("Gym class featuring a brown fox and lazy dog", metadata.get(Metadata.SUBJECT));
+            assertEquals("Nevin Nollop", metadata.get(TikaCoreProperties.CREATOR));
+            assertEquals("Nevin Nollop", metadata.get(Metadata.AUTHOR));
             assertTrue(handler.toString().contains("The quick brown fox jumps over the lazy dog"));
         } finally {
             input.close();
@@ -243,8 +248,11 @@ public class WordParserTest extends TikaTest {
                      metadata.get(TikaCoreProperties.KEYWORDS));
 
         assertContains("Subject is here", content);
+        // TODO: Move to OO subject in Tika 2.0
         assertEquals("Subject is here",
-                     metadata.get(TikaCoreProperties.SUBJECT));
+                     metadata.get(Metadata.SUBJECT));
+        assertEquals("Subject is here",
+                     metadata.get(OfficeOpenXMLCore.SUBJECT));
 
         assertContains("Suddenly some Japanese text:", content);
         // Special version of (GHQ)
@@ -274,18 +282,20 @@ public class WordParserTest extends TikaTest {
        }
        
        assertEquals("application/msword",   metadata.get(Metadata.CONTENT_TYPE));
-       assertEquals("EJ04325S",             metadata.get(TikaCoreProperties.AUTHOR));
-       assertEquals("Etienne Jouvin",       metadata.get(TikaCoreProperties.LAST_AUTHOR));
-       assertEquals("2012-01-03T22:14:00Z", metadata.get(TikaCoreProperties.SAVE_DATE));
-       assertEquals("2010-10-05T09:03:00Z", metadata.get(TikaCoreProperties.CREATION_DATE));
+       assertEquals("EJ04325S",             metadata.get(TikaCoreProperties.CREATOR));
+       assertEquals("Etienne Jouvin",       metadata.get(TikaCoreProperties.MODIFIER));
+       assertEquals("2012-01-03T22:14:00Z", metadata.get(TikaCoreProperties.MODIFIED));
+       assertEquals("2010-10-05T09:03:00Z", metadata.get(TikaCoreProperties.CREATED));
        assertEquals("Microsoft Office Word",metadata.get(OfficeOpenXMLExtended.APPLICATION));
        assertEquals("1",                    metadata.get(Office.PAGE_COUNT));
        assertEquals("2",                    metadata.get(Office.WORD_COUNT));
        assertEquals("My Title",             metadata.get(TikaCoreProperties.TITLE));
        assertEquals("My Keyword",           metadata.get(TikaCoreProperties.KEYWORDS));
        assertEquals("Normal.dotm",          metadata.get(OfficeOpenXMLExtended.TEMPLATE));
-       assertEquals("My Comments",          metadata.get(Metadata.COMMENTS));
-       assertEquals("My subject",           metadata.get(TikaCoreProperties.SUBJECT));
+       assertEquals("My Comments",          metadata.get(TikaCoreProperties.COMMENTS));
+       // TODO: Move to OO subject in Tika 2.0
+       assertEquals("My subject",           metadata.get(Metadata.SUBJECT));
+       assertEquals("My subject",           metadata.get(OfficeOpenXMLCore.SUBJECT));
        assertEquals("EDF-DIT",              metadata.get(OfficeOpenXMLExtended.COMPANY));
        assertEquals("MyStringValue",        metadata.get("custom:MyCustomString"));
        assertEquals("2010-12-30T23:00:00Z", metadata.get("custom:MyCustomDate"));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
index 518256030..f518a78eb 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
@@ -29,6 +29,7 @@ import org.apache.tika.TikaTest;
 import org.apache.tika.io.TikaInputStream;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.Office;
+import org.apache.tika.metadata.OfficeOpenXMLCore;
 import org.apache.tika.metadata.OfficeOpenXMLExtended;
 import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.metadata.TikaMetadataKeys;
@@ -61,7 +62,8 @@ public class OOXMLParserTest extends TikaTest {
                     "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                     metadata.get(Metadata.CONTENT_TYPE));
             assertEquals("Simple Excel document", metadata.get(TikaCoreProperties.TITLE));
-            assertEquals("Keith Bennett", metadata.get(TikaCoreProperties.AUTHOR));
+            assertEquals("Keith Bennett", metadata.get(TikaCoreProperties.CREATOR));
+            assertEquals("Keith Bennett", metadata.get(Metadata.AUTHOR));
             String content = handler.toString();
             assertTrue(content.contains("Sample Excel Worksheet"));
             assertTrue(content.contains("Numbers and their Squares"));
@@ -188,7 +190,8 @@ public class OOXMLParserTest extends TikaTest {
                         mimeTypes[i],
                         metadata.get(Metadata.CONTENT_TYPE));
                 assertEquals("Attachment Test", metadata.get(TikaCoreProperties.TITLE));
-                assertEquals("Rajiv", metadata.get(TikaCoreProperties.AUTHOR));
+                assertEquals("Rajiv", metadata.get(TikaCoreProperties.CREATOR));
+                assertEquals("Rajiv", metadata.get(Metadata.AUTHOR));
                 
                 String content = handler.toString();
                 // Theme files don't have the text in them
@@ -277,7 +280,8 @@ public class OOXMLParserTest extends TikaTest {
                     "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                     metadata.get(Metadata.CONTENT_TYPE));
             assertEquals("Sample Word Document", metadata.get(TikaCoreProperties.TITLE));
-            assertEquals("Keith Bennett", metadata.get(TikaCoreProperties.AUTHOR));
+            assertEquals("Keith Bennett", metadata.get(TikaCoreProperties.CREATOR));
+            assertEquals("Keith Bennett", metadata.get(Metadata.AUTHOR));
             assertTrue(handler.toString().contains("Sample Word Document"));
         } finally {
             input.close();
@@ -348,7 +352,8 @@ public class OOXMLParserTest extends TikaTest {
                    "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                    metadata.get(Metadata.CONTENT_TYPE));
       assertEquals("Sample Word Document", metadata.get(TikaCoreProperties.TITLE));
-      assertEquals("Keith Bennett", metadata.get(TikaCoreProperties.AUTHOR));
+      assertEquals("Keith Bennett", metadata.get(TikaCoreProperties.CREATOR));
+      assertEquals("Keith Bennett", metadata.get(Metadata.AUTHOR));
       assertTrue(xml.contains("Sample Word Document"));
             
       // Check that custom headings came through
@@ -559,8 +564,11 @@ public class OOXMLParserTest extends TikaTest {
                      metadata.get(Metadata.KEYWORDS));
 
         assertContains("Subject is here", content);
+        // TODO: Remove subject in Tika 2.0
         assertEquals("Subject is here",
-                     metadata.get(TikaCoreProperties.SUBJECT));
+                     metadata.get(Metadata.SUBJECT));
+        assertEquals("Subject is here",
+                     metadata.get(OfficeOpenXMLCore.SUBJECT));
 
         assertContains("Suddenly some Japanese text:", content);
         // Special version of (GHQ)
@@ -627,8 +635,11 @@ public class OOXMLParserTest extends TikaTest {
                      metadata.get(Metadata.KEYWORDS));
 
         assertContains("Subject is here", content);
+        // TODO: Remove subject in Tika 2.0
+        assertEquals("Subject is here",
+                     metadata.get(Metadata.SUBJECT));
         assertEquals("Subject is here",
-                     metadata.get(TikaCoreProperties.SUBJECT));
+                     metadata.get(OfficeOpenXMLCore.SUBJECT));
 
         assertContains("Suddenly some Japanese text:", content);
         // Special version of (GHQ)
@@ -730,11 +741,11 @@ public class OOXMLParserTest extends TikaTest {
        assertEquals(
              "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", 
              metadata.get(Metadata.CONTENT_TYPE));
-       assertEquals(null,                   metadata.get(TikaCoreProperties.AUTHOR));
-       assertEquals(null,                   metadata.get(TikaCoreProperties.LAST_AUTHOR));
-       assertEquals("2006-09-12T15:06:44Z", metadata.get(TikaCoreProperties.DATE));
-       assertEquals("2006-09-12T15:06:44Z", metadata.get(TikaCoreProperties.CREATION_DATE));
+       assertEquals(null,                   metadata.get(TikaCoreProperties.CREATOR));
+       assertEquals(null,                   metadata.get(TikaCoreProperties.MODIFIER));
+       assertEquals("2006-09-12T15:06:44Z", metadata.get(TikaCoreProperties.CREATED));
        assertEquals("2011-08-22T14:24:38Z", metadata.get(Metadata.LAST_MODIFIED));
+       assertEquals("2011-08-22T14:24:38Z", metadata.get(TikaCoreProperties.MODIFIED));
        assertEquals("Microsoft Excel",      metadata.get(Metadata.APPLICATION_NAME));
        assertEquals("Microsoft Excel",      metadata.get(OfficeOpenXMLExtended.APPLICATION));
        assertEquals("true",                 metadata.get("custom:myCustomBoolean"));
@@ -760,10 +771,9 @@ public class OOXMLParserTest extends TikaTest {
        assertEquals(
              "application/vnd.openxmlformats-officedocument.wordprocessingml.document", 
              metadata.get(Metadata.CONTENT_TYPE));
-       assertEquals("EJ04325S",             metadata.get(TikaCoreProperties.AUTHOR));
-       assertEquals("Etienne Jouvin",       metadata.get(TikaCoreProperties.LAST_AUTHOR));
-       assertEquals("2011-07-29T16:52:00Z", metadata.get(TikaCoreProperties.DATE));
-       assertEquals("2011-07-29T16:52:00Z", metadata.get(TikaCoreProperties.CREATION_DATE));
+       assertEquals("EJ04325S",             metadata.get(TikaCoreProperties.CREATOR));
+       assertEquals("Etienne Jouvin",       metadata.get(TikaCoreProperties.MODIFIER));
+       assertEquals("2011-07-29T16:52:00Z", metadata.get(TikaCoreProperties.CREATED));
        assertEquals("2012-01-03T22:14:00Z", metadata.get(TikaCoreProperties.MODIFIED));
        assertEquals("Microsoft Office Word",metadata.get(Metadata.APPLICATION_NAME));
        assertEquals("Microsoft Office Word",metadata.get(OfficeOpenXMLExtended.APPLICATION));
@@ -773,7 +783,9 @@ public class OOXMLParserTest extends TikaTest {
        assertEquals("My Keyword",           metadata.get(TikaCoreProperties.KEYWORDS));
        assertEquals("Normal.dotm",          metadata.get(Metadata.TEMPLATE));
        assertEquals("Normal.dotm",          metadata.get(OfficeOpenXMLExtended.TEMPLATE));
-       assertEquals("My subject",           metadata.get(TikaCoreProperties.SUBJECT));
+       // TODO: Remove subject in Tika 2.0
+       assertEquals("My subject",           metadata.get(Metadata.SUBJECT));
+       assertEquals("My subject",           metadata.get(OfficeOpenXMLCore.SUBJECT));
        assertEquals("EDF-DIT",              metadata.get(TikaCoreProperties.PUBLISHER));
        assertEquals("true",                 metadata.get("custom:myCustomBoolean"));
        assertEquals("3",                    metadata.get("custom:myCustomNumber"));
@@ -798,10 +810,9 @@ public class OOXMLParserTest extends TikaTest {
        assertEquals(
              "application/vnd.openxmlformats-officedocument.presentationml.presentation", 
              metadata.get(Metadata.CONTENT_TYPE));
-       assertEquals("JOUVIN ETIENNE",       metadata.get(TikaCoreProperties.AUTHOR));
-       assertEquals("EJ04325S",             metadata.get(TikaCoreProperties.LAST_AUTHOR));
-       assertEquals("2011-08-22T13:30:53Z", metadata.get(TikaCoreProperties.DATE));
-       assertEquals("2011-08-22T13:30:53Z", metadata.get(TikaCoreProperties.CREATION_DATE));
+       assertEquals("JOUVIN ETIENNE",       metadata.get(TikaCoreProperties.CREATOR));
+       assertEquals("EJ04325S",             metadata.get(TikaCoreProperties.MODIFIER));
+       assertEquals("2011-08-22T13:30:53Z", metadata.get(TikaCoreProperties.CREATED));
        assertEquals("2011-08-22T13:32:49Z", metadata.get(TikaCoreProperties.MODIFIED));
        assertEquals("1",                    metadata.get(Office.SLIDE_COUNT));
        assertEquals("3",                    metadata.get(Office.WORD_COUNT));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/mp3/Mp3ParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/mp3/Mp3ParserTest.java
index 12bba017c..b59e8641a 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/mp3/Mp3ParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/mp3/Mp3ParserTest.java
@@ -53,7 +53,8 @@ public class Mp3ParserTest extends TestCase {
 
         assertEquals("audio/mpeg", metadata.get(Metadata.CONTENT_TYPE));
         assertEquals("Test Title", metadata.get(TikaCoreProperties.TITLE));
-        assertEquals("Test Artist", metadata.get(TikaCoreProperties.AUTHOR));
+        assertEquals("Test Artist", metadata.get(TikaCoreProperties.CREATOR));
+        assertEquals("Test Artist", metadata.get(Metadata.AUTHOR));
 
         String content = handler.toString();
         assertTrue(content.contains("Test Title"));
@@ -88,7 +89,8 @@ public class Mp3ParserTest extends TestCase {
         // Check core properties
         assertEquals("audio/mpeg", metadata.get(Metadata.CONTENT_TYPE));
         assertEquals("Test Title", metadata.get(TikaCoreProperties.TITLE));
-        assertEquals("Test Artist", metadata.get(TikaCoreProperties.AUTHOR));
+        assertEquals("Test Artist", metadata.get(TikaCoreProperties.CREATOR));
+        assertEquals("Test Artist", metadata.get(Metadata.AUTHOR));
 
         // Check the textual contents
         String content = handler.toString();
@@ -137,7 +139,8 @@ public class Mp3ParserTest extends TestCase {
 
         assertEquals("audio/mpeg", metadata.get(Metadata.CONTENT_TYPE));
         assertEquals("Test Title", metadata.get(TikaCoreProperties.TITLE));
-        assertEquals("Test Artist", metadata.get(TikaCoreProperties.AUTHOR));
+        assertEquals("Test Artist", metadata.get(TikaCoreProperties.CREATOR));
+        assertEquals("Test Artist", metadata.get(Metadata.AUTHOR));
 
         String content = handler.toString();
         assertTrue(content.contains("Test Title"));
@@ -171,7 +174,8 @@ public class Mp3ParserTest extends TestCase {
 
         assertEquals("audio/mpeg", metadata.get(Metadata.CONTENT_TYPE));
         assertEquals("Test Title", metadata.get(TikaCoreProperties.TITLE));
-        assertEquals("Test Artist", metadata.get(TikaCoreProperties.AUTHOR));
+        assertEquals("Test Artist", metadata.get(TikaCoreProperties.CREATOR));
+        assertEquals("Test Artist", metadata.get(Metadata.AUTHOR));
 
         String content = handler.toString();
         assertTrue(content.contains("Test Title"));
@@ -205,7 +209,8 @@ public class Mp3ParserTest extends TestCase {
 
        assertEquals("audio/mpeg", metadata.get(Metadata.CONTENT_TYPE));
        assertEquals("Une chason en Fran\u00e7ais", metadata.get(TikaCoreProperties.TITLE));
-       assertEquals("Test Artist \u2468\u2460", metadata.get(TikaCoreProperties.AUTHOR));
+       assertEquals("Test Artist \u2468\u2460", metadata.get(TikaCoreProperties.CREATOR));
+       assertEquals("Test Artist \u2468\u2460", metadata.get(Metadata.AUTHOR));
        assertEquals("Test Artist \u2468\u2460", metadata.get(XMPDM.ARTIST));
        assertEquals("Test Album \u2460\u2468", metadata.get(XMPDM.ALBUM));
 
@@ -243,7 +248,8 @@ public class Mp3ParserTest extends TestCase {
 
         assertEquals("audio/mpeg", metadata.get(Metadata.CONTENT_TYPE));
         assertEquals("Test Title", metadata.get(TikaCoreProperties.TITLE));
-        assertEquals("Test Artist", metadata.get(TikaCoreProperties.AUTHOR));
+        assertEquals("Test Artist", metadata.get(TikaCoreProperties.CREATOR));
+        assertEquals("Test Artist", metadata.get(Metadata.AUTHOR));
 
         String content = handler.toString();
         assertTrue(content.contains("Test Title"));
@@ -308,7 +314,8 @@ public class Mp3ParserTest extends TestCase {
 
        assertEquals("audio/mpeg", metadata.get(Metadata.CONTENT_TYPE));
        assertEquals("Plus loin vers l'ouest", metadata.get(TikaCoreProperties.TITLE));
-       assertEquals("Merzhin", metadata.get(TikaCoreProperties.AUTHOR));
+       assertEquals("Merzhin", metadata.get(TikaCoreProperties.CREATOR));
+       assertEquals("Merzhin", metadata.get(Metadata.AUTHOR));
 
        String content = handler.toString();
        assertTrue(content.contains("Plus loin vers l'ouest"));
@@ -343,7 +350,8 @@ public class Mp3ParserTest extends TestCase {
        // Check we coud get the headers from the start
        assertEquals("audio/mpeg", metadata.get(Metadata.CONTENT_TYPE));
        assertEquals("Girl you have no faith in medicine", metadata.get(TikaCoreProperties.TITLE));
-       assertEquals("The White Stripes", metadata.get(TikaCoreProperties.AUTHOR));
+       assertEquals("The White Stripes", metadata.get(TikaCoreProperties.CREATOR));
+       assertEquals("The White Stripes", metadata.get(Metadata.AUTHOR));
 
        String content = handler.toString();
        assertTrue(content.contains("Girl you have no faith in medicine"));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/mp4/MP4ParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/mp4/MP4ParserTest.java
index 2a69e9613..77eae089b 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/mp4/MP4ParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/mp4/MP4ParserTest.java
@@ -54,8 +54,9 @@ public class MP4ParserTest extends TestCase {
         // Check core properties
         assertEquals("audio/mp4", metadata.get(Metadata.CONTENT_TYPE));
         assertEquals("Test Title", metadata.get(TikaCoreProperties.TITLE));
-        assertEquals("Test Artist", metadata.get(TikaCoreProperties.AUTHOR));
-        assertEquals("2012-01-28T18:39:18Z", metadata.get(TikaCoreProperties.CREATION_DATE));
+        assertEquals("Test Artist", metadata.get(TikaCoreProperties.CREATOR));
+        assertEquals("Test Artist", metadata.get(Metadata.AUTHOR));
+        assertEquals("2012-01-28T18:39:18Z", metadata.get(TikaCoreProperties.CREATED));
         assertEquals("2012-01-28T18:40:25Z", metadata.get(TikaCoreProperties.MODIFIED));
 
         // Check the textual contents
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/odf/ODFParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/odf/ODFParserTest.java
index 9f4c17cbe..3bfa384fd 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/odf/ODFParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/odf/ODFParserTest.java
@@ -21,6 +21,7 @@ import java.io.InputStream;
 import org.apache.tika.TikaTest;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.Office;
+import org.apache.tika.metadata.OfficeOpenXMLCore;
 import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.AutoDetectParser;
 import org.apache.tika.parser.ParseContext;
@@ -85,9 +86,10 @@ public class ODFParserTest extends TikaTest {
                    metadata.get("generator"));
              
              // Check date metadata, both old-style and new-style
-             assertEquals("2007-09-14T11:07:10", metadata.get(TikaCoreProperties.DATE));
-             assertEquals("2007-09-14T11:06:08", metadata.get(TikaCoreProperties.CREATION_DATE));
-             assertEquals("2007-09-14T11:07:10", metadata.get(Metadata.DATE));
+             assertEquals("2007-09-14T11:07:10", metadata.get(TikaCoreProperties.MODIFIED));
+             assertEquals("2007-09-14T11:07:10", metadata.get(Metadata.MODIFIED));
+             assertEquals("2007-09-14T11:06:08", metadata.get(Metadata.DATE));
+             assertEquals("2007-09-14T11:06:08", metadata.get(TikaCoreProperties.CREATED));
              assertEquals("2007-09-14T11:06:08", metadata.get(Metadata.CREATION_DATE));
              
              // Check the document statistics
@@ -148,10 +150,16 @@ public class ODFParserTest extends TikaTest {
            assertEquals(
                    "application/vnd.oasis.opendocument.formula",
                    metadata.get(Metadata.CONTENT_TYPE));
-           assertEquals(null, metadata.get(TikaCoreProperties.DATE));
+           assertEquals(null, metadata.get(TikaCoreProperties.MODIFIED));
            assertEquals("2006-01-27T11:55:22", metadata.get(Metadata.CREATION_DATE));
-           assertEquals("The quick brown fox jumps over the lazy dog", metadata.get(TikaCoreProperties.TITLE));
-           assertEquals("Gym class featuring a brown fox and lazy dog", metadata.get(TikaCoreProperties.SUBJECT));
+           assertEquals("The quick brown fox jumps over the lazy dog", 
+                   metadata.get(TikaCoreProperties.TITLE));
+           assertEquals("Gym class featuring a brown fox and lazy dog", 
+                   metadata.get(TikaCoreProperties.DESCRIPTION));
+           assertEquals("Gym class featuring a brown fox and lazy dog", 
+                   metadata.get(OfficeOpenXMLCore.SUBJECT));
+           assertEquals("Gym class featuring a brown fox and lazy dog", 
+                   metadata.get(Metadata.SUBJECT));
            assertEquals("PT0S", metadata.get(Metadata.EDIT_TIME));
            assertEquals("1", metadata.get("editing-cycles"));
            assertEquals(
@@ -203,10 +211,12 @@ public class ODFParserTest extends TikaTest {
            assertEquals(
                    "application/vnd.oasis.opendocument.text",
                    metadata.get(Metadata.CONTENT_TYPE));
-           assertEquals("2009-10-05T21:22:38", metadata.get(TikaCoreProperties.DATE));
+           assertEquals("2009-10-05T21:22:38", metadata.get(TikaCoreProperties.MODIFIED));
+           assertEquals("2009-10-05T19:04:01", metadata.get(TikaCoreProperties.CREATED));
            assertEquals("2009-10-05T19:04:01", metadata.get(Metadata.CREATION_DATE));
            assertEquals("Apache Tika", metadata.get(TikaCoreProperties.TITLE));
-           assertEquals("Test document", metadata.get(TikaCoreProperties.SUBJECT));
+           assertEquals("Test document", metadata.get(OfficeOpenXMLCore.SUBJECT));
+           assertEquals("Test document", metadata.get(Metadata.SUBJECT));
            assertEquals("A rather complex document", metadata.get(TikaCoreProperties.DESCRIPTION));
            assertEquals("Bart Hanssens", metadata.get(TikaCoreProperties.CREATOR));
            assertEquals("Bart Hanssens", metadata.get("initial-creator"));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java
index 9ab709649..169a3244f 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java
@@ -26,6 +26,7 @@ import javax.xml.transform.stream.StreamResult;
 
 import org.apache.tika.TikaTest;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.OfficeOpenXMLCore;
 import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.AutoDetectParser;
 import org.apache.tika.parser.ParseContext;
@@ -53,7 +54,9 @@ public class PDFParserTest extends TikaTest {
         }
 
         assertEquals("application/pdf", metadata.get(Metadata.CONTENT_TYPE));
-        assertEquals("Bertrand Delacr\u00e9taz", metadata.get(TikaCoreProperties.AUTHOR));
+        assertEquals("Bertrand Delacr\u00e9taz", metadata.get(TikaCoreProperties.CREATOR));
+        assertEquals("Bertrand Delacr\u00e9taz", metadata.get(Metadata.AUTHOR));
+        assertEquals("Firefox", metadata.get(TikaCoreProperties.CREATOR_TOOL));
         assertEquals("Apache Tika - Apache Tika", metadata.get(TikaCoreProperties.TITLE));
         
         // Can't reliably test dates yet - see TIKA-451 
@@ -87,7 +90,8 @@ public class PDFParserTest extends TikaTest {
         }
 
         assertEquals("application/pdf", metadata.get(Metadata.CONTENT_TYPE));
-        assertEquals("Document author", metadata.get(TikaCoreProperties.AUTHOR));
+        assertEquals("Document author", metadata.get(TikaCoreProperties.CREATOR));
+        assertEquals("Document author", metadata.get(Metadata.AUTHOR));
         assertEquals("Document title", metadata.get(TikaCoreProperties.TITLE));
         
         assertEquals("Custom Value", metadata.get("Custom Property"));
@@ -120,8 +124,10 @@ public class PDFParserTest extends TikaTest {
        }
 
        assertEquals("application/pdf", metadata.get(Metadata.CONTENT_TYPE));
-       assertEquals("The Bank of England", metadata.get(TikaCoreProperties.AUTHOR));
-       assertEquals("Speeches by Andrew G Haldane", metadata.get(TikaCoreProperties.SUBJECT));
+       assertEquals("The Bank of England", metadata.get(TikaCoreProperties.CREATOR));
+       assertEquals("The Bank of England", metadata.get(Metadata.AUTHOR));
+       assertEquals("Speeches by Andrew G Haldane", metadata.get(OfficeOpenXMLCore.SUBJECT));
+       assertEquals("Speeches by Andrew G Haldane", metadata.get(Metadata.SUBJECT));
        assertEquals("Rethinking the Financial Network, Speech by Andrew G Haldane, Executive Director, Financial Stability delivered at the Financial Student Association, Amsterdam on 28 April 2009", metadata.get(TikaCoreProperties.TITLE));
 
        String content = handler.toString();
@@ -150,8 +156,9 @@ public class PDFParserTest extends TikaTest {
        }
 
        assertEquals("application/pdf", metadata.get(Metadata.CONTENT_TYPE));
-       assertEquals("The Bank of England", metadata.get(TikaCoreProperties.AUTHOR));
-       assertEquals("Speeches by Andrew G Haldane", metadata.get(TikaCoreProperties.SUBJECT));
+       assertEquals("The Bank of England", metadata.get(TikaCoreProperties.CREATOR));
+       assertEquals("Speeches by Andrew G Haldane", metadata.get(OfficeOpenXMLCore.SUBJECT));
+       assertEquals("Speeches by Andrew G Haldane", metadata.get(Metadata.SUBJECT));
        assertEquals("Rethinking the Financial Network, Speech by Andrew G Haldane, Executive Director, Financial Stability delivered at the Financial Student Association, Amsterdam on 28 April 2009", metadata.get(TikaCoreProperties.TITLE));
 
        assertTrue(content.contains("RETHINKING THE FINANCIAL NETWORK"));
@@ -234,7 +241,9 @@ public class PDFParserTest extends TikaTest {
 
         assertContains("Subject is here", content);
         assertEquals("Subject is here",
-                     metadata.get(TikaCoreProperties.SUBJECT));
+                     metadata.get(OfficeOpenXMLCore.SUBJECT));
+        assertEquals("Subject is here",
+                     metadata.get(Metadata.SUBJECT));
 
         assertContains("Suddenly some Japanese text:", content);
         // Special version of (GHQ)
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/prt/PRTParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/prt/PRTParserTest.java
index b8c4bdba9..4f2e1851e 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/prt/PRTParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/prt/PRTParserTest.java
@@ -39,7 +39,7 @@ public class PRTParserTest extends TikaTest {
 
           // This file has a date
           assertEquals("2011-06-20T16:54:00",
-                metadata.get(TikaCoreProperties.DATE));
+                metadata.get(TikaCoreProperties.CREATED));
           assertEquals("2011-06-20T16:54:00",
                 metadata.get(Metadata.CREATION_DATE));
           // But no description
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/rtf/RTFParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/rtf/RTFParserTest.java
index 6615a2a44..a89236653 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/rtf/RTFParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/rtf/RTFParserTest.java
@@ -30,6 +30,7 @@ import org.apache.tika.Tika;
 import org.apache.tika.TikaTest;
 import org.apache.tika.io.TikaInputStream;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.OfficeOpenXMLCore;
 import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.sax.WriteOutContentHandler;
@@ -155,8 +156,9 @@ public class RTFParserTest extends TikaTest {
         // title info field:
         assertEquals("\u30be\u30eb\u30b2\u3068\u5c3e\u5d0e\u3001\u6de1\u3005\u3068\u6700\u671f\u3000",
                      r.metadata.get(TikaCoreProperties.TITLE));
-        assertEquals("VMazel", r.metadata.get(TikaCoreProperties.AUTHOR));
-        assertEquals("StarWriter", r.metadata.get(Metadata.COMMENT));
+        assertEquals("VMazel", r.metadata.get(TikaCoreProperties.CREATOR));
+        assertEquals("VMazel", r.metadata.get(Metadata.AUTHOR));
+        assertEquals("StarWriter", r.metadata.get(TikaCoreProperties.COMMENTS));
         assertContains("1.", content);
         assertContains("4.", content);
        
@@ -268,7 +270,9 @@ public class RTFParserTest extends TikaTest {
 
         assertContains("Subject is here", content);
         assertEquals("Subject is here",
-                     r.metadata.get(TikaCoreProperties.SUBJECT));
+                     r.metadata.get(OfficeOpenXMLCore.SUBJECT));
+        assertEquals("Subject is here",
+                     r.metadata.get(Metadata.SUBJECT));
 
         assertContains("Suddenly some Japanese text:", content);
         // Special version of (GHQ)
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/xml/DcXMLParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/xml/DcXMLParserTest.java
index 44160ffd1..087966e12 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/xml/DcXMLParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/xml/DcXMLParserTest.java
@@ -44,13 +44,20 @@ public class DcXMLParserTest extends TestCase {
             
             // The file contains 5 dc:subject tags, which come through as
             //  a multi-valued Tika Metadata entry in file order
-            assertEquals(true, metadata.isMultiValued(TikaCoreProperties.SUBJECT));
-            assertEquals(5,      metadata.getValues(TikaCoreProperties.SUBJECT).length);
-            assertEquals("Java", metadata.getValues(TikaCoreProperties.SUBJECT)[0]);
-            assertEquals("XML",  metadata.getValues(TikaCoreProperties.SUBJECT)[1]);
-            assertEquals("XSLT", metadata.getValues(TikaCoreProperties.SUBJECT)[2]);
-            assertEquals("JDOM", metadata.getValues(TikaCoreProperties.SUBJECT)[3]);
-            assertEquals("Indexation", metadata.getValues(TikaCoreProperties.SUBJECT)[4]);
+            assertEquals(true, metadata.isMultiValued(TikaCoreProperties.KEYWORDS));
+            assertEquals(5,      metadata.getValues(TikaCoreProperties.KEYWORDS).length);
+            assertEquals("Java", metadata.getValues(TikaCoreProperties.KEYWORDS)[0]);
+            assertEquals("XML",  metadata.getValues(TikaCoreProperties.KEYWORDS)[1]);
+            assertEquals("XSLT", metadata.getValues(TikaCoreProperties.KEYWORDS)[2]);
+            assertEquals("JDOM", metadata.getValues(TikaCoreProperties.KEYWORDS)[3]);
+            assertEquals("Indexation", metadata.getValues(TikaCoreProperties.KEYWORDS)[4]);
+            assertEquals(true, metadata.isMultiValued(Metadata.SUBJECT));
+            assertEquals(5,      metadata.getValues(Metadata.SUBJECT).length);
+            assertEquals("Java", metadata.getValues(Metadata.SUBJECT)[0]);
+            assertEquals("XML",  metadata.getValues(Metadata.SUBJECT)[1]);
+            assertEquals("XSLT", metadata.getValues(Metadata.SUBJECT)[2]);
+            assertEquals("JDOM", metadata.getValues(Metadata.SUBJECT)[3]);
+            assertEquals("Indexation", metadata.getValues(Metadata.SUBJECT)[4]);
 
             assertEquals(
                     "Framework d\'indexation des documents XML, HTML, PDF etc..",
@@ -66,7 +73,7 @@ public class DcXMLParserTest extends TestCase {
             String content = handler.toString();
             assertTrue(content.contains("Tika test document"));
             
-            assertEquals("2000-12-01T00:00:00.000Z", metadata.get(TikaCoreProperties.DATE));
+            assertEquals("2000-12-01T00:00:00.000Z", metadata.get(TikaCoreProperties.CREATED));
         } finally {
             input.close();
         }
diff --git a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/MSOfficeBinaryConverter.java b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/MSOfficeBinaryConverter.java
index 86718e167..2e0b55b7b 100644
--- a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/MSOfficeBinaryConverter.java
+++ b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/MSOfficeBinaryConverter.java
@@ -66,17 +66,17 @@ public class MSOfficeBinaryConverter extends AbstractConverter
 		// For all formats, Tika uses the same keys 
 		createProperty(HttpHeaders.CONTENT_TYPE, XMPConst.NS_DC, "format");
 		createProperty(OfficeOpenXMLExtended.APPLICATION, XMPConst.NS_XMP, "CreatorTool");
-		createCommaSeparatedArray(TikaCoreProperties.AUTHOR, XMPConst.NS_DC, "creator", PropertyOptions.ARRAY_ORDERED);
+		createCommaSeparatedArray(TikaCoreProperties.CREATOR, XMPConst.NS_DC, "creator", PropertyOptions.ARRAY_ORDERED);
 		createProperty(OfficeOpenXMLCore.CATEGORY, XMPConst.NS_IPTCCORE, "intellectualGenre");
-		createProperty(TikaCoreProperties.CREATION_DATE, XMPConst.NS_XMP, "CreateDate");
+		createProperty(TikaCoreProperties.CREATED, XMPConst.NS_XMP, "CreateDate");
 		createProperty(Office.CHARACTER_COUNT, OfficeOpenXMLExtended.NAMESPACE_URI, "Characters");
-		createProperty(MSOffice.COMMENTS, XMPConst.NS_PDFX, "Comments");
+		createProperty(TikaCoreProperties.COMMENTS, XMPConst.NS_PDFX, "Comments");
 		createProperty(OfficeOpenXMLExtended.COMPANY, OfficeOpenXMLExtended.NAMESPACE_URI, "Company");
 		createCommaSeparatedArray(TikaCoreProperties.KEYWORDS, XMPConst.NS_DC, "subject", PropertyOptions.ARRAY);
-		createLangAltProperty(TikaCoreProperties.SUBJECT, XMPConst.NS_DC, "description");
+		createLangAltProperty(TikaCoreProperties.DESCRIPTION, XMPConst.NS_DC, "description");
 		createProperty(TikaCoreProperties.LANGUAGE, OfficeOpenXMLCore.NAMESPACE_URI, "language");
 		createProperty(TikaCoreProperties.PRINT_DATE, OfficeOpenXMLCore.NAMESPACE_URI, "lastPrinted");
-		createProperty(TikaCoreProperties.SAVE_DATE, XMPConst.NS_XMP, "ModifyDate");
+		createProperty(TikaCoreProperties.MODIFIED, XMPConst.NS_XMP, "ModifyDate");
 		createProperty(Office.PAGE_COUNT, XMPConst.TYPE_PAGEDFILE, "NPages");
 		createProperty(OfficeOpenXMLCore.REVISION, OfficeOpenXMLCore.NAMESPACE_URI, "revision");
 		createProperty(Office.SLIDE_COUNT, OfficeOpenXMLExtended.NAMESPACE_URI, "Pages");
diff --git a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/MSOfficeXMLConverter.java b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/MSOfficeXMLConverter.java
index 577dd0c21..2bf9c69c2 100644
--- a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/MSOfficeXMLConverter.java
+++ b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/MSOfficeXMLConverter.java
@@ -64,14 +64,14 @@ public class MSOfficeXMLConverter extends AbstractConverter
 		// Core Properties
 		createProperty(OfficeOpenXMLCore.CATEGORY, XMPConst.NS_IPTCCORE, "intellectualGenre");
 		createProperty(OfficeOpenXMLCore.CONTENT_STATUS, OfficeOpenXMLCore.NAMESPACE_URI, "contentStatus");
-		createProperty(TikaCoreProperties.CREATION_DATE, XMPConst.NS_XMP, "CreateDate");
+		createProperty(TikaCoreProperties.CREATED, XMPConst.NS_XMP, "CreateDate");
 		createCommaSeparatedArray(TikaCoreProperties.CREATOR, XMPConst.NS_DC, "creator", PropertyOptions.ARRAY_ORDERED);
-		createProperty(TikaCoreProperties.DESCRIPTION, XMPConst.NS_PDFX, "Comments");
+		createProperty(TikaCoreProperties.COMMENTS, XMPConst.NS_PDFX, "Comments");
 		createProperty(TikaCoreProperties.IDENTIFIER, XMPConst.NS_DC, "identifier");
 		createCommaSeparatedArray(TikaCoreProperties.KEYWORDS, XMPConst.NS_DC, "subject", PropertyOptions.ARRAY); 
-		createLangAltProperty(TikaCoreProperties.SUBJECT, XMPConst.NS_DC, "description"); 
+		createLangAltProperty(TikaCoreProperties.DESCRIPTION, XMPConst.NS_DC, "description"); 
 		createProperty(TikaCoreProperties.LANGUAGE, XMPConst.NS_DC, "language");
-		createProperty(TikaCoreProperties.LAST_AUTHOR, OfficeOpenXMLCore.NAMESPACE_URI, "lastModifiedBy");
+		createProperty(TikaCoreProperties.MODIFIER, OfficeOpenXMLCore.NAMESPACE_URI, "lastModifiedBy");
 		createProperty(TikaCoreProperties.PRINT_DATE, OfficeOpenXMLCore.NAMESPACE_URI, "lastPrinted");
 		createProperty(TikaCoreProperties.MODIFIED, XMPConst.NS_XMP, "ModifyDate");
 		createProperty(OfficeOpenXMLCore.REVISION, OfficeOpenXMLCore.NAMESPACE_URI, "revision");
diff --git a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/OpenDocumentConverter.java b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/OpenDocumentConverter.java
index 46ceaa6ce..5c8adb1bd 100644
--- a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/OpenDocumentConverter.java
+++ b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/OpenDocumentConverter.java
@@ -66,12 +66,12 @@ public class OpenDocumentConverter extends AbstractConverter
 		createProperty(HttpHeaders.CONTENT_TYPE, XMPConst.NS_DC, "format");
 		
 		createProperty(Office.CHARACTER_COUNT, Office.NAMESPACE_URI_DOC_META, "character-count");
-		createProperty(TikaCoreProperties.CREATION_DATE, XMPConst.NS_XMP, "CreateDate");
+		createProperty(TikaCoreProperties.CREATED, XMPConst.NS_XMP, "CreateDate");
 		createCommaSeparatedArray(TikaCoreProperties.CREATOR, XMPConst.NS_DC, "creator", PropertyOptions.ARRAY_ORDERED);
-		createProperty(TikaCoreProperties.DATE, XMPConst.NS_XMP, "ModifyDate");
-		createProperty(TikaCoreProperties.DESCRIPTION, XMPConst.NS_PDFX, "Comments");
+		createProperty(TikaCoreProperties.MODIFIED, XMPConst.NS_XMP, "ModifyDate");
+		createProperty(TikaCoreProperties.COMMENTS, XMPConst.NS_PDFX, "Comments");
 		createCommaSeparatedArray(TikaCoreProperties.KEYWORDS, XMPConst.NS_DC, "subject", PropertyOptions.ARRAY);
-		createLangAltProperty(TikaCoreProperties.SUBJECT, XMPConst.NS_DC, "description");
+		createLangAltProperty(TikaCoreProperties.DESCRIPTION, XMPConst.NS_DC, "description");
 		createProperty(MSOffice.EDIT_TIME, Office.NAMESPACE_URI_DOC_META, "editing-duration");
 		createProperty("editing-cycles", Office.NAMESPACE_URI_DOC_META, "editing-cycles");
 		createProperty("generator", XMPConst.NS_XMP, "CreatorTool");
diff --git a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/RTFConverter.java b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/RTFConverter.java
index ceff2c266..0cd630277 100644
--- a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/RTFConverter.java
+++ b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/RTFConverter.java
@@ -60,13 +60,13 @@ public class RTFConverter extends AbstractConverter
 		
 		createProperty(HttpHeaders.CONTENT_TYPE, XMPConst.NS_DC, "format");
 
-		createCommaSeparatedArray(TikaCoreProperties.AUTHOR, XMPConst.NS_DC, "creator", PropertyOptions.ARRAY_ORDERED);
+		createCommaSeparatedArray(TikaCoreProperties.CREATOR, XMPConst.NS_DC, "creator", PropertyOptions.ARRAY_ORDERED);
 		createLangAltProperty(TikaCoreProperties.TITLE, XMPConst.NS_DC, "title");
-		createLangAltProperty(TikaCoreProperties.SUBJECT, XMPConst.NS_DC, "description");
+		createLangAltProperty(TikaCoreProperties.DESCRIPTION, XMPConst.NS_DC, "description");
 		createCommaSeparatedArray(TikaCoreProperties.KEYWORDS, XMPConst.NS_DC, "subject", PropertyOptions.ARRAY);
 		createProperty(OfficeOpenXMLCore.CATEGORY, XMPConst.NS_IPTCCORE, "intellectualGenre");
 		createProperty(OfficeOpenXMLExtended.TEMPLATE, OfficeOpenXMLExtended.NAMESPACE_URI, "Template");
-		createProperty(ClimateForcast.COMMENT, XMPConst.NS_PDFX, "Comments");
+		createProperty(TikaCoreProperties.COMMENTS, XMPConst.NS_PDFX, "Comments");
 		createProperty(OfficeOpenXMLExtended.COMPANY, OfficeOpenXMLExtended.NAMESPACE_URI, "Company");
 		createProperty(OfficeOpenXMLExtended.MANAGER, OfficeOpenXMLExtended.NAMESPACE_URI, "Manager");
 				
diff --git a/tika-xmp/src/test/java/org/apache/tika/xmp/TikaToXMPTest.java b/tika-xmp/src/test/java/org/apache/tika/xmp/TikaToXMPTest.java
index 8f98c5d51..4ef489db2 100644
--- a/tika-xmp/src/test/java/org/apache/tika/xmp/TikaToXMPTest.java
+++ b/tika-xmp/src/test/java/org/apache/tika/xmp/TikaToXMPTest.java
@@ -69,7 +69,7 @@ public class TikaToXMPTest
 		// comma separated array
 		metadata.set(TikaCoreProperties.KEYWORDS, "keyword1,keyword2");
 		// OOXML specific simple prop
-		metadata.set(TikaCoreProperties.LAST_AUTHOR, "lastModifiedBy");
+		metadata.set(TikaCoreProperties.MODIFIER, "lastModifiedBy");
 	}
 	
 	private void checkOOXMLMetadata(XMPMeta xmp) throws XMPException
@@ -156,7 +156,7 @@ public class TikaToXMPTest
 		// language alternative
 		tikaMetadata.set(TikaCoreProperties.TITLE, "title");
 		// array
-		tikaMetadata.set(TikaCoreProperties.SUBJECT, new String[] {"keyword1", "keyword2"});
+		tikaMetadata.set(TikaCoreProperties.KEYWORDS, new String[] {"keyword1", "keyword2"});
 		
 		
 		XMPMeta xmp = TikaToXMP.convert(tikaMetadata, null);
diff --git a/tika-xmp/src/test/java/org/apache/tika/xmp/XMPMetadataTest.java b/tika-xmp/src/test/java/org/apache/tika/xmp/XMPMetadataTest.java
index 54637b883..9be050fbf 100644
--- a/tika-xmp/src/test/java/org/apache/tika/xmp/XMPMetadataTest.java
+++ b/tika-xmp/src/test/java/org/apache/tika/xmp/XMPMetadataTest.java
@@ -26,6 +26,7 @@ import java.util.Date;
 import java.util.Properties;
 
 import org.apache.tika.exception.TikaException;
+import org.apache.tika.metadata.DublinCore;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.Property;
 import org.apache.tika.metadata.PropertyTypeException;
@@ -51,6 +52,7 @@ public class XMPMetadataTest
 	@Before
 	public void setUp() throws Exception 
 	{
+	    XMPMetadata.registerNamespace(DublinCore.NAMESPACE_URI_DC_TERMS, DublinCore.PREFIX_DC_TERMS);
 		xmpMeta = new XMPMetadata();
 		tikaMetadata = new Metadata();
 		setupMetadata(tikaMetadata);
@@ -63,7 +65,7 @@ public class XMPMetadataTest
 		// language alternative
 		metadata.set(TikaCoreProperties.TITLE, "title");
 		// array
-		metadata.set(TikaCoreProperties.SUBJECT, new String[] {"keyword1", "keyword2"});
+		metadata.set(TikaCoreProperties.KEYWORDS, new String[] {"keyword1", "keyword2"});
 		// date
 		metadata.set(TikaCoreProperties.MODIFIED,"2001-01-01T01:01" );
 		// int simple property
@@ -114,7 +116,7 @@ public class XMPMetadataTest
 	{
 		xmpMeta.process(tikaMetadata);
 		
-		assertTrue(xmpMeta.isMultiValued(TikaCoreProperties.SUBJECT));
+		assertTrue(xmpMeta.isMultiValued(TikaCoreProperties.KEYWORDS));
 	}
 
 	@Test
@@ -138,7 +140,7 @@ public class XMPMetadataTest
 	{
 		xmpMeta.process(tikaMetadata);
 		
-		assertEquals("keyword1", xmpMeta.get(TikaCoreProperties.SUBJECT));
+		assertEquals("keyword1", xmpMeta.get(TikaCoreProperties.KEYWORDS));
 	}
 
 	@Test
@@ -188,7 +190,7 @@ public class XMPMetadataTest
 	{
 		xmpMeta.process(tikaMetadata);
 		
-		String[] values = xmpMeta.getValues(TikaCoreProperties.SUBJECT);
+		String[] values = xmpMeta.getValues(TikaCoreProperties.KEYWORDS);
 		assertEquals(2, values.length);
 		
 		checkArrayValues(values, "keyword");
@@ -199,13 +201,13 @@ public class XMPMetadataTest
 	{
 		Properties props = new Properties();
 		props.put(TikaCoreProperties.FORMAT.getName(), "format");
-		props.put(TikaCoreProperties.SUBJECT.getName(), "keyword");
+		props.put(TikaCoreProperties.KEYWORDS.getName(), "keyword");
 		
 		xmpMeta.setAll(props);
 		
 		assertEquals("format", xmpMeta.get(TikaCoreProperties.FORMAT));
 		
-		String[] values = xmpMeta.getValues(TikaCoreProperties.SUBJECT);
+		String[] values = xmpMeta.getValues(TikaCoreProperties.KEYWORDS);
 		assertEquals(1, values.length);
 		
 		assertEquals("keyword", values[0]);
@@ -241,9 +243,9 @@ public class XMPMetadataTest
 	@Test
 	public void set_arrayProperty_ok() 
 	{
-		xmpMeta.set(TikaCoreProperties.SUBJECT, new String[] {"keyword1", "keyword2"});
+		xmpMeta.set(TikaCoreProperties.KEYWORDS, new String[] {"keyword1", "keyword2"});
 
-		String[] values = xmpMeta.getValues(TikaCoreProperties.SUBJECT);
+		String[] values = xmpMeta.getValues(TikaCoreProperties.KEYWORDS);
 		assertEquals(2, values.length);
 		
 		checkArrayValues(values, "keyword");
@@ -273,11 +275,11 @@ public class XMPMetadataTest
 	{
 		xmpMeta.process(tikaMetadata);
 		
-		assertEquals(2, xmpMeta.size());
+		assertEquals(3, xmpMeta.size());
 		
 		xmpMeta.set(XMPRights.OWNER, "owner");
 		
-		assertEquals(3, xmpMeta.size());
+		assertEquals(4, xmpMeta.size());
 	}
 
 }

Commit:
352210be6b6eb0740ea2c16f291259cffeea7421
Jukka Zitting
jukka@apache.org
2012-07-02 22:45:42 +0000
TIKA-773: .NET version of Tika
diff --git a/tika-dotnet/pom.xml b/tika-dotnet/pom.xml
index ec3b1a538..8ab30adfc 100644
--- a/tika-dotnet/pom.xml
+++ b/tika-dotnet/pom.xml
@@ -35,8 +35,8 @@
 
   <properties>
     <ikvm>C:\ikvm-7.0.4335.0</ikvm>
-    <mscorlib>${ikvm}\mscorlib</mscorlib>
-    <System>${ikvm}\System</System>
+    <mscorlib.jar>${ikvm}\mscorlib.jar</mscorlib.jar>
+    <System.jar>${ikvm}\System.jar</System.jar>
   </properties>
 
   <dependencies>
@@ -50,14 +50,14 @@
       <artifactId>mscorlib</artifactId>
       <version>2.0</version>
       <scope>system</scope>
-      <systemPath>${mscorlib}.jar</systemPath>
+      <systemPath>${mscorlib.jar}</systemPath>
     </dependency>
     <dependency>
       <groupId>ikvm</groupId>
       <artifactId>System</artifactId>
       <version>2.0</version>
       <scope>system</scope>
-      <systemPath>${System}.jar</systemPath>
+      <systemPath>${System.jar}</systemPath>
     </dependency>
   </dependencies>
 
@@ -103,8 +103,6 @@
                   <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.Util.dll" />
                   <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.XML.API.dll" />
                   <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.XML.Transform.dll" />
-                  <arg value="-r:${mscorlib}.dll" />
-                  <arg value="-r:${System}.dll" />
                   <arg value="-target:library" />
                   <arg value="-compressresources" />
                   <arg value="-out:${project.build.directory}/${project.build.finalName}.dll" />

Commit:
63c2c69317e5cedb61d58e8ca995ba8dc3585c3e
Jukka Zitting
jukka@apache.org
2012-07-02 22:45:16 +0000
TIKA-756: XMP output from Tika CLI
diff --git a/pom.xml b/pom.xml
index 283cdc29a..c2ac30c47 100644
--- a/pom.xml
+++ b/pom.xml
@@ -48,7 +48,6 @@
     <module>tika-parent</module>
     <module>tika-core</module>
     <module>tika-parsers</module>
-    <module>tika-xmp</module>
     <module>tika-app</module>
     <module>tika-bundle</module>
     <module>tika-server</module>
@@ -89,6 +88,15 @@
   </build>
 
   <profiles>
+    <profile>
+      <id>java6</id>
+      <activation>
+        <jdk>[1.6,)</jdk>
+      </activation>
+      <modules>
+        <module>tika-xmp</module>
+      </modules>
+    </profile>
     <profile>
       <id>apache-release</id>
       <properties>

Commit:
75585bd7e137583c341df299c13ae22de0508730
Jukka Zitting
jukka@apache.org
2012-07-02 21:39:33 +0000
TIKA-773: .NET version of Tika
Commit:
23eb923e98ac1ee079834334d39a668f5bf231a3
Ray Gauss II
rgauss@apache.org
2012-07-02 18:55:44 +0000
TIKA-947: AbstractMetadataHandler addMetadata Does not Check Property.isMultiValuePermitted    - Added check for isMultiValuePermitted, if false call metadata.set instead of metadata.add
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/xml/AbstractMetadataHandler.java b/tika-parsers/src/main/java/org/apache/tika/parser/xml/AbstractMetadataHandler.java
index 1e87538ed..d36f79cfc 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/xml/AbstractMetadataHandler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/xml/AbstractMetadataHandler.java
@@ -70,7 +70,12 @@ class AbstractMetadataHandler extends DefaultHandler {
                 if (previous != null && previous.length() > 0) {
                     if (!previous.equals(value)) {
                        if (property != null) {
-                          metadata.add(property, value);
+                          if (property.isMultiValuePermitted()) {
+                              metadata.add(property, value);
+                          } else {
+                              // Replace the existing value if isMultiValuePermitted is false
+                              metadata.set(property, value);
+                          }
                        } else {
                           metadata.add(name, value);
                        }

Commit:
dfd8dc5b5b4b83361487ec3bcf5484ee405848ce
Jukka Zitting
jukka@apache.org
2012-07-02 13:57:57 +0000
TIKA-756: XMP output from Tika CLI
diff --git a/tika-xmp/pom.xml b/tika-xmp/pom.xml
index ebd8cd188..26ee6e5d2 100644
--- a/tika-xmp/pom.xml
+++ b/tika-xmp/pom.xml
@@ -32,7 +32,7 @@
   <artifactId>tika-xmp</artifactId>
   <packaging>bundle</packaging>
 
-  <name>Tika to XMP converter</name>
+  <name>Apache Tika XMP</name>
   <description>Converts Tika metadata to XMP</description>
 
   <build>

Commit:
6bc6c8877a8e6e8812c27794317ee4d18bd6c4ce
Jukka Zitting
jukka@apache.org
2012-07-02 13:48:02 +0000
TIKA-756: XMP output from Tika CLI
diff --git a/tika-app/src/main/appended-resources/META-INF/LICENSE b/tika-app/src/main/appended-resources/META-INF/LICENSE
index 86803f2e9..cd323bbca 100644
--- a/tika-app/src/main/appended-resources/META-INF/LICENSE
+++ b/tika-app/src/main/appended-resources/META-INF/LICENSE
@@ -391,3 +391,35 @@ XZ compression library (xz)
     public domain. You can do whatever you want with these files.
 
     This software is provided "as is", without any warranty.
+
+XMPCore library (xmpcore)
+
+    The BSD License
+
+    Copyright (c) 2009, Adobe Systems Incorporated  All rights reserved.
+
+    Redistribution and use in source and binary forms, with or without
+    modification, are permitted provided that the following conditions are met:
+
+    * Redistributions of source code must retain the above copyright notice,
+      this list of conditions and the following disclaimer.
+
+    * Redistributions in binary form must reproduce the above copyright
+      notice, this list of conditions and the following disclaimer in the
+      documentation and/or other materials provided with the distribution.
+
+    * Neither the name of Adobe Systems Incorporated, nor the names of its
+      contributors may be used to endorse or promote products derived from
+      this software without specific prior written permission.
+
+    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+    "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+    LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANT ABILITY AND FITNESS FOR
+    A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+    OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+    SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
+    TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+    PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+    LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+    NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+    SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

Commit:
87f40d27a8f4165727faa4060bcb33a07a8afdc8
Jukka Zitting
jukka@apache.org
2012-07-02 12:47:54 +0000
TIKA-756: XMP output from Tika CLI
diff --git a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/MSOfficeXMLConverter.java b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/MSOfficeXMLConverter.java
index 37edd4846..577dd0c21 100644
--- a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/MSOfficeXMLConverter.java
+++ b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/MSOfficeXMLConverter.java
@@ -94,7 +94,7 @@ public class MSOfficeXMLConverter extends AbstractConverter
 			}
 		}
 		
-		if( ! creatorTool.isEmpty() ) 
+		if( creatorTool.length() > 0 )
 		{
 			meta.setProperty(XMPConst.NS_XMP, "CreatorTool", creatorTool);
 		}

Commit:
a63b9b8a80d52c172d074ae6a7569ac0f5f42b5b
Jukka Zitting
jukka@apache.org
2012-07-02 12:26:09 +0000
TIKA-756: XMP output from Tika CLI
diff --git a/pom.xml b/pom.xml
index d8d7c96e2..283cdc29a 100644
--- a/pom.xml
+++ b/pom.xml
@@ -48,6 +48,7 @@
     <module>tika-parent</module>
     <module>tika-core</module>
     <module>tika-parsers</module>
+    <module>tika-xmp</module>
     <module>tika-app</module>
     <module>tika-bundle</module>
     <module>tika-server</module>
diff --git a/tika-app/src/main/java/org/apache/tika/cli/TikaCLI.java b/tika-app/src/main/java/org/apache/tika/cli/TikaCLI.java
index eef1eab36..8cc01480e 100644
--- a/tika-app/src/main/java/org/apache/tika/cli/TikaCLI.java
+++ b/tika-app/src/main/java/org/apache/tika/cli/TikaCLI.java
@@ -84,7 +84,6 @@ import org.apache.tika.parser.ParserDecorator;
 import org.apache.tika.parser.PasswordProvider;
 import org.apache.tika.parser.html.BoilerpipeContentHandler;
 import org.apache.tika.sax.BodyContentHandler;
-import org.apache.tika.sax.XMPContentHandler;
 import org.apache.tika.xmp.XMPMetadata;
 import org.xml.sax.ContentHandler;
 import org.xml.sax.SAXException;
@@ -218,11 +217,10 @@ public class TikaCLI {
     private final OutputType XMP = new OutputType() {
         @Override
         protected ContentHandler getContentHandler(
-                OutputStream output, final Metadata metadata) throws Exception 
-        {
-        	final PrintWriter writer = new PrintWriter(getOutputWriter(output, encoding));
-        	
-        	return new NoDocumentXMPMetaHandler(metadata, writer);
+                OutputStream output, final Metadata metadata) throws Exception {
+            final PrintWriter writer =
+                    new PrintWriter(getOutputWriter(output, encoding));
+            return new NoDocumentXMPMetaHandler(metadata, writer);
         }
     };
 
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/Property.java b/tika-core/src/main/java/org/apache/tika/metadata/Property.java
index 2fb338dc9..109706161 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/Property.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/Property.java
@@ -156,27 +156,24 @@ public final class Property implements Comparable<Property> {
      * @param key name of the property
      * @return the type of the property
      */
-    public static PropertyType getPropertyType(String key)
-    {
-    	PropertyType type = null;
-    	Property prop = properties.get(key);
-    	if( prop != null )
-    	{
-    		type = prop.getPropertyType();
-    	}
-    	return type;
+    public static PropertyType getPropertyType(String key) {
+        PropertyType type = null;
+        Property prop = properties.get(key);
+        if (prop != null) {
+            type = prop.getPropertyType();
+        }
+        return type;
     }
-    
+
     /**
      * Retrieve the property object that corresponds to the given key
      * @param key the property key or name
      * @return the Property object
      */
-    public static Property get(String key)
-    {
-    	return properties.get(key);
+    public static Property get(String key) {
+        return properties.get(key);
     }
-    
+
     public PropertyType getPropertyType() {
         return propertyType;
     }
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/PropertyTypeException.java b/tika-core/src/main/java/org/apache/tika/metadata/PropertyTypeException.java
index 5400b1f0a..44dbfd0ca 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/PropertyTypeException.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/PropertyTypeException.java
@@ -28,18 +28,23 @@ import org.apache.tika.metadata.Property.ValueType;
  * @since Apache Tika 0.8
  */
 public final class PropertyTypeException extends IllegalArgumentException {
-	public PropertyTypeException(String msg) {
-		super(msg);
-	}
+
+    public PropertyTypeException(String msg) {
+        super(msg);
+    }
+
     public PropertyTypeException(PropertyType expected, PropertyType found) {
         super("Expected a property of type " + expected + ", but received " + found);
     }
+
     public PropertyTypeException(ValueType expected, ValueType found) {
         super("Expected a property with a " + expected + " value, but received a " + found);
     }
+
     public PropertyTypeException(PropertyType unsupportedPropertyType) {
-    	super((unsupportedPropertyType != PropertyType.COMPOSITE) ? 
-    			(unsupportedPropertyType + " is not supported") : 
-    			("Composite Properties must not include other Composite Properties as either Primary or Secondary"));
+        super((unsupportedPropertyType != PropertyType.COMPOSITE)
+                ? unsupportedPropertyType + " is not supported"
+                : "Composite Properties must not include other Composite"
+                   + " Properties as either Primary or Secondary");
     }
 }
diff --git a/tika-xmp/pom.xml b/tika-xmp/pom.xml
index 48594119c..ebd8cd188 100644
--- a/tika-xmp/pom.xml
+++ b/tika-xmp/pom.xml
@@ -20,68 +20,67 @@
 -->
 
 <project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
-	<modelVersion>4.0.0</modelVersion>
-	
-	<parent>
-		<groupId>org.apache.tika</groupId>
-		<artifactId>tika-parent</artifactId>
-		<version>1.2-SNAPSHOT</version>
-		<relativePath>../tika-parent/pom.xml</relativePath>
-	</parent>
-	  
-	<artifactId>tika-xmp</artifactId>
-	<packaging>bundle</packaging>
-	  
-	<name>Tika to XMP converter</name>
-	<description>Converts Tika metadata to XMP</description>
-  
-	<build>
-	  <plugins>
-			<plugin>
-				<groupId>org.apache.felix</groupId>
-				<artifactId>maven-scr-plugin</artifactId>
-				<version>1.7.4</version>
-			</plugin>
-		  
-			<plugin><!-- builds the bundle -->
-				<groupId>org.apache.felix</groupId>
-				<artifactId>maven-bundle-plugin</artifactId>
-				<extensions>true</extensions>
-				<configuration>
-					<instructions>
-						<Export-Package>
-							org.apache.tika.xmp,
-							org.apache.tika.xmp.convert
-						</Export-Package>
-						<Private-Package/>
-					</instructions> 
-				</configuration>
-			</plugin>
-			
-		</plugins>
-    </build>
-	
-    <dependencies>
-		<dependency>
-			<groupId>${project.groupId}</groupId>
-            <artifactId>tika-core</artifactId>
-            <version>${project.version}</version>
-		</dependency>
-		<dependency>
-			<groupId>${project.groupId}</groupId>
-            <artifactId>tika-parsers</artifactId>
-            <version>${project.version}</version>
-		</dependency>
-		<dependency>
-			<groupId>com.adobe.xmp</groupId>
-			<artifactId>xmpcore</artifactId>
-			<version>5.1.1</version>
-		</dependency>
-		
-		<dependency>
-			<groupId>junit</groupId>
-			<artifactId>junit</artifactId>
-			<scope>test</scope>
-		</dependency>
-    </dependencies>
-</project>
\ No newline at end of file
+  <modelVersion>4.0.0</modelVersion>
+
+  <parent>
+    <groupId>org.apache.tika</groupId>
+    <artifactId>tika-parent</artifactId>
+    <version>1.2-SNAPSHOT</version>
+    <relativePath>../tika-parent/pom.xml</relativePath>
+  </parent>
+
+  <artifactId>tika-xmp</artifactId>
+  <packaging>bundle</packaging>
+
+  <name>Tika to XMP converter</name>
+  <description>Converts Tika metadata to XMP</description>
+
+  <build>
+    <plugins>
+      <plugin>
+        <groupId>org.apache.felix</groupId>
+        <artifactId>maven-scr-plugin</artifactId>
+        <version>1.7.4</version>
+      </plugin>
+      <plugin>
+        <!-- builds the bundle -->
+        <groupId>org.apache.felix</groupId>
+        <artifactId>maven-bundle-plugin</artifactId>
+        <extensions>true</extensions>
+        <configuration>
+          <instructions>
+            <Export-Package>
+              org.apache.tika.xmp,
+              org.apache.tika.xmp.convert
+            </Export-Package>
+            <Private-Package />
+          </instructions>
+        </configuration>
+      </plugin>
+    </plugins>
+  </build>
+
+  <dependencies>
+    <dependency>
+      <groupId>${project.groupId}</groupId>
+      <artifactId>tika-core</artifactId>
+      <version>${project.version}</version>
+    </dependency>
+    <dependency>
+      <groupId>${project.groupId}</groupId>
+      <artifactId>tika-parsers</artifactId>
+      <version>${project.version}</version>
+    </dependency>
+    <dependency>
+      <groupId>com.adobe.xmp</groupId>
+      <artifactId>xmpcore</artifactId>
+      <version>5.1.1</version>
+    </dependency>
+    <dependency>
+      <groupId>junit</groupId>
+      <artifactId>junit</artifactId>
+      <scope>test</scope>
+    </dependency>
+  </dependencies>
+
+</project>

Commit:
aa6c45eb3cae0ff0b74c67ba3273d579bde2f56f
Jukka Zitting
jukka@apache.org
2012-07-02 12:17:15 +0000
TIKA-756: XMP output from Tika CLI
diff --git a/tika-app/pom.xml b/tika-app/pom.xml
index e3cc85135..fd9ad57ac 100644
--- a/tika-app/pom.xml
+++ b/tika-app/pom.xml
@@ -43,6 +43,11 @@
       <artifactId>tika-parsers</artifactId>
       <version>${project.version}</version>
     </dependency>
+    <dependency>
+      <groupId>${project.groupId}</groupId>
+      <artifactId>tika-xmp</artifactId>
+      <version>${project.version}</version>
+    </dependency>
     <dependency>
       <groupId>org.slf4j</groupId>
       <artifactId>slf4j-log4j12</artifactId>
diff --git a/tika-app/src/main/java/org/apache/tika/cli/TikaCLI.java b/tika-app/src/main/java/org/apache/tika/cli/TikaCLI.java
index fd5c2ee8e..eef1eab36 100644
--- a/tika-app/src/main/java/org/apache/tika/cli/TikaCLI.java
+++ b/tika-app/src/main/java/org/apache/tika/cli/TikaCLI.java
@@ -16,7 +16,16 @@
  */
 package org.apache.tika.cli;
 
-import java.io.*;
+import java.io.File;
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.OutputStream;
+import java.io.OutputStreamWriter;
+import java.io.PrintStream;
+import java.io.PrintWriter;
+import java.io.UnsupportedEncodingException;
+import java.io.Writer;
 import java.lang.reflect.Field;
 import java.net.ServerSocket;
 import java.net.Socket;
@@ -53,6 +62,7 @@ import org.apache.tika.config.TikaConfig;
 import org.apache.tika.detect.CompositeDetector;
 import org.apache.tika.detect.DefaultDetector;
 import org.apache.tika.detect.Detector;
+import org.apache.tika.exception.TikaException;
 import org.apache.tika.extractor.EmbeddedDocumentExtractor;
 import org.apache.tika.fork.ForkParser;
 import org.apache.tika.gui.TikaGUI;
@@ -75,6 +85,7 @@ import org.apache.tika.parser.PasswordProvider;
 import org.apache.tika.parser.html.BoilerpipeContentHandler;
 import org.apache.tika.sax.BodyContentHandler;
 import org.apache.tika.sax.XMPContentHandler;
+import org.apache.tika.xmp.XMPMetadata;
 import org.xml.sax.ContentHandler;
 import org.xml.sax.SAXException;
 import org.xml.sax.helpers.DefaultHandler;
@@ -207,18 +218,11 @@ public class TikaCLI {
     private final OutputType XMP = new OutputType() {
         @Override
         protected ContentHandler getContentHandler(
-                OutputStream output, final Metadata metadata) throws Exception {
-            final ContentHandler handler =
-                    getTransformerHandler(output, "xml", encoding, prettyPrint);
-            return new DefaultHandler() {
-                @Override
-                public void endDocument() throws SAXException {
-                    XMPContentHandler xmp = new XMPContentHandler(handler);
-                    xmp.startDocument();
-                    xmp.metadata(metadata);
-                    xmp.endDocument();
-                }
-            };
+                OutputStream output, final Metadata metadata) throws Exception 
+        {
+        	final PrintWriter writer = new PrintWriter(getOutputWriter(output, encoding));
+        	
+        	return new NoDocumentXMPMetaHandler(metadata, writer);
         }
     };
 
@@ -832,6 +836,38 @@ public class TikaCLI {
         
     }
 
+    /**
+     * Outputs the Tika metadata as XMP using the Tika XMP module
+     */
+    private class NoDocumentXMPMetaHandler extends DefaultHandler
+    {
+    	protected final Metadata metadata;
+    	
+        protected PrintWriter writer;
+        
+        public NoDocumentXMPMetaHandler(Metadata metadata, PrintWriter writer){
+        	this.metadata = metadata;
+            this.writer = writer;
+        }
+        
+        @Override
+        public void endDocument() throws SAXException 
+        {
+        	try 
+        	{
+        		XMPMetadata xmp = new XMPMetadata(metadata);
+        		String result;
+        		result = xmp.toString();
+        		writer.write(result);
+        		writer.flush();
+        	} 
+        	catch (TikaException e) 
+        	{
+        		throw new SAXException(e);
+        	}
+        }
+    }
+    
     /**
      * Uses GSON to do the JSON escaping, but does
      *  the general JSON glueing ourselves.
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/Property.java b/tika-core/src/main/java/org/apache/tika/metadata/Property.java
index 0149c07d3..2fb338dc9 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/Property.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/Property.java
@@ -151,6 +151,32 @@ public final class Property implements Comparable<Property> {
         return false;
     }
 
+    /**
+     * Get the type of a property
+     * @param key name of the property
+     * @return the type of the property
+     */
+    public static PropertyType getPropertyType(String key)
+    {
+    	PropertyType type = null;
+    	Property prop = properties.get(key);
+    	if( prop != null )
+    	{
+    		type = prop.getPropertyType();
+    	}
+    	return type;
+    }
+    
+    /**
+     * Retrieve the property object that corresponds to the given key
+     * @param key the property key or name
+     * @return the Property object
+     */
+    public static Property get(String key)
+    {
+    	return properties.get(key);
+    }
+    
     public PropertyType getPropertyType() {
         return propertyType;
     }
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/PropertyTypeException.java b/tika-core/src/main/java/org/apache/tika/metadata/PropertyTypeException.java
index cf9b662f4..5400b1f0a 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/PropertyTypeException.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/PropertyTypeException.java
@@ -28,6 +28,9 @@ import org.apache.tika.metadata.Property.ValueType;
  * @since Apache Tika 0.8
  */
 public final class PropertyTypeException extends IllegalArgumentException {
+	public PropertyTypeException(String msg) {
+		super(msg);
+	}
     public PropertyTypeException(PropertyType expected, PropertyType found) {
         super("Expected a property of type " + expected + ", but received " + found);
     }
diff --git a/tika-xmp/pom.xml b/tika-xmp/pom.xml
new file mode 100644
index 000000000..48594119c
--- /dev/null
+++ b/tika-xmp/pom.xml
@@ -0,0 +1,87 @@
+<?xml version="1.0" encoding="UTF-8"?>
+
+<!--
+  Licensed to the Apache Software Foundation (ASF) under one
+  or more contributor license agreements.  See the NOTICE file
+  distributed with this work for additional information
+  regarding copyright ownership.  The ASF licenses this file
+  to you under the Apache License, Version 2.0 (the
+  "License"); you may not use this file except in compliance
+  with the License.  You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+  Unless required by applicable law or agreed to in writing,
+  software distributed under the License is distributed on an
+  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+  KIND, either express or implied.  See the License for the
+  specific language governing permissions and limitations
+  under the License.
+-->
+
+<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
+	<modelVersion>4.0.0</modelVersion>
+	
+	<parent>
+		<groupId>org.apache.tika</groupId>
+		<artifactId>tika-parent</artifactId>
+		<version>1.2-SNAPSHOT</version>
+		<relativePath>../tika-parent/pom.xml</relativePath>
+	</parent>
+	  
+	<artifactId>tika-xmp</artifactId>
+	<packaging>bundle</packaging>
+	  
+	<name>Tika to XMP converter</name>
+	<description>Converts Tika metadata to XMP</description>
+  
+	<build>
+	  <plugins>
+			<plugin>
+				<groupId>org.apache.felix</groupId>
+				<artifactId>maven-scr-plugin</artifactId>
+				<version>1.7.4</version>
+			</plugin>
+		  
+			<plugin><!-- builds the bundle -->
+				<groupId>org.apache.felix</groupId>
+				<artifactId>maven-bundle-plugin</artifactId>
+				<extensions>true</extensions>
+				<configuration>
+					<instructions>
+						<Export-Package>
+							org.apache.tika.xmp,
+							org.apache.tika.xmp.convert
+						</Export-Package>
+						<Private-Package/>
+					</instructions> 
+				</configuration>
+			</plugin>
+			
+		</plugins>
+    </build>
+	
+    <dependencies>
+		<dependency>
+			<groupId>${project.groupId}</groupId>
+            <artifactId>tika-core</artifactId>
+            <version>${project.version}</version>
+		</dependency>
+		<dependency>
+			<groupId>${project.groupId}</groupId>
+            <artifactId>tika-parsers</artifactId>
+            <version>${project.version}</version>
+		</dependency>
+		<dependency>
+			<groupId>com.adobe.xmp</groupId>
+			<artifactId>xmpcore</artifactId>
+			<version>5.1.1</version>
+		</dependency>
+		
+		<dependency>
+			<groupId>junit</groupId>
+			<artifactId>junit</artifactId>
+			<scope>test</scope>
+		</dependency>
+    </dependencies>
+</project>
\ No newline at end of file
diff --git a/tika-xmp/src/main/java/org/apache/tika/xmp/XMPMetadata.java b/tika-xmp/src/main/java/org/apache/tika/xmp/XMPMetadata.java
new file mode 100644
index 000000000..30cfad19d
--- /dev/null
+++ b/tika-xmp/src/main/java/org/apache/tika/xmp/XMPMetadata.java
@@ -0,0 +1,753 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * IPTC Metadata Descriptions taken from the IPTC Photo Metadata (July 2010) 
+ * standard. These parts Copyright 2010 International Press Telecommunications 
+ * Council.
+ */
+package org.apache.tika.xmp;
+
+import java.io.IOException;
+import java.io.NotSerializableException;
+import java.io.ObjectInputStream;
+import java.io.ObjectOutputStream;
+import java.util.Calendar;
+import java.util.Date;
+import java.util.Enumeration;
+import java.util.Map;
+import java.util.Properties;
+
+import org.apache.tika.exception.TikaException;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.Property;
+import org.apache.tika.metadata.Property.PropertyType;
+import org.apache.tika.metadata.PropertyTypeException;
+import org.apache.tika.xmp.convert.TikaToXMP;
+
+import com.adobe.xmp.XMPDateTime;
+import com.adobe.xmp.XMPException;
+import com.adobe.xmp.XMPIterator;
+import com.adobe.xmp.XMPMeta;
+import com.adobe.xmp.XMPMetaFactory;
+import com.adobe.xmp.XMPSchemaRegistry;
+import com.adobe.xmp.XMPUtils;
+import com.adobe.xmp.options.IteratorOptions;
+import com.adobe.xmp.options.PropertyOptions;
+import com.adobe.xmp.options.SerializeOptions;
+import com.adobe.xmp.properties.XMPProperty;
+
+/**
+ * Provides a conversion of the Metadata map from Tika to the XMP data model
+ * by also providing the Metadata API for clients to ease transition.
+ * But clients can also work directly on the XMP data model, by getting the XMPMeta 
+ * reference from this class.
+ * Usually the instance would be initialized by providing the Metadata object that
+ * had been returned from Tika-core which populates the XMP data model with
+ * all properties that can be converted.
+ * 
+ * This class is not serializable!
+ */
+@SuppressWarnings("serial")
+public class XMPMetadata extends Metadata
+{
+	/** The XMP data */
+	private XMPMeta xmpData;
+	/** Use the XMP namespace registry implementation */
+	private static final XMPSchemaRegistry registry = XMPMetaFactory.getSchemaRegistry();
+
+	/**
+	 *  Initializes with an empty XMP packet 
+	 */
+    public XMPMetadata() 
+    {
+    	xmpData = XMPMetaFactory.create();
+    }
+    
+	/**
+     * @see org.apache.tika.xmp.XMPMetadata(org.apache.tika.metadata.Metadata, java.lang.String)
+	 * But the mimetype is retrieved from the metadata map.
+	 */
+    public XMPMetadata (Metadata meta) throws TikaException
+    {
+    	this.xmpData = TikaToXMP.convert(meta);
+    }
+    
+    /**
+     * Initializes the data by converting the Metadata information to XMP.
+     * If a mimetype is provided, a specific converter can be used, that converts all
+     * available metadata. If there is no mimetype provided or no specific converter 
+     * available a generic conversion is done which will convert only those properties 
+     * that are in known namespaces and are using the correct prefixes
+     * 
+     * @param meta the Metadata information from Tika-core
+     * @param mimetype mimetype information
+     * @throws In case an error occured during conversion
+     */
+    public XMPMetadata (Metadata meta, String mimetype) throws TikaException
+    {
+    	this.xmpData = TikaToXMP.convert(meta, mimetype);
+    }
+    
+    /**
+     * @see org.apache.tika.xmp.XMPMetadata#process(org.apache.tika.metadata.Metadata, java.lang.String)
+	 * But the mimetype is retrieved from the metadata map.
+	 */
+    public void process(Metadata meta) throws TikaException
+    {  
+    	this.xmpData = TikaToXMP.convert(meta);
+    }
+
+    /**
+     * Converts the Metadata information to XMP.
+     * If a mimetype is provided, a specific converter can be used, that converts all
+     * available metadata. If there is no mimetype provided or no specific converter 
+     * available a generic conversion is done which will convert only those properties 
+     * that are in known namespaces and are using the correct prefixes
+     * 
+     * @param meta the Metadata information from Tika-core
+     * @param mimetype mimetype information
+     * @throws In case an error occured during conversion
+     */
+    public void process(Metadata meta, String mimetype) throws TikaException
+    {  
+    	this.xmpData = TikaToXMP.convert(meta, mimetype);
+    }
+
+    
+    /**
+     * Provides direct access to the XMP data model, in case a client prefers to work directly on it
+     * instead of using the Metadata API
+     * @return the "internal" XMP data object
+     */
+    public XMPMeta getXMPData() { return xmpData; }
+
+    
+    // === Namespace Registry API === //
+    /**
+	 * Register a namespace URI with a suggested prefix. It is not an error if
+	 * the URI is already registered, no matter what the prefix is. If the URI
+	 * is not registered but the suggested prefix is in use, a unique prefix is
+	 * created from the suggested one. The actual registeed prefix is always
+	 * returned. The function result tells if the registered prefix is the
+	 * suggested one.
+	 * <p>
+	 * Note: No checking is presently done on either the URI or the prefix.
+	 *
+	 * @param namespaceURI
+	 *            The URI for the namespace. Must be a valid XML URI.
+	 * @param suggestedPrefix
+	 *            The suggested prefix to be used if the URI is not yet
+	 *            registered. Must be a valid XML name.
+	 * @return Returns the registered prefix for this URI, is equal to the
+	 *         suggestedPrefix if the namespace hasn't been registered before,
+	 *         otherwise the existing prefix.
+	 * @throws XMPException If the parameters are not accordingly set
+	 */
+	public static String registerNamespace(String namespaceURI, String suggestedPrefix) throws XMPException
+	{
+		return registry.registerNamespace(namespaceURI, suggestedPrefix);
+	}
+
+	/**
+	 * Obtain the prefix for a registered namespace URI.
+	 * <p>
+	 * It is not an error if the namespace URI is not registered.
+	 *
+	 * @param namespaceURI
+	 *            The URI for the namespace. Must not be null or the empty
+	 *            string.
+	 * @return Returns the prefix registered for this namespace URI or null.
+	 */
+	public static String getNamespacePrefix(String namespaceURI)
+	{
+		return registry.getNamespacePrefix(namespaceURI);
+	}
+
+
+	/**
+	 * Obtain the URI for a registered namespace prefix.
+	 * <p>
+	 * It is not an error if the namespace prefix is not registered.
+	 *
+	 * @param namespacePrefix
+	 *            The prefix for the namespace. Must not be null or the empty
+	 *            string.
+	 * @return Returns the URI registered for this prefix or null.
+	 */
+	public static String getNamespaceURI(String namespacePrefix)
+	{
+		return registry.getNamespaceURI(namespacePrefix);
+	}
+
+
+	/**
+	 * @return Returns the registered prefix/namespace-pairs as map, where the keys are the
+	 *         namespaces and the values are the prefixes.
+	 */
+	@SuppressWarnings("unchecked")
+	public static Map<String, String> getNamespaces()
+	{
+		return registry.getNamespaces();
+	}
+
+
+	/**
+	 * @return Returns the registered namespace/prefix-pairs as map, where the keys are the
+	 *         prefixes and the values are the namespaces.
+	 */
+	@SuppressWarnings("unchecked")
+	public static Map<String, String> getPrefixes()
+	{
+		return registry.getPrefixes();
+	}
+
+	/**
+	 * Deletes a namespace from the registry.
+	 * <p>
+	 * Does nothing if the URI is not registered, or if the namespaceURI
+	 * parameter is null or the empty string.
+	 * <p>
+	 * Note: Not yet implemented.
+	 *
+	 * @param namespaceURI
+	 *            The URI for the namespace.
+	 */
+	public static void deleteNamespace(String namespaceURI)
+	{
+		registry.deleteNamespace(namespaceURI);
+	}
+	
+	
+	// === Metadata API === //
+	/**
+	 * @see org.apache.tika.xmp.XMPMetadata#isMultiValued(java.lang.String)
+	 */
+	@Override
+	public boolean isMultiValued(Property property) 
+	{
+		return this.isMultiValued(property.getName());
+	}
+
+	/**
+	 * Checks if the named property is an array.
+	 * @see org.apache.tika.metadata.Metadata#isMultiValued(java.lang.String)
+	 */
+	@Override
+	public boolean isMultiValued(String name)
+	{
+		checkKey(name);
+
+		String[] keyParts = splitKey(name);
+			
+		String ns = registry.getNamespaceURI(keyParts[0]);
+		if( ns != null )
+		{
+			try 
+			{
+				XMPProperty prop = xmpData.getProperty(ns, keyParts[1]);
+				
+				return prop.getOptions().isArray();
+			} 
+			catch (XMPException e) 
+			{
+				// Ignore
+			}
+		}
+		
+		return false;
+	}
+
+	/**
+	 * For XMP it is not clear what that API should return, therefor not implemented
+	 */
+	@Override
+	public String[] names() 
+	{
+		throw new UnsupportedOperationException("Not implemented");
+	}
+
+	/**
+	 * Returns the value of a simple property or the first one of an array. 
+	 * The given name must contain a namespace prefix of a registered namespace.
+	 * 
+	 * @see org.apache.tika.metadata.Metadata#get(java.lang.String)
+	 */
+	@Override
+	public String get(String name) 
+	{
+		checkKey(name);
+
+		String value = null;
+		String[] keyParts = splitKey(name);
+		
+		String ns = registry.getNamespaceURI(keyParts[0]);
+		if( ns != null )
+		{
+			try 
+			{
+				XMPProperty prop = xmpData.getProperty(ns, keyParts[1]);
+				
+				if( prop != null && prop.getOptions().isSimple() )
+				{
+					value = prop.getValue();
+				}
+				else if( prop != null && prop.getOptions().isArray() )
+				{
+					prop = xmpData.getArrayItem(ns, keyParts[1], 1);
+					value = prop.getValue();
+				}
+				// in all other cases, null is returned
+			} 
+			catch (XMPException e) 
+			{
+				// Ignore
+			}
+		}
+		
+		return value;
+	}
+
+	/**
+	 * @see org.apache.tika.xmp.XMPMetadata#get(java.lang.String)
+	 */
+	@Override
+	public String get(Property property) {
+		return this.get(property.getName());
+	}
+
+	/**
+	 * @see org.apache.tika.xmp.XMPMetadata#get(java.lang.String)
+	 */
+	@Override
+	public Integer getInt(Property property) 
+	{
+		Integer result = null;
+		
+		try 
+		{
+			result = new Integer(XMPUtils.convertToInteger(this.get(property.getName())));
+		} 
+		catch (XMPException e) 
+		{
+			//Ignore
+		}
+		
+		return result;
+	}
+
+	/**
+	 * @see org.apache.tika.xmp.XMPMetadata#get(java.lang.String)
+	 */
+	@Override
+	public Date getDate(Property property) 
+	{
+		Date result = null;
+		
+		try 
+		{
+			XMPDateTime xmpDate = XMPUtils.convertToDate(this.get(property.getName()));
+			if (xmpDate != null)
+			{
+				Calendar cal = xmpDate.getCalendar();
+				// TODO Timezone is currently lost
+				// need another solution that preserves the timezone
+				result = cal.getTime();
+			}
+		} 
+		catch (XMPException e) 
+		{
+			//Ignore
+		}
+		
+		return result;
+	}
+
+	/**
+	 * @see org.apache.tika.xmp.XMPMetadata#getValues(java.lang.String)
+	 */
+	@Override
+	public String[] getValues(Property property) 
+	{
+		return this.getValues(property.getName());
+	}
+
+	/**
+	 * Returns the value of a simple property or all if the property is an array and the elements are of simple type. 
+	 * The given name must contain a namespace prefix of a registered namespace.
+	 * @see org.apache.tika.metadata.Metadata#getValues(java.lang.String)
+	 */
+	@Override
+	public String[] getValues(String name) {
+		checkKey(name);
+
+		String[] value = null;
+		String[] keyParts = splitKey(name);
+		
+		String ns = registry.getNamespaceURI(keyParts[0]);
+		if( ns != null )
+		{
+			try
+			{
+				XMPProperty prop = xmpData.getProperty(ns, keyParts[1]);
+				
+				if( prop != null && prop.getOptions().isSimple() )
+				{
+					value = new String[1];
+					value[0] = prop.getValue();
+				}
+				else if( prop != null && prop.getOptions().isArray() )
+				{
+					int size = xmpData.countArrayItems(ns, keyParts[1]);
+					value = new String[size];
+					boolean onlySimpleChildren = true;
+					
+					for( int i = 0 ; i < size && onlySimpleChildren ; i++)
+					{
+						prop = xmpData.getArrayItem(ns, keyParts[1], i+1);
+						if( prop.getOptions().isSimple() )
+						{
+							value[i] = prop.getValue();
+						}
+						else
+						{
+							onlySimpleChildren = false;
+						}
+					}
+					
+					if( ! onlySimpleChildren )
+					{
+						value = null;
+					}
+				}
+				// in all other cases, null is returned
+			} 
+			catch (XMPException e) 
+			{
+				// Ignore
+			}
+		}
+		
+		return value;
+	}
+
+
+
+	/**
+	 * As this API could only possibly work for simple properties in XMP,
+	 * it just calls the set method, which replaces any existing value
+	 * @see org.apache.tika.metadata.Metadata#add(java.lang.String, java.lang.String)
+	 */
+	@Override
+	public void add(String name, String value) 
+	{
+		set(name, value);
+	}
+
+	/**
+	 * Sets the given property. If the property already exists, it is overwritten. 
+	 * Only simple properties that use a registered prefix are stored in the XMP.
+	 *  
+	 * @see org.apache.tika.metadata.Metadata#set(java.lang.String, java.lang.String)
+	 */
+	@Override
+	public void set(String name, String value) 
+	{
+		checkKey(name);
+		
+		String[] keyParts = splitKey(name);
+		
+		String ns = registry.getNamespaceURI(keyParts[0]);
+		if( ns != null )
+		{
+			try 
+			{
+				xmpData.setProperty(ns, keyParts[1], value);
+			} 
+			catch (XMPException e) 
+			{
+				// Ignore
+			}
+		}
+	}
+
+	/**
+	 * @see org.apache.tika.xmp.XMPMetadata#set(java.lang.String, java.lang.String)
+	 */
+	@Override
+	public void set(Property property, String value) 
+	{
+		this.set(property.getName(), value);
+	}
+	
+	/**
+	 * @see org.apache.tika.xmp.XMPMetadata#set(java.lang.String, java.lang.String)
+	 */
+	@Override
+	public void set(Property property, int value) 
+	{
+		// Can reuse the checks from the base class implementation which will call 
+		// the set(String, String) method in the end 
+		super.set(property, value);
+	}
+	
+	/**
+	 * @see org.apache.tika.xmp.XMPMetadata#set(java.lang.String, java.lang.String)
+	 */
+	@Override
+	public void set(Property property, double value) 
+	{
+		super.set(property, value);
+	}
+	
+	/**
+	 * @see org.apache.tika.xmp.XMPMetadata#set(java.lang.String, java.lang.String)
+	 */
+	@Override
+	public void set(Property property, Date date) 
+	{
+		super.set(property, date);
+	}
+	
+	/**
+	 * Sets array properties. If the property already exists, it is overwritten. 
+	 * Only array properties that use a registered prefix are stored in the XMP.
+	 * @see org.apache.tika.metadata.Metadata#set(org.apache.tika.metadata.Property, java.lang.String[])
+	 */
+	@Override
+	public void set(Property property, String[] values) 
+	{
+		checkKey(property.getName());
+	
+		if(	! property.isMultiValuePermitted() ) 
+		{
+            throw new PropertyTypeException("Property is not of an array type");
+        }
+		
+		String[] keyParts = splitKey(property.getName());
+		
+		String ns = registry.getNamespaceURI(keyParts[0]);
+		if( ns != null )
+		{
+			try 
+			{
+				int arrayType = tikaToXMPArrayType(property.getPrimaryProperty().getPropertyType());
+				xmpData.setProperty(ns, keyParts[1], null, new PropertyOptions(arrayType));
+				
+				for( String value : values )
+				{
+					xmpData.appendArrayItem(ns, keyParts[1], value);
+				}
+			} 
+			catch (XMPException e) 
+			{
+				// Ignore
+			}
+		}
+	}
+	
+	/**
+	 * It will set all simple and array properties that have QName keys in registered namespaces.
+	 * @see org.apache.tika.metadata.Metadata#setAll(java.util.Properties)
+	 */
+	@Override
+	public void setAll(Properties properties) 
+	{
+		@SuppressWarnings("unchecked")
+		Enumeration<String> names = (Enumeration<String>) properties.propertyNames();
+        
+		while (names.hasMoreElements()) 
+		{
+            String name = names.nextElement();
+            Property property = Property.get(name);
+            if( property == null )
+            {
+            	throw new PropertyTypeException("Unknown property: " + name);
+            }
+            
+            String value = properties.getProperty(name);
+            
+            if( property.isMultiValuePermitted() )
+            {
+            	this.set(property,  new String[] { value });
+            }
+            else
+            {
+            	this.set(property, value);
+            }
+        }
+	}
+
+
+	/**
+	 * @see org.apache.tika.xmp.XMPMetadata#remove(java.lang.String)
+	 */
+	public void remove(Property property) 
+	{
+		this.remove(property.getName());
+	}
+	
+	/**
+	 * Removes the given property from the XMP data. 
+	 * If it is a complex property the whole subtree is removed
+	 * @see org.apache.tika.metadata.Metadata#remove(java.lang.String)
+	 */
+	@Override
+	public void remove(String name) 
+	{
+		checkKey(name);
+		
+		String[] keyParts = splitKey(name);
+			
+		String ns = registry.getNamespaceURI(keyParts[0]);
+		if( ns != null )
+		{
+			xmpData.deleteProperty(ns, keyParts[1]);
+		}
+	}
+	
+	/**
+	 * Returns the number of top-level namespaces
+	 */
+	@Override
+	public int size() 
+	{
+		int size = 0;
+
+		try 
+		{
+			// Get an iterator for the XMP packet, starting at the top level schema nodes
+			XMPIterator nsIter = xmpData.iterator( new IteratorOptions().setJustChildren(true).setOmitQualifiers(true) );
+			// iterate all top level namespaces
+			while (nsIter.hasNext())
+			{
+				nsIter.next();
+				size++;
+			}
+		} 
+		catch (XMPException e) 
+		{
+			// ignore
+		}
+		
+		return size;
+	}
+
+	/**
+	 * This method is not implemented, yet. It is very tedious to check for semantic equality of XMP packets
+	 */
+	@Override
+	public boolean equals(Object o) 
+	{
+		throw new UnsupportedOperationException("Not implemented");
+	}
+
+	/**
+	 * Serializes the XMP data in compact form without packet wrapper
+	 * @see org.apache.tika.metadata.Metadata#toString()
+	 */
+	@Override
+	public String toString() 
+	{
+		String result = null;
+		try 
+		{
+			result = XMPMetaFactory.serializeToString(xmpData, new SerializeOptions().setOmitPacketWrapper(true).setUseCompactFormat(true));
+		} 
+		catch (XMPException e) 
+		{
+			// ignore
+		}
+		return result;
+	}
+
+	// The XMP object is not serializable!
+	private void readObject(ObjectInputStream ois) throws ClassNotFoundException, IOException 
+	{
+		throw new NotSerializableException();
+	}
+
+	// The XMP object is not serializable!
+	private void writeObject(ObjectOutputStream ois) throws IOException 
+	{
+		throw new NotSerializableException();
+	}
+
+	/**
+	 * Checks if the given key is a valid QName with a known standard namespace prefix
+	 * 
+	 * @param key
+	 *            the key to check
+	 * @return true if the key is valid otherwise false
+	 */
+	private void checkKey(String key) throws PropertyTypeException
+	{
+		if( key == null || key.length() == 0 )
+		{
+			throw new PropertyTypeException("Key must not be null");
+		}
+		
+		String[] keyParts = splitKey(key);
+		if( keyParts == null )
+		{
+			throw new PropertyTypeException("Key must be a QName in the form prefix:localName");
+		}
+
+		if( registry.getNamespaceURI(keyParts[0]) == null )
+		{
+			throw new PropertyTypeException("Key does not use a registered Namespace prefix");
+		}
+	}
+	
+	/**
+	 * Split the given key at the namespace prefix delimiter
+	 * @param key the key to split
+	 * @return prefix and local name of the property or null if the key did not
+	 * contain a delimiter or too much of them
+	 */
+	private String[] splitKey(String key)
+	{
+		String[] keyParts = key.split(Metadata.NAMESPACE_PREFIX_DELIMITER);
+		if (keyParts.length > 0 && keyParts.length <= 2)
+		{
+			return keyParts;
+		}
+		
+		return null;
+	}// checkKeyPrefix
+
+	/**
+	 * Convert Tika array types to XMP array types
+	 * @param type
+	 * @return
+	 */
+	private int tikaToXMPArrayType(PropertyType type)
+	{
+		int result = 0;
+		switch(type)
+		{
+			case BAG:
+				result = PropertyOptions.ARRAY;
+				break;
+			case SEQ:
+				result = PropertyOptions.ARRAY_ORDERED;
+				break;
+			case ALT:
+				result = PropertyOptions.ARRAY_ALTERNATE;
+				break;
+		}
+		return result;
+	}
+}
diff --git a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/AbstractConverter.java b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/AbstractConverter.java
new file mode 100644
index 000000000..121404d73
--- /dev/null
+++ b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/AbstractConverter.java
@@ -0,0 +1,199 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * IPTC Metadata Descriptions taken from the IPTC Photo Metadata (July 2010) 
+ * standard. These parts Copyright 2010 International Press Telecommunications 
+ * Council.
+ */
+package org.apache.tika.xmp.convert;
+
+import java.util.Set;
+
+import org.apache.tika.exception.TikaException;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.Property;
+
+import com.adobe.xmp.XMPConst;
+import com.adobe.xmp.XMPException;
+import com.adobe.xmp.XMPMeta;
+import com.adobe.xmp.XMPMetaFactory;
+import com.adobe.xmp.XMPSchemaRegistry;
+import com.adobe.xmp.XMPUtils;
+import com.adobe.xmp.options.PropertyOptions;
+
+/**
+ * Base class for Tika Metadata to XMP converter which provides some needed
+ * common functionality.
+ */
+public abstract class AbstractConverter implements ITikaToXMPConverter
+{
+	private Metadata metadata;
+	protected XMPMeta meta;
+
+	abstract public XMPMeta process(Metadata metadata) throws XMPException;
+	
+	/**
+	 * Every Converter has to provide information about namespaces
+	 * that are used additionally to the core set of XMP namespaces.
+	 * 
+	 * @return the additional namespace information
+	 */
+	abstract protected Set<Namespace> getAdditionalNamespaces();
+	
+	public AbstractConverter() throws TikaException
+	{
+		meta = XMPMetaFactory.create();
+		metadata = new Metadata();
+		registerNamespaces(getAdditionalNamespaces());
+	}
+
+	public void setMetadata(Metadata metadata)
+	{
+		this.metadata = metadata;
+	}
+
+	public XMPMeta getXMPMeta()
+	{
+		return meta;
+	}
+
+	// --- utility methods used by sub-classes ---
+	
+	/** 
+	 * Registers a number <code>Namespace</code> information with XMPCore.
+	 * Any already registered namespace is not registered again.
+	 * 
+	 * @param namespaces the list of namespaces to be registered
+	 * @throws TikaException in case a namespace oculd not be registered
+	 */
+	protected void registerNamespaces(Set<Namespace> namespaces) throws TikaException
+	{
+		XMPSchemaRegistry registry = XMPMetaFactory.getSchemaRegistry();
+
+		for( Namespace namespace : namespaces)
+		{
+			// Any already registered namespace is not registered again
+			try 
+			{
+				registry.registerNamespace(namespace.uri, namespace.prefix);
+			} 
+			catch (XMPException e) 
+			{
+				throw new TikaException("Namespace needed by converter could not be registiered with XMPCore", e);
+			}
+		}
+	}
+	
+	/**
+	 * @see AbstractConverter#createProperty(String, String, String);
+	 */
+	protected void createProperty(Property metadataProperty, String ns, String propertyName) throws XMPException
+	{
+		createProperty(metadataProperty.getName(), ns, propertyName);
+	}
+
+	/**
+	 * Creates a simple property.
+	 * @param tikaKey Key in the Tika metadata map
+	 * @param ns namespace the property should be created in
+	 * @param propertyName name of the property
+	 * @throws XMPException if the property could not be created
+	 */
+	protected void createProperty(String tikaKey, String ns, String propertyName) throws XMPException
+	{
+		String value = metadata.get(tikaKey);
+		if (value != null  &&  value.length() > 0)
+		{
+			meta.setProperty(ns, propertyName, value);
+		}
+	}
+
+	/**
+	 * @see AbstractConverter#createLangAltProperty(String, String, String);
+	 */
+	protected void createLangAltProperty(Property metadataProperty, String ns, String propertyName) throws XMPException
+	{
+		createLangAltProperty(metadataProperty.getName(), ns, propertyName);
+	}
+	
+	/**
+	 * Creates a language alternative property in the x-default language
+	 * @param tikaKey Key in the Tika metadata map
+	 * @param ns namespace the property should be created in
+	 * @param propertyName name of the property
+	 * @throws XMPException if the property could not be created
+	 */
+	protected void createLangAltProperty(String tikaKey, String ns, String propertyName) throws XMPException
+	{
+		String value = metadata.get(tikaKey);
+		if (value != null  &&  value.length() > 0)
+		{
+			meta.setLocalizedText(ns, propertyName, null, XMPConst.X_DEFAULT, value);
+		}
+	}
+
+	protected void createArrayProperty(Property metadataProperty, String nsDc, String arrayProperty, int arrayType) throws XMPException
+	{
+		createArrayProperty(metadataProperty.getName(), nsDc, arrayProperty, arrayType);
+	}
+	
+	/**
+	 * Creates an array property from a list of values.
+	 * @param tikaKey Key in the Tika metadata map
+	 * @param ns namespace the property should be created in
+	 * @param propertyName name of the property
+	 * @param arrayType depicts which kind of array shall be created
+	 * @throws XMPException if the property could not be created
+	 */
+	protected void createArrayProperty(String tikaKey, String ns, String propertyName, int arrayType) throws XMPException
+	{
+		String[] values = metadata.getValues(tikaKey);
+		if (values != null)
+		{
+			meta.setProperty(ns, propertyName, null, new PropertyOptions(arrayType));
+			for( String value : values )
+			{
+				meta.appendArrayItem( ns, propertyName, value );
+			}
+		}
+	}
+	
+	protected void createCommaSeparatedArray(Property metadataProperty, String nsDc, String arrayProperty, int arrayType) throws XMPException
+	{
+		createCommaSeparatedArray(metadataProperty.getName(), nsDc, arrayProperty, arrayType);
+	}
+	
+	/**
+	 * Creates an array property from a comma separated list.
+	 * @param tikaKey Key in the Tika metadata map
+	 * @param ns namespace the property should be created in
+	 * @param propertyName name of the property
+	 * @param arrayType depicts which kind of array shall be created
+	 * @throws XMPException if the property could not be created
+	 */
+	protected void createCommaSeparatedArray(String tikaKey, String ns, String propertyName, int arrayType) throws XMPException
+	{
+		String value = metadata.get(tikaKey);
+		if (value != null  &&  value.length() > 0)
+		{
+			XMPUtils.separateArrayItems(meta, ns, propertyName, value, new PropertyOptions(arrayType), false);
+		}
+	}
+
+
+
+
+}
diff --git a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/GenericConverter.java b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/GenericConverter.java
new file mode 100644
index 000000000..83fe83762
--- /dev/null
+++ b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/GenericConverter.java
@@ -0,0 +1,116 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * IPTC Metadata Descriptions taken from the IPTC Photo Metadata (July 2010) 
+ * standard. These parts Copyright 2010 International Press Telecommunications 
+ * Council.
+ */
+package org.apache.tika.xmp.convert;
+
+import java.util.Collections;
+import java.util.HashSet;
+import java.util.Set;
+
+import org.apache.tika.exception.TikaException;
+import org.apache.tika.metadata.DublinCore;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.Property;
+import org.apache.tika.metadata.XMPRights;
+import org.apache.tika.metadata.Property.PropertyType;
+
+import com.adobe.xmp.XMPException;
+import com.adobe.xmp.XMPMeta;
+import com.adobe.xmp.XMPMetaFactory;
+import com.adobe.xmp.XMPSchemaRegistry;
+import com.adobe.xmp.options.PropertyOptions;
+
+/**
+ * Trys to convert as much of the properties in the <code>Metadata</code> map
+ * to XMP namespaces. only those properties will be cnverted where the name contains 
+ * a prefix and this prefix correlates with a "known" prefix for a standard namespace.
+ * For example "dc:title" would be mapped to the "title" property in the DublinCore namespace.
+ */
+public class GenericConverter extends AbstractConverter 
+{
+	public GenericConverter() throws TikaException 
+	{
+		super();
+	}
+
+	@Override
+	public XMPMeta process(Metadata metadata) throws XMPException 
+	{
+		setMetadata(metadata);
+		XMPSchemaRegistry registry = XMPMetaFactory.getSchemaRegistry();
+		
+		String [] keys = metadata.names();
+		for( String key : keys)
+		{
+			String[] keyParts = key.split(Metadata.NAMESPACE_PREFIX_DELIMITER);
+			if (keyParts.length > 0 && keyParts.length <= 2)
+			{
+				String uri = registry.getNamespaceURI(keyParts[0]);
+				
+				if( uri != null )
+				{
+					// Tika properties where the type differs from the XMP specification
+					if( key.equals(DublinCore.TITLE.getName()) || 
+						key.equals(DublinCore.DESCRIPTION.getName()) || 
+						key.equals(XMPRights.USAGE_TERMS.getName()) )
+					{
+						createLangAltProperty(key, uri, keyParts[1]);
+					}
+					else if( key.equals(DublinCore.CREATOR.getName()) )
+					{
+						createArrayProperty(key, uri, keyParts[1], PropertyOptions.ARRAY_ORDERED);
+					}
+					else
+					{
+						PropertyType type = Property.getPropertyType(key);
+						if( type != null )
+						{
+							switch( type )
+							{
+								case SIMPLE:
+									createProperty(key, uri, keyParts[1]);
+									break;
+								case BAG:
+									createArrayProperty(key, uri, keyParts[1], PropertyOptions.ARRAY);
+									break;
+								case SEQ:
+									createArrayProperty(key, uri, keyParts[1], PropertyOptions.ARRAY_ORDERED);
+									break;
+								case ALT:
+									createArrayProperty(key, uri, keyParts[1], PropertyOptions.ARRAY_ALTERNATE);
+									break;
+								// TODO Add support for structs and lang-alts, but those types are currently not used in Tika
+							}
+						}
+					}
+				}
+			} // ignore keys that are not qualified
+		}
+				
+		return getXMPMeta();
+	}
+
+	@Override
+	public Set<Namespace> getAdditionalNamespaces() 
+	{
+		// no additional namespaces needed
+		return Collections.unmodifiableSet(new HashSet<Namespace>());
+	}
+}
diff --git a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/ITikaToXMPConverter.java b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/ITikaToXMPConverter.java
new file mode 100644
index 000000000..e86fe0117
--- /dev/null
+++ b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/ITikaToXMPConverter.java
@@ -0,0 +1,42 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * IPTC Metadata Descriptions taken from the IPTC Photo Metadata (July 2010) 
+ * standard. These parts Copyright 2010 International Press Telecommunications 
+ * Council.
+ */
+package org.apache.tika.xmp.convert;
+
+import org.apache.tika.metadata.Metadata;
+
+import com.adobe.xmp.XMPException;
+import com.adobe.xmp.XMPMeta;
+
+/**
+ * Interface for the specific <code>Metadata</code> to XMP converters
+ */
+public interface ITikaToXMPConverter 
+{
+	/**
+	 * Converts a Tika {@link Metadata}-object into an {@link XMPMeta} containing 
+	 * the useful properties.
+	 * 
+	 * @param metadata a Tika Metadata object
+	 * @return Returns an XMPMeta object.
+	 * @throws XMPException If an error occurs during the creation of the XMP object.
+	 */
+	XMPMeta process(Metadata metadata) throws XMPException;	
+}
diff --git a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/MSOfficeBinaryConverter.java b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/MSOfficeBinaryConverter.java
new file mode 100644
index 000000000..86718e167
--- /dev/null
+++ b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/MSOfficeBinaryConverter.java
@@ -0,0 +1,97 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * IPTC Metadata Descriptions taken from the IPTC Photo Metadata (July 2010) 
+ * standard. These parts Copyright 2010 International Press Telecommunications 
+ * Council.
+ */
+package org.apache.tika.xmp.convert;
+
+import java.util.Arrays;
+import java.util.Collections;
+import java.util.HashSet;
+import java.util.Set;
+
+import org.apache.tika.exception.TikaException;
+import org.apache.tika.metadata.HttpHeaders;
+import org.apache.tika.metadata.MSOffice;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.Office;
+import org.apache.tika.metadata.OfficeOpenXMLCore;
+import org.apache.tika.metadata.OfficeOpenXMLExtended;
+import org.apache.tika.metadata.TikaCoreProperties;
+
+import com.adobe.xmp.XMPConst;
+import com.adobe.xmp.XMPException;
+import com.adobe.xmp.XMPMeta;
+import com.adobe.xmp.options.PropertyOptions;
+
+/**
+ * Tika to XMP mapping for the binary MS formats Word (.doc), Excel (.xls) and PowerPoint (.ppt).
+ */
+public class MSOfficeBinaryConverter extends AbstractConverter
+{
+	 public MSOfficeBinaryConverter() throws TikaException 
+	 {
+		super();
+	}
+
+	protected static final Set<Namespace> ADDITIONAL_NAMESPACES =
+		        Collections.unmodifiableSet(new HashSet<Namespace>(Arrays.asList(
+		        		new Namespace(OfficeOpenXMLCore.NAMESPACE_URI, OfficeOpenXMLCore.PREFIX),
+		        		new Namespace(OfficeOpenXMLExtended.NAMESPACE_URI, OfficeOpenXMLExtended.PREFIX)
+		        		)));
+		        		
+	/**
+	 * @throws XMPException Forwards XMP errors
+	 * @see XMPFilesProcessor.MSOfficeXMLConverter.onverter#process(Metadata)
+	 */
+	public XMPMeta process(Metadata metadata) throws XMPException
+	{
+		super.setMetadata(metadata);
+
+		// For all formats, Tika uses the same keys 
+		createProperty(HttpHeaders.CONTENT_TYPE, XMPConst.NS_DC, "format");
+		createProperty(OfficeOpenXMLExtended.APPLICATION, XMPConst.NS_XMP, "CreatorTool");
+		createCommaSeparatedArray(TikaCoreProperties.AUTHOR, XMPConst.NS_DC, "creator", PropertyOptions.ARRAY_ORDERED);
+		createProperty(OfficeOpenXMLCore.CATEGORY, XMPConst.NS_IPTCCORE, "intellectualGenre");
+		createProperty(TikaCoreProperties.CREATION_DATE, XMPConst.NS_XMP, "CreateDate");
+		createProperty(Office.CHARACTER_COUNT, OfficeOpenXMLExtended.NAMESPACE_URI, "Characters");
+		createProperty(MSOffice.COMMENTS, XMPConst.NS_PDFX, "Comments");
+		createProperty(OfficeOpenXMLExtended.COMPANY, OfficeOpenXMLExtended.NAMESPACE_URI, "Company");
+		createCommaSeparatedArray(TikaCoreProperties.KEYWORDS, XMPConst.NS_DC, "subject", PropertyOptions.ARRAY);
+		createLangAltProperty(TikaCoreProperties.SUBJECT, XMPConst.NS_DC, "description");
+		createProperty(TikaCoreProperties.LANGUAGE, OfficeOpenXMLCore.NAMESPACE_URI, "language");
+		createProperty(TikaCoreProperties.PRINT_DATE, OfficeOpenXMLCore.NAMESPACE_URI, "lastPrinted");
+		createProperty(TikaCoreProperties.SAVE_DATE, XMPConst.NS_XMP, "ModifyDate");
+		createProperty(Office.PAGE_COUNT, XMPConst.TYPE_PAGEDFILE, "NPages");
+		createProperty(OfficeOpenXMLCore.REVISION, OfficeOpenXMLCore.NAMESPACE_URI, "revision");
+		createProperty(Office.SLIDE_COUNT, OfficeOpenXMLExtended.NAMESPACE_URI, "Pages");
+		createProperty(OfficeOpenXMLExtended.TEMPLATE, OfficeOpenXMLExtended.NAMESPACE_URI, "Template");
+		createLangAltProperty(TikaCoreProperties.TITLE, XMPConst.NS_DC, "title");
+		createProperty(Office.WORD_COUNT, OfficeOpenXMLExtended.NAMESPACE_URI, "Words");
+		// Not mapped: (MSOffice) Edit-Time 	???
+		// Not mapped:	(MSOffice) Last-Author 	???
+		// not mapped: (MSOffice) Security 	???
+		
+		return super.getXMPMeta();
+	}
+
+	protected Set<Namespace> getAdditionalNamespaces() 
+	{
+		return ADDITIONAL_NAMESPACES;
+	}
+}
diff --git a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/MSOfficeXMLConverter.java b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/MSOfficeXMLConverter.java
new file mode 100644
index 000000000..37edd4846
--- /dev/null
+++ b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/MSOfficeXMLConverter.java
@@ -0,0 +1,125 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * IPTC Metadata Descriptions taken from the IPTC Photo Metadata (July 2010) 
+ * standard. These parts Copyright 2010 International Press Telecommunications 
+ * Council.
+ */
+package org.apache.tika.xmp.convert;
+
+import java.util.Arrays;
+import java.util.Collections;
+import java.util.HashSet;
+import java.util.Set;
+
+import org.apache.tika.exception.TikaException;
+import org.apache.tika.metadata.HttpHeaders;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.Office;
+import org.apache.tika.metadata.OfficeOpenXMLCore;
+import org.apache.tika.metadata.OfficeOpenXMLExtended;
+import org.apache.tika.metadata.TikaCoreProperties;
+
+import com.adobe.xmp.XMPConst;
+import com.adobe.xmp.XMPException;
+import com.adobe.xmp.XMPMeta;
+import com.adobe.xmp.options.PropertyOptions;
+
+/**
+ * Tika to XMP mapping for the Office Open XML formats Word (.docx), Excel (.xlsx) and PowerPoint (.pptx).
+ */
+public class MSOfficeXMLConverter extends AbstractConverter 
+{
+	protected static final Set<Namespace> ADDITIONAL_NAMESPACES =
+	        Collections.unmodifiableSet(new HashSet<Namespace>(Arrays.asList(
+	        		new Namespace(OfficeOpenXMLCore.NAMESPACE_URI, OfficeOpenXMLCore.PREFIX),
+	        		new Namespace(OfficeOpenXMLExtended.NAMESPACE_URI, OfficeOpenXMLExtended.PREFIX)
+	        		)));
+	
+	public MSOfficeXMLConverter() throws TikaException 
+	{
+		super();
+	}
+
+	@Override
+	public XMPMeta process(Metadata metadata) throws XMPException 
+	{
+		super.setMetadata(metadata);
+		
+		createProperty(HttpHeaders.CONTENT_TYPE, XMPConst.NS_DC, "format");
+		
+		// Core Properties
+		createProperty(OfficeOpenXMLCore.CATEGORY, XMPConst.NS_IPTCCORE, "intellectualGenre");
+		createProperty(OfficeOpenXMLCore.CONTENT_STATUS, OfficeOpenXMLCore.NAMESPACE_URI, "contentStatus");
+		createProperty(TikaCoreProperties.CREATION_DATE, XMPConst.NS_XMP, "CreateDate");
+		createCommaSeparatedArray(TikaCoreProperties.CREATOR, XMPConst.NS_DC, "creator", PropertyOptions.ARRAY_ORDERED);
+		createProperty(TikaCoreProperties.DESCRIPTION, XMPConst.NS_PDFX, "Comments");
+		createProperty(TikaCoreProperties.IDENTIFIER, XMPConst.NS_DC, "identifier");
+		createCommaSeparatedArray(TikaCoreProperties.KEYWORDS, XMPConst.NS_DC, "subject", PropertyOptions.ARRAY); 
+		createLangAltProperty(TikaCoreProperties.SUBJECT, XMPConst.NS_DC, "description"); 
+		createProperty(TikaCoreProperties.LANGUAGE, XMPConst.NS_DC, "language");
+		createProperty(TikaCoreProperties.LAST_AUTHOR, OfficeOpenXMLCore.NAMESPACE_URI, "lastModifiedBy");
+		createProperty(TikaCoreProperties.PRINT_DATE, OfficeOpenXMLCore.NAMESPACE_URI, "lastPrinted");
+		createProperty(TikaCoreProperties.MODIFIED, XMPConst.NS_XMP, "ModifyDate");
+		createProperty(OfficeOpenXMLCore.REVISION, OfficeOpenXMLCore.NAMESPACE_URI, "revision");
+		createLangAltProperty(TikaCoreProperties.TITLE, XMPConst.NS_DC, "title");
+		createProperty(OfficeOpenXMLCore.VERSION, OfficeOpenXMLCore.NAMESPACE_URI, "version");
+		
+		// Extended Properties
+		
+		// Put both App name and version in xmp:CreatorTool 
+		String creatorTool = "";
+		String value = metadata.get(OfficeOpenXMLExtended.APPLICATION);
+		if (value != null  &&  value.length() > 0)
+		{
+			creatorTool = value;
+
+			value = metadata.get(OfficeOpenXMLExtended.APP_VERSION);
+			if (value != null  &&  value.length() > 0)
+			{
+				creatorTool += " " + value;
+			}
+		}
+		
+		if( ! creatorTool.isEmpty() ) 
+		{
+			meta.setProperty(XMPConst.NS_XMP, "CreatorTool", creatorTool);
+		}
+		
+		createProperty(Office.CHARACTER_COUNT, OfficeOpenXMLExtended.NAMESPACE_URI, "Characters");
+		createProperty(Office.CHARACTER_COUNT_WITH_SPACES, OfficeOpenXMLExtended.NAMESPACE_URI, "CharactersWithSpaces");
+		createProperty(TikaCoreProperties.PUBLISHER, OfficeOpenXMLExtended.NAMESPACE_URI, "Company");
+		createProperty(Office.LINE_COUNT, OfficeOpenXMLExtended.NAMESPACE_URI, "Lines");
+		createProperty(OfficeOpenXMLExtended.MANAGER, OfficeOpenXMLExtended.NAMESPACE_URI, "Manager");
+		createProperty(OfficeOpenXMLExtended.NOTES, OfficeOpenXMLExtended.NAMESPACE_URI, "Notes");
+		createProperty(Office.PAGE_COUNT, XMPConst.TYPE_PAGEDFILE, "NPages");
+		createProperty(Office.PARAGRAPH_COUNT, OfficeOpenXMLExtended.NAMESPACE_URI, "Paragraphs");
+		createProperty(OfficeOpenXMLExtended.PRESENTATION_FORMAT, OfficeOpenXMLExtended.NAMESPACE_URI, "PresentationFormat");
+		createProperty(Office.SLIDE_COUNT, OfficeOpenXMLExtended.NAMESPACE_URI, "Slides");
+		createProperty(OfficeOpenXMLExtended.TEMPLATE, OfficeOpenXMLExtended.NAMESPACE_URI, "Template");
+		createProperty(OfficeOpenXMLExtended.TOTAL_TIME, OfficeOpenXMLExtended.NAMESPACE_URI, "TotalTime");
+		createProperty(Office.WORD_COUNT, OfficeOpenXMLExtended.NAMESPACE_URI, "Words");
+		
+		return super.getXMPMeta();
+	}
+
+	@Override
+	protected Set<Namespace> getAdditionalNamespaces() 
+	{
+		return ADDITIONAL_NAMESPACES;
+	}
+
+}
diff --git a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/Namespace.java b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/Namespace.java
new file mode 100644
index 000000000..10a2e5551
--- /dev/null
+++ b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/Namespace.java
@@ -0,0 +1,36 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * IPTC Metadata Descriptions taken from the IPTC Photo Metadata (July 2010) 
+ * standard. These parts Copyright 2010 International Press Telecommunications 
+ * Council.
+ */
+package org.apache.tika.xmp.convert;
+
+/**
+ * Utility class to hold namespace information.
+ */
+public class Namespace 
+{
+	public String uri;
+	public String prefix;
+
+	public Namespace(String uri, String prefix) 
+	{
+		this.uri = uri;
+		this.prefix = prefix;
+	}
+}
diff --git a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/OpenDocumentConverter.java b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/OpenDocumentConverter.java
new file mode 100644
index 000000000..46ceaa6ce
--- /dev/null
+++ b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/OpenDocumentConverter.java
@@ -0,0 +1,103 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * IPTC Metadata Descriptions taken from the IPTC Photo Metadata (July 2010) 
+ * standard. These parts Copyright 2010 International Press Telecommunications 
+ * Council.
+ */
+package org.apache.tika.xmp.convert;
+
+import java.util.Arrays;
+import java.util.Collections;
+import java.util.HashSet;
+import java.util.Set;
+
+import org.apache.tika.exception.TikaException;
+import org.apache.tika.metadata.HttpHeaders;
+import org.apache.tika.metadata.MSOffice;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.Office;
+import org.apache.tika.metadata.PagedText;
+import org.apache.tika.metadata.TikaCoreProperties;
+
+import com.adobe.xmp.XMPConst;
+import com.adobe.xmp.XMPException;
+import com.adobe.xmp.XMPMeta;
+import com.adobe.xmp.options.PropertyOptions;
+
+/**
+ * Tika to XMP mapping for the Open Document formats:
+ * Text (.odt), Spreatsheet (.ods), Graphics (.odg) and Presentation (.odp).
+ */
+public class OpenDocumentConverter extends AbstractConverter
+{
+	protected static final Set<Namespace> ADDITIONAL_NAMESPACES =
+	        Collections.unmodifiableSet(new HashSet<Namespace>(Arrays.asList(
+	        		new Namespace(Office.NAMESPACE_URI_DOC_META, Office.PREFIX_DOC_META)
+	        		)));
+	
+	public OpenDocumentConverter() throws TikaException 
+	{
+		super();
+	}
+
+	/**
+	 * @throws XMPException Forwards XMP errors
+	 * @see XMPFilesProcessor.onverter#process(Metadata)
+	 */
+	@Override
+	public XMPMeta process(Metadata metadata) throws XMPException
+	{
+		super.setMetadata(metadata);
+
+		createProperty(HttpHeaders.CONTENT_TYPE, XMPConst.NS_DC, "format");
+		
+		createProperty(Office.CHARACTER_COUNT, Office.NAMESPACE_URI_DOC_META, "character-count");
+		createProperty(TikaCoreProperties.CREATION_DATE, XMPConst.NS_XMP, "CreateDate");
+		createCommaSeparatedArray(TikaCoreProperties.CREATOR, XMPConst.NS_DC, "creator", PropertyOptions.ARRAY_ORDERED);
+		createProperty(TikaCoreProperties.DATE, XMPConst.NS_XMP, "ModifyDate");
+		createProperty(TikaCoreProperties.DESCRIPTION, XMPConst.NS_PDFX, "Comments");
+		createCommaSeparatedArray(TikaCoreProperties.KEYWORDS, XMPConst.NS_DC, "subject", PropertyOptions.ARRAY);
+		createLangAltProperty(TikaCoreProperties.SUBJECT, XMPConst.NS_DC, "description");
+		createProperty(MSOffice.EDIT_TIME, Office.NAMESPACE_URI_DOC_META, "editing-duration");
+		createProperty("editing-cycles", Office.NAMESPACE_URI_DOC_META, "editing-cycles");
+		createProperty("generator", XMPConst.NS_XMP, "CreatorTool");
+		createProperty(Office.IMAGE_COUNT, Office.NAMESPACE_URI_DOC_META, "image-count");
+		createProperty("initial-creator", Office.NAMESPACE_URI_DOC_META, "initial-creator");
+		createProperty(Office.OBJECT_COUNT, Office.NAMESPACE_URI_DOC_META, "object-count");
+		createProperty(PagedText.N_PAGES, XMPConst.TYPE_PAGEDFILE, "NPages");
+		createProperty(Office.PARAGRAPH_COUNT, Office.NAMESPACE_URI_DOC_META, "paragraph-count");
+		createProperty(Office.TABLE_COUNT, Office.NAMESPACE_URI_DOC_META, "table-count");
+		createLangAltProperty(TikaCoreProperties.TITLE, XMPConst.NS_DC, "title");
+		createProperty(Office.WORD_COUNT, Office.NAMESPACE_URI_DOC_META, "word-count");
+
+		// duplicate properties not mapped:
+		//		nbImg | 0
+		//		nbObject | 0
+		//		nbPage | 1
+		//		nbPara | 3
+		//		nbTab | 0
+		//		nbWord | 5
+		
+		return super.getXMPMeta();
+	}
+
+	@Override
+	protected Set<Namespace> getAdditionalNamespaces() 
+	{
+		return ADDITIONAL_NAMESPACES;
+	}
+}
diff --git a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/RTFConverter.java b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/RTFConverter.java
new file mode 100644
index 000000000..ceff2c266
--- /dev/null
+++ b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/RTFConverter.java
@@ -0,0 +1,81 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * IPTC Metadata Descriptions taken from the IPTC Photo Metadata (July 2010) 
+ * standard. These parts Copyright 2010 International Press Telecommunications 
+ * Council.
+ */
+package org.apache.tika.xmp.convert;
+
+import java.util.Arrays;
+import java.util.Collections;
+import java.util.HashSet;
+import java.util.Set;
+
+import org.apache.tika.exception.TikaException;
+import org.apache.tika.metadata.ClimateForcast;
+import org.apache.tika.metadata.HttpHeaders;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.OfficeOpenXMLCore;
+import org.apache.tika.metadata.OfficeOpenXMLExtended;
+import org.apache.tika.metadata.TikaCoreProperties;
+
+import com.adobe.xmp.XMPConst;
+import com.adobe.xmp.XMPException;
+import com.adobe.xmp.XMPMeta;
+import com.adobe.xmp.options.PropertyOptions;
+
+/**
+ * Tika to XMP mapping for the RTF format.
+ */
+public class RTFConverter extends AbstractConverter
+{
+	protected static final Set<Namespace> ADDITIONAL_NAMESPACES =
+	        Collections.unmodifiableSet(new HashSet<Namespace>(Arrays.asList(
+	        		new Namespace(OfficeOpenXMLExtended.NAMESPACE_URI, OfficeOpenXMLExtended.PREFIX)
+	        		)));
+	
+	public RTFConverter() throws TikaException 
+	{
+		super();
+	}
+
+	@Override
+	public XMPMeta process(Metadata metadata) throws XMPException
+	{
+		setMetadata(metadata);
+		
+		createProperty(HttpHeaders.CONTENT_TYPE, XMPConst.NS_DC, "format");
+
+		createCommaSeparatedArray(TikaCoreProperties.AUTHOR, XMPConst.NS_DC, "creator", PropertyOptions.ARRAY_ORDERED);
+		createLangAltProperty(TikaCoreProperties.TITLE, XMPConst.NS_DC, "title");
+		createLangAltProperty(TikaCoreProperties.SUBJECT, XMPConst.NS_DC, "description");
+		createCommaSeparatedArray(TikaCoreProperties.KEYWORDS, XMPConst.NS_DC, "subject", PropertyOptions.ARRAY);
+		createProperty(OfficeOpenXMLCore.CATEGORY, XMPConst.NS_IPTCCORE, "intellectualGenre");
+		createProperty(OfficeOpenXMLExtended.TEMPLATE, OfficeOpenXMLExtended.NAMESPACE_URI, "Template");
+		createProperty(ClimateForcast.COMMENT, XMPConst.NS_PDFX, "Comments");
+		createProperty(OfficeOpenXMLExtended.COMPANY, OfficeOpenXMLExtended.NAMESPACE_URI, "Company");
+		createProperty(OfficeOpenXMLExtended.MANAGER, OfficeOpenXMLExtended.NAMESPACE_URI, "Manager");
+				
+		return getXMPMeta();
+	}
+
+	@Override
+	protected Set<Namespace> getAdditionalNamespaces() 
+	{
+		return ADDITIONAL_NAMESPACES;
+	}
+}
diff --git a/tika-xmp/src/main/java/org/apache/tika/xmp/convert/TikaToXMP.java b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/TikaToXMP.java
new file mode 100644
index 000000000..7d4501dab
--- /dev/null
+++ b/tika-xmp/src/main/java/org/apache/tika/xmp/convert/TikaToXMP.java
@@ -0,0 +1,225 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * IPTC Metadata Descriptions taken from the IPTC Photo Metadata (July 2010) 
+ * standard. These parts Copyright 2010 International Press Telecommunications 
+ * Council.
+ */
+package org.apache.tika.xmp.convert;
+
+import java.util.HashMap;
+import java.util.Map;
+import java.util.Set;
+
+import org.apache.tika.exception.TikaException;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
+import org.apache.tika.mime.MediaType;
+import org.apache.tika.parser.ParseContext;
+import org.apache.tika.parser.microsoft.OfficeParser;
+import org.apache.tika.parser.microsoft.ooxml.OOXMLParser;
+import org.apache.tika.parser.odf.OpenDocumentParser;
+import org.apache.tika.parser.rtf.RTFParser;
+
+import com.adobe.xmp.XMPException;
+import com.adobe.xmp.XMPMeta;
+import com.adobe.xmp.XMPMetaFactory;
+
+public class TikaToXMP
+{
+	/** 
+	 * Map from mimetype to converter class 
+	 * Must only be accessed through <code>getConverterMap</code>
+	 */
+	private static Map<MediaType, Class<? extends ITikaToXMPConverter>> converterMap;		
+
+	// --- public API implementation---
+	
+	public TikaToXMP() 
+	{
+		// Nothing to do
+	}
+	
+
+	/**
+	 * @see ITikaToXMP#convert(Metadata, String)
+	 * But the mimetype is retrieved from the metadata map.
+	 */
+	public static XMPMeta convert(Metadata tikaMetadata) throws TikaException 
+	{
+		if( tikaMetadata == null )
+		{
+			throw new IllegalArgumentException("Metadata parameter must not be null");
+		}
+		
+		String mimetype = tikaMetadata.get(Metadata.CONTENT_TYPE);
+		if(mimetype == null)
+		{
+			mimetype = tikaMetadata.get(TikaCoreProperties.FORMAT);
+		}
+		
+		return convert(tikaMetadata, mimetype);
+	}
+
+
+	/**
+	 * Convert the given Tika metadata map to XMP object.
+	 * If a mimetype is provided in the Metadata map, a specific converter can be used, that converts all
+     * available metadata.
+     * If there is no mimetype provided or no specific converter available a generic conversion is done
+     * which will convert only those properties that are in known namespaces and are using the correct prefixes.
+	 *
+	 * @param tikaMetadata the Metadata map from Tika
+	 * @param mimetype depicts the format's converter to use
+	 * @return XMP object
+	 * @throws TikaException
+	 */
+	public static XMPMeta convert(Metadata tikaMetadata, String mimetype) throws TikaException 
+	{
+		if( tikaMetadata == null )
+		{
+			throw new IllegalArgumentException("Metadata parameter must not be null");
+		}
+		
+		ITikaToXMPConverter converter = null;
+		
+		if( isConverterAvailable(mimetype) )
+		{
+			converter = getConverter(mimetype);
+		}
+		else
+		{
+			converter = new GenericConverter();
+		}
+		
+		XMPMeta xmp = null;
+		
+		if( converter != null )
+		{
+			try 
+			{
+				xmp = converter.process(tikaMetadata);
+			} 
+			catch (XMPException e) 
+			{
+				throw new TikaException("Tika metadata could not be converted to XMP", e);
+			}
+		}
+		else
+		{
+			xmp = XMPMetaFactory.create(); // empty packet
+		}
+		
+		return xmp;
+	}
+
+	/** 
+	 * Check if there is a converter available which allows to convert the
+	 * Tika metadata to XMP
+	 * @param mimetype the Mimetype
+	 * @return true if the Metadata object can be converted or false if not
+	 */
+	public static boolean isConverterAvailable(String mimetype) 
+	{
+		MediaType type = MediaType.parse(mimetype);
+		
+        if (type != null) 
+        {
+        	return (getConverterMap().get(type) != null);
+        }
+        
+        return false;
+	}
+	
+	/**
+	 * Retrieve a specific converter according to the mimetype
+	 * @param mimetype the Mimetype
+	 * @return the converter or null, if none exists
+	 * @throws TikaException
+	 */
+	public static ITikaToXMPConverter getConverter(String mimetype) throws TikaException 
+	{
+		if( mimetype == null )
+		{
+			throw new IllegalArgumentException("mimetype must not be null");
+		}
+		
+		ITikaToXMPConverter converter = null;
+		
+		MediaType type = MediaType.parse(mimetype);
+		
+        if (type != null) 
+        {
+			Class<? extends ITikaToXMPConverter> clazz = getConverterMap().get( type );
+			if (clazz != null)
+			{
+				try
+				{
+					converter = clazz.newInstance();
+				}
+				catch (Exception e)
+				{
+					throw new TikaException("TikaToXMP converter class cannot be instantiated for mimetype: " + type.toString(), e);
+				}
+			}
+        }
+        
+        return converter;
+	}
+
+	// --- Private methods ---
+	
+	private static Map<MediaType, Class<? extends ITikaToXMPConverter>> getConverterMap()
+	{
+		if( converterMap == null )
+		{
+			converterMap = new HashMap<MediaType, Class<? extends ITikaToXMPConverter>>();
+			initialize();
+		}
+		return converterMap;
+	}
+	
+	
+	/**
+	 * Initializes the map with supported converters.
+	 */
+	private static void initialize()
+	{
+		// No particular parsing context is needed
+		ParseContext parseContext = new ParseContext();
+		
+		// MS Office Binary File Format
+		addConverter(new OfficeParser().getSupportedTypes(parseContext), MSOfficeBinaryConverter.class);
+		
+		// Rich Text Format
+		addConverter(new RTFParser().getSupportedTypes(parseContext), RTFConverter.class);
+
+		// MS Open XML Format
+		addConverter(new OOXMLParser().getSupportedTypes(parseContext), MSOfficeXMLConverter.class);
+		
+		// Open document format
+		addConverter(new OpenDocumentParser().getSupportedTypes(parseContext), OpenDocumentConverter.class);
+	}
+	
+	
+	private static void addConverter(Set<MediaType> supportedTypes, Class<? extends ITikaToXMPConverter> converter)
+	{
+		for( MediaType type : supportedTypes )
+		{
+			getConverterMap().put(type, converter);
+		}
+	}
+}
diff --git a/tika-xmp/src/test/java/org/apache/tika/xmp/TikaToXMPTest.java b/tika-xmp/src/test/java/org/apache/tika/xmp/TikaToXMPTest.java
new file mode 100644
index 000000000..8f98c5d51
--- /dev/null
+++ b/tika-xmp/src/test/java/org/apache/tika/xmp/TikaToXMPTest.java
@@ -0,0 +1,243 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * IPTC Metadata Descriptions taken from the IPTC Photo Metadata (July 2010) 
+ * standard. These parts Copyright 2010 International Press Telecommunications 
+ * Council.
+ */
+package org.apache.tika.xmp;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertNotNull;
+import static org.junit.Assert.assertNull;
+import static org.junit.Assert.assertTrue;
+
+import org.apache.tika.exception.TikaException;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.OfficeOpenXMLCore;
+import org.apache.tika.metadata.TikaCoreProperties;
+import org.apache.tika.xmp.convert.ITikaToXMPConverter;
+import org.apache.tika.xmp.convert.MSOfficeXMLConverter;
+import org.apache.tika.xmp.convert.TikaToXMP;
+import org.junit.Before;
+import org.junit.Test;
+
+import com.adobe.xmp.XMPConst;
+import com.adobe.xmp.XMPException;
+import com.adobe.xmp.XMPIterator;
+import com.adobe.xmp.XMPMeta;
+import com.adobe.xmp.XMPMetaFactory;
+import com.adobe.xmp.properties.XMPProperty;
+
+/**
+ * Tests the Tika <code>Metadata</code> to XMP conversion functionatlity
+ */
+public class TikaToXMPTest 
+{
+	private Metadata tikaMetadata;
+	
+	private static final String OOXML_MIMETYPE = "application/vnd.openxmlformats-officedocument.wordprocessingml.document";
+	private static final String GENERIC_MIMETYPE = "generic/mimetype";
+	
+	// --- Set up ---
+	@Before
+	public void setup()
+	{
+		tikaMetadata = new Metadata();
+	}
+	
+	private void setupOOXMLMetadata(Metadata metadata)
+	{
+		// simple property
+		metadata.set(TikaCoreProperties.LANGUAGE, "language");
+		// language alternative
+		metadata.set(TikaCoreProperties.TITLE, "title");
+		// comma separated array
+		metadata.set(TikaCoreProperties.KEYWORDS, "keyword1,keyword2");
+		// OOXML specific simple prop
+		metadata.set(TikaCoreProperties.LAST_AUTHOR, "lastModifiedBy");
+	}
+	
+	private void checkOOXMLMetadata(XMPMeta xmp) throws XMPException
+	{
+		// check simple property
+		XMPProperty prop = xmp.getProperty(XMPConst.NS_DC, "language");
+		assertNotNull(prop);
+		assertEquals("language", prop.getValue());
+		
+		// check lang alt
+		prop = xmp.getLocalizedText(XMPConst.NS_DC, "title", null, XMPConst.X_DEFAULT);
+		assertNotNull(prop);
+		assertEquals("title", prop.getValue());
+		
+		// check array
+		prop = xmp.getArrayItem(XMPConst.NS_DC, "subject", 1);
+		assertNotNull(prop);
+		assertEquals("keyword1", prop.getValue());
+		prop = xmp.getArrayItem(XMPConst.NS_DC, "subject", 2);
+		assertNotNull(prop);
+		assertEquals("keyword2", prop.getValue());
+		
+		// check OOXML specific simple property
+		prop = xmp.getProperty(OfficeOpenXMLCore.NAMESPACE_URI, "lastModifiedBy");
+		assertNotNull(prop);
+		assertEquals("lastModifiedBy", prop.getValue());
+	}
+	
+	
+	// --- TESTS ---
+	@Test
+	public void convert_OOXMLMetadataWithMimetype_everythingConverted() throws XMPException, TikaException 
+	{
+		setupOOXMLMetadata(tikaMetadata);
+		tikaMetadata.set(Metadata.CONTENT_TYPE, OOXML_MIMETYPE);
+
+		XMPMeta xmp = TikaToXMP.convert(tikaMetadata);
+		
+		checkOOXMLMetadata(xmp);
+	}
+
+	
+	@Test
+	public void convert_OOXMLMetadataWithExtraMimetype_everythingConverted() throws XMPException, TikaException 
+	{
+		setupOOXMLMetadata(tikaMetadata);
+		
+		XMPMeta xmp = TikaToXMP.convert(tikaMetadata, OOXML_MIMETYPE);
+		
+		checkOOXMLMetadata(xmp);
+	}
+
+
+	@Test
+	public void convert_OOXMLMetadataWithoutMimetype_onlyGeneralMetadataconverted() throws XMPException, TikaException 
+	{
+		setupOOXMLMetadata(tikaMetadata);
+		
+		XMPMeta xmp = TikaToXMP.convert(tikaMetadata, null);
+		
+		// general metadata is converted
+		// check simple property
+		XMPProperty prop = xmp.getProperty(XMPConst.NS_DC, "language");
+		assertNotNull(prop);
+		assertEquals("language", prop.getValue());
+		
+		// check lang alt
+		prop = xmp.getLocalizedText(XMPConst.NS_DC, "title", null, XMPConst.X_DEFAULT);
+		assertNotNull(prop);
+		assertEquals("title", prop.getValue());
+		
+		// OOXML one is not, the namespace has also not been registiered as the converter has not been used
+		XMPMetaFactory.getSchemaRegistry().registerNamespace(OfficeOpenXMLCore.NAMESPACE_URI, OfficeOpenXMLCore.PREFIX);
+		prop = xmp.getProperty(OfficeOpenXMLCore.NAMESPACE_URI, "lastModifiedBy");
+		assertNull(prop);
+	}
+	
+	
+	@Test
+	public void convert_genericMetadataAllQualified_allConverted() throws XMPException, TikaException 
+	{
+		// simple property
+		tikaMetadata.set(TikaCoreProperties.FORMAT, GENERIC_MIMETYPE);
+		// language alternative
+		tikaMetadata.set(TikaCoreProperties.TITLE, "title");
+		// array
+		tikaMetadata.set(TikaCoreProperties.SUBJECT, new String[] {"keyword1", "keyword2"});
+		
+		
+		XMPMeta xmp = TikaToXMP.convert(tikaMetadata, null);
+		
+		// check simple property
+		XMPProperty prop = xmp.getProperty(XMPConst.NS_DC, "format");
+		assertNotNull(prop);
+		assertEquals(GENERIC_MIMETYPE, prop.getValue());
+		
+		// check lang alt
+		prop = xmp.getLocalizedText(XMPConst.NS_DC, "title", null, XMPConst.X_DEFAULT);
+		assertNotNull(prop);
+		assertEquals("title", prop.getValue());
+		
+		// check array
+		prop = xmp.getArrayItem(XMPConst.NS_DC, "subject", 1);
+		assertNotNull(prop);
+		assertEquals("keyword1", prop.getValue());
+		prop = xmp.getArrayItem(XMPConst.NS_DC, "subject", 2);
+		assertNotNull(prop);
+		assertEquals("keyword2", prop.getValue());
+	}
+	
+	
+	@Test
+	public void convert_wrongGenericMetadata_notConverted() throws XMPException, TikaException 
+	{
+		// unknown prefix
+		tikaMetadata.set("unknown:key", "unknownPrefixValue");
+		// not qualified key
+		tikaMetadata.set("wrongKey", "wrongKeyValue");
+		
+		XMPMeta xmp = TikaToXMP.convert(tikaMetadata, null);
+		
+		// XMP is empty
+		XMPIterator iter = xmp.iterator();
+		assertFalse(iter.hasNext());
+	}
+	
+	@Test(expected=IllegalArgumentException.class)
+	public void convert_nullInput_throw() throws TikaException 
+	{
+		TikaToXMP.convert(null);
+	}
+	
+	@Test
+	public void isConverterAvailable_availableMime_true() 
+	{
+		assertTrue(TikaToXMP.isConverterAvailable(OOXML_MIMETYPE));
+	}
+
+	@Test
+	public void isConverterAvailable_noAvailableMime_false() 
+	{
+		assertFalse(TikaToXMP.isConverterAvailable(GENERIC_MIMETYPE));
+	}
+	
+	@Test
+	public void isConverterAvailable_nullInput_false() 
+	{
+		assertFalse(TikaToXMP.isConverterAvailable(null));
+	}
+	
+	@Test
+	public void getConverter_ConverterAvailable_class() throws TikaException
+	{
+		ITikaToXMPConverter converter = TikaToXMP.getConverter(OOXML_MIMETYPE);
+		assertNotNull(converter);
+		assertTrue(converter instanceof MSOfficeXMLConverter);
+	}
+
+	@Test
+	public void getConverter_noConverterAvailable_null() throws TikaException 
+	{
+		ITikaToXMPConverter converter = TikaToXMP.getConverter(GENERIC_MIMETYPE);
+		assertNull(converter);
+	}
+	
+	@Test(expected=IllegalArgumentException.class)
+	public void getConverter_nullInput_throw() throws TikaException 
+	{
+		TikaToXMP.getConverter(null);
+	}
+}
diff --git a/tika-xmp/src/test/java/org/apache/tika/xmp/XMPMetadataTest.java b/tika-xmp/src/test/java/org/apache/tika/xmp/XMPMetadataTest.java
new file mode 100644
index 000000000..54637b883
--- /dev/null
+++ b/tika-xmp/src/test/java/org/apache/tika/xmp/XMPMetadataTest.java
@@ -0,0 +1,283 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * IPTC Metadata Descriptions taken from the IPTC Photo Metadata (July 2010) 
+ * standard. These parts Copyright 2010 International Press Telecommunications 
+ * Council.
+ */
+package org.apache.tika.xmp;
+
+import static org.junit.Assert.*;
+
+import java.util.Date;
+import java.util.Properties;
+
+import org.apache.tika.exception.TikaException;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.Property;
+import org.apache.tika.metadata.PropertyTypeException;
+import org.apache.tika.metadata.TikaCoreProperties;
+import org.apache.tika.metadata.XMPRights;
+import org.junit.Before;
+import org.junit.Test;
+
+import com.adobe.xmp.XMPConst;
+import com.adobe.xmp.XMPException;
+import com.adobe.xmp.XMPMeta;
+import com.adobe.xmp.XMPUtils;
+import com.adobe.xmp.properties.XMPProperty;
+
+public class XMPMetadataTest 
+{
+	private Metadata tikaMetadata;
+	private XMPMetadata xmpMeta;
+	
+	private static final String GENERIC_MIMETYPE = "generic/mimetype";
+	
+	// --- SETUP ---
+	@Before
+	public void setUp() throws Exception 
+	{
+		xmpMeta = new XMPMetadata();
+		tikaMetadata = new Metadata();
+		setupMetadata(tikaMetadata);
+	}
+
+	private void setupMetadata(Metadata metadata)
+	{
+		// simple property
+		metadata.set(TikaCoreProperties.FORMAT, GENERIC_MIMETYPE);
+		// language alternative
+		metadata.set(TikaCoreProperties.TITLE, "title");
+		// array
+		metadata.set(TikaCoreProperties.SUBJECT, new String[] {"keyword1", "keyword2"});
+		// date
+		metadata.set(TikaCoreProperties.MODIFIED,"2001-01-01T01:01" );
+		// int simple property
+		metadata.set(Property.internalInteger("xmp:Integer"), "2");
+	}
+	
+	// --- HELPER ---
+	private void checkArrayValues(String[] values, String baseValue)
+	{
+		int i = 1;
+		for(String value : values)
+		{
+			assertEquals(baseValue+i, value);
+			i++;
+		}
+	}
+	
+	
+	// --- TESTS ---
+	@Test
+	public void process_genericConversion_ok() throws TikaException, XMPException
+	{
+		xmpMeta.process(tikaMetadata, GENERIC_MIMETYPE);
+		
+		XMPMeta xmp = xmpMeta.getXMPData();
+		
+		// check simple property
+		XMPProperty prop = xmp.getProperty(XMPConst.NS_DC, "format");
+		assertNotNull(prop);
+		assertEquals(GENERIC_MIMETYPE, prop.getValue());
+		
+		// check lang alt
+		prop = xmp.getLocalizedText(XMPConst.NS_DC, "title", null, XMPConst.X_DEFAULT);
+		assertNotNull(prop);
+		assertEquals("title", prop.getValue());
+		
+		// check array
+		prop = xmp.getArrayItem(XMPConst.NS_DC, "subject", 1);
+		assertNotNull(prop);
+		assertEquals("keyword1", prop.getValue());
+		prop = xmp.getArrayItem(XMPConst.NS_DC, "subject", 2);
+		assertNotNull(prop);
+		assertEquals("keyword2", prop.getValue());
+	}
+	
+	@Test
+	public void isMultiValued_multiProp_true() throws TikaException 
+	{
+		xmpMeta.process(tikaMetadata);
+		
+		assertTrue(xmpMeta.isMultiValued(TikaCoreProperties.SUBJECT));
+	}
+
+	@Test
+	public void isMultiValued_simpleProp_false() throws TikaException 
+	{
+		xmpMeta.process(tikaMetadata);
+		
+		assertFalse(xmpMeta.isMultiValued(TikaCoreProperties.FORMAT));
+	}
+
+	@Test
+	public void get_simpleProp_valueReturned() throws TikaException 
+	{
+		xmpMeta.process(tikaMetadata);
+		
+		assertEquals(GENERIC_MIMETYPE, xmpMeta.get(TikaCoreProperties.FORMAT));
+	}
+
+	@Test
+	public void get_arrayProp_firstValueReturned() throws TikaException 
+	{
+		xmpMeta.process(tikaMetadata);
+		
+		assertEquals("keyword1", xmpMeta.get(TikaCoreProperties.SUBJECT));
+	}
+
+	@Test
+	public void get_notExistingProp_null() throws TikaException 
+	{
+		assertNull(xmpMeta.get(TikaCoreProperties.FORMAT));
+	}
+	
+	@Test(expected=PropertyTypeException.class)
+	public void get_nullInput_throw() 
+	{
+		String notInitialized = null;
+		xmpMeta.get(notInitialized);
+	}
+	
+	@Test(expected=PropertyTypeException.class)
+	public void get_notQualifiedKey_throw() 
+	{
+		xmpMeta.get("wrongKey");
+	}
+	
+	@Test(expected=PropertyTypeException.class)
+	public void get_unknownPrefixKey_throw() 
+	{
+		xmpMeta.get("unknown:key");
+	}
+	
+	@Test
+	public void getInt_IntegerProperty_valueReturned() throws TikaException 
+	{
+		xmpMeta.process(tikaMetadata);
+		
+		assertEquals(new Integer(2), xmpMeta.getInt(Property.get("xmp:Integer")));
+	}
+
+	@Test
+	public void getDate_DateProperty_valueReturned()  throws TikaException, XMPException 
+	{
+		xmpMeta.process(tikaMetadata);
+		
+		Date date = XMPUtils.convertToDate("2001-01-01T01:01").getCalendar().getTime();
+		assertTrue(date.equals(xmpMeta.getDate(TikaCoreProperties.MODIFIED)));
+	}
+
+	@Test
+	public void getValues_arrayProperty_allElementsReturned() throws TikaException 
+	{
+		xmpMeta.process(tikaMetadata);
+		
+		String[] values = xmpMeta.getValues(TikaCoreProperties.SUBJECT);
+		assertEquals(2, values.length);
+		
+		checkArrayValues(values, "keyword");
+	}
+
+	@Test
+	public void testSetAll() 
+	{
+		Properties props = new Properties();
+		props.put(TikaCoreProperties.FORMAT.getName(), "format");
+		props.put(TikaCoreProperties.SUBJECT.getName(), "keyword");
+		
+		xmpMeta.setAll(props);
+		
+		assertEquals("format", xmpMeta.get(TikaCoreProperties.FORMAT));
+		
+		String[] values = xmpMeta.getValues(TikaCoreProperties.SUBJECT);
+		assertEquals(1, values.length);
+		
+		assertEquals("keyword", values[0]);
+	}
+
+	@Test
+	public void set_simpleProp_ok() 
+	{
+		xmpMeta.set(TikaCoreProperties.FORMAT, GENERIC_MIMETYPE);
+		
+		assertEquals(GENERIC_MIMETYPE, xmpMeta.get(TikaCoreProperties.FORMAT));
+	}
+	
+	@Test(expected=PropertyTypeException.class)
+	public void set_nullInput_throw() 
+	{
+		String notInitialized = null;
+		xmpMeta.set(notInitialized,"value");
+	}
+	
+	@Test(expected=PropertyTypeException.class)
+	public void set_notQualifiedKey_throw() 
+	{
+		xmpMeta.set("wrongKey","value");
+	}
+	
+	@Test(expected=PropertyTypeException.class)
+	public void set_unknownPrefixKey_throw() 
+	{
+		xmpMeta.set("unknown:key","value");
+	}
+
+	@Test
+	public void set_arrayProperty_ok() 
+	{
+		xmpMeta.set(TikaCoreProperties.SUBJECT, new String[] {"keyword1", "keyword2"});
+
+		String[] values = xmpMeta.getValues(TikaCoreProperties.SUBJECT);
+		assertEquals(2, values.length);
+		
+		checkArrayValues(values, "keyword");
+	}
+
+	@Test(expected=PropertyTypeException.class)
+	public void set_simplePropWithMultipleValues_throw() 
+	{
+		xmpMeta.set(TikaCoreProperties.FORMAT,new String[] {"value1", "value2"});
+	}
+	
+
+	@Test
+	public void remove_existingProperty_propertyRemoved() throws TikaException 
+	{
+		xmpMeta.process(tikaMetadata);
+		
+		assertNotNull(xmpMeta.get(TikaCoreProperties.FORMAT));
+		
+		xmpMeta.remove(TikaCoreProperties.FORMAT);
+		
+		assertNull(xmpMeta.get(TikaCoreProperties.FORMAT));
+	}
+
+	@Test
+	public void size_numberOfNamespacesReturned() throws TikaException
+	{
+		xmpMeta.process(tikaMetadata);
+		
+		assertEquals(2, xmpMeta.size());
+		
+		xmpMeta.set(XMPRights.OWNER, "owner");
+		
+		assertEquals(3, xmpMeta.size());
+	}
+
+}

Commit:
ce112b205b0f0d1613b6f086b56efb393d049c23
Jukka Zitting
jukka@apache.org
2012-07-01 23:17:26 +0000
TIKA-773: .NET version of Tika
diff --git a/tika-dotnet/AssemblyInfo.cs b/tika-dotnet/AssemblyInfo.cs
deleted file mode 100644
index ff222aa3d..000000000
--- a/tika-dotnet/AssemblyInfo.cs
+++ /dev/null
@@ -1,36 +0,0 @@
-using System.Reflection;
-using System.Runtime.CompilerServices;
-using System.Runtime.InteropServices;
-
-// General Information about an assembly is controlled through the following
-// set of attributes. Change these attribute values to modify the information
-// associated with an assembly.
-[assembly: AssemblyTitle("Tika")]
-[assembly: AssemblyDescription("Apache Tika for .NET")]
-[assembly: AssemblyConfiguration("")]
-[assembly: AssemblyCompany("The Apache Software Foundation")]
-[assembly: AssemblyProduct("Apache Tika")]
-[assembly: AssemblyCopyright("Copyright   2012 The Apache Software Foundation")]
-[assembly: AssemblyTrademark("Apache Tika")]
-[assembly: AssemblyCulture("")]
-
-// Setting ComVisible to false makes the types in this assembly not visible
-// to COM components.  If you need to access a type in this assembly from
-// COM, set the ComVisible attribute to true on that type.
-[assembly: ComVisible(false)]
-
-// The following GUID is for the ID of the typelib if this project is exposed to COM
-[assembly: Guid("6213ebb8-975d-4641-a037-18b264a04642")]
-
-// Version information for an assembly consists of the following four values:
-//
-//      Major Version
-//      Minor Version
-//      Build Number
-//      Revision
-//
-// You can specify all the values or you can default the Build and Revision Numbers
-// by using the '*' as shown below:
-// [assembly: AssemblyVersion("1.0.*")]
-[assembly: AssemblyVersion("1.0.0.0")]
-[assembly: AssemblyFileVersion("1.0.0.0")]
diff --git a/tika-dotnet/Tika.csproj b/tika-dotnet/Tika.csproj
deleted file mode 100644
index 254f8bbfd..000000000
--- a/tika-dotnet/Tika.csproj
+++ /dev/null
@@ -1,54 +0,0 @@
-<?xml version="1.0" encoding="utf-8"?>
-<Project ToolsVersion="4.0" DefaultTargets="Build" xmlns="http://schemas.microsoft.com/developer/msbuild/2003">
-  <PropertyGroup>
-    <Configuration Condition=" '$(Configuration)' == '' ">Debug</Configuration>
-    <Platform Condition=" '$(Platform)' == '' ">AnyCPU</Platform>
-    <ProductVersion>8.0.30703</ProductVersion>
-    <SchemaVersion>2.0</SchemaVersion>
-    <ProjectGuid>{C5497120-111C-43B5-ADEB-3F34ABEF5C54}</ProjectGuid>
-    <OutputType>Library</OutputType>
-    <AppDesignerFolder>Properties</AppDesignerFolder>
-    <RootNamespace>Apache</RootNamespace>
-    <AssemblyName>Tika</AssemblyName>
-    <TargetFrameworkVersion>v4.0</TargetFrameworkVersion>
-    <FileAlignment>512</FileAlignment>
-  </PropertyGroup>
-  <PropertyGroup Condition=" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' ">
-    <DebugSymbols>true</DebugSymbols>
-    <DebugType>full</DebugType>
-    <Optimize>false</Optimize>
-    <OutputPath>target\Debug\</OutputPath>
-    <DefineConstants>DEBUG;TRACE</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-  </PropertyGroup>
-  <PropertyGroup Condition=" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' ">
-    <DebugType>pdbonly</DebugType>
-    <Optimize>true</Optimize>
-    <OutputPath>target\Release\</OutputPath>
-    <DefineConstants>TRACE</DefineConstants>
-    <ErrorReport>prompt</ErrorReport>
-    <WarningLevel>4</WarningLevel>
-  </PropertyGroup>
-  <ItemGroup>
-    <Reference Include="System" />
-    <Reference Include="System.Core" />
-    <Reference Include="IKVM.Runtime" />
-    <Reference Include="IKVM.OpenJDK.Core" />
-    <Reference Include="tika-app-1.2-SNAPSHOT">
-      <HintPath>..\tika-app\target\tika-app-1.2-SNAPSHOT.dll</HintPath>
-    </Reference>
-  </ItemGroup>
-  <ItemGroup>
-    <Compile Include="src\main\csharp\Apache\Tika.cs" />
-    <Compile Include="AssemblyInfo.cs" />
-  </ItemGroup>
-  <Import Project="$(MSBuildToolsPath)\Microsoft.CSharp.targets" />
-  <!-- To modify your build process, add your task inside one of the targets below and uncomment it. 
-       Other similar extension points exist, see Microsoft.Common.targets.
-  <Target Name="BeforeBuild">
-  </Target>
-  <Target Name="AfterBuild">
-  </Target>
-  -->
-</Project>
\ No newline at end of file
diff --git a/tika-dotnet/Tika.sln b/tika-dotnet/Tika.sln
deleted file mode 100644
index 5b39d7dd2..000000000
--- a/tika-dotnet/Tika.sln
+++ /dev/null
@@ -1,20 +0,0 @@
-
-Microsoft Visual Studio Solution File, Format Version 11.00
-# Visual C# Express 2010
-Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "Tika", "Tika.csproj", "{C5497120-111C-43B5-ADEB-3F34ABEF5C54}"
-EndProject
-Global
-	GlobalSection(SolutionConfigurationPlatforms) = preSolution
-		Debug|Any CPU = Debug|Any CPU
-		Release|Any CPU = Release|Any CPU
-	EndGlobalSection
-	GlobalSection(ProjectConfigurationPlatforms) = postSolution
-		{C5497120-111C-43B5-ADEB-3F34ABEF5C54}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
-		{C5497120-111C-43B5-ADEB-3F34ABEF5C54}.Debug|Any CPU.Build.0 = Debug|Any CPU
-		{C5497120-111C-43B5-ADEB-3F34ABEF5C54}.Release|Any CPU.ActiveCfg = Release|Any CPU
-		{C5497120-111C-43B5-ADEB-3F34ABEF5C54}.Release|Any CPU.Build.0 = Release|Any CPU
-	EndGlobalSection
-	GlobalSection(SolutionProperties) = preSolution
-		HideSolutionNode = FALSE
-	EndGlobalSection
-EndGlobal
diff --git a/tika-dotnet/pom.xml b/tika-dotnet/pom.xml
index 7007b7c50..ec3b1a538 100644
--- a/tika-dotnet/pom.xml
+++ b/tika-dotnet/pom.xml
@@ -32,20 +32,142 @@
   <artifactId>tika-dotnet</artifactId>
   <name>Apache Tika for .NET</name>
   <url>http://tika.apache.org/</url>
-  <packaging>netpack</packaging>
+
+  <properties>
+    <ikvm>C:\ikvm-7.0.4335.0</ikvm>
+    <mscorlib>${ikvm}\mscorlib</mscorlib>
+    <System>${ikvm}\System</System>
+  </properties>
+
+  <dependencies>
+    <dependency>
+      <groupId>org.apache.tika</groupId>
+      <artifactId>tika-app</artifactId>
+      <version>${project.version}</version>
+    </dependency>
+    <dependency>
+      <groupId>ikvm</groupId>
+      <artifactId>mscorlib</artifactId>
+      <version>2.0</version>
+      <scope>system</scope>
+      <systemPath>${mscorlib}.jar</systemPath>
+    </dependency>
+    <dependency>
+      <groupId>ikvm</groupId>
+      <artifactId>System</artifactId>
+      <version>2.0</version>
+      <scope>system</scope>
+      <systemPath>${System}.jar</systemPath>
+    </dependency>
+  </dependencies>
 
   <build>
     <plugins>
       <plugin>
-        <groupId>org.codehaus.sonar-plugins.dotnet</groupId>
-        <artifactId>maven-dotnet-plugin</artifactId>
-        <version>1.1</version>
-        <configuration>
-          <solutionName>Tika.sln</solutionName>
-        </configuration>
-        <extensions>true</extensions>
+        <artifactId>maven-dependency-plugin</artifactId>
+        <version>2.4</version>
+        <executions>
+          <execution>
+            <id>copy-dependencies</id>
+            <phase>package</phase>
+            <goals>
+              <goal>copy-dependencies</goal>
+            </goals>
+            <configuration>
+              <stripVersion>true</stripVersion>
+              <excludeTransitive>true</excludeTransitive>
+              <excludeScope>system</excludeScope>
+            </configuration>
+          </execution>
+        </executions>
+      </plugin>
+      <plugin>
+        <artifactId>maven-antrun-plugin</artifactId>
+        <executions>
+          <execution>
+            <phase>package</phase>
+            <goals>
+              <goal>run</goal>
+            </goals>
+            <configuration>
+              <target>
+                <exec executable="${ikvm}/bin/ikvmc.exe">
+                  <arg value="-nowarn:0100" />
+                  <arg value="-nowarn:0105" />
+                  <arg value="-nowarn:0109" />
+                  <arg value="-nowarn:0111" />
+                  <arg value="-nowarn:0112" />
+                  <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.Charsets.dll" />
+                  <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.Core.dll" />
+                  <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.Text.dll" />
+                  <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.Util.dll" />
+                  <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.XML.API.dll" />
+                  <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.XML.Transform.dll" />
+                  <arg value="-r:${mscorlib}.dll" />
+                  <arg value="-r:${System}.dll" />
+                  <arg value="-target:library" />
+                  <arg value="-compressresources" />
+                  <arg value="-out:${project.build.directory}/${project.build.finalName}.dll" />
+                  <arg value="-recurse:${project.build.directory}\*.class" />
+                  <arg value="${project.build.directory}/dependency/tika-app.jar" />
+                </exec>
+              </target>
+            </configuration>
+          </execution>
+        </executions>
+      </plugin>
+      <plugin>
+        <groupId>org.codehaus.mojo</groupId>
+        <artifactId>build-helper-maven-plugin</artifactId>
+        <version>1.7</version>
+        <executions>
+          <execution>
+            <phase>package</phase>
+            <goals>
+              <goal>attach-artifact</goal>
+            </goals>
+            <configuration>
+              <artifacts>
+                <artifacts>
+                  <file>${project.build.directory}/${project.build.finalName}.dll</file>
+                  <type>dll</type>
+                </artifacts>
+              </artifacts>
+            </configuration>
+          </execution>
+        </executions>
       </plugin>
     </plugins>
+    <pluginManagement>
+      <plugins>
+        <!-- This plugin's configuration is used to store Eclipse m2e settings 
+            only. It has no influence on the Maven build itself. -->
+        <plugin>
+          <groupId>org.eclipse.m2e</groupId>
+          <artifactId>lifecycle-mapping</artifactId>
+          <version>1.0.0</version>
+          <configuration>
+            <lifecycleMappingMetadata>
+              <pluginExecutions>
+                <pluginExecution>
+                  <pluginExecutionFilter>
+                    <groupId>org.apache.maven.plugins</groupId>
+                    <artifactId>maven-dependency-plugin</artifactId>
+                    <versionRange>[2.4,)</versionRange>
+                    <goals>
+                      <goal>copy-dependencies</goal>
+                    </goals>
+                  </pluginExecutionFilter>
+                  <action>
+                    <ignore></ignore>
+                  </action>
+                </pluginExecution>
+              </pluginExecutions>
+            </lifecycleMappingMetadata>
+          </configuration>
+        </plugin>
+      </plugins>
+    </pluginManagement>
   </build>
 
 </project>
diff --git a/tika-dotnet/src/main/csharp/Apache/Tika.cs b/tika-dotnet/src/main/csharp/Apache/Tika.cs
deleted file mode 100644
index 77714c1d3..000000000
--- a/tika-dotnet/src/main/csharp/Apache/Tika.cs
+++ /dev/null
@@ -1,55 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-using System;
-using System.IO;
-
-namespace Apache
-{
-
-    public class Tika
-    {
-
-        private readonly org.apache.tika.Tika tika = new org.apache.tika.Tika();
-
-        public string detect(string name)
-        {
-            return tika.detect(name);
-        }
-
-        public string detect(FileInfo file)
-        {
-            return tika.detect(new java.io.File(file.FullName)); ;
-        }
-
-        public string detect(Uri uri)
-        {
-            return tika.detect(new java.net.URL(uri.AbsoluteUri));
-        }
-
-        public string parseToString(FileInfo file)
-        {
-            return tika.parseToString(new java.io.File(file.FullName)); ;
-        }
-
-        public string parseToString(Uri uri)
-        {
-            return tika.parseToString(new java.net.URL(uri.AbsoluteUri)); ;
-        }
-
-    }
-
-}
diff --git a/tika-dotnet/src/main/java/Tika/Tika.java b/tika-dotnet/src/main/java/Tika/Tika.java
new file mode 100644
index 000000000..933509eaf
--- /dev/null
+++ b/tika-dotnet/src/main/java/Tika/Tika.java
@@ -0,0 +1,77 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package Tika;
+
+import java.io.File;
+import java.io.IOException;
+import java.net.URL;
+
+import org.apache.tika.exception.TikaException;
+
+public class Tika {
+
+    private final org.apache.tika.Tika tika = new org.apache.tika.Tika();
+
+    public cli.System.String detect(cli.System.String name) {
+        return toCliString(tika.detect(toJvmString(name)));
+    }
+
+    public cli.System.String detect(cli.System.IO.FileInfo file)
+            throws cli.System.IO.IOException {
+        try {
+            return toCliString(tika.detect(new File(file.get_FullName())));
+        } catch (IOException e) {
+            throw new cli.System.IO.IOException(e.getMessage(), e);
+        }
+    }
+
+    public cli.System.String detect(cli.System.Uri uri)
+            throws cli.System.IO.IOException {
+        try {
+            return toCliString(tika.detect(new URL(uri.get_AbsolutePath())));
+        } catch (IOException e) {
+            throw new cli.System.IO.IOException(e.getMessage(), e);
+        }
+    }
+
+    public cli.System.String parseToString(cli.System.IO.FileInfo file)
+            throws cli.System.IO.IOException, TikaException {
+        try {
+            return toCliString(tika.parseToString(new File(file.get_FullName())));
+        } catch (IOException e) {
+            throw new cli.System.IO.IOException(e.getMessage(), e);
+        }
+    }
+
+    public cli.System.String parseToString(cli.System.Uri uri)
+            throws cli.System.IO.IOException, TikaException {
+        try {
+            return toCliString(tika.parseToString(new URL(uri.get_AbsoluteUri())));
+        } catch (IOException e) {
+            throw new cli.System.IO.IOException(e.getMessage(), e);
+        }
+    }
+
+    private static cli.System.String toCliString(String string) {
+        return new cli.System.String(string.toCharArray());
+    }
+
+    private static String toJvmString(cli.System.String string) {
+        return new String(string.ToCharArray());
+    }
+
+}

Commit:
e154de93ed6fb9ffc856e994b7cb36fd0a2142a9
Jukka Zitting
jukka@apache.org
2012-07-01 21:39:13 +0000
TIKA-773: .NET version of Tika
diff --git a/pom.xml b/pom.xml
index ed24f7d4c..d8d7c96e2 100644
--- a/pom.xml
+++ b/pom.xml
@@ -75,12 +75,12 @@
           <excludes>
             <exclude>.*/**</exclude>
             <exclude>CHANGES.txt</exclude>
-            <exclude>tika-dll/AssemblyInfo.cs</exclude>
-            <exclude>tika-dll/Tika.csproj</exclude>
-            <exclude>tika-dll/Tika.sln</exclude>
-            <exclude>tika-dll/Tika.sln.cache</exclude>
-            <exclude>tika-dll/obj/**</exclude>
-            <exclude>tika-dll/target/**</exclude>
+            <exclude>tika-dotnet/AssemblyInfo.cs</exclude>
+            <exclude>tika-dotnet/Tika.csproj</exclude>
+            <exclude>tika-dotnet/Tika.sln</exclude>
+            <exclude>tika-dotnet/Tika.sln.cache</exclude>
+            <exclude>tika-dotnet/obj/**</exclude>
+            <exclude>tika-dotnet/target/**</exclude>
           </excludes>
         </configuration>
       </plugin>
diff --git a/tika-dll/.gitignore b/tika-dotnet/.gitignore
similarity index 100%
rename from tika-dll/.gitignore
rename to tika-dotnet/.gitignore
diff --git a/tika-dll/AssemblyInfo.cs b/tika-dotnet/AssemblyInfo.cs
similarity index 100%
rename from tika-dll/AssemblyInfo.cs
rename to tika-dotnet/AssemblyInfo.cs
diff --git a/tika-dll/Tika.csproj b/tika-dotnet/Tika.csproj
similarity index 100%
rename from tika-dll/Tika.csproj
rename to tika-dotnet/Tika.csproj
diff --git a/tika-dll/Tika.sln b/tika-dotnet/Tika.sln
similarity index 100%
rename from tika-dll/Tika.sln
rename to tika-dotnet/Tika.sln
diff --git a/tika-dll/pom.xml b/tika-dotnet/pom.xml
similarity index 100%
rename from tika-dll/pom.xml
rename to tika-dotnet/pom.xml
diff --git a/tika-dll/src/main/csharp/Apache/Tika.cs b/tika-dotnet/src/main/csharp/Apache/Tika.cs
similarity index 100%
rename from tika-dll/src/main/csharp/Apache/Tika.cs
rename to tika-dotnet/src/main/csharp/Apache/Tika.cs

Commit:
b8fe97ea1bad2a081142b69e29825e5d08d78a97
Ray Gauss II
rgauss@apache.org
2012-07-01 16:39:29 +0000
Added rgauss as developer to tika-parent/pom.xml First commit
diff --git a/tika-parent/pom.xml b/tika-parent/pom.xml
index 5bd7d38d8..6dc0279fe 100644
--- a/tika-parent/pom.xml
+++ b/tika-parent/pom.xml
@@ -195,6 +195,16 @@
       </roles>
       <timezone>+2</timezone>
     </developer>
+    <developer>
+      <name>Ray Gauss II</name>
+      <id>rgauss</id>
+      <organization>Alfresco</organization>
+      <organizationUrl>http://alfresco.com</organizationUrl>
+      <timezone>-5</timezone>
+      <roles>
+        <role>committer</role>
+      </roles>
+    </developer>
   </developers>
   <contributors>
     <contributor>

Commit:
1051da07c8595b07d2b10301c64f8ca1b13b746f
Jukka Zitting
jukka@apache.org
2012-07-01 13:04:00 +0000
TIKA-773: .NET version of Tika
diff --git a/pom.xml b/pom.xml
index 5ed9e9251..ed24f7d4c 100644
--- a/pom.xml
+++ b/pom.xml
@@ -75,8 +75,12 @@
           <excludes>
             <exclude>.*/**</exclude>
             <exclude>CHANGES.txt</exclude>
-            <exclude>tika-server/.*/**</exclude>
-            <exclude>tika-server/target/**</exclude>
+            <exclude>tika-dll/AssemblyInfo.cs</exclude>
+            <exclude>tika-dll/Tika.csproj</exclude>
+            <exclude>tika-dll/Tika.sln</exclude>
+            <exclude>tika-dll/Tika.sln.cache</exclude>
+            <exclude>tika-dll/obj/**</exclude>
+            <exclude>tika-dll/target/**</exclude>
           </excludes>
         </configuration>
       </plugin>
diff --git a/tika-dll/.gitignore b/tika-dll/.gitignore
new file mode 100644
index 000000000..8b7111121
--- /dev/null
+++ b/tika-dll/.gitignore
@@ -0,0 +1,2 @@
+Tika.sln.cache
+obj
diff --git a/tika-dll/AssemblyInfo.cs b/tika-dll/AssemblyInfo.cs
new file mode 100644
index 000000000..ff222aa3d
--- /dev/null
+++ b/tika-dll/AssemblyInfo.cs
@@ -0,0 +1,36 @@
+using System.Reflection;
+using System.Runtime.CompilerServices;
+using System.Runtime.InteropServices;
+
+// General Information about an assembly is controlled through the following
+// set of attributes. Change these attribute values to modify the information
+// associated with an assembly.
+[assembly: AssemblyTitle("Tika")]
+[assembly: AssemblyDescription("Apache Tika for .NET")]
+[assembly: AssemblyConfiguration("")]
+[assembly: AssemblyCompany("The Apache Software Foundation")]
+[assembly: AssemblyProduct("Apache Tika")]
+[assembly: AssemblyCopyright("Copyright   2012 The Apache Software Foundation")]
+[assembly: AssemblyTrademark("Apache Tika")]
+[assembly: AssemblyCulture("")]
+
+// Setting ComVisible to false makes the types in this assembly not visible
+// to COM components.  If you need to access a type in this assembly from
+// COM, set the ComVisible attribute to true on that type.
+[assembly: ComVisible(false)]
+
+// The following GUID is for the ID of the typelib if this project is exposed to COM
+[assembly: Guid("6213ebb8-975d-4641-a037-18b264a04642")]
+
+// Version information for an assembly consists of the following four values:
+//
+//      Major Version
+//      Minor Version
+//      Build Number
+//      Revision
+//
+// You can specify all the values or you can default the Build and Revision Numbers
+// by using the '*' as shown below:
+// [assembly: AssemblyVersion("1.0.*")]
+[assembly: AssemblyVersion("1.0.0.0")]
+[assembly: AssemblyFileVersion("1.0.0.0")]
diff --git a/tika-dll/Tika.csproj b/tika-dll/Tika.csproj
new file mode 100644
index 000000000..254f8bbfd
--- /dev/null
+++ b/tika-dll/Tika.csproj
@@ -0,0 +1,54 @@
+<?xml version="1.0" encoding="utf-8"?>
+<Project ToolsVersion="4.0" DefaultTargets="Build" xmlns="http://schemas.microsoft.com/developer/msbuild/2003">
+  <PropertyGroup>
+    <Configuration Condition=" '$(Configuration)' == '' ">Debug</Configuration>
+    <Platform Condition=" '$(Platform)' == '' ">AnyCPU</Platform>
+    <ProductVersion>8.0.30703</ProductVersion>
+    <SchemaVersion>2.0</SchemaVersion>
+    <ProjectGuid>{C5497120-111C-43B5-ADEB-3F34ABEF5C54}</ProjectGuid>
+    <OutputType>Library</OutputType>
+    <AppDesignerFolder>Properties</AppDesignerFolder>
+    <RootNamespace>Apache</RootNamespace>
+    <AssemblyName>Tika</AssemblyName>
+    <TargetFrameworkVersion>v4.0</TargetFrameworkVersion>
+    <FileAlignment>512</FileAlignment>
+  </PropertyGroup>
+  <PropertyGroup Condition=" '$(Configuration)|$(Platform)' == 'Debug|AnyCPU' ">
+    <DebugSymbols>true</DebugSymbols>
+    <DebugType>full</DebugType>
+    <Optimize>false</Optimize>
+    <OutputPath>target\Debug\</OutputPath>
+    <DefineConstants>DEBUG;TRACE</DefineConstants>
+    <ErrorReport>prompt</ErrorReport>
+    <WarningLevel>4</WarningLevel>
+  </PropertyGroup>
+  <PropertyGroup Condition=" '$(Configuration)|$(Platform)' == 'Release|AnyCPU' ">
+    <DebugType>pdbonly</DebugType>
+    <Optimize>true</Optimize>
+    <OutputPath>target\Release\</OutputPath>
+    <DefineConstants>TRACE</DefineConstants>
+    <ErrorReport>prompt</ErrorReport>
+    <WarningLevel>4</WarningLevel>
+  </PropertyGroup>
+  <ItemGroup>
+    <Reference Include="System" />
+    <Reference Include="System.Core" />
+    <Reference Include="IKVM.Runtime" />
+    <Reference Include="IKVM.OpenJDK.Core" />
+    <Reference Include="tika-app-1.2-SNAPSHOT">
+      <HintPath>..\tika-app\target\tika-app-1.2-SNAPSHOT.dll</HintPath>
+    </Reference>
+  </ItemGroup>
+  <ItemGroup>
+    <Compile Include="src\main\csharp\Apache\Tika.cs" />
+    <Compile Include="AssemblyInfo.cs" />
+  </ItemGroup>
+  <Import Project="$(MSBuildToolsPath)\Microsoft.CSharp.targets" />
+  <!-- To modify your build process, add your task inside one of the targets below and uncomment it. 
+       Other similar extension points exist, see Microsoft.Common.targets.
+  <Target Name="BeforeBuild">
+  </Target>
+  <Target Name="AfterBuild">
+  </Target>
+  -->
+</Project>
\ No newline at end of file
diff --git a/tika-dll/Tika.sln b/tika-dll/Tika.sln
new file mode 100644
index 000000000..5b39d7dd2
--- /dev/null
+++ b/tika-dll/Tika.sln
@@ -0,0 +1,20 @@
+
+Microsoft Visual Studio Solution File, Format Version 11.00
+# Visual C# Express 2010
+Project("{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}") = "Tika", "Tika.csproj", "{C5497120-111C-43B5-ADEB-3F34ABEF5C54}"
+EndProject
+Global
+	GlobalSection(SolutionConfigurationPlatforms) = preSolution
+		Debug|Any CPU = Debug|Any CPU
+		Release|Any CPU = Release|Any CPU
+	EndGlobalSection
+	GlobalSection(ProjectConfigurationPlatforms) = postSolution
+		{C5497120-111C-43B5-ADEB-3F34ABEF5C54}.Debug|Any CPU.ActiveCfg = Debug|Any CPU
+		{C5497120-111C-43B5-ADEB-3F34ABEF5C54}.Debug|Any CPU.Build.0 = Debug|Any CPU
+		{C5497120-111C-43B5-ADEB-3F34ABEF5C54}.Release|Any CPU.ActiveCfg = Release|Any CPU
+		{C5497120-111C-43B5-ADEB-3F34ABEF5C54}.Release|Any CPU.Build.0 = Release|Any CPU
+	EndGlobalSection
+	GlobalSection(SolutionProperties) = preSolution
+		HideSolutionNode = FALSE
+	EndGlobalSection
+EndGlobal
diff --git a/tika-dll/pom.xml b/tika-dll/pom.xml
new file mode 100644
index 000000000..7007b7c50
--- /dev/null
+++ b/tika-dll/pom.xml
@@ -0,0 +1,51 @@
+<?xml version="1.0" encoding="UTF-8"?>
+
+<!--
+  Licensed to the Apache Software Foundation (ASF) under one
+  or more contributor license agreements.  See the NOTICE file
+  distributed with this work for additional information
+  regarding copyright ownership.  The ASF licenses this file
+  to you under the Apache License, Version 2.0 (the
+  "License"); you may not use this file except in compliance
+  with the License.  You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+  Unless required by applicable law or agreed to in writing,
+  software distributed under the License is distributed on an
+  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+  KIND, either express or implied.  See the License for the
+  specific language governing permissions and limitations
+  under the License.
+-->
+
+<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
+  <modelVersion>4.0.0</modelVersion>
+
+  <parent>
+    <groupId>org.apache.tika</groupId>
+    <artifactId>tika-parent</artifactId>
+    <version>1.2-SNAPSHOT</version>
+    <relativePath>../tika-parent/pom.xml</relativePath>
+  </parent>
+
+  <artifactId>tika-dotnet</artifactId>
+  <name>Apache Tika for .NET</name>
+  <url>http://tika.apache.org/</url>
+  <packaging>netpack</packaging>
+
+  <build>
+    <plugins>
+      <plugin>
+        <groupId>org.codehaus.sonar-plugins.dotnet</groupId>
+        <artifactId>maven-dotnet-plugin</artifactId>
+        <version>1.1</version>
+        <configuration>
+          <solutionName>Tika.sln</solutionName>
+        </configuration>
+        <extensions>true</extensions>
+      </plugin>
+    </plugins>
+  </build>
+
+</project>
diff --git a/tika-dll/src/main/csharp/Apache/Tika.cs b/tika-dll/src/main/csharp/Apache/Tika.cs
new file mode 100644
index 000000000..77714c1d3
--- /dev/null
+++ b/tika-dll/src/main/csharp/Apache/Tika.cs
@@ -0,0 +1,55 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+using System;
+using System.IO;
+
+namespace Apache
+{
+
+    public class Tika
+    {
+
+        private readonly org.apache.tika.Tika tika = new org.apache.tika.Tika();
+
+        public string detect(string name)
+        {
+            return tika.detect(name);
+        }
+
+        public string detect(FileInfo file)
+        {
+            return tika.detect(new java.io.File(file.FullName)); ;
+        }
+
+        public string detect(Uri uri)
+        {
+            return tika.detect(new java.net.URL(uri.AbsoluteUri));
+        }
+
+        public string parseToString(FileInfo file)
+        {
+            return tika.parseToString(new java.io.File(file.FullName)); ;
+        }
+
+        public string parseToString(Uri uri)
+        {
+            return tika.parseToString(new java.net.URL(uri.AbsoluteUri)); ;
+        }
+
+    }
+
+}

Commit:
59e93d729211e811cfe15fdad2de98158fb75d93
Jukka Zitting
jukka@apache.org
2012-07-01 11:35:05 +0000
TIKA-593: Tika network server
diff --git a/tika-app/pom.xml b/tika-app/pom.xml
index 5fb32055a..e3cc85135 100644
--- a/tika-app/pom.xml
+++ b/tika-app/pom.xml
@@ -80,7 +80,6 @@
     <plugins>
       <plugin>
         <artifactId>maven-shade-plugin</artifactId>
-        <version>1.6</version>
         <executions>
           <execution>
             <phase>package</phase>
diff --git a/tika-parent/pom.xml b/tika-parent/pom.xml
index a94164f4b..5bd7d38d8 100644
--- a/tika-parent/pom.xml
+++ b/tika-parent/pom.xml
@@ -261,6 +261,16 @@
           <artifactId>maven-bundle-plugin</artifactId>
           <version>2.3.4</version>
         </plugin>
+        <plugin>
+          <groupId>org.apache.maven.plugins</groupId>
+          <artifactId>maven-surefire-plugin</artifactId>
+          <version>2.12</version>
+        </plugin>
+        <plugin>
+          <groupId>org.apache.maven.plugins</groupId>
+          <artifactId>maven-shade-plugin</artifactId>
+          <version>1.6</version>
+        </plugin>
       </plugins>
     </pluginManagement>
   </build>
diff --git a/tika-server/pom.xml b/tika-server/pom.xml
index 81a63f5be..c0c741c28 100644
--- a/tika-server/pom.xml
+++ b/tika-server/pom.xml
@@ -25,7 +25,6 @@
   </parent>
 
   <artifactId>tika-server</artifactId>
-  <packaging>bundle</packaging>
   <name>Apache Tika server</name>
 
   <dependencies>
@@ -68,61 +67,19 @@
 
   <build>
     <plugins>
-      <!--  Maven Exec Plug-In: http://mojo.codehaus.org/exec-maven-plugin/  -->
       <plugin>
-        <groupId>org.codehaus.mojo</groupId>
-        <artifactId>exec-maven-plugin</artifactId>
-        <version>1.1</version>
-        <executions>
-          <execution>
-            <goals>
-              <goal>java</goal>
-            </goals>
-          </execution>
-        </executions>
-        <configuration>
-          <mainClass>su.msk.jet.tikaserver.TikaServerCli</mainClass>
-        </configuration>
-      </plugin>
-      <plugin>
-        <groupId>org.apache.maven.plugins</groupId>
-        <artifactId>maven-compiler-plugin</artifactId>
-        <inherited>true</inherited>
-        <configuration>
-          <source>1.5</source>
-          <target>1.5</target>
-        </configuration>
-      </plugin>
-      <plugin>
-        <groupId>org.apache.felix</groupId>
-        <artifactId>maven-bundle-plugin</artifactId>
-        <extensions>true</extensions>
-        <version>2.3.6</version>
-        <configuration>
-          <instructions>
-            <Export-Package>org.apache.tika.*</Export-Package>
-            <Bundle-DocURL>${project.url}</Bundle-DocURL>
-              <Main-Class>org.apache.tika.server.TikaServerCli</Main-Class>
-          </instructions>
-        </configuration>
-      </plugin>
-      <plugin>
-        <groupId>org.apache.maven.plugins</groupId>
         <artifactId>maven-surefire-plugin</artifactId>
-        <version>2.12</version>
         <configuration>
           <redirectTestOutputToFile>true</redirectTestOutputToFile>
           <argLine>-da -XX:+HeapDumpOnOutOfMemoryError -Xmx512m</argLine>
-          <systemProperties>
-            <property>
-              <name>java.util.logging.config.file</name>
-              <value>${basedir}/src/main/resources/commons-logging.properties</value>
-            </property>
-          </systemProperties>
+          <systemPropertyVariables>
+            <java.util.logging.config.file>
+              ${basedir}/src/main/resources/commons-logging.properties
+            </java.util.logging.config.file>
+          </systemPropertyVariables>
         </configuration>
       </plugin>
       <plugin>
-        <groupId>org.apache.maven.plugins</groupId>
         <artifactId>maven-shade-plugin</artifactId>
         <executions>
           <execution>
@@ -131,6 +88,9 @@
               <goal>shade</goal>
             </goals>
             <configuration>
+              <createDependencyReducedPom>
+                false
+              </createDependencyReducedPom>
               <filters>
                 <filter>
                   <artifact>*:*</artifact>
@@ -138,15 +98,43 @@
                     <exclude>META-INF/*.SF</exclude>
                     <exclude>META-INF/*.DSA</exclude>
                     <exclude>META-INF/*.RSA</exclude>
+                    <exclude>META-INF/*.txt</exclude>
+                    <exclude>META-INF/ASL2.0</exclude>
+                    <exclude>META-INF/DEPENDENCIES</exclude>
+                    <exclude>META-INF/LICENSE</exclude>
+                    <exclude>META-INF/NOTICE</exclude>
+                    <exclude>META-INF/README</exclude>
+                    <exclude>LICENSE.txt</exclude>
+                    <exclude>NOTICE.txt</exclude>
+                    <exclude>CHANGES</exclude>
+                    <exclude>README</exclude>
+                    <exclude>builddef.lst</exclude>
+                    <!-- TIKA-763: Workaround to avoid including LGPL classes -->
+                    <exclude>ucar/nc2/iosp/fysat/Fysat*.class</exclude>
+                    <exclude>ucar/nc2/dataset/transform/VOceanSG1*class</exclude>
+                    <exclude>ucar/unidata/geoloc/vertical/OceanSG*.class</exclude>
                   </excludes>
                 </filter>
               </filters>
               <transformers>
-                <transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer">
-                  <resource>META-INF/spring.handlers</resource>
+                <transformer implementation="org.apache.maven.plugins.shade.resource.ManifestResourceTransformer">
+                  <mainClass>org.apache.tika.server.TikaServerCli</mainClass>
+                </transformer>
+                <transformer implementation="org.apache.maven.plugins.shade.resource.ServicesResourceTransformer"/>
+                <transformer implementation="org.apache.maven.plugins.shade.resource.IncludeResourceTransformer">
+                  <resource>META-INF/LICENSE</resource>
+                  <file>target/classes/META-INF/LICENSE</file>
+                </transformer>
+                <transformer implementation="org.apache.maven.plugins.shade.resource.IncludeResourceTransformer">
+                  <resource>META-INF/NOTICE</resource>
+                  <file>target/classes/META-INF/NOTICE</file>
+                </transformer>
+                <transformer implementation="org.apache.maven.plugins.shade.resource.IncludeResourceTransformer">
+                  <resource>META-INF/DEPENDENCIES</resource>
+                  <file>target/classes/META-INF/DEPENDENCIES</file>
                 </transformer>
                 <transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer">
-                  <resource>META-INF/services/com.sun.tools.xjc.Plugin</resource>
+                  <resource>META-INF/spring.handlers</resource>
                 </transformer>
                 <transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer">
                   <resource>META-INF/spring.schemas</resource>

Commit:
89d98a25c99e2d0d7522dc9cac55b287bf4cc4a3
Jukka Zitting
jukka@apache.org
2012-07-01 11:05:14 +0000
TIKA-593: Tika network server
diff --git a/tika-server/pom.xml b/tika-server/pom.xml
index f636f2216..81a63f5be 100644
--- a/tika-server/pom.xml
+++ b/tika-server/pom.xml
@@ -28,71 +28,71 @@
   <packaging>bundle</packaging>
   <name>Apache Tika server</name>
 
-    <dependencies>
-        <dependency>
-            <groupId>${project.groupId}</groupId>
-            <artifactId>tika-parsers</artifactId>
-            <version>${project.version}</version>
-        </dependency>
-		<dependency>
-			<groupId>net.sf.opencsv</groupId>
-			<artifactId>opencsv</artifactId>
-			<version>2.0</version>
-		</dependency>      
-		<dependency>
-	      <groupId>org.apache.cxf</groupId>
-	      <artifactId>cxf-rt-frontend-jaxrs</artifactId>
-	      <version>2.5.2</version>
-		</dependency>  
-		<dependency>
-		   <groupId>org.apache.cxf</groupId>
-		   <artifactId>cxf-rt-transports-http-jetty</artifactId>
-		   <version>2.5.2</version>
-		</dependency>   	
-        <dependency>
-            <groupId>commons-cli</groupId>
-            <artifactId>commons-cli</artifactId>
-            <version>1.2</version>
-        </dependency>
-        <dependency>
-            <groupId>commons-lang</groupId>
-            <artifactId>commons-lang</artifactId>
-            <version>2.5</version>
-        </dependency>
-        <dependency>
-            <groupId>junit</groupId>
-            <artifactId>junit</artifactId>
-            <scope>test</scope>
-        </dependency>
-    </dependencies>
+  <dependencies>
+    <dependency>
+      <groupId>${project.groupId}</groupId>
+      <artifactId>tika-parsers</artifactId>
+      <version>${project.version}</version>
+    </dependency>
+    <dependency>
+      <groupId>net.sf.opencsv</groupId>
+      <artifactId>opencsv</artifactId>
+      <version>2.0</version>
+    </dependency>
+    <dependency>
+      <groupId>org.apache.cxf</groupId>
+      <artifactId>cxf-rt-frontend-jaxrs</artifactId>
+      <version>2.5.2</version>
+    </dependency>
+    <dependency>
+      <groupId>org.apache.cxf</groupId>
+      <artifactId>cxf-rt-transports-http-jetty</artifactId>
+      <version>2.5.2</version>
+    </dependency>
+    <dependency>
+      <groupId>commons-cli</groupId>
+      <artifactId>commons-cli</artifactId>
+      <version>1.2</version>
+    </dependency>
+    <dependency>
+      <groupId>commons-lang</groupId>
+      <artifactId>commons-lang</artifactId>
+      <version>2.5</version>
+    </dependency>
+    <dependency>
+      <groupId>junit</groupId>
+      <artifactId>junit</artifactId>
+      <scope>test</scope>
+    </dependency>
+  </dependencies>
 
-    <build>
-        <plugins>
-           <!--  Maven Exec Plug-In: http://mojo.codehaus.org/exec-maven-plugin/  -->
-            <plugin>
-                <groupId>org.codehaus.mojo</groupId>
-                <artifactId>exec-maven-plugin</artifactId>
-                <version>1.1</version>
-                <executions>
-                    <execution>
-                        <goals>
-                            <goal>java</goal>
-                        </goals>
-                    </execution>
-                </executions>
-                <configuration>
-                    <mainClass>su.msk.jet.tikaserver.TikaServerCli</mainClass>
-                </configuration>
-            </plugin>
-            <plugin>
-                <groupId>org.apache.maven.plugins</groupId>
-                <artifactId>maven-compiler-plugin</artifactId>
-                <inherited>true</inherited>
-                <configuration>
-                    <source>1.5</source>
-                    <target>1.5</target>
-                </configuration>
-            </plugin>
+  <build>
+    <plugins>
+      <!--  Maven Exec Plug-In: http://mojo.codehaus.org/exec-maven-plugin/  -->
+      <plugin>
+        <groupId>org.codehaus.mojo</groupId>
+        <artifactId>exec-maven-plugin</artifactId>
+        <version>1.1</version>
+        <executions>
+          <execution>
+            <goals>
+              <goal>java</goal>
+            </goals>
+          </execution>
+        </executions>
+        <configuration>
+          <mainClass>su.msk.jet.tikaserver.TikaServerCli</mainClass>
+        </configuration>
+      </plugin>
+      <plugin>
+        <groupId>org.apache.maven.plugins</groupId>
+        <artifactId>maven-compiler-plugin</artifactId>
+        <inherited>true</inherited>
+        <configuration>
+          <source>1.5</source>
+          <target>1.5</target>
+        </configuration>
+      </plugin>
       <plugin>
         <groupId>org.apache.felix</groupId>
         <artifactId>maven-bundle-plugin</artifactId>
@@ -102,86 +102,85 @@
           <instructions>
             <Export-Package>org.apache.tika.*</Export-Package>
             <Bundle-DocURL>${project.url}</Bundle-DocURL>
-                    <Main-Class>org.apache.tika.server.TikaServerCli</Main-Class>
+              <Main-Class>org.apache.tika.server.TikaServerCli</Main-Class>
           </instructions>
         </configuration>
       </plugin>
-            <plugin>
-                <groupId>org.apache.maven.plugins</groupId>
-                <artifactId>maven-surefire-plugin</artifactId>
-                <version>2.12</version>
-                <configuration>
-                    <redirectTestOutputToFile>true</redirectTestOutputToFile>
-                    <argLine>-da -XX:+HeapDumpOnOutOfMemoryError -Xmx512m</argLine>
-                    <systemProperties>
-		             <property>
-		               <name>java.util.logging.config.file</name>
-		               <value>${basedir}/src/main/resources/commons-logging.properties</value>
-		             </property>
-                    </systemProperties>
-                </configuration>
-            </plugin>
+      <plugin>
+        <groupId>org.apache.maven.plugins</groupId>
+        <artifactId>maven-surefire-plugin</artifactId>
+        <version>2.12</version>
+        <configuration>
+          <redirectTestOutputToFile>true</redirectTestOutputToFile>
+          <argLine>-da -XX:+HeapDumpOnOutOfMemoryError -Xmx512m</argLine>
+          <systemProperties>
+            <property>
+              <name>java.util.logging.config.file</name>
+              <value>${basedir}/src/main/resources/commons-logging.properties</value>
+            </property>
+          </systemProperties>
+        </configuration>
+      </plugin>
+      <plugin>
+        <groupId>org.apache.maven.plugins</groupId>
+        <artifactId>maven-shade-plugin</artifactId>
+        <executions>
+          <execution>
+            <phase>package</phase>
+            <goals>
+              <goal>shade</goal>
+            </goals>
+            <configuration>
+              <filters>
+                <filter>
+                  <artifact>*:*</artifact>
+                  <excludes>
+                    <exclude>META-INF/*.SF</exclude>
+                    <exclude>META-INF/*.DSA</exclude>
+                    <exclude>META-INF/*.RSA</exclude>
+                  </excludes>
+                </filter>
+              </filters>
+              <transformers>
+                <transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer">
+                  <resource>META-INF/spring.handlers</resource>
+                </transformer>
+                <transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer">
+                  <resource>META-INF/services/com.sun.tools.xjc.Plugin</resource>
+                </transformer>
+                <transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer">
+                  <resource>META-INF/spring.schemas</resource>
+                </transformer>
+                <transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer">
+                  <resource>META-INF/cxf/cxf.extension</resource>
+                </transformer>
+                <transformer implementation="org.apache.maven.plugins.shade.resource.XmlAppendingTransformer">
+                  <resource>META-INF/extensions.xml</resource>
+                </transformer>
+                <transformer implementation="org.apache.maven.plugins.shade.resource.XmlAppendingTransformer">
+                  <resource>META-INF/cxf/extensions.xml</resource>
+                </transformer>
+                <transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer">
+                  <resource>META-INF/cxf/bus-extensions.txt</resource>
+                </transformer>
+                <transformer implementation="org.apache.maven.plugins.shade.resource.XmlAppendingTransformer">
+                  <resource>META-INF/cxf/bus-extensions.xml</resource>
+                </transformer>
+                <transformer implementation="org.apache.maven.plugins.shade.resource.XmlAppendingTransformer">
+                  <resource>META-INF/wsdl.plugin.xml</resource>
+                </transformer>
+                <transformer implementation="org.apache.maven.plugins.shade.resource.XmlAppendingTransformer">
+                  <resource>META-INF/tools.service.validator.xml</resource>
+                </transformer>
+                <transformer implementation="org.apache.maven.plugins.shade.resource.XmlAppendingTransformer">
+                  <resource>META-INF/cxf/java2wsbeans.xml</resource>
+                </transformer>
+              </transformers>
+            </configuration>
+          </execution>
+        </executions>
+      </plugin>
+    </plugins>
+  </build>
 
-          <plugin>
-            <groupId>org.apache.maven.plugins</groupId>
-            <artifactId>maven-shade-plugin</artifactId>
-            <executions>
-              <execution>
-                <phase>package</phase>
-                <goals>
-                  <goal>shade</goal>
-                </goals>
-                <configuration>
-                  <filters>
-                    <filter>
-                      <artifact>*:*</artifact>
-                      <excludes>
-                        <exclude>META-INF/*.SF</exclude>
-                        <exclude>META-INF/*.DSA</exclude>
-                        <exclude>META-INF/*.RSA</exclude>
-                      </excludes>
-                    </filter>
-                  </filters>
-                  <transformers>
-                    <transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer">
-                      <resource>META-INF/spring.handlers</resource>
-                    </transformer>
-                    <transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer">
-                      <resource>META-INF/services/com.sun.tools.xjc.Plugin</resource>
-                    </transformer>
-                    <transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer">
-                      <resource>META-INF/spring.schemas</resource>
-                    </transformer>
-                    <transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer">
-                      <resource>META-INF/cxf/cxf.extension</resource>
-                    </transformer>
-                    <transformer implementation="org.apache.maven.plugins.shade.resource.XmlAppendingTransformer">
-                      <resource>META-INF/extensions.xml</resource>
-                    </transformer>
-                    <transformer implementation="org.apache.maven.plugins.shade.resource.XmlAppendingTransformer">
-                      <resource>META-INF/cxf/extensions.xml</resource>
-                    </transformer>
-                    <transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer">
-                      <resource>META-INF/cxf/bus-extensions.txt</resource>
-                    </transformer>
-                    <transformer implementation="org.apache.maven.plugins.shade.resource.XmlAppendingTransformer">
-                      <resource>META-INF/cxf/bus-extensions.xml</resource>
-                    </transformer>
-                    <transformer implementation="org.apache.maven.plugins.shade.resource.XmlAppendingTransformer">
-                      <resource>META-INF/wsdl.plugin.xml</resource>
-                    </transformer>
-                    <transformer implementation="org.apache.maven.plugins.shade.resource.XmlAppendingTransformer">
-                      <resource>META-INF/tools.service.validator.xml</resource>
-                    </transformer>
-                    <transformer implementation="org.apache.maven.plugins.shade.resource.XmlAppendingTransformer">
-                      <resource>META-INF/cxf/java2wsbeans.xml</resource>
-                    </transformer>
-                  </transformers>
-                </configuration>
-              </execution>
-            </executions>
-          </plugin>
-        </plugins>
-    </build>
 </project>
-

Commit:
fad14f3b4d5c538012a969a6dca8958e19d26580
Jukka Zitting
jukka@apache.org
2012-07-01 10:56:15 +0000
TIKA-593: Tika network server
diff --git a/pom.xml b/pom.xml
index 4423da54d..5ed9e9251 100644
--- a/pom.xml
+++ b/pom.xml
@@ -50,7 +50,7 @@
     <module>tika-parsers</module>
     <module>tika-app</module>
     <module>tika-bundle</module>
-    <!-- <module>tika-server</module>-->
+    <module>tika-server</module>
   </modules>
 
   <build>

Commit:
5c29442148711a86f01ded50bc5e13f1343090c9
Nick Burch
nick@apache.org
2012-06-30 17:40:05 +0000
TIKA-863 Avoid creating a new AutoDetectParser (and implicit TikaConfig) for each part in a RFC822 message. Instead, check for one on the ParseContext, otherwise cache the TikaConfig for the lifetime of the message being parsed
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mail/MailContentHandler.java b/tika-parsers/src/main/java/org/apache/tika/parser/mail/MailContentHandler.java
index 1df6032ee..c9193b9be 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mail/MailContentHandler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mail/MailContentHandler.java
@@ -35,10 +35,13 @@ import org.apache.james.mime4j.field.LenientFieldParser;
 import org.apache.james.mime4j.parser.ContentHandler;
 import org.apache.james.mime4j.stream.BodyDescriptor;
 import org.apache.james.mime4j.stream.Field;
+import org.apache.tika.config.TikaConfig;
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.AutoDetectParser;
+import org.apache.tika.parser.ParseContext;
+import org.apache.tika.parser.Parser;
 import org.apache.tika.sax.BodyContentHandler;
 import org.apache.tika.sax.EmbeddedContentHandler;
 import org.apache.tika.sax.XHTMLContentHandler;
@@ -54,21 +57,38 @@ class MailContentHandler implements ContentHandler {
     private boolean strictParsing = false;
 
     private XHTMLContentHandler handler;
+    private ParseContext context;
     private Metadata metadata;
+    private TikaConfig tikaConfig = null;
 
     private boolean inPart = false;
     
-    MailContentHandler(XHTMLContentHandler xhtml, Metadata metadata, boolean strictParsing) {
+    MailContentHandler(XHTMLContentHandler xhtml, Metadata metadata, ParseContext context, boolean strictParsing) {
         this.handler = xhtml;
+        this.context = context;
         this.metadata = metadata;
         this.strictParsing = strictParsing;
     }
 
     public void body(BodyDescriptor body, InputStream is) throws MimeException,
             IOException {
-        // call the underlying parser for the part
-        // TODO how to retrieve a non-default config?
-        AutoDetectParser parser = new AutoDetectParser();
+        // Work out the best underlying parser for the part
+        // Check first for a specified AutoDetectParser (which may have a
+        //  specific Config), then a recursing parser, and finally the default
+        Parser parser = context.get(AutoDetectParser.class);
+        if (parser == null) {
+           parser = context.get(Parser.class);
+        }
+        if (parser == null) {
+           if (tikaConfig == null) {
+              tikaConfig = context.get(TikaConfig.class);
+              if (tikaConfig == null) {
+                 tikaConfig = TikaConfig.getDefaultConfig();
+              }
+           }
+           parser = tikaConfig.getParser();
+        }
+
         // use a different metadata object
         // in order to specify the mime type of the
         // sub part without damaging the main metadata
@@ -79,7 +99,7 @@ class MailContentHandler implements ContentHandler {
 
         try {
             BodyContentHandler bch = new BodyContentHandler(handler);
-            parser.parse(is, new EmbeddedContentHandler(bch), submd);
+            parser.parse(is, new EmbeddedContentHandler(bch), submd, context);
         } catch (SAXException e) {
             throw new MimeException(e);
         } catch (TikaException e) {
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mail/RFC822Parser.java b/tika-parsers/src/main/java/org/apache/tika/parser/mail/RFC822Parser.java
index 6131fd9bc..4fdfc066e 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mail/RFC822Parser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mail/RFC822Parser.java
@@ -68,7 +68,7 @@ public class RFC822Parser extends AbstractParser {
         XHTMLContentHandler xhtml = new XHTMLContentHandler(handler, metadata);
 
         MailContentHandler mch = new MailContentHandler(
-                xhtml, metadata, config.isStrictParsing());
+                xhtml, metadata, context, config.isStrictParsing());
         parser.setContentHandler(mch);
         parser.setContentDecoding(true);
         TaggedInputStream tagged = TaggedInputStream.get(stream);

Commit:
f5021783895b9352cf428f7b7d6c8731aab34a20
Nick Burch
nick@apache.org
2012-06-30 17:25:56 +0000
TIKA-788 Some DWG files have an implausable header offset. Avoid problems and just skip over them, pending a better understanding of the file format
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/dwg/DWGParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/dwg/DWGParser.java
index aff4cacc2..fe5f36ee0 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/dwg/DWGParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/dwg/DWGParser.java
@@ -270,6 +270,16 @@ public class DWGParser extends AbstractParser {
             throws IOException, TikaException {
         // The offset is stored in the header from 0x20 onwards
         long offsetToSection = EndianUtils.getLongLE(header, 0x20);
+        
+        // Sanity check the offset. Some files seem to use a different format,
+        //  and the offset isn't available at 0x20. Until we can work out how
+        //  to find the offset in those files, skip them if detected
+        if (offsetToSection > 0xa00000l) {
+           // Header should never be more than 10mb into the file, something is wrong
+           offsetToSection = 0;
+        }
+        
+        // Work out how far to skip, and sanity check
         long toSkip = offsetToSection - header.length;
         if(offsetToSection == 0){
             return false;

Commit:
9e38af6975e80ffdc8ca028f0abdd6ed1e4f5fbd
Nick Burch
nick@apache.org
2012-06-30 17:18:06 +0000
TIKA-941 KML/KMZ detection unit tests
diff --git a/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java b/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
index c9bc97f04..693de3eac 100644
--- a/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
+++ b/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
@@ -278,6 +278,10 @@ public class TestContainerAwareDetector extends TestCase {
         assertTypeByData("testPages.pages", "application/vnd.apple.pages");
     }
 
+    public void testDetectKMZ() throws Exception {
+       assertTypeByData("testKMZ.kmz", "application/vnd.google-earth.kmz");
+    }
+    
     public void testDetectZip() throws Exception {
         assertTypeByData("test-documents.zip", "application/zip");
         assertTypeByData("test-zip-of-zip.zip", "application/zip");
diff --git a/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java b/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
index 06827ea14..1f7befcd2 100644
--- a/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
+++ b/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
@@ -589,6 +589,22 @@ public class TestMimeTypes extends TestCase {
         assertTypeByNameAndData("application/x-webarchive", "testWEBARCHIVE.webarchive");
     }
 
+    /**
+     * KML, and KMZ (zipped KML)
+     */
+    public void testKMLZDetection() throws Exception {
+       assertTypeByName("application/vnd.google-earth.kml+xml","testKML.kml");
+       assertTypeByData("application/vnd.google-earth.kml+xml","testKML.kml");
+       assertTypeByNameAndData("application/vnd.google-earth.kml+xml", "testKML.kml");
+       
+       assertTypeByName("application/vnd.google-earth.kmz","testKMZ.kmz");
+       assertTypeByNameAndData("application/vnd.google-earth.kmz", "testKMZ.kmz");
+       
+       // By data only, mimetype magic only gets us to a .zip
+       // We need to use the Zip Aware detector to get the full type
+       assertTypeByData("application/zip","testKMZ.kmz");
+   }
+
     private void assertType(String expected, String filename) throws Exception {
         InputStream stream = TestMimeTypes.class.getResourceAsStream(
                 "/test-documents/" + filename);

Commit:
5c51b4810957da20bcba5808cde4a6260dd6ce3a
Nick Burch
nick@apache.org
2012-06-30 17:15:53 +0000
TIKA-941 Mark KMZ as being Zip based, so data only detection works properly
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 38cc2c216..e6ce50970 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -934,6 +934,7 @@
   </mime-type>
 
   <mime-type type="application/vnd.google-earth.kmz">
+    <sub-class-of type="application/zip"/>
     <glob pattern="*.kmz"/>
   </mime-type>
   <mime-type type="application/vnd.grafeq">

Commit:
411e942590135829beafd2bd89acd15d9adeb478
Nick Burch
nick@apache.org
2012-06-30 17:10:24 +0000
TIKA-941 Sample KML and KMZ files, KML sample file from Google from the file format documentation
diff --git a/tika-parsers/src/test/resources/test-documents/testKML.kml b/tika-parsers/src/test/resources/test-documents/testKML.kml
new file mode 100644
index 000000000..5f17f62d8
--- /dev/null
+++ b/tika-parsers/src/test/resources/test-documents/testKML.kml
@@ -0,0 +1,917 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<kml xmlns="http://www.opengis.net/kml/2.2">
+  <!-- Provided by Google as part of their KML Documentation -->
+  <!-- Available at https://developers.google.com/kml/documentation/KML_Samples.kml -->
+  <Document>
+    <name>KML Samples</name>
+    <open>1</open>
+    <description>Unleash your creativity with the help of these examples!</description>
+    <Style id="downArrowIcon">
+      <IconStyle>
+        <Icon>
+          <href>http://maps.google.com/mapfiles/kml/pal4/icon28.png</href>
+        </Icon>
+      </IconStyle>
+    </Style>
+    <Style id="globeIcon">
+      <IconStyle>
+        <Icon>
+          <href>http://maps.google.com/mapfiles/kml/pal3/icon19.png</href>
+        </Icon>
+      </IconStyle>
+      <LineStyle>
+        <width>2</width>
+      </LineStyle>
+    </Style>
+    <Style id="transPurpleLineGreenPoly">
+      <LineStyle>
+        <color>7fff00ff</color>
+        <width>4</width>
+      </LineStyle>
+      <PolyStyle>
+        <color>7f00ff00</color>
+      </PolyStyle>
+    </Style>
+    <Style id="yellowLineGreenPoly">
+      <LineStyle>
+        <color>7f00ffff</color>
+        <width>4</width>
+      </LineStyle>
+      <PolyStyle>
+        <color>7f00ff00</color>
+      </PolyStyle>
+    </Style>
+    <Style id="thickBlackLine">
+      <LineStyle>
+        <color>87000000</color>
+        <width>10</width>
+      </LineStyle>
+    </Style>
+    <Style id="redLineBluePoly">
+      <LineStyle>
+        <color>ff0000ff</color>
+      </LineStyle>
+      <PolyStyle>
+        <color>ffff0000</color>
+      </PolyStyle>
+    </Style>
+    <Style id="blueLineRedPoly">
+      <LineStyle>
+        <color>ffff0000</color>
+      </LineStyle>
+      <PolyStyle>
+        <color>ff0000ff</color>
+      </PolyStyle>
+    </Style>
+    <Style id="transRedPoly">
+      <LineStyle>
+        <width>1.5</width>
+      </LineStyle>
+      <PolyStyle>
+        <color>7d0000ff</color>
+      </PolyStyle>
+    </Style>
+    <Style id="transBluePoly">
+      <LineStyle>
+        <width>1.5</width>
+      </LineStyle>
+      <PolyStyle>
+        <color>7dff0000</color>
+      </PolyStyle>
+    </Style>
+    <Style id="transGreenPoly">
+      <LineStyle>
+        <width>1.5</width>
+      </LineStyle>
+      <PolyStyle>
+        <color>7d00ff00</color>
+      </PolyStyle>
+    </Style>
+    <Style id="transYellowPoly">
+      <LineStyle>
+        <width>1.5</width>
+      </LineStyle>
+      <PolyStyle>
+        <color>7d00ffff</color>
+      </PolyStyle>
+    </Style>
+    <Style id="noDrivingDirections">
+      <BalloonStyle>
+        <text><![CDATA[
+          <b>$[name]</b>
+          <br /><br />
+          $[description]
+        ]]></text>
+      </BalloonStyle>
+    </Style>
+    <Folder>
+      <name>Placemarks</name>
+      <description>These are just some of the different kinds of placemarks with
+        which you can mark your favorite places</description>
+      <LookAt>
+        <longitude>-122.0839597145766</longitude>
+        <latitude>37.42222904525232</latitude>
+        <altitude>0</altitude>
+        <heading>-148.4122922628044</heading>
+        <tilt>40.5575073395506</tilt>
+        <range>500.6566641072245</range>
+      </LookAt>
+      <Placemark>
+        <name>Simple placemark</name>
+        <description>Attached to the ground. Intelligently places itself at the
+          height of the underlying terrain.</description>
+        <Point>
+          <coordinates>-122.0822035425683,37.42228990140251,0</coordinates>
+        </Point>
+      </Placemark>
+      <Placemark>
+        <name>Floating placemark</name>
+        <visibility>0</visibility>
+        <description>Floats a defined distance above the ground.</description>
+        <LookAt>
+          <longitude>-122.0839597145766</longitude>
+          <latitude>37.42222904525232</latitude>
+          <altitude>0</altitude>
+          <heading>-148.4122922628044</heading>
+          <tilt>40.5575073395506</tilt>
+          <range>500.6566641072245</range>
+        </LookAt>
+        <styleUrl>#downArrowIcon</styleUrl>
+        <Point>
+          <altitudeMode>relativeToGround</altitudeMode>
+          <coordinates>-122.084075,37.4220033612141,50</coordinates>
+        </Point>
+      </Placemark>
+      <Placemark>
+        <name>Extruded placemark</name>
+        <visibility>0</visibility>
+        <description>Tethered to the ground by a customizable
+          &quot;tail&quot;</description>
+        <LookAt>
+          <longitude>-122.0845787421525</longitude>
+          <latitude>37.42215078737763</latitude>
+          <altitude>0</altitude>
+          <heading>-148.4126684946234</heading>
+          <tilt>40.55750733918048</tilt>
+          <range>365.2646606980322</range>
+        </LookAt>
+        <styleUrl>#globeIcon</styleUrl>
+        <Point>
+          <extrude>1</extrude>
+          <altitudeMode>relativeToGround</altitudeMode>
+          <coordinates>-122.0857667006183,37.42156927867553,50</coordinates>
+        </Point>
+      </Placemark>
+    </Folder>
+    <Folder>
+      <name>Styles and Markup</name>
+      <visibility>0</visibility>
+      <description>With KML it is easy to create rich, descriptive markup to
+        annotate and enrich your placemarks</description>
+      <LookAt>
+        <longitude>-122.0845787422371</longitude>
+        <latitude>37.42215078726837</latitude>
+        <altitude>0</altitude>
+        <heading>-148.4126777488172</heading>
+        <tilt>40.55750733930874</tilt>
+        <range>365.2646826292919</range>
+      </LookAt>
+      <styleUrl>#noDrivingDirections</styleUrl>
+      <Document>
+        <name>Highlighted Icon</name>
+        <visibility>0</visibility>
+        <description>Place your mouse over the icon to see it display the new
+          icon</description>
+        <LookAt>
+          <longitude>-122.0856552124024</longitude>
+          <latitude>37.4224281311035</latitude>
+          <altitude>0</altitude>
+          <heading>0</heading>
+          <tilt>0</tilt>
+          <range>265.8520424250024</range>
+        </LookAt>
+        <Style id="highlightPlacemark">
+          <IconStyle>
+            <Icon>
+              <href>http://maps.google.com/mapfiles/kml/paddle/red-stars.png</href>
+            </Icon>
+          </IconStyle>
+        </Style>
+        <Style id="normalPlacemark">
+          <IconStyle>
+            <Icon>
+              <href>http://maps.google.com/mapfiles/kml/paddle/wht-blank.png</href>
+            </Icon>
+          </IconStyle>
+        </Style>
+        <StyleMap id="exampleStyleMap">
+          <Pair>
+            <key>normal</key>
+            <styleUrl>#normalPlacemark</styleUrl>
+          </Pair>
+          <Pair>
+            <key>highlight</key>
+            <styleUrl>#highlightPlacemark</styleUrl>
+          </Pair>
+        </StyleMap>
+        <Placemark>
+          <name>Roll over this icon</name>
+          <visibility>0</visibility>
+          <styleUrl>#exampleStyleMap</styleUrl>
+          <Point>
+            <coordinates>-122.0856545755255,37.42243077405461,0</coordinates>
+          </Point>
+        </Placemark>
+      </Document>
+      <Placemark>
+        <name>Descriptive HTML</name>
+        <visibility>0</visibility>
+        <description><![CDATA[Click on the blue link!<br><br>
+Placemark descriptions can be enriched by using many standard HTML tags.<br>
+For example:
+<hr>
+Styles:<br>
+<i>Italics</i>, 
+<b>Bold</b>, 
+<u>Underlined</u>, 
+<s>Strike Out</s>, 
+subscript<sub>subscript</sub>, 
+superscript<sup>superscript</sup>, 
+<big>Big</big>, 
+<small>Small</small>, 
+<tt>Typewriter</tt>, 
+<em>Emphasized</em>, 
+<strong>Strong</strong>, 
+<code>Code</code>
+<hr>
+Fonts:<br> 
+<font color="red">red by name</font>, 
+<font color="#408010">leaf green by hexadecimal RGB</font>
+<br>
+<font size=1>size 1</font>, 
+<font size=2>size 2</font>, 
+<font size=3>size 3</font>, 
+<font size=4>size 4</font>, 
+<font size=5>size 5</font>, 
+<font size=6>size 6</font>, 
+<font size=7>size 7</font>
+<br>
+<font face=times>Times</font>, 
+<font face=verdana>Verdana</font>, 
+<font face=arial>Arial</font><br>
+<hr>
+Links: 
+<br>
+<a href="http://earth.google.com/">Google Earth!</a>
+<br>
+ or:  Check out our website at www.google.com
+<hr>
+Alignment:<br>
+<p align=left>left</p>
+<p align=center>center</p>
+<p align=right>right</p>
+<hr>
+Ordered Lists:<br>
+<ol><li>First</li><li>Second</li><li>Third</li></ol>
+<ol type="a"><li>First</li><li>Second</li><li>Third</li></ol>
+<ol type="A"><li>First</li><li>Second</li><li>Third</li></ol>
+<hr>
+Unordered Lists:<br>
+<ul><li>A</li><li>B</li><li>C</li></ul>
+<ul type="circle"><li>A</li><li>B</li><li>C</li></ul>
+<ul type="square"><li>A</li><li>B</li><li>C</li></ul>
+<hr>
+Definitions:<br>
+<dl>
+<dt>Google:</dt><dd>The best thing since sliced bread</dd>
+</dl>
+<hr>
+Centered:<br><center>
+Time present and time past<br>
+Are both perhaps present in time future,<br>
+And time future contained in time past.<br>
+If all time is eternally present<br>
+All time is unredeemable.<br>
+</center>
+<hr>
+Block Quote:
+<br>
+<blockquote>
+We shall not cease from exploration<br>
+And the end of all our exploring<br>
+Will be to arrive where we started<br>
+And know the place for the first time.<br>
+<i>-- T.S. Eliot</i>
+</blockquote>
+<br>
+<hr>
+Headings:<br>
+<h1>Header 1</h1>
+<h2>Header 2</h2>
+<h3>Header 3</h3>
+<h3>Header 4</h4>
+<h3>Header 5</h5>
+<hr>
+Images:<br>
+<i>Remote image</i><br>
+<img src="//developers.google.com/kml/documentation/images/googleSample.png"><br>
+<i>Scaled image</i><br>
+<img src="//developers.google.com/kml/documentation/images/googleSample.png" width=100><br>
+<hr>
+Simple Tables:<br>
+<table border="1" padding="1">
+<tr><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td></tr>
+<tr><td>a</td><td>b</td><td>c</td><td>d</td><td>e</td></tr>
+</table>
+<br>
+[Did you notice that double-clicking on the placemark doesn't cause the viewer to take you anywhere? This is because it is possible to directly author a "placeless placemark". If you look at the code for this example, you will see that it has neither a point coordinate nor a LookAt element.]]]></description>
+      </Placemark>
+    </Folder>
+    <Folder>
+      <name>Ground Overlays</name>
+      <visibility>0</visibility>
+      <description>Examples of ground overlays</description>
+      <GroundOverlay>
+        <name>Large-scale overlay on terrain</name>
+        <visibility>0</visibility>
+        <description>Overlay shows Mount Etna erupting on July 13th, 2001.</description>
+        <LookAt>
+          <longitude>15.02468937557116</longitude>
+          <latitude>37.67395167941667</latitude>
+          <altitude>0</altitude>
+          <heading>-16.5581842842829</heading>
+          <tilt>58.31228652890705</tilt>
+          <range>30350.36838438907</range>
+        </LookAt>
+        <Icon>
+          <href>http://developers.google.com/kml/documentation/images/etna.jpg</href>
+        </Icon>
+        <LatLonBox>
+          <north>37.91904192681665</north>
+          <south>37.46543388598137</south>
+          <east>15.35832653742206</east>
+          <west>14.60128369746704</west>
+          <rotation>-0.1556640799496235</rotation>
+        </LatLonBox>
+      </GroundOverlay>
+    </Folder>
+    <Folder>
+      <name>Screen Overlays</name>
+      <visibility>0</visibility>
+      <description>Screen overlays have to be authored directly in KML. These
+        examples illustrate absolute and dynamic positioning in screen space.</description>
+      <ScreenOverlay>
+        <name>Simple crosshairs</name>
+        <visibility>0</visibility>
+        <description>This screen overlay uses fractional positioning to put the
+          image in the exact center of the screen</description>
+        <Icon>
+          <href>http://developers.google.com/kml/documentation/images/crosshairs.png</href>
+        </Icon>
+        <overlayXY x="0.5" y="0.5" xunits="fraction" yunits="fraction"/>
+        <screenXY x="0.5" y="0.5" xunits="fraction" yunits="fraction"/>
+        <rotationXY x="0.5" y="0.5" xunits="fraction" yunits="fraction"/>
+        <size x="0" y="0" xunits="pixels" yunits="pixels"/>
+      </ScreenOverlay>
+      <ScreenOverlay>
+        <name>Absolute Positioning: Top left</name>
+        <visibility>0</visibility>
+        <Icon>
+          <href>http://developers.google.com/kml/documentation/images/top_left.jpg</href>
+        </Icon>
+        <overlayXY x="0" y="1" xunits="fraction" yunits="fraction"/>
+        <screenXY x="0" y="1" xunits="fraction" yunits="fraction"/>
+        <rotationXY x="0" y="0" xunits="fraction" yunits="fraction"/>
+        <size x="0" y="0" xunits="fraction" yunits="fraction"/>
+      </ScreenOverlay>
+      <ScreenOverlay>
+        <name>Absolute Positioning: Top right</name>
+        <visibility>0</visibility>
+        <Icon>
+          <href>http://developers.google.com/kml/documentation/images/top_right.jpg</href>
+        </Icon>
+        <overlayXY x="1" y="1" xunits="fraction" yunits="fraction"/>
+        <screenXY x="1" y="1" xunits="fraction" yunits="fraction"/>
+        <rotationXY x="0" y="0" xunits="fraction" yunits="fraction"/>
+        <size x="0" y="0" xunits="fraction" yunits="fraction"/>
+      </ScreenOverlay>
+      <ScreenOverlay>
+        <name>Absolute Positioning: Bottom left</name>
+        <visibility>0</visibility>
+        <Icon>
+          <href>http://developers.google.com/kml/documentation/images/bottom_left.jpg</href>
+        </Icon>
+        <overlayXY x="0" y="-1" xunits="fraction" yunits="fraction"/>
+        <screenXY x="0" y="0" xunits="fraction" yunits="fraction"/>
+        <rotationXY x="0" y="0" xunits="fraction" yunits="fraction"/>
+        <size x="0" y="0" xunits="fraction" yunits="fraction"/>
+      </ScreenOverlay>
+      <ScreenOverlay>
+        <name>Absolute Positioning: Bottom right</name>
+        <visibility>0</visibility>
+        <Icon>
+          <href>http://developers.google.com/kml/documentation/images/bottom_right.jpg</href>
+        </Icon>
+        <overlayXY x="1" y="-1" xunits="fraction" yunits="fraction"/>
+        <screenXY x="1" y="0" xunits="fraction" yunits="fraction"/>
+        <rotationXY x="0" y="0" xunits="fraction" yunits="fraction"/>
+        <size x="0" y="0" xunits="fraction" yunits="fraction"/>
+      </ScreenOverlay>
+      <ScreenOverlay>
+        <name>Dynamic Positioning: Top of screen</name>
+        <visibility>0</visibility>
+        <Icon>
+          <href>http://developers.google.com/kml/documentation/images/dynamic_screenoverlay.jpg</href>
+        </Icon>
+        <overlayXY x="0" y="1" xunits="fraction" yunits="fraction"/>
+        <screenXY x="0" y="1" xunits="fraction" yunits="fraction"/>
+        <rotationXY x="0" y="0" xunits="fraction" yunits="fraction"/>
+        <size x="1" y="0.2" xunits="fraction" yunits="fraction"/>
+      </ScreenOverlay>
+      <ScreenOverlay>
+        <name>Dynamic Positioning: Right of screen</name>
+        <visibility>0</visibility>
+        <Icon>
+          <href>http://developers.google.com/kml/documentation/images/dynamic_right.jpg</href>
+        </Icon>
+        <overlayXY x="1" y="1" xunits="fraction" yunits="fraction"/>
+        <screenXY x="1" y="1" xunits="fraction" yunits="fraction"/>
+        <rotationXY x="0" y="0" xunits="fraction" yunits="fraction"/>
+        <size x="0" y="1" xunits="fraction" yunits="fraction"/>
+      </ScreenOverlay>
+    </Folder>
+    <Folder>
+      <name>Paths</name>
+      <visibility>0</visibility>
+      <description>Examples of paths. Note that the tessellate tag is by default
+        set to 0. If you want to create tessellated lines, they must be authored
+        (or edited) directly in KML.</description>
+      <Placemark>
+        <name>Tessellated</name>
+        <visibility>0</visibility>
+        <description><![CDATA[If the <tessellate> tag has a value of 1, the line will contour to the underlying terrain]]></description>
+        <LookAt>
+          <longitude>-112.0822680013139</longitude>
+          <latitude>36.09825589333556</latitude>
+          <altitude>0</altitude>
+          <heading>103.8120432044965</heading>
+          <tilt>62.04855796276328</tilt>
+          <range>2889.145007690472</range>
+        </LookAt>
+        <LineString>
+          <tessellate>1</tessellate>
+          <coordinates> -112.0814237830345,36.10677870477137,0
+            -112.0870267752693,36.0905099328766,0 </coordinates>
+        </LineString>
+      </Placemark>
+      <Placemark>
+        <name>Untessellated</name>
+        <visibility>0</visibility>
+        <description><![CDATA[If the <tessellate> tag has a value of 0, the line follow a simple straight-line path from point to point]]></description>
+        <LookAt>
+          <longitude>-112.0822680013139</longitude>
+          <latitude>36.09825589333556</latitude>
+          <altitude>0</altitude>
+          <heading>103.8120432044965</heading>
+          <tilt>62.04855796276328</tilt>
+          <range>2889.145007690472</range>
+        </LookAt>
+        <LineString>
+          <tessellate>0</tessellate>
+          <coordinates> -112.080622229595,36.10673460007995,0
+            -112.085242575315,36.09049598612422,0 </coordinates>
+        </LineString>
+      </Placemark>
+      <Placemark>
+        <name>Absolute</name>
+        <visibility>0</visibility>
+        <description>Transparent purple line</description>
+        <LookAt>
+          <longitude>-112.2719329043177</longitude>
+          <latitude>36.08890633450894</latitude>
+          <altitude>0</altitude>
+          <heading>-106.8161545998597</heading>
+          <tilt>44.60763714063257</tilt>
+          <range>2569.386744398339</range>
+        </LookAt>
+        <styleUrl>#transPurpleLineGreenPoly</styleUrl>
+        <LineString>
+          <tessellate>1</tessellate>
+          <altitudeMode>absolute</altitudeMode>
+          <coordinates> -112.265654928602,36.09447672602546,2357
+            -112.2660384528238,36.09342608838671,2357
+            -112.2668139013453,36.09251058776881,2357
+            -112.2677826834445,36.09189827357996,2357
+            -112.2688557510952,36.0913137941187,2357
+            -112.2694810717219,36.0903677207521,2357
+            -112.2695268555611,36.08932171487285,2357
+            -112.2690144567276,36.08850916060472,2357
+            -112.2681528815339,36.08753813597956,2357
+            -112.2670588176031,36.08682685262568,2357
+            -112.2657374587321,36.08646312301303,2357 </coordinates>
+        </LineString>
+      </Placemark>
+      <Placemark>
+        <name>Absolute Extruded</name>
+        <visibility>0</visibility>
+        <description>Transparent green wall with yellow outlines</description>
+        <LookAt>
+          <longitude>-112.2643334742529</longitude>
+          <latitude>36.08563154742419</latitude>
+          <altitude>0</altitude>
+          <heading>-125.7518698668815</heading>
+          <tilt>44.61038665812578</tilt>
+          <range>4451.842204068102</range>
+        </LookAt>
+        <styleUrl>#yellowLineGreenPoly</styleUrl>
+        <LineString>
+          <extrude>1</extrude>
+          <tessellate>1</tessellate>
+          <altitudeMode>absolute</altitudeMode>
+          <coordinates> -112.2550785337791,36.07954952145647,2357
+            -112.2549277039738,36.08117083492122,2357
+            -112.2552505069063,36.08260761307279,2357
+            -112.2564540158376,36.08395660588506,2357
+            -112.2580238976449,36.08511401044813,2357
+            -112.2595218489022,36.08584355239394,2357
+            -112.2608216347552,36.08612634548589,2357
+            -112.262073428656,36.08626019085147,2357
+            -112.2633204928495,36.08621519860091,2357
+            -112.2644963846444,36.08627897945274,2357
+            -112.2656969554589,36.08649599090644,2357 </coordinates>
+        </LineString>
+      </Placemark>
+      <Placemark>
+        <name>Relative</name>
+        <visibility>0</visibility>
+        <description>Black line (10 pixels wide), height tracks terrain</description>
+        <LookAt>
+          <longitude>-112.2580438551384</longitude>
+          <latitude>36.1072674824385</latitude>
+          <altitude>0</altitude>
+          <heading>4.947421249553717</heading>
+          <tilt>44.61324882043339</tilt>
+          <range>2927.61105910266</range>
+        </LookAt>
+        <styleUrl>#thickBlackLine</styleUrl>
+        <LineString>
+          <tessellate>1</tessellate>
+          <altitudeMode>relativeToGround</altitudeMode>
+          <coordinates> -112.2532845153347,36.09886943729116,645
+            -112.2540466121145,36.09919570465255,645
+            -112.254734666947,36.09984998366178,645
+            -112.255493345654,36.10051310621746,645
+            -112.2563157098468,36.10108441943419,645
+            -112.2568033076439,36.10159722088088,645
+            -112.257494011321,36.10204323542867,645
+            -112.2584106072308,36.10229131995655,645
+            -112.2596588987972,36.10240001286358,645
+            -112.2610581199487,36.10213176873407,645
+            -112.2626285262793,36.10157011437219,645 </coordinates>
+        </LineString>
+      </Placemark>
+      <Placemark>
+        <name>Relative Extruded</name>
+        <visibility>0</visibility>
+        <description>Opaque blue walls with red outline, height tracks terrain</description>
+        <LookAt>
+          <longitude>-112.2683594333433</longitude>
+          <latitude>36.09884362144909</latitude>
+          <altitude>0</altitude>
+          <heading>-72.24271551768405</heading>
+          <tilt>44.60855445139561</tilt>
+          <range>2184.193522571467</range>
+        </LookAt>
+        <styleUrl>#redLineBluePoly</styleUrl>
+        <LineString>
+          <extrude>1</extrude>
+          <tessellate>1</tessellate>
+          <altitudeMode>relativeToGround</altitudeMode>
+          <coordinates> -112.2656634181359,36.09445214722695,630
+            -112.2652238941097,36.09520916122063,630
+            -112.2645079986395,36.09580763864907,630
+            -112.2638827428817,36.09628572284063,630
+            -112.2635746835406,36.09679275951239,630
+            -112.2635711822407,36.09740038871899,630
+            -112.2640296531825,36.09804913435539,630
+            -112.264327720538,36.09880337400301,630
+            -112.2642436562271,36.09963644790288,630
+            -112.2639148687042,36.10055381117246,630
+            -112.2626894973474,36.10149062823369,630 </coordinates>
+        </LineString>
+      </Placemark>
+    </Folder>
+    <Folder>
+      <name>Polygons</name>
+      <visibility>0</visibility>
+      <description>Examples of polygon shapes</description>
+      <Folder>
+        <name>Google Campus</name>
+        <visibility>0</visibility>
+        <description>A collection showing how easy it is to create 3-dimensional
+          buildings</description>
+        <LookAt>
+          <longitude>-122.084120030116</longitude>
+          <latitude>37.42174011925477</latitude>
+          <altitude>0</altitude>
+          <heading>-34.82469740081282</heading>
+          <tilt>53.454348562403</tilt>
+          <range>276.7870053764046</range>
+        </LookAt>
+        <Placemark>
+          <name>Building 40</name>
+          <visibility>0</visibility>
+          <styleUrl>#transRedPoly</styleUrl>
+          <Polygon>
+            <extrude>1</extrude>
+            <altitudeMode>relativeToGround</altitudeMode>
+            <outerBoundaryIs>
+              <LinearRing>
+                <coordinates> -122.0848938459612,37.42257124044786,17
+                  -122.0849580979198,37.42211922626856,17
+                  -122.0847469573047,37.42207183952619,17
+                  -122.0845725380962,37.42209006729676,17
+                  -122.0845954886723,37.42215932700895,17
+                  -122.0838521118269,37.42227278564371,17
+                  -122.083792243335,37.42203539112084,17
+                  -122.0835076656616,37.42209006957106,17
+                  -122.0834709464152,37.42200987395161,17
+                  -122.0831221085748,37.4221046494946,17
+                  -122.0829247374572,37.42226503990386,17
+                  -122.0829339169385,37.42231242843094,17
+                  -122.0833837359737,37.42225046087618,17
+                  -122.0833607854248,37.42234159228745,17
+                  -122.0834204551642,37.42237075460644,17
+                  -122.083659133885,37.42251292011001,17
+                  -122.0839758438952,37.42265873093781,17
+                  -122.0842374743331,37.42265143972521,17
+                  -122.0845036949503,37.4226514386435,17
+                  -122.0848020460801,37.42261133916315,17
+                  -122.0847882750515,37.42256395055121,17
+                  -122.0848938459612,37.42257124044786,17 </coordinates>
+              </LinearRing>
+            </outerBoundaryIs>
+          </Polygon>
+        </Placemark>
+        <Placemark>
+          <name>Building 41</name>
+          <visibility>0</visibility>
+          <styleUrl>#transBluePoly</styleUrl>
+          <Polygon>
+            <extrude>1</extrude>
+            <altitudeMode>relativeToGround</altitudeMode>
+            <outerBoundaryIs>
+              <LinearRing>
+                <coordinates> -122.0857412771483,37.42227033155257,17
+                  -122.0858169768481,37.42231408832346,17
+                  -122.085852582875,37.42230337469744,17
+                  -122.0858799945639,37.42225686138789,17
+                  -122.0858860101409,37.4222311076138,17
+                  -122.0858069157288,37.42220250173855,17
+                  -122.0858379542653,37.42214027058678,17
+                  -122.0856732640519,37.42208690214408,17
+                  -122.0856022926407,37.42214885429042,17
+                  -122.0855902778436,37.422128290487,17
+                  -122.0855841672237,37.42208171967246,17
+                  -122.0854852065741,37.42210455874995,17
+                  -122.0855067264352,37.42214267949824,17
+                  -122.0854430712915,37.42212783846172,17
+                  -122.0850990714904,37.42251282407603,17
+                  -122.0856769818632,37.42281815323651,17
+                  -122.0860162273783,37.42244918858722,17
+                  -122.0857260327004,37.42229239604253,17
+                  -122.0857412771483,37.42227033155257,17 </coordinates>
+              </LinearRing>
+            </outerBoundaryIs>
+          </Polygon>
+        </Placemark>
+        <Placemark>
+          <name>Building 42</name>
+          <visibility>0</visibility>
+          <styleUrl>#transGreenPoly</styleUrl>
+          <Polygon>
+            <extrude>1</extrude>
+            <altitudeMode>relativeToGround</altitudeMode>
+            <outerBoundaryIs>
+              <LinearRing>
+                <coordinates> -122.0857862287242,37.42136208886969,25
+                  -122.0857312990603,37.42136935989481,25
+                  -122.0857312992918,37.42140934910903,25
+                  -122.0856077073679,37.42138390166565,25
+                  -122.0855802426516,37.42137299550869,25
+                  -122.0852186221971,37.42137299504316,25
+                  -122.0852277765639,37.42161656508265,25
+                  -122.0852598189347,37.42160565894403,25
+                  -122.0852598185499,37.42168200156,25
+                  -122.0852369311478,37.42170017860346,25
+                  -122.0852643957828,37.42176197982575,25
+                  -122.0853239032746,37.42176198013907,25
+                  -122.0853559454324,37.421852864452,25
+                  -122.0854108752463,37.42188921823734,25
+                  -122.0854795379357,37.42189285337048,25
+                  -122.0855436229819,37.42188921797546,25
+                  -122.0856260178042,37.42186013499926,25
+                  -122.085937287963,37.42186013453605,25
+                  -122.0859428718666,37.42160898590042,25
+                  -122.0859655469861,37.42157992759144,25
+                  -122.0858640462341,37.42147115002957,25
+                  -122.0858548911215,37.42140571326184,25
+                  -122.0858091162768,37.4214057134039,25
+                  -122.0857862287242,37.42136208886969,25 </coordinates>
+              </LinearRing>
+            </outerBoundaryIs>
+          </Polygon>
+        </Placemark>
+        <Placemark>
+          <name>Building 43</name>
+          <visibility>0</visibility>
+          <styleUrl>#transYellowPoly</styleUrl>
+          <Polygon>
+            <extrude>1</extrude>
+            <altitudeMode>relativeToGround</altitudeMode>
+            <outerBoundaryIs>
+              <LinearRing>
+                <coordinates> -122.0844371128284,37.42177253003091,19
+                  -122.0845118855746,37.42191111542896,19
+                  -122.0850470999805,37.42178755121535,19
+                  -122.0850719913391,37.42143663023161,19
+                  -122.084916406232,37.42137237822116,19
+                  -122.0842193868167,37.42137237801626,19
+                  -122.08421938659,37.42147617161496,19
+                  -122.0838086419991,37.4214613409357,19
+                  -122.0837899728564,37.42131306410796,19
+                  -122.0832796534698,37.42129328840593,19
+                  -122.0832609819207,37.42139213944298,19
+                  -122.0829373621737,37.42137236399876,19
+                  -122.0829062425667,37.42151569778871,19
+                  -122.0828502269665,37.42176282576465,19
+                  -122.0829435788635,37.42176776969635,19
+                  -122.083217411188,37.42179248552686,19
+                  -122.0835970430103,37.4217480074456,19
+                  -122.0839455556771,37.42169364237603,19
+                  -122.0840077894637,37.42176283815853,19
+                  -122.084113587521,37.42174801104392,19
+                  -122.0840762473784,37.42171341292375,19
+                  -122.0841447047739,37.42167881534569,19
+                  -122.084144704223,37.42181720660197,19
+                  -122.0842503333074,37.4218170700446,19
+                  -122.0844371128284,37.42177253003091,19 </coordinates>
+              </LinearRing>
+            </outerBoundaryIs>
+          </Polygon>
+        </Placemark>
+      </Folder>
+      <Folder>
+        <name>Extruded Polygon</name>
+        <description>A simple way to model a building</description>
+        <Placemark>
+          <name>The Pentagon</name>
+          <LookAt>
+            <longitude>-77.05580139178142</longitude>
+            <latitude>38.870832443487</latitude>
+            <heading>59.88865561738225</heading>
+            <tilt>48.09646074797388</tilt>
+            <range>742.0552506670548</range>
+          </LookAt>
+          <Polygon>
+            <extrude>1</extrude>
+            <altitudeMode>relativeToGround</altitudeMode>
+            <outerBoundaryIs>
+              <LinearRing>
+                <coordinates> -77.05788457660967,38.87253259892824,100
+                  -77.05465973756702,38.87291016281703,100
+                  -77.05315536854791,38.87053267794386,100
+                  -77.05552622493516,38.868757801256,100
+                  -77.05844056290393,38.86996206506943,100
+                  -77.05788457660967,38.87253259892824,100 </coordinates>
+              </LinearRing>
+            </outerBoundaryIs>
+            <innerBoundaryIs>
+              <LinearRing>
+                <coordinates> -77.05668055019126,38.87154239798456,100
+                  -77.05542625960818,38.87167890344077,100
+                  -77.05485125901024,38.87076535397792,100
+                  -77.05577677433152,38.87008686581446,100
+                  -77.05691162017543,38.87054446963351,100
+                  -77.05668055019126,38.87154239798456,100 </coordinates>
+              </LinearRing>
+            </innerBoundaryIs>
+          </Polygon>
+        </Placemark>
+      </Folder>
+      <Folder>
+        <name>Absolute and Relative</name>
+        <visibility>0</visibility>
+        <description>Four structures whose roofs meet exactly. Turn on/off
+          terrain to see the difference between relative and absolute
+          positioning.</description>
+        <LookAt>
+          <longitude>-112.3348969157552</longitude>
+          <latitude>36.14845533214919</latitude>
+          <altitude>0</altitude>
+          <heading>-86.91235037566909</heading>
+          <tilt>49.30695423894192</tilt>
+          <range>990.6761201087104</range>
+        </LookAt>
+        <Placemark>
+          <name>Absolute</name>
+          <visibility>0</visibility>
+          <styleUrl>#transBluePoly</styleUrl>
+          <Polygon>
+            <tessellate>1</tessellate>
+            <altitudeMode>absolute</altitudeMode>
+            <outerBoundaryIs>
+              <LinearRing>
+                <coordinates> -112.3372510731295,36.14888505105317,1784
+                  -112.3356128688403,36.14781540589019,1784
+                  -112.3368169371048,36.14658677734382,1784
+                  -112.3384408457543,36.14762778914076,1784
+                  -112.3372510731295,36.14888505105317,1784 </coordinates>
+              </LinearRing>
+            </outerBoundaryIs>
+          </Polygon>
+        </Placemark>
+        <Placemark>
+          <name>Absolute Extruded</name>
+          <visibility>0</visibility>
+          <styleUrl>#transRedPoly</styleUrl>
+          <Polygon>
+            <extrude>1</extrude>
+            <tessellate>1</tessellate>
+            <altitudeMode>absolute</altitudeMode>
+            <outerBoundaryIs>
+              <LinearRing>
+                <coordinates> -112.3396586818843,36.14637618647505,1784
+                  -112.3380597654315,36.14531751871353,1784
+                  -112.3368254237788,36.14659596244607,1784
+                  -112.3384555043203,36.14762621763982,1784
+                  -112.3396586818843,36.14637618647505,1784 </coordinates>
+              </LinearRing>
+            </outerBoundaryIs>
+          </Polygon>
+        </Placemark>
+        <Placemark>
+          <name>Relative</name>
+          <visibility>0</visibility>
+          <LookAt>
+            <longitude>-112.3350152490417</longitude>
+            <latitude>36.14943123077423</latitude>
+            <altitude>0</altitude>
+            <heading>-118.9214100848499</heading>
+            <tilt>37.92486261093203</tilt>
+            <range>345.5169113679813</range>
+          </LookAt>
+          <styleUrl>#transGreenPoly</styleUrl>
+          <Polygon>
+            <tessellate>1</tessellate>
+            <altitudeMode>relativeToGround</altitudeMode>
+            <outerBoundaryIs>
+              <LinearRing>
+                <coordinates> -112.3349463145932,36.14988705767721,100
+                  -112.3354019540677,36.14941108398372,100
+                  -112.3344428289146,36.14878490381308,100
+                  -112.3331289492913,36.14780840132443,100
+                  -112.3317019516947,36.14680755678357,100
+                  -112.331131440106,36.1474173426228,100
+                  -112.332616324338,36.14845453364654,100
+                  -112.3339876620524,36.14926570522069,100
+                  -112.3349463145932,36.14988705767721,100 </coordinates>
+              </LinearRing>
+            </outerBoundaryIs>
+          </Polygon>
+        </Placemark>
+        <Placemark>
+          <name>Relative Extruded</name>
+          <visibility>0</visibility>
+          <LookAt>
+            <longitude>-112.3351587892382</longitude>
+            <latitude>36.14979247129029</latitude>
+            <altitude>0</altitude>
+            <heading>-55.42811560891606</heading>
+            <tilt>56.10280503739589</tilt>
+            <range>401.0997279712519</range>
+          </LookAt>
+          <styleUrl>#transYellowPoly</styleUrl>
+          <Polygon>
+            <extrude>1</extrude>
+            <tessellate>1</tessellate>
+            <altitudeMode>relativeToGround</altitudeMode>
+            <outerBoundaryIs>
+              <LinearRing>
+                <coordinates> -112.3348783983763,36.1514008468736,100
+                  -112.3372535345629,36.14888517553886,100
+                  -112.3356068927954,36.14781612679284,100
+                  -112.3350034807972,36.14846469024177,100
+                  -112.3358353861232,36.1489624162954,100
+                  -112.3345888301373,36.15026229372507,100
+                  -112.3337937856278,36.14978096026463,100
+                  -112.3331798208424,36.1504472788618,100
+                  -112.3348783983763,36.1514008468736,100 </coordinates>
+              </LinearRing>
+            </outerBoundaryIs>
+          </Polygon>
+        </Placemark>
+      </Folder>
+    </Folder>
+  </Document>
+</kml>
diff --git a/tika-parsers/src/test/resources/test-documents/testKMZ.kmz b/tika-parsers/src/test/resources/test-documents/testKMZ.kmz
new file mode 100644
index 000000000..6632711f6
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testKMZ.kmz differ

Commit:
833b5e1985f3bb37ee76c85ceddf400b916e3a3b
Jukka Zitting
jukka@apache.org
2012-06-30 16:30:39 +0000
TIKA-832: ForkParser is unfriendly to code that prints things to its output
diff --git a/tika-core/src/main/java/org/apache/tika/fork/ForkClient.java b/tika-core/src/main/java/org/apache/tika/fork/ForkClient.java
index 7b8a67bc1..930598ea0 100644
--- a/tika-core/src/main/java/org/apache/tika/fork/ForkClient.java
+++ b/tika-core/src/main/java/org/apache/tika/fork/ForkClient.java
@@ -70,6 +70,8 @@ class ForkClient {
             this.input = new DataInputStream(process.getInputStream());
             this.error = process.getErrorStream();
 
+            waitForStartBeacon();
+
             sendObject(loader, resources);
             sendObject(object, resources);
 
@@ -81,6 +83,17 @@ class ForkClient {
         }
     }
 
+    private void waitForStartBeacon() throws IOException {
+        while (true) {
+            consumeErrorStream();
+            int type = input.read();
+            if ((byte) type == ForkServer.READY) {
+                consumeErrorStream();
+                return;
+            }
+        }
+    }
+
     public synchronized boolean ping() {
         try {
             output.writeByte(ForkServer.PING);
diff --git a/tika-core/src/main/java/org/apache/tika/fork/ForkServer.java b/tika-core/src/main/java/org/apache/tika/fork/ForkServer.java
index baeae203d..5b606449f 100644
--- a/tika-core/src/main/java/org/apache/tika/fork/ForkServer.java
+++ b/tika-core/src/main/java/org/apache/tika/fork/ForkServer.java
@@ -44,6 +44,8 @@ class ForkServer implements Runnable, Checksum {
 
     public static final byte RESOURCE = 3;
 
+    public static final byte READY = 4;
+
     /**
      * Starts a forked server process using the standard input and output
      * streams for communication with the parent process. Any attempts by
@@ -104,6 +106,9 @@ class ForkServer implements Runnable, Checksum {
 
     public void processRequests() {
         try {
+            output.writeByte(READY);
+            output.flush();
+
             ClassLoader loader = (ClassLoader) readObject(
                     ForkServer.class.getClassLoader());
             Thread.currentThread().setContextClassLoader(loader);
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/fork/ForkParserIntegrationTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/fork/ForkParserIntegrationTest.java
index b2b61af8a..7b7829b9b 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/fork/ForkParserIntegrationTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/fork/ForkParserIntegrationTest.java
@@ -26,6 +26,8 @@ import java.util.Set;
 import junit.framework.TestCase;
 
 import org.apache.tika.Tika;
+import org.apache.tika.config.TikaConfig;
+import org.apache.tika.detect.DefaultDetector;
 import org.apache.tika.detect.Detector;
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.fork.ForkParser;
@@ -42,9 +44,9 @@ import org.xml.sax.SAXException;
  *  wired in to the regular Parsers and their test data
  */
 public class ForkParserIntegrationTest extends TestCase {
-//    private TikaConfig tika = TikaConfig.getDefaultConfig();
+
     private Tika tika = new Tika(); // TODO Use TikaConfig instead, when it works
-    
+
     /**
      * Simple text parsing
      */
@@ -205,6 +207,33 @@ public class ForkParserIntegrationTest extends TestCase {
        }
     }
 
+    /**
+     * TIKA-832
+     */
+    public void testAttachingADebuggerOnTheForkedParserShouldWork()
+            throws Exception {
+        ParseContext context = new ParseContext();
+        context.set(Parser.class, tika.getParser());
+
+        ForkParser parser = new ForkParser(
+                ForkParserIntegrationTest.class.getClassLoader(),
+                tika.getParser());
+        parser.setJavaCommand(
+                "java -Xmx32m -Xdebug -Xrunjdwp:"
+                + "transport=dt_socket,address=54321,server=y,suspend=n");
+        try {
+            ContentHandler body = new BodyContentHandler();
+            InputStream stream = ForkParserIntegrationTest.class.getResourceAsStream(
+                    "/test-documents/testTXT.txt");
+            parser.parse(stream, body, new Metadata(), context);
+            String content = body.toString();
+            assertTrue(content.contains("Test d'indexation"));
+            assertTrue(content.contains("http://www.apache.org"));
+        } finally {
+            parser.close();
+        }
+    }
+
     /**
      * TIKA-808 - Ensure that parsing of our test PDFs work under
      * the Fork Parser, to ensure that complex parsing behaves

Commit:
3ffc69f708beda7886fe2ebd51b4b3543851a91e
Jukka Zitting
jukka@apache.org
2012-06-30 15:57:02 +0000
TIKA-847: Add regular expression support to the MagicDetector
diff --git a/tika-core/src/main/java/org/apache/tika/detect/MagicDetector.java b/tika-core/src/main/java/org/apache/tika/detect/MagicDetector.java
index 0b1c2cb9d..fff67f32e 100644
--- a/tika-core/src/main/java/org/apache/tika/detect/MagicDetector.java
+++ b/tika-core/src/main/java/org/apache/tika/detect/MagicDetector.java
@@ -19,6 +19,11 @@ package org.apache.tika.detect;
 import java.io.CharArrayWriter;
 import java.io.IOException;
 import java.io.InputStream;
+import java.nio.ByteBuffer;
+import java.nio.CharBuffer;
+import java.nio.charset.Charset;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
 
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.mime.MediaType;
@@ -54,7 +59,8 @@ public class MagicDetector implements Detector {
         }
 
         return new MagicDetector(
-                mediaType, patternBytes, maskBytes, start, end);
+                mediaType, patternBytes, maskBytes,
+                type.equals("regex"), start, end);
     }
 
     private static byte[] decodeValue(String value, String type) {
@@ -76,7 +82,9 @@ public class MagicDetector implements Detector {
             radix = 8;
         }
 
-        if (type.equals("string") || type.equals("unicodeLE")
+        if (type.equals("string")
+                || type.equals("regex")
+                || type.equals("unicodeLE")
                 || type.equals("unicodeBE")) {
             decoded = decodeString(value, type);
         } else if (type.equals("byte")) {
@@ -179,7 +187,7 @@ public class MagicDetector implements Detector {
     private final MediaType type;
 
     /**
-     * Length of the comparison window. All the byte arrays here are this long.
+     * Length of the comparison window.
      */
     private final int length;
 
@@ -189,6 +197,17 @@ public class MagicDetector implements Detector {
      * detection succeeds and the configured {@link #type} is returned.
      */
     private final byte[] pattern;
+    
+    /**
+     * Length of the pattern, which in the case of regular expressions will
+     * not be the same as the comparison window length.
+     */
+    private final int patternLength;
+    
+    /**
+     * True if pattern is a regular expression, false otherwise.
+     */
+    private final boolean isRegex;
 
     /**
      * Bit mask that is applied to the source bytes before pattern matching.
@@ -234,6 +253,17 @@ public class MagicDetector implements Detector {
     public MagicDetector(MediaType type, byte[] pattern, int offset) {
         this(type, pattern, null, offset, offset);
     }
+    
+    /**
+     * Creates a detector for input documents that meet the specified magic
+     * match.  {@code pattern} must NOT be a regular expression.
+     * Constructor maintained for legacy reasons.
+     */
+    public MagicDetector(
+        MediaType type, byte[] pattern, byte[] mask,
+        int offsetRangeBegin, int offsetRangeEnd) {
+        this(type, pattern, mask, false, offsetRangeBegin, offsetRangeEnd);
+    }
 
     /**
      * Creates a detector for input documents that meet the specified
@@ -241,6 +271,7 @@ public class MagicDetector implements Detector {
      */
     public MagicDetector(
             MediaType type, byte[] pattern, byte[] mask,
+            boolean isRegex,
             int offsetRangeBegin, int offsetRangeEnd) {
         if (type == null) {
             throw new IllegalArgumentException("Matching media type is null");
@@ -255,12 +286,21 @@ public class MagicDetector implements Detector {
 
         this.type = type;
 
-        this.length = Math.max(pattern.length, mask != null ? mask.length : 0);
+        this.isRegex = isRegex;
+
+        this.patternLength = Math.max(pattern.length, mask != null ? mask.length : 0);
+
+        if (this.isRegex) {
+            // 8K buffer should cope with most regex patterns
+            this.length = 8 * 1024;
+        } else {
+            this.length = patternLength;
+        }
 
-        this.mask = new byte[length];
-        this.pattern = new byte[length];
+        this.mask = new byte[this.patternLength];
+        this.pattern = new byte[this.patternLength];
 
-        for (int i = 0; i < length; i++) {
+        for (int i = 0; i < this.patternLength; i++) {
             if (mask != null && i < mask.length) {
                 this.mask[i] = mask[i];
             } else {
@@ -316,19 +356,41 @@ public class MagicDetector implements Detector {
                 int bufferOffset = offset - offsetRangeBegin;
                 n = input.read(
                         buffer, bufferOffset, buffer.length - bufferOffset);
+                // increment offset - in case not all read (see testDetectStreamReadProblems)
+                if (n > 0) {
+                    offset += n;
+                }
             }
-            if (offset < offsetRangeBegin + length) {
-                return MediaType.OCTET_STREAM;
-            }
 
-            // Loop until we've covered the entire offset range
-            for (int i = 0; i <= offsetRangeEnd - offsetRangeBegin; i++) {
-                boolean match = true;
-                for (int j = 0; match && j < length; j++) {
-                    match = (buffer[i + j] & mask[j]) == pattern[j];
+            if (this.isRegex) {
+                Pattern p = Pattern.compile(new String(this.pattern));
+
+                ByteBuffer bb = ByteBuffer.wrap(buffer);
+                CharBuffer result = Charset.forName("ISO-8859-1").decode(bb);
+                Matcher m = p.matcher(result);
+
+                boolean match = false;
+                // Loop until we've covered the entire offset range
+                for (int i = 0; i <= offsetRangeEnd - offsetRangeBegin; i++) {
+                    m.region(i,  length+i);
+                    match = m.lookingAt(); // match regex from start of region
+                    if (match) {
+                        return type;
+                    }
+                }
+            } else {
+                if (offset < offsetRangeBegin + length) {
+                    return MediaType.OCTET_STREAM;
                 }
-                if (match) {
-                    return type;
+                // Loop until we've covered the entire offset range
+                for (int i = 0; i <= offsetRangeEnd - offsetRangeBegin; i++) {
+                    boolean match = true;
+                    for (int j = 0; match && j < length; j++) {
+                        match = (buffer[i + j] & mask[j]) == pattern[j];
+                    }
+                    if (match) {
+                        return type;
+                    }
                 }
             }
 
@@ -339,7 +401,7 @@ public class MagicDetector implements Detector {
     }
 
     public int getLength() {
-        return length;
+        return this.patternLength;
     }
 
     /**
diff --git a/tika-core/src/test/java/org/apache/tika/detect/MagicDetectorTest.java b/tika-core/src/test/java/org/apache/tika/detect/MagicDetectorTest.java
index 18d842ff1..0112a8942 100644
--- a/tika-core/src/test/java/org/apache/tika/detect/MagicDetectorTest.java
+++ b/tika-core/src/test/java/org/apache/tika/detect/MagicDetectorTest.java
@@ -72,7 +72,7 @@ public class MagicDetectorTest extends TestCase {
                 + "12345<html");
 
         assertDetect(detector, MediaType.OCTET_STREAM, "");
-}
+    }
 
     public void testDetectMask() throws Exception {
         MediaType html = new MediaType("text", "html");
@@ -101,6 +101,84 @@ public class MagicDetectorTest extends TestCase {
         assertDetect(detector, MediaType.OCTET_STREAM, "");
     }
 
+    public void testDetectRegExPDF() throws Exception {
+        MediaType pdf = new MediaType("application", "pdf");
+        Detector detector = new MagicDetector(
+                pdf, "(?s)\\A.{0,144}%PDF-".getBytes("ASCII"), null, true, 0, 0);
+
+        assertDetect(detector, pdf, "%PDF-1.0");
+        assertDetect(
+                detector, pdf,
+                "0        10        20        30        40        50        6"
+                + "0        70        80        90        100       110       1"
+                + "20       130       140"
+                + "34%PDF-1.0");
+        assertDetect(
+                detector, MediaType.OCTET_STREAM,
+                "0        10        20        30        40        50        6"
+                + "0        70        80        90        100       110       1"
+                + "20       130       140"
+                + "345%PDF-1.0");
+        assertDetect(detector, MediaType.OCTET_STREAM, "");
+    }
+
+    public void testDetectRegExGreedy() throws Exception {
+        String pattern =
+                "(?s)\\x3chtml xmlns=\"http://www\\.w3\\.org/1999/xhtml"
+                + "\".*\\x3ctitle\\x3e.*\\x3c/title\\x3e";
+        MediaType xhtml = new MediaType("application", "xhtml+xml");
+        Detector detector = new MagicDetector(xhtml,
+                pattern.getBytes("ASCII"), null,
+                true, 0, 8192);
+
+        assertDetect(detector, xhtml,
+                "<html xmlns=\"http://www.w3.org/1999/xhtml\">"
+                + "<head><title>XHTML test document</title></head>");
+    }
+
+    public void testDetectRegExOptions() throws Exception {
+        String pattern =
+                "(?s)\\A.{0,1024}\\x3c\\!(?:DOCTYPE|doctype) (?:HTML|html) "
+                + "(?:PUBLIC|public) \"-//.{1,16}//(?:DTD|dtd) .{0,64}"
+                + "(?:HTML|html) 4\\.01";
+
+        String data =
+                "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\""
+                + "\"http://www.w3.org/TR/html4/strict.dtd\"><HTML>"
+                + "<HEAD><TITLE>HTML document</TITLE></HEAD>"
+                + "<BODY><P>Hello world!</BODY></HTML>";
+
+        String data1 =
+                "<!DOCTYPE html PUBLIC \"-//W3C//dtd html 4.01//EN\""
+                + "\"http://www.w3.org/TR/html4/strict.dtd\"><HTML>"
+                + "<HEAD><TITLE>HTML document</TITLE></HEAD>"
+                + "<BODY><P>Hello world!</BODY></HTML>";
+
+        String data2 =
+                "<!DoCtYpE hTmL pUbLiC \"-//W3C//dTd HtMl 4.01//EN\""
+                + "\"http://www.w3.org/TR/html4/strict.dtd\"><HTML>"
+                + "<HEAD><TITLE>HTML document</TITLE></HEAD>"
+                + "<BODY><P>Hello world!</BODY></HTML>";
+
+        MediaType html = new MediaType("text", "html");
+        Detector detector = new MagicDetector(
+                html, pattern.getBytes("ASCII"), null, true, 0, 0);
+
+        assertDetect(detector, html, data);
+        assertDetect(detector, html, data1);
+        assertDetect(detector, MediaType.OCTET_STREAM, data2);
+    }
+
+    public void testDetectStreamReadProblems() throws Exception {
+        byte[] data = "abcdefghijklmnopqrstuvwxyz0123456789".getBytes("ASCII");
+        MediaType testMT = new MediaType("application", "test");
+        Detector detector = new MagicDetector(testMT, data, null, false, 0, 0);
+        // Deliberately prevent InputStream.read(...) from reading the entire
+        // buffer in one go
+        InputStream stream = new RestrictiveInputStream(data);
+        assertEquals(testMT, detector.detect(stream, new Metadata()));
+    }
+
     private void assertDetect(Detector detector, MediaType type, String data) {
         try {
             byte[] bytes = data.getBytes("ASCII");
@@ -117,4 +195,26 @@ public class MagicDetectorTest extends TestCase {
         }
     }
 
+    /**
+     * InputStream class that does not read in all available bytes in
+     * one go.
+     */
+    private class RestrictiveInputStream extends ByteArrayInputStream {
+        public RestrictiveInputStream(byte[] buf) {
+            super(buf);
+        }
+
+        /**
+         * Prevent reading the entire len of bytes if requesting more
+         * than 10 bytes.
+         */
+        public int read(byte[] b, int off, int len) {
+            if (len > 10) {
+                return super.read(b, off, len-10);
+            } else {
+                return super.read(b, off, len);
+            }
+        }
+    }
+
 }

Commit:
d22a1fd7bab0db1fc4ae8ea34cb7cc04548b0551
Jukka Zitting
jukka@apache.org
2012-06-30 15:30:07 +0000
TIKA-747: Ogg Vorbis and FLAC Parsers
diff --git a/tika-app/pom.xml b/tika-app/pom.xml
index 848a83344..5fb32055a 100644
--- a/tika-app/pom.xml
+++ b/tika-app/pom.xml
@@ -80,7 +80,7 @@
     <plugins>
       <plugin>
         <artifactId>maven-shade-plugin</artifactId>
-        <version>1.7</version>
+        <version>1.6</version>
         <executions>
           <execution>
             <phase>package</phase>
@@ -88,6 +88,9 @@
               <goal>shade</goal>
             </goals>
             <configuration>
+              <createDependencyReducedPom>
+                false
+              </createDependencyReducedPom>
               <filters>
                 <filter>
                   <artifact>*:*</artifact>

Commit:
78b1b5a6835aaca00e91e1516815fb4f641dbf84
Jukka Zitting
jukka@apache.org
2012-06-30 15:04:36 +0000
TIKA-810: Upgrade to PDFbox 1.7.0 as available
diff --git a/tika-parsers/pom.xml b/tika-parsers/pom.xml
index e64aff363..18fb9fa81 100644
--- a/tika-parsers/pom.xml
+++ b/tika-parsers/pom.xml
@@ -100,7 +100,7 @@
     <dependency>
       <groupId>org.apache.pdfbox</groupId>
       <artifactId>pdfbox</artifactId>
-      <version>1.6.0</version>
+      <version>1.7.0</version>
     </dependency>
     <!-- TIKA-370: PDFBox declares the Bouncy Castle dependencies
          as optional, but we prefer to have them always to avoid

Commit:
3725dbf4579df1db808baef1997d0461212b4b1a
Jukka Zitting
jukka@apache.org
2012-06-30 14:15:01 +0000
TIKA-747: Ogg Vorbis and FLAC Parsers
diff --git a/tika-app/pom.xml b/tika-app/pom.xml
index 6d8272398..848a83344 100644
--- a/tika-app/pom.xml
+++ b/tika-app/pom.xml
@@ -30,7 +30,6 @@
   </parent>
 
   <artifactId>tika-app</artifactId>
-  <packaging>bundle</packaging>
   <name>Apache Tika application</name>
   <url>http://tika.apache.org/</url>
 
@@ -43,19 +42,16 @@
       <groupId>${project.groupId}</groupId>
       <artifactId>tika-parsers</artifactId>
       <version>${project.version}</version>
-      <scope>provided</scope>
     </dependency>
     <dependency>
       <groupId>org.slf4j</groupId>
       <artifactId>slf4j-log4j12</artifactId>
       <version>1.5.6</version>
-      <scope>provided</scope>
     </dependency>
     <dependency>
       <groupId>com.google.code.gson</groupId>
       <artifactId>gson</artifactId>
       <version>1.7.1</version>
-      <scope>provided</scope>
     </dependency>
     <dependency>
       <groupId>junit</groupId>
@@ -83,42 +79,50 @@
     </resources>
     <plugins>
       <plugin>
-        <groupId>org.apache.felix</groupId>
-        <artifactId>maven-bundle-plugin</artifactId>
-        <extensions>true</extensions>
-        <configuration>
-          <instructions>
-            <Export-Package>
-              org.apache.tika.cli,
-              org.apache.tika.gui
-            </Export-Package>
-            <Embed-Dependency>!netcdf;scope=provided;inline=net/**|javax/**|org/**|com/**|de/**|javassist/**|*.properties|repackage/**|schema*/**|META-INF/services/**|META-INF/maven/**</Embed-Dependency>
-            <Embed-Transitive>true</Embed-Transitive>
-            <Bundle-DocURL>${project.url}</Bundle-DocURL>
-            <Main-Class>org.apache.tika.cli.TikaCLI</Main-Class>
-          </instructions>
-        </configuration>
-      </plugin>
-      <!-- TIKA-763: Workaround to avoid including LGPL classes -->
-      <plugin>
-        <artifactId>maven-dependency-plugin</artifactId>
+        <artifactId>maven-shade-plugin</artifactId>
+        <version>1.7</version>
         <executions>
           <execution>
-            <phase>prepare-package</phase>
+            <phase>package</phase>
             <goals>
-              <goal>unpack-dependencies</goal>
+              <goal>shade</goal>
             </goals>
             <configuration>
-              <includeArtifactIds>netcdf</includeArtifactIds>
-              <excludes>
-                ucar/nc2/iosp/fysat/Fysat*.class,
-                ucar/nc2/dataset/transform/VOceanSG1*class,
-                ucar/unidata/geoloc/vertical/OceanSG*.class,
-                META-INF/**,CHANGES,README
-              </excludes>
-              <outputDirectory>
-                ${project.build.directory}/classes
-              </outputDirectory>
+              <filters>
+                <filter>
+                  <artifact>*:*</artifact>
+                  <excludes>
+                    <exclude>META-INF/*</exclude>
+                    <exclude>LICENSE.txt</exclude>
+                    <exclude>NOTICE.txt</exclude>
+                    <exclude>CHANGES</exclude>
+                    <exclude>README</exclude>
+                    <exclude>builddef.lst</exclude>
+                    <!-- TIKA-763: Workaround to avoid including LGPL classes -->
+                    <exclude>ucar/nc2/iosp/fysat/Fysat*.class</exclude>
+                    <exclude>ucar/nc2/dataset/transform/VOceanSG1*class</exclude>
+                    <exclude>ucar/unidata/geoloc/vertical/OceanSG*.class</exclude>
+                  </excludes>
+                </filter>
+              </filters>
+              <transformers>
+                <transformer implementation="org.apache.maven.plugins.shade.resource.ManifestResourceTransformer">
+                  <mainClass>org.apache.tika.cli.TikaCLI</mainClass>
+                </transformer>
+                <transformer implementation="org.apache.maven.plugins.shade.resource.ServicesResourceTransformer"/>
+                <transformer implementation="org.apache.maven.plugins.shade.resource.IncludeResourceTransformer">
+                  <resource>META-INF/LICENSE</resource>
+                  <file>target/classes/META-INF/LICENSE</file>
+                </transformer>
+                <transformer implementation="org.apache.maven.plugins.shade.resource.IncludeResourceTransformer">
+                  <resource>META-INF/NOTICE</resource>
+                  <file>target/classes/META-INF/NOTICE</file>
+                </transformer>
+                <transformer implementation="org.apache.maven.plugins.shade.resource.IncludeResourceTransformer">
+                  <resource>META-INF/DEPENDENCIES</resource>
+                  <file>target/classes/META-INF/DEPENDENCIES</file>
+                </transformer>
+              </transformers>
             </configuration>
           </execution>
         </executions>

Commit:
c181ed933b85bdccb109cb231e12bc421c2d2e67
Jukka Zitting
jukka@apache.org
2012-06-30 13:28:38 +0000
TIKA-900: Tika fails to detect ISO9660 disk images
diff --git a/tika-core/src/main/java/org/apache/tika/mime/MimeTypes.java b/tika-core/src/main/java/org/apache/tika/mime/MimeTypes.java
index 3316fd73e..f94ccbfca 100644
--- a/tika-core/src/main/java/org/apache/tika/mime/MimeTypes.java
+++ b/tika-core/src/main/java/org/apache/tika/mime/MimeTypes.java
@@ -355,7 +355,7 @@ public final class MimeTypes implements Detector, Serializable {
     public int getMinLength() {
         // This needs to be reasonably large to be able to correctly detect
         // things like XML root elements after initial comment and DTDs
-        return 8 * 1024;
+        return 64 * 1024;
     }
 
     /**
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 5c846f357..38cc2c216 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -2654,10 +2654,12 @@
   </mime-type>
 
   <mime-type type="application/x-iso9660-image">
+    <acronym>ISO</acronym>
+    <_comment>ISO 9660 CD-ROM filesystem data</_comment>
     <magic priority="50">
-      <match value="CD001" type="string" offset="37633"/>
+      <match value="CD001" type="string" offset="32769"/>
     </magic>
-    <glob pattern="*.iso" />
+    <glob pattern="*.iso"/>
   </mime-type>
 
   <mime-type type="application/x-java-jnlp-file">

Commit:
19a8688603dcf50d396c5619685ba75b83107e86
Jukka Zitting
jukka@apache.org
2012-06-30 13:22:59 +0000
TIKA-908: Adding XMP specification part one namespaces and properties
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/XMP.java b/tika-core/src/main/java/org/apache/tika/metadata/XMP.java
index d489f4976..9101dfd06 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/XMP.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/XMP.java
@@ -22,7 +22,8 @@ public interface XMP {
 
     String PREFIX = "xmp";
 
-    String PREFIX_DELIMITER = ":";
+    /** The xmp prefix followed by the colon delimiter */
+    String PREFIX_ = PREFIX + ":";
 
     /**
      * The date and time the resource was created. For a digital file, this need not
@@ -30,14 +31,12 @@ public interface XMP {
      * be close to that time, modulo the time taken to write the file. Later file
      * transfer, copying, and so on, can make the file-system time arbitrarily different.
      */
-    Property CREATE_DATE = Property.externalDate(
-            PREFIX + PREFIX_DELIMITER + "CreateDate");
+    Property CREATE_DATE = Property.externalDate(PREFIX_ + "CreateDate");
 
     /**
      * The name of the first known tool used to create the resource.
      */
-    Property CREATOR_TOOL = Property.externalText(
-            PREFIX + PREFIX_DELIMITER + "CreatorTool");
+    Property CREATOR_TOOL = Property.externalText(PREFIX_ + "CreatorTool");
 
     /**
      * An unordered array of text strings that unambiguously identify the resource
@@ -45,34 +44,29 @@ public interface XMP {
      * (see 8.7, xmpidq namespace) to denote the formal identification system to
      * which that identifier conforms.
      */
-    Property IDENTIFIER = Property.externalTextBag(
-            PREFIX + PREFIX_DELIMITER + "Identifier");
+    Property IDENTIFIER = Property.externalTextBag(PREFIX_ + "Identifier");
 
     /**
      * A word or short phrase that identifies a resource as a member of a userdefined collection.
      */
-    Property LABEL = Property.externalDate(
-            PREFIX + PREFIX_DELIMITER + "Label");
+    Property LABEL = Property.externalDate(PREFIX_ + "Label");
 
     /**
      * The date and time that any metadata for this resource was last changed. It
      * should be the same as or more recent than xmp:ModifyDate
      */
-    Property METADATA_DATE = Property.externalDate(
-            PREFIX + PREFIX_DELIMITER + "MetadataDate");
+    Property METADATA_DATE = Property.externalDate(PREFIX_ + "MetadataDate");
 
     /**
      * The date and time the resource was last modified.
      */
-    Property MODIFY_DATE = Property.externalDate(
-            PREFIX + PREFIX_DELIMITER + "ModifyDate");
+    Property MODIFY_DATE = Property.externalDate(PREFIX_ + "ModifyDate");
 
     /**
      * A user-assigned rating for this file. The value shall be -1 or in the range
      * [0..5], where -1 indicates rejected and 0 indicates unrated. If xmp:Rating
      * is not present, a value of 0 should be assumed.
      */
-    Property RATING = Property.externalReal(
-            PREFIX + PREFIX_DELIMITER + "Rating");
+    Property RATING = Property.externalReal(PREFIX_ + "Rating");
 
 }
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/XMPIdq.java b/tika-core/src/main/java/org/apache/tika/metadata/XMPIdq.java
index ba651f7bc..1a46bc34f 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/XMPIdq.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/XMPIdq.java
@@ -22,13 +22,13 @@ public interface XMPIdq {
 
     String PREFIX = "xmpidq";
 
-    String PREFIX_DELIMITER = ":";
+    /** The xmpidq prefix followed by the colon delimiter */
+    String PREFIX_ = PREFIX + ":";
 
     /**
      * A qualifier providing the name of the formal identification
      * scheme used for an item in the xmp:Identifier array.
      */
-    Property SCHEME = Property.externalText(
-            PREFIX + PREFIX_DELIMITER + "Scheme");
+    Property SCHEME = Property.externalText(PREFIX_ + "Scheme");
 
 }
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/XMPMM.java b/tika-core/src/main/java/org/apache/tika/metadata/XMPMM.java
index 5ecd3b620..3fc4dfa07 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/XMPMM.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/XMPMM.java
@@ -22,7 +22,8 @@ public interface XMPMM {
 
     String PREFIX = "xmpMM";
 
-    String PREFIX_DELIMITER = ":";
+    /** The xmpMM prefix followed by the colon delimiter */
+    String PREFIX_ = PREFIX + ":";
 
     /**
      * A reference to the resource from which this one is derived.
@@ -31,21 +32,18 @@ public interface XMPMM {
      * 
      * TODO This property is of type RessourceRef which is a struct
      */
-//    Property DERIVED_FROM = Property.externalText(
-//            PREFIX + PREFIX_DELIMITER + "DerivedFrom");
+//    Property DERIVED_FROM = Property.externalText(PREFIX_ + "DerivedFrom");
 
     /**
      * The common identifier for all versions and renditions of a resource.
      */
-    Property DOCUMENTID = Property.externalText(
-            PREFIX + PREFIX_DELIMITER + "DocumentID");
+    Property DOCUMENTID = Property.externalText(PREFIX_ + "DocumentID");
 
     /**
      * An identifier for a specific incarnation of a resource, updated
      * each time a file is saved.
      */
-    Property INSTANCEID = Property.externalText(
-            PREFIX + PREFIX_DELIMITER + "InstanceID");
+    Property INSTANCEID = Property.externalText(PREFIX_ + "InstanceID");
 
     /**
      * The common identifier for the original resource from which
@@ -56,7 +54,7 @@ public interface XMPMM {
      * that format, but should retain the ID of the source file here.
      */
     Property ORIGINAL_DOCUMENTID = Property.externalText(
-            PREFIX + PREFIX_DELIMITER + "OriginalDocumentID");
+            PREFIX_ + "OriginalDocumentID");
 
     /**
      * The rendition class name for this resource. This property
@@ -64,13 +62,14 @@ public interface XMPMM {
      * a derived rendition
      */
     Property RENDITION_CLASS = Property.externalOpenChoise(
-            PREFIX + PREFIX_DELIMITER + "RenditionClass", "default", "draft", "low-res", "proof", "screen", "thumbnail");
+            PREFIX_ + "RenditionClass",
+            "default", "draft", "low-res", "proof", "screen", "thumbnail");
 
     /**
      * Can be used to provide additional rendition parameters that
      * are too complex or verbose to encode in xmpMM:RenditionClass
      */
     Property RENDITION_PARAMS = Property.externalText(
-            PREFIX + PREFIX_DELIMITER + "RenditionParams");
+            PREFIX_ + "RenditionParams");
 
 }
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/XMPRights.java b/tika-core/src/main/java/org/apache/tika/metadata/XMPRights.java
index 33db66483..9c8b18524 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/XMPRights.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/XMPRights.java
@@ -35,37 +35,35 @@ public interface XMPRights {
     String NAMESPACE_URI_XMP_RIGHTS = "http://ns.adobe.com/xap/1.0/rights/";
     String PREFIX_XMP_RIGHTS = "xmpRights";
 
+    /** The xmpRights prefix followed by the colon delimiter */
+    String PREFIX_ = PREFIX_XMP_RIGHTS + ":";
+
     /**
      * A Web URL for a rights management certificate.
      */
-    Property CERTIFICATE = Property.internalText(
-            PREFIX_XMP_RIGHTS + Metadata.NAMESPACE_PREFIX_DELIMITER + "Certificate");
+    Property CERTIFICATE = Property.internalText(PREFIX_ + "Certificate");
 
     /**
      * When true, indicates that this is a rights-managed resource. When
      * false, indicates that this is a public-domain resource. Omit if the
      * state is unknown.
      */
-    Property MARKED = Property.internalBoolean(
-            PREFIX_XMP_RIGHTS + Metadata.NAMESPACE_PREFIX_DELIMITER + "Marked");
+    Property MARKED = Property.internalBoolean(PREFIX_ + "Marked");
 
     /**
      * A list of legal owners of the resource.
      */
-    Property OWNER = Property.internalTextBag(
-            PREFIX_XMP_RIGHTS + Metadata.NAMESPACE_PREFIX_DELIMITER + "Owner");
+    Property OWNER = Property.internalTextBag(PREFIX_ + "Owner");
 
     /**
      * A word or short phrase that identifies a resource as a member of a userdefined collection.
      * TODO This is actually a language alternative property
      */
-    Property USAGE_TERMS = Property.internalText(
-            PREFIX_XMP_RIGHTS + Metadata.NAMESPACE_PREFIX_DELIMITER + "UsageTerms");
+    Property USAGE_TERMS = Property.internalText(PREFIX_ + "UsageTerms");
 
     /**
      * A Web URL for a statement of the ownership and usage rights for this resource.
      */
-    Property WEB_STATEMENT = Property.internalText(
-            PREFIX_XMP_RIGHTS + Metadata.NAMESPACE_PREFIX_DELIMITER + "WebStatement");
+    Property WEB_STATEMENT = Property.internalText(PREFIX_ + "WebStatement");
 
 }

Commit:
1d1f29260677d955e66c4dbd6f1120426b421a94
Jukka Zitting
jukka@apache.org
2012-06-30 13:22:08 +0000
TIKA-908: Adding XMP specification part one namespaces and properties
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/Property.java b/tika-core/src/main/java/org/apache/tika/metadata/Property.java
index 36ca6492d..0149c07d3 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/Property.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/Property.java
@@ -251,6 +251,11 @@ public final class Property implements Comparable<Property> {
         return new Property(name, false, ValueType.CLOSED_CHOICE, choices);
     }
 
+    public static Property externalOpenChoise(
+            String name, String... choices) {
+        return new Property(name, false, ValueType.OPEN_CHOICE, choices);
+    }
+
     public static Property externalDate(String name) {
         return new Property(name, false, ValueType.DATE);
     }
@@ -270,7 +275,11 @@ public final class Property implements Comparable<Property> {
     public static Property externalText(String name) {
         return new Property(name, false, ValueType.TEXT);
     }
-    
+
+    public static Property externalTextBag(String name) {
+        return new Property(name, false, PropertyType.BAG, ValueType.TEXT);
+    }
+
     /**
      * Constructs a new composite property from the given primary and array of secondary properties.
      * <p>
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/XMP.java b/tika-core/src/main/java/org/apache/tika/metadata/XMP.java
new file mode 100644
index 000000000..d489f4976
--- /dev/null
+++ b/tika-core/src/main/java/org/apache/tika/metadata/XMP.java
@@ -0,0 +1,78 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.metadata;
+
+public interface XMP {
+
+    String NAMESPACE_URI = "http://ns.adobe.com/xap/1.0/";
+
+    String PREFIX = "xmp";
+
+    String PREFIX_DELIMITER = ":";
+
+    /**
+     * The date and time the resource was created. For a digital file, this need not
+     * match a file-system creation time. For a freshly created resource, it should
+     * be close to that time, modulo the time taken to write the file. Later file
+     * transfer, copying, and so on, can make the file-system time arbitrarily different.
+     */
+    Property CREATE_DATE = Property.externalDate(
+            PREFIX + PREFIX_DELIMITER + "CreateDate");
+
+    /**
+     * The name of the first known tool used to create the resource.
+     */
+    Property CREATOR_TOOL = Property.externalText(
+            PREFIX + PREFIX_DELIMITER + "CreatorTool");
+
+    /**
+     * An unordered array of text strings that unambiguously identify the resource
+     * within a given context. An array item may be qualified with xmpidq:Scheme
+     * (see 8.7, xmpidq namespace) to denote the formal identification system to
+     * which that identifier conforms.
+     */
+    Property IDENTIFIER = Property.externalTextBag(
+            PREFIX + PREFIX_DELIMITER + "Identifier");
+
+    /**
+     * A word or short phrase that identifies a resource as a member of a userdefined collection.
+     */
+    Property LABEL = Property.externalDate(
+            PREFIX + PREFIX_DELIMITER + "Label");
+
+    /**
+     * The date and time that any metadata for this resource was last changed. It
+     * should be the same as or more recent than xmp:ModifyDate
+     */
+    Property METADATA_DATE = Property.externalDate(
+            PREFIX + PREFIX_DELIMITER + "MetadataDate");
+
+    /**
+     * The date and time the resource was last modified.
+     */
+    Property MODIFY_DATE = Property.externalDate(
+            PREFIX + PREFIX_DELIMITER + "ModifyDate");
+
+    /**
+     * A user-assigned rating for this file. The value shall be -1 or in the range
+     * [0..5], where -1 indicates rejected and 0 indicates unrated. If xmp:Rating
+     * is not present, a value of 0 should be assumed.
+     */
+    Property RATING = Property.externalReal(
+            PREFIX + PREFIX_DELIMITER + "Rating");
+
+}
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/XMPIdq.java b/tika-core/src/main/java/org/apache/tika/metadata/XMPIdq.java
new file mode 100644
index 000000000..ba651f7bc
--- /dev/null
+++ b/tika-core/src/main/java/org/apache/tika/metadata/XMPIdq.java
@@ -0,0 +1,34 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.metadata;
+
+public interface XMPIdq {
+
+    String NAMESPACE_URI = "http://ns.adobe.com/xmp/identifier/qual/1.0/";
+
+    String PREFIX = "xmpidq";
+
+    String PREFIX_DELIMITER = ":";
+
+    /**
+     * A qualifier providing the name of the formal identification
+     * scheme used for an item in the xmp:Identifier array.
+     */
+    Property SCHEME = Property.externalText(
+            PREFIX + PREFIX_DELIMITER + "Scheme");
+
+}
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/XMPMM.java b/tika-core/src/main/java/org/apache/tika/metadata/XMPMM.java
new file mode 100644
index 000000000..5ecd3b620
--- /dev/null
+++ b/tika-core/src/main/java/org/apache/tika/metadata/XMPMM.java
@@ -0,0 +1,76 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.metadata;
+
+public interface XMPMM {
+
+    String NAMESPACE_URI = "http://ns.adobe.com/xap/1.0/mm/";
+
+    String PREFIX = "xmpMM";
+
+    String PREFIX_DELIMITER = ":";
+
+    /**
+     * A reference to the resource from which this one is derived.
+     * This should be a minimal reference, in which missing
+     * components can be assumed to be unchanged.
+     * 
+     * TODO This property is of type RessourceRef which is a struct
+     */
+//    Property DERIVED_FROM = Property.externalText(
+//            PREFIX + PREFIX_DELIMITER + "DerivedFrom");
+
+    /**
+     * The common identifier for all versions and renditions of a resource.
+     */
+    Property DOCUMENTID = Property.externalText(
+            PREFIX + PREFIX_DELIMITER + "DocumentID");
+
+    /**
+     * An identifier for a specific incarnation of a resource, updated
+     * each time a file is saved.
+     */
+    Property INSTANCEID = Property.externalText(
+            PREFIX + PREFIX_DELIMITER + "InstanceID");
+
+    /**
+     * The common identifier for the original resource from which
+     * the current resource is derived. For example, if you save a
+     * resource to a different format, then save that one to another
+     * format, each save operation should generate a new
+     * xmpMM:DocumentID that uniquely identifies the resource in
+     * that format, but should retain the ID of the source file here.
+     */
+    Property ORIGINAL_DOCUMENTID = Property.externalText(
+            PREFIX + PREFIX_DELIMITER + "OriginalDocumentID");
+
+    /**
+     * The rendition class name for this resource. This property
+     * should be absent or set to default for a resource that is not
+     * a derived rendition
+     */
+    Property RENDITION_CLASS = Property.externalOpenChoise(
+            PREFIX + PREFIX_DELIMITER + "RenditionClass", "default", "draft", "low-res", "proof", "screen", "thumbnail");
+
+    /**
+     * Can be used to provide additional rendition parameters that
+     * are too complex or verbose to encode in xmpMM:RenditionClass
+     */
+    Property RENDITION_PARAMS = Property.externalText(
+            PREFIX + PREFIX_DELIMITER + "RenditionParams");
+
+}
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/XMPRights.java b/tika-core/src/main/java/org/apache/tika/metadata/XMPRights.java
index e2800b02c..33db66483 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/XMPRights.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/XMPRights.java
@@ -34,20 +34,38 @@ public interface XMPRights {
 
     String NAMESPACE_URI_XMP_RIGHTS = "http://ns.adobe.com/xap/1.0/rights/";
     String PREFIX_XMP_RIGHTS = "xmpRights";
-    
+
+    /**
+     * A Web URL for a rights management certificate.
+     */
     Property CERTIFICATE = Property.internalText(
             PREFIX_XMP_RIGHTS + Metadata.NAMESPACE_PREFIX_DELIMITER + "Certificate");
-    
+
+    /**
+     * When true, indicates that this is a rights-managed resource. When
+     * false, indicates that this is a public-domain resource. Omit if the
+     * state is unknown.
+     */
     Property MARKED = Property.internalBoolean(
             PREFIX_XMP_RIGHTS + Metadata.NAMESPACE_PREFIX_DELIMITER + "Marked");
-    
+
+    /**
+     * A list of legal owners of the resource.
+     */
     Property OWNER = Property.internalTextBag(
             PREFIX_XMP_RIGHTS + Metadata.NAMESPACE_PREFIX_DELIMITER + "Owner");
-    
+
+    /**
+     * A word or short phrase that identifies a resource as a member of a userdefined collection.
+     * TODO This is actually a language alternative property
+     */
     Property USAGE_TERMS = Property.internalText(
             PREFIX_XMP_RIGHTS + Metadata.NAMESPACE_PREFIX_DELIMITER + "UsageTerms");
-    
+
+    /**
+     * A Web URL for a statement of the ownership and usage rights for this resource.
+     */
     Property WEB_STATEMENT = Property.internalText(
             PREFIX_XMP_RIGHTS + Metadata.NAMESPACE_PREFIX_DELIMITER + "WebStatement");
 
-}
\ No newline at end of file
+}

Commit:
bb535a0e370a78660bd05da7daf41658f9519a5e
Jukka Zitting
jukka@apache.org
2012-06-30 13:01:38 +0000
TIKA-876: Signed pdf parsing
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 1bc1caf4e..5c846f357 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -390,10 +390,12 @@
   <mime-type type="application/pkcs10">
     <glob pattern="*.p10"/>
   </mime-type>
+
   <mime-type type="application/pkcs7-mime">
     <glob pattern="*.p7m"/>
     <glob pattern="*.p7c"/>
   </mime-type>
+
   <mime-type type="application/pkcs7-signature">
     <glob pattern="*.p7s"/>
     <magic priority="50">
@@ -404,6 +406,7 @@
               mask="0xFFFFFFFFFFFFFFFFFFFFFFFF00FF" offset="0"/>
     </magic>
   </mime-type>
+
   <mime-type type="application/pkix-cert">
     <glob pattern="*.cer"/>
   </mime-type>
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/crypto/Pkcs7Parser.java b/tika-parsers/src/main/java/org/apache/tika/parser/crypto/Pkcs7Parser.java
new file mode 100644
index 000000000..1e84b6c35
--- /dev/null
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/crypto/Pkcs7Parser.java
@@ -0,0 +1,80 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.parser.crypto;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.util.Set;
+
+import org.apache.tika.exception.TikaException;
+import org.apache.tika.io.CloseShieldInputStream;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.mime.MediaType;
+import org.apache.tika.parser.AbstractParser;
+import org.apache.tika.parser.EmptyParser;
+import org.apache.tika.parser.ParseContext;
+import org.apache.tika.parser.Parser;
+import org.bouncycastle.cms.CMSException;
+import org.bouncycastle.cms.CMSSignedDataParser;
+import org.bouncycastle.cms.CMSTypedStream;
+import org.xml.sax.ContentHandler;
+import org.xml.sax.SAXException;
+
+/**
+ * Basic parser for PKCS7 data.
+ */
+public class Pkcs7Parser extends AbstractParser {
+
+    /** Serial version UID */
+    private static final long serialVersionUID = -7310531559075115044L;
+
+    private static final MediaType PKCS7_MIME =
+            MediaType.application("pkcs7-mime");
+
+    private static final MediaType PKCS7_SIGNATURE =
+            MediaType.application("pkcs7-signature");
+
+    public Set<MediaType> getSupportedTypes(ParseContext context) {
+        return MediaType.set(PKCS7_MIME, PKCS7_SIGNATURE);
+    }
+
+    public void parse(
+            InputStream stream, ContentHandler handler,
+            Metadata metadata, ParseContext context)
+            throws IOException, SAXException, TikaException {
+        try {
+            CMSSignedDataParser parser =
+                    new CMSSignedDataParser(new CloseShieldInputStream(stream));
+            try {
+                CMSTypedStream content = parser.getSignedContent();
+                InputStream input = content.getContentStream();
+                try {
+                    Parser delegate =
+                            context.get(Parser.class, EmptyParser.INSTANCE);
+                    delegate.parse(input, handler, metadata, context);
+                } finally {
+                    input.close();
+                }
+            } finally {
+                parser.close();
+            }
+        } catch (CMSException e) {
+            throw new TikaException("Unable to parse pkcs7 signed data", e);
+        }
+    }
+
+}
diff --git a/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.parser.Parser b/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.parser.Parser
index fcdf75b22..e7b4b4257 100644
--- a/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.parser.Parser
+++ b/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.parser.Parser
@@ -16,6 +16,7 @@
 org.apache.tika.parser.asm.ClassParser
 org.apache.tika.parser.audio.AudioParser
 org.apache.tika.parser.audio.MidiParser
+org.apache.tika.parser.crypto.Pkcs7Parser
 org.apache.tika.parser.dwg.DWGParser
 org.apache.tika.parser.epub.EpubParser
 org.apache.tika.parser.executable.ExecutableParser

Commit:
4c58d09499bf164ed123410464d43c20b764b5d5
Jukka Zitting
jukka@apache.org
2012-06-30 12:14:01 +0000
TIKA-934: Tika in server mode stops responding and reports NPE over and over in logs
diff --git a/tika-app/src/main/java/org/apache/tika/cli/TikaCLI.java b/tika-app/src/main/java/org/apache/tika/cli/TikaCLI.java
index 6cdbcb463..fd5c2ee8e 100644
--- a/tika-app/src/main/java/org/apache/tika/cli/TikaCLI.java
+++ b/tika-app/src/main/java/org/apache/tika/cli/TikaCLI.java
@@ -117,14 +117,15 @@ public class TikaCLI {
 
     private class OutputType {
 
-        public void process(InputStream input, OutputStream output)
+        public void process(
+                InputStream input, OutputStream output, Metadata metadata)
                 throws Exception {
             Parser p = parser;
             if (fork) {
                 p = new ForkParser(TikaCLI.class.getClassLoader(), p);
             }
-            ContentHandler handler = getContentHandler(output);
-            p.parse(input, handler, metadata, context);   
+            ContentHandler handler = getContentHandler(output, metadata);
+            p.parse(input, handler, metadata, context);
             // fix for TIKA-596: if a parser doesn't generate
             // XHTML output, the lack of an output document prevents
             // metadata from being output: this fixes that
@@ -136,8 +137,8 @@ public class TikaCLI {
             }
         }
 
-        protected ContentHandler getContentHandler(OutputStream output)
-                throws Exception {
+        protected ContentHandler getContentHandler(
+                OutputStream output, Metadata metadata) throws Exception {
             throw new UnsupportedOperationException();
         }
         
@@ -145,67 +146,68 @@ public class TikaCLI {
 
     private final OutputType XML = new OutputType() {
         @Override
-        protected ContentHandler getContentHandler(OutputStream output)
-                throws Exception {
+        protected ContentHandler getContentHandler(
+                OutputStream output, Metadata metadata) throws Exception {
             return getTransformerHandler(output, "xml", encoding, prettyPrint);
         }
     };
 
     private final OutputType HTML = new OutputType() {
         @Override
-        protected ContentHandler getContentHandler(OutputStream output)
-                throws Exception {
+        protected ContentHandler getContentHandler(
+                OutputStream output, Metadata metadata) throws Exception {
             return getTransformerHandler(output, "html", encoding, prettyPrint);
         }
     };
 
     private final OutputType TEXT = new OutputType() {
         @Override
-        protected ContentHandler getContentHandler(OutputStream output)
-                throws Exception {
+        protected ContentHandler getContentHandler(
+                OutputStream output, Metadata metadata) throws Exception {
             return new BodyContentHandler(getOutputWriter(output, encoding));
         }
     };
 
     private final OutputType NO_OUTPUT = new OutputType() {
         @Override
-        protected ContentHandler getContentHandler(OutputStream output) {
+        protected ContentHandler getContentHandler(
+                OutputStream output, Metadata metadata) {
             return new DefaultHandler();
         }
     };
 
     private final OutputType TEXT_MAIN = new OutputType() {
         @Override
-        protected ContentHandler getContentHandler(OutputStream output)
-                throws Exception {
+        protected ContentHandler getContentHandler(
+                OutputStream output, Metadata metadata) throws Exception {
             return new BoilerpipeContentHandler(getOutputWriter(output, encoding));
         }
     };
     
     private final OutputType METADATA = new OutputType() {
         @Override
-        protected ContentHandler getContentHandler(OutputStream output)
-                throws Exception {
+        protected ContentHandler getContentHandler(
+                OutputStream output, Metadata metadata) throws Exception {
             final PrintWriter writer =
                 new PrintWriter(getOutputWriter(output, encoding));
-            return new NoDocumentMetHandler(writer);
+            return new NoDocumentMetHandler(metadata, writer);
         }
     };
 
     private final OutputType JSON = new OutputType() {
         @Override
-        protected ContentHandler getContentHandler(OutputStream output)
-                throws Exception {
+        protected ContentHandler getContentHandler(
+                OutputStream output, Metadata metadata) throws Exception {
             final PrintWriter writer =
                     new PrintWriter(getOutputWriter(output, encoding));
-            return new NoDocumentJSONMetHandler(writer);
+            return new NoDocumentJSONMetHandler(metadata, writer);
         }
     };
 
     private final OutputType XMP = new OutputType() {
         @Override
-        protected ContentHandler getContentHandler(OutputStream output)
-                throws Exception {
+        protected ContentHandler getContentHandler(
+                OutputStream output, final Metadata metadata) throws Exception {
             final ContentHandler handler =
                     getTransformerHandler(output, "xml", encoding, prettyPrint);
             return new DefaultHandler() {
@@ -222,8 +224,8 @@ public class TikaCLI {
 
     private final OutputType LANGUAGE = new OutputType() {
         @Override
-        protected ContentHandler getContentHandler(OutputStream output)
-                throws Exception {
+        protected ContentHandler getContentHandler(
+                OutputStream output, Metadata metadata) throws Exception {
             final PrintWriter writer =
                 new PrintWriter(getOutputWriter(output, encoding));
             return new ProfilingHandler() {
@@ -237,7 +239,8 @@ public class TikaCLI {
 
     private final OutputType DETECT = new OutputType() {
         @Override
-        public void process(InputStream stream, OutputStream output)
+        public void process(
+                InputStream stream, OutputStream output, Metadata metadata)
                 throws Exception {
             PrintWriter writer =
                 new PrintWriter(getOutputWriter(output, encoding));
@@ -250,7 +253,8 @@ public class TikaCLI {
     /* Creates ngram profile */
     private final OutputType CREATE_PROFILE = new OutputType() {
         @Override
-        public void process(InputStream stream, OutputStream output)
+        public void process(
+                InputStream stream, OutputStream output, Metadata metadata)
                 throws Exception {
             ngp = LanguageProfilerBuilder.create(profileName, stream, encoding);
             FileOutputStream fos = new FileOutputStream(new File(profileName + ".ngp"));
@@ -268,8 +272,6 @@ public class TikaCLI {
 
     private Parser parser;
 
-    private Metadata metadata;
-
     private OutputType type = XML;
     
     private LanguageProfilerBuilder ngp = null;
@@ -386,14 +388,13 @@ public class TikaCLI {
             type = CREATE_PROFILE;
         } else {
             pipeMode = false;
-            metadata = new Metadata();
             if (serverMode) {
                 new TikaServer(Integer.parseInt(arg)).start();
             } else if (arg.equals("-")) {
                 InputStream stream =
                     TikaInputStream.get(new CloseShieldInputStream(System.in));
                 try {
-                    type.process(stream, System.out);
+                    type.process(stream, System.out, new Metadata());
                 } finally {
                     stream.close();
                 }
@@ -405,9 +406,10 @@ public class TikaCLI {
                 } else {
                     url = new URL(arg);
                 }
+                Metadata metadata = new Metadata();
                 InputStream input = TikaInputStream.get(url, metadata);
                 try {
-                    type.process(input, System.out);
+                    type.process(input, System.out, metadata);
                 } finally {
                     input.close();
                     System.out.flush();
@@ -777,8 +779,9 @@ public class TikaCLI {
                 public void run() {
                     try {
                         try {
+                            InputStream input = socket.getInputStream();
                             OutputStream output = socket.getOutputStream();
-                            type.process(socket.getInputStream(), output);
+                            type.process(input, output, new Metadata());
                             output.flush();
                         } finally {
                             socket.close();
@@ -794,13 +797,16 @@ public class TikaCLI {
 
     }
     
-    private class NoDocumentMetHandler extends DefaultHandler{
-        
+    private class NoDocumentMetHandler extends DefaultHandler {
+
+        protected final Metadata metadata;
+
         protected PrintWriter writer;
         
         private boolean metOutput;
-        
-        public NoDocumentMetHandler(PrintWriter writer){
+
+        public NoDocumentMetHandler(Metadata metadata, PrintWriter writer){
+            this.metadata = metadata;
             this.writer = writer;
             this.metOutput = false;
         }
@@ -834,8 +840,8 @@ public class TikaCLI {
         private NumberFormat formatter;
         private Gson gson;
        
-        public NoDocumentJSONMetHandler(PrintWriter writer){
-            super(writer);
+        public NoDocumentJSONMetHandler(Metadata metadata, PrintWriter writer){
+            super(metadata, writer);
             
             formatter = NumberFormat.getInstance();
             gson = new Gson();

Commit:
14113de27f6f8c0bb56d5b2d025acdf4ef2b1685
Jukka Zitting
jukka@apache.org
2012-06-30 11:53:31 +0000
TIKA-943: Add parameter to tika-app to supply password for decryption
diff --git a/CHANGES.txt b/CHANGES.txt
index 9ba6daf11..aa166f166 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -33,6 +33,10 @@ Release 1.2 - Current Development
     (KML and KMZ) used by tools like Google Earth. See also
     http://www.opengeospatial.org/standards/kml/. (TIKA-941)
 
+  * CLI: You can now use the TIKA_PASSWORD environment variable or the
+    --password=X command line option to specify the password that Tika CLI
+    should use for opening encrypted documents (TIKA-943).
+
 Release 1.1 - 3/7/2012
 ---------------------------------
 
diff --git a/tika-app/src/main/java/org/apache/tika/cli/TikaCLI.java b/tika-app/src/main/java/org/apache/tika/cli/TikaCLI.java
index 236c23f06..6cdbcb463 100644
--- a/tika-app/src/main/java/org/apache/tika/cli/TikaCLI.java
+++ b/tika-app/src/main/java/org/apache/tika/cli/TikaCLI.java
@@ -71,6 +71,7 @@ import org.apache.tika.parser.NetworkParser;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.parser.Parser;
 import org.apache.tika.parser.ParserDecorator;
+import org.apache.tika.parser.PasswordProvider;
 import org.apache.tika.parser.html.BoilerpipeContentHandler;
 import org.apache.tika.sax.BodyContentHandler;
 import org.apache.tika.sax.XMPContentHandler;
@@ -278,6 +279,11 @@ public class TikaCLI {
      */
     private String encoding = null;
 
+    /**
+     * Password for opening encrypted documents, or <code>null</code>.
+     */
+    private String password = System.getenv("TIKA_PASSWORD");
+
     private boolean pipeMode = true;
 
     private boolean serverMode = false;
@@ -293,6 +299,11 @@ public class TikaCLI {
         detector = new DefaultDetector();
         parser = new AutoDetectParser(detector);
         context.set(Parser.class, parser);
+        context.set(PasswordProvider.class, new PasswordProvider() {
+            public String getPassword(Metadata metadata) {
+                return password;
+            }
+        });
     }
 
     public void process(String arg) throws Exception {
@@ -331,6 +342,10 @@ public class TikaCLI {
             encoding = arg.substring("-e".length());
         } else if (arg.startsWith("--encoding=")) {
             encoding = arg.substring("--encoding=".length());
+        } else if (arg.startsWith("-p") && !arg.equals("-p")) {
+            password = arg.substring("-p".length());
+        } else if (arg.startsWith("--password=")) {
+            password = arg.substring("--password=".length());
         } else  if (arg.equals("-j") || arg.equals("--json")) {
             type = JSON;
         } else  if (arg.equals("-y") || arg.equals("--xmp")) {
@@ -424,8 +439,9 @@ public class TikaCLI {
         out.println("    -l  or --language      Output only language");
         out.println("    -d  or --detect        Detect document type");
         out.println("    -eX or --encoding=X    Use output encoding X");
-        out.println("    -z  or --extract       Extract all attachements into current directory");        
-        out.println("    --extract-dir=<dir>    Specify target directory for -z");        
+        out.println("    -pX or --password=X    Use document password X");
+        out.println("    -z  or --extract       Extract all attachements into current directory");
+        out.println("    --extract-dir=<dir>    Specify target directory for -z");
         out.println("    -r  or --pretty-print  For XML and XHTML outputs, adds newlines and");
         out.println("                           whitespace, for better readability");
         out.println();

Commit:
328b935c08b61bf785ec99952c687f04f7cf989f
Jukka Zitting
jukka@apache.org
2012-06-30 11:39:51 +0000
TIKA-929: Consistent, namespaced definitions for office file related metadata
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/MSOffice.java b/tika-core/src/main/java/org/apache/tika/metadata/MSOffice.java
index 5b748090d..4b49cac85 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/MSOffice.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/MSOffice.java
@@ -32,31 +32,31 @@ public interface MSOffice {
 
     @Deprecated String AUTHOR = "Author";
 
-    String APPLICATION_NAME = "Application-Name";
+    @Deprecated String APPLICATION_NAME = "Application-Name";
 
-    String REVISION_NUMBER = "Revision-Number";
+    @Deprecated String REVISION_NUMBER = "Revision-Number";
 
-    String TEMPLATE = "Template";
+    @Deprecated String TEMPLATE = "Template";
 
-    String TOTAL_TIME = "Total-Time";
+    @Deprecated String TOTAL_TIME = "Total-Time";
 
-    String PRESENTATION_FORMAT = "Presentation-Format";
+    @Deprecated String PRESENTATION_FORMAT = "Presentation-Format";
 
-    String NOTES = "Notes";
+    @Deprecated String NOTES = "Notes";
 
-    String MANAGER = "Manager";
+    @Deprecated String MANAGER = "Manager";
 
-    String APPLICATION_VERSION = "Application-Version";
+    @Deprecated String APPLICATION_VERSION = "Application-Version";
 
-    String VERSION = "Version";
+    @Deprecated String VERSION = "Version";
 
-    String CONTENT_STATUS = "Content-Status";
+    @Deprecated String CONTENT_STATUS = "Content-Status";
 
-    String CATEGORY = "Category";
+    @Deprecated String CATEGORY = "Category";
 
-    String COMPANY = "Company";
+    @Deprecated String COMPANY = "Company";
 
-    String SECURITY = "Security";
+    @Deprecated String SECURITY = "Security";
 
     
     /** The number of Slides are there in the (presentation) document */
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/Office.java b/tika-core/src/main/java/org/apache/tika/metadata/Office.java
index b0e1cb333..eeaaa4f90 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/Office.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/Office.java
@@ -31,8 +31,7 @@ package org.apache.tika.metadata;
 public interface Office {
    // These are taken from the OpenDocumentFormat specification
    public static final String NAMESPACE_URI_DOC_META = "urn:oasis:names:tc:opendocument:xmlns:meta:1.0";
-   public static final String PREFIX_DOC_META = "doc-meta";
-   public static final String PREFIX_DOC_META_STATS = "doc-meta-stats";
+   public static final String PREFIX_DOC_META = "meta";
 
    /** 
     * For user defined metadata entries in the document,
@@ -83,44 +82,44 @@ public interface Office {
     
     /** The number of Slides are there in the (presentation) document */
     Property SLIDE_COUNT = Property.internalInteger(
-          PREFIX_DOC_META_STATS + Metadata.NAMESPACE_PREFIX_DELIMITER + "slide-count");
+    	  PREFIX_DOC_META + Metadata.NAMESPACE_PREFIX_DELIMITER + "slide-count");
     
     /** The number of Pages are there in the (paged) document */
     Property PAGE_COUNT = Property.internalInteger(
-          PREFIX_DOC_META_STATS + Metadata.NAMESPACE_PREFIX_DELIMITER + "page-count");
+          PREFIX_DOC_META + Metadata.NAMESPACE_PREFIX_DELIMITER + "page-count");
 
     /** The number of individual Paragraphs in the document */ 
     Property PARAGRAPH_COUNT = Property.internalInteger(
-          PREFIX_DOC_META_STATS + Metadata.NAMESPACE_PREFIX_DELIMITER + "paragraph-count");
+          PREFIX_DOC_META + Metadata.NAMESPACE_PREFIX_DELIMITER + "paragraph-count");
     
     /** The number of lines in the document */
     Property LINE_COUNT = Property.internalInteger(
-          PREFIX_DOC_META_STATS + Metadata.NAMESPACE_PREFIX_DELIMITER + "line-count");
+          PREFIX_DOC_META + Metadata.NAMESPACE_PREFIX_DELIMITER + "line-count");
 
     /** The number of Words in the document */
     Property WORD_COUNT = Property.internalInteger(
-          PREFIX_DOC_META_STATS + Metadata.NAMESPACE_PREFIX_DELIMITER + "word-count");
+          PREFIX_DOC_META + Metadata.NAMESPACE_PREFIX_DELIMITER + "word-count");
 
     /** The number of Characters in the document */
     Property CHARACTER_COUNT = Property.internalInteger(
-          PREFIX_DOC_META_STATS + Metadata.NAMESPACE_PREFIX_DELIMITER + "character-count");
+          PREFIX_DOC_META + Metadata.NAMESPACE_PREFIX_DELIMITER + "character-count");
     
     /** The number of Characters in the document, including spaces */
     Property CHARACTER_COUNT_WITH_SPACES = Property.internalInteger(
-          PREFIX_DOC_META_STATS + Metadata.NAMESPACE_PREFIX_DELIMITER + "character-count-with-spaces");
+          PREFIX_DOC_META + Metadata.NAMESPACE_PREFIX_DELIMITER + "character-count-with-spaces");
 
     /** The number of Tables in the document */
     Property TABLE_COUNT = Property.internalInteger(
-          PREFIX_DOC_META_STATS + Metadata.NAMESPACE_PREFIX_DELIMITER + "table-count");
+          PREFIX_DOC_META + Metadata.NAMESPACE_PREFIX_DELIMITER + "table-count");
     
     /** The number of Images in the document */
     Property IMAGE_COUNT = Property.internalInteger(
-          PREFIX_DOC_META_STATS + Metadata.NAMESPACE_PREFIX_DELIMITER + "image-count");
+          PREFIX_DOC_META + Metadata.NAMESPACE_PREFIX_DELIMITER + "image-count");
     
     /** 
      * The number of Objects in the document. These are typically non-Image resources 
      * embedded in the document, such as other documents or non-Image media. 
      */
     Property OBJECT_COUNT = Property.internalInteger(
-          PREFIX_DOC_META_STATS + Metadata.NAMESPACE_PREFIX_DELIMITER + "object-count");
+          PREFIX_DOC_META + Metadata.NAMESPACE_PREFIX_DELIMITER + "object-count");
 }
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/OfficeOpenXMLCore.java b/tika-core/src/main/java/org/apache/tika/metadata/OfficeOpenXMLCore.java
new file mode 100644
index 000000000..5f33f1fd3
--- /dev/null
+++ b/tika-core/src/main/java/org/apache/tika/metadata/OfficeOpenXMLCore.java
@@ -0,0 +1,70 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.metadata;
+
+/**
+ * Core properties as defined in the Office Open XML specification part Two that are not
+ * in the DublinCore namespace.
+ * There is also a keyword property definition in the specification which is omitted here, 
+ * because Tika should stick to the DublinCore/IPTC definition. 
+ * 
+ * @see <a href="http://www.iso.org/iso/iso_catalogue/catalogue_tc/catalogue_detail.htm?csnumber=59575"
+ *        >ISO document of Office Open XML specification</a>
+ * @see <a href="http://www.ecma-international.org/publications/standards/Ecma-376.htm
+ *        >ECMA document of Office Open XML specification</a> 
+ */
+public interface OfficeOpenXMLCore 
+{
+	String NAMESPACE_URI = "http://schemas.openxmlformats.org/package/2006/metadata/core-properties/";
+	String PREFIX = "cp";
+	
+	/**
+     * A categorization of the content of this package.
+     */
+    Property CATEGORY = Property.externalText(
+    		PREFIX + Metadata.NAMESPACE_PREFIX_DELIMITER + "category");
+    
+    /**
+     * The status of the content.
+     */
+    Property CONTENT_STATUS = Property.externalText(
+    		PREFIX + Metadata.NAMESPACE_PREFIX_DELIMITER + "contentStatus");
+    
+    /**
+     * The user who performed the last modification. The identification is environment-specific.
+     */
+    Property LAST_MODIFIED_BY = Property.externalText(
+    		PREFIX + Metadata.NAMESPACE_PREFIX_DELIMITER + "lastModifiedBy");
+    
+    /**
+     * The date and time of the last printing.
+     */
+    Property LAST_PRINTED = Property.externalDate(
+    		PREFIX + Metadata.NAMESPACE_PREFIX_DELIMITER + "lastPrinted");
+    
+    /**
+     * The revision number.
+     */
+    Property REVISION = Property.externalText(
+    		PREFIX + Metadata.NAMESPACE_PREFIX_DELIMITER + "revision");
+    
+    /**
+     * The version number. This value is set by the user or by the application.
+     */
+    Property VERSION = Property.externalText(
+    		PREFIX + Metadata.NAMESPACE_PREFIX_DELIMITER + "version");
+}
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/OfficeOpenXMLExtended.java b/tika-core/src/main/java/org/apache/tika/metadata/OfficeOpenXMLExtended.java
new file mode 100644
index 000000000..330a83006
--- /dev/null
+++ b/tika-core/src/main/java/org/apache/tika/metadata/OfficeOpenXMLExtended.java
@@ -0,0 +1,65 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.metadata;
+
+/**
+ * Extended properties as defined in the Office Open XML specification part Four.
+ * Those properties are omitted which have equivalent properties defined in the ODF
+ * namespace like "word count".
+ * Also not all properties from the specification are defined here, yet. Only those which have been in
+ * use by the parsers so far.
+ * 
+ * @see <a href="http://www.iso.org/iso/iso_catalogue/catalogue_tc/catalogue_detail.htm?csnumber=59575"
+ *        >ISO document of Office Open XML specification</a>
+ * @see <a href="http://www.ecma-international.org/publications/standards/Ecma-376.htm
+ *        >ECMA document of Office Open XML specification</a> 
+ */
+public interface OfficeOpenXMLExtended 
+{
+	String NAMESPACE_URI = "http://schemas.openxmlformats.org/officeDocument/2006/extended-properties/";
+	String PREFIX = "extended-properties";
+	
+    Property TEMPLATE = Property.externalText(
+    		PREFIX + Metadata.NAMESPACE_PREFIX_DELIMITER + "Template");
+    
+    Property MANAGER = Property.externalText(
+    		PREFIX + Metadata.NAMESPACE_PREFIX_DELIMITER + "Manager");
+    
+    Property COMPANY = Property.externalText(
+    		PREFIX + Metadata.NAMESPACE_PREFIX_DELIMITER + "Company");
+    
+    Property PRESENTATION_FORMAT = Property.externalText(
+    		PREFIX + Metadata.NAMESPACE_PREFIX_DELIMITER + "PresentationFormat");
+    
+    Property NOTES = Property.externalInteger(
+    		PREFIX + Metadata.NAMESPACE_PREFIX_DELIMITER + "Notes");
+    
+    Property TOTAL_TIME = Property.externalInteger(
+    		PREFIX + Metadata.NAMESPACE_PREFIX_DELIMITER + "TotalTime");
+    
+    Property HIDDEN_SLIDES = Property.externalInteger(
+    		PREFIX + Metadata.NAMESPACE_PREFIX_DELIMITER + "HiddedSlides");
+    
+    Property APPLICATION = Property.externalText(
+    		PREFIX + Metadata.NAMESPACE_PREFIX_DELIMITER + "Application");
+    
+    Property APP_VERSION = Property.externalText(
+    		PREFIX + Metadata.NAMESPACE_PREFIX_DELIMITER + "AppVersion");
+    
+    Property DOC_SECURITY = Property.externalInteger(
+    		PREFIX + Metadata.NAMESPACE_PREFIX_DELIMITER + "DocSecurity");
+}
\ No newline at end of file
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/SummaryExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/SummaryExtractor.java
index 6a4a2940f..73b47fa0f 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/SummaryExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/SummaryExtractor.java
@@ -35,6 +35,8 @@ import org.apache.tika.exception.TikaException;
 import org.apache.tika.metadata.MSOffice;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.Office;
+import org.apache.tika.metadata.OfficeOpenXMLCore;
+import org.apache.tika.metadata.OfficeOpenXMLExtended;
 import org.apache.tika.metadata.PagedText;
 import org.apache.tika.metadata.Property;
 import org.apache.tika.metadata.TikaCoreProperties;
@@ -99,14 +101,14 @@ class SummaryExtractor {
         set(TikaCoreProperties.SUBJECT, summary.getSubject());
         set(TikaCoreProperties.LAST_AUTHOR, summary.getLastAuthor());
         set(Metadata.COMMENTS, summary.getComments());
-        set(Metadata.TEMPLATE, summary.getTemplate());
-        set(Metadata.APPLICATION_NAME, summary.getApplicationName());
-        set(Metadata.REVISION_NUMBER, summary.getRevNumber());
+        set(OfficeOpenXMLExtended.TEMPLATE, summary.getTemplate());
+        set(OfficeOpenXMLExtended.APPLICATION, summary.getApplicationName());
+        set(OfficeOpenXMLCore.REVISION, summary.getRevNumber());
         set(TikaCoreProperties.CREATION_DATE, summary.getCreateDateTime());
         set(TikaCoreProperties.SAVE_DATE, summary.getLastSaveDateTime());
         set(TikaCoreProperties.PRINT_DATE, summary.getLastPrinted());
         set(Metadata.EDIT_TIME, summary.getEditTime());
-        set(Metadata.SECURITY, summary.getSecurity());
+        set(OfficeOpenXMLExtended.DOC_SECURITY, summary.getSecurity());
         
         // New style counts
         set(Office.WORD_COUNT, summary.getWordCount());
@@ -116,17 +118,22 @@ class SummaryExtractor {
             metadata.set(PagedText.N_PAGES, summary.getPageCount());
         }
         
-        // Old style, Tika 1.0 counts
+        // Old style, Tika 1.0 properties
+     // TODO Remove these in Tika 2.0
+        set(Metadata.TEMPLATE, summary.getTemplate());
+        set(Metadata.APPLICATION_NAME, summary.getApplicationName());
+        set(Metadata.REVISION_NUMBER, summary.getRevNumber());
+        set(Metadata.SECURITY, summary.getSecurity());
         set(MSOffice.WORD_COUNT, summary.getWordCount());
         set(MSOffice.CHARACTER_COUNT, summary.getCharCount());
         set(MSOffice.PAGE_COUNT, summary.getPageCount());
     }
 
     private void parse(DocumentSummaryInformation summary) {
-        set(Metadata.COMPANY, summary.getCompany());
-        set(Metadata.MANAGER, summary.getManager());
+        set(OfficeOpenXMLExtended.COMPANY, summary.getCompany());
+        set(OfficeOpenXMLExtended.MANAGER, summary.getManager());
         set(TikaCoreProperties.LANGUAGE, getLanguage(summary));
-        set(Metadata.CATEGORY, summary.getCategory());
+        set(OfficeOpenXMLCore.CATEGORY, summary.getCategory());
         
         // New style counts
         set(Office.SLIDE_COUNT, summary.getSlideCount());
@@ -134,7 +141,11 @@ class SummaryExtractor {
             metadata.set(PagedText.N_PAGES, summary.getSlideCount());
         }
         // Old style, Tika 1.0 counts
+     // TODO Remove these in Tika 2.0
+        set(Metadata.COMPANY, summary.getCompany());
+        set(Metadata.MANAGER, summary.getManager());
         set(MSOffice.SLIDE_COUNT, summary.getSlideCount());
+        set(Metadata.CATEGORY, summary.getCategory());
         
         parse(summary.getCustomProperties());
     }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java
index ec9b64b16..52045375b 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java
@@ -30,6 +30,8 @@ import org.apache.tika.exception.TikaException;
 import org.apache.tika.metadata.MSOffice;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.Office;
+import org.apache.tika.metadata.OfficeOpenXMLCore;
+import org.apache.tika.metadata.OfficeOpenXMLExtended;
 import org.apache.tika.metadata.PagedText;
 import org.apache.tika.metadata.Property;
 import org.apache.tika.metadata.TikaCoreProperties;
@@ -65,8 +67,8 @@ public class MetadataExtractor {
         PackagePropertiesPart propsHolder = properties
                 .getUnderlyingProperties();
 
-        addProperty(metadata, Metadata.CATEGORY, propsHolder.getCategoryProperty());
-        addProperty(metadata, Metadata.CONTENT_STATUS, propsHolder
+        addProperty(metadata, OfficeOpenXMLCore.CATEGORY, propsHolder.getCategoryProperty());
+        addProperty(metadata, OfficeOpenXMLCore.CONTENT_STATUS, propsHolder
                 .getContentStatusProperty());
         addProperty(metadata, TikaCoreProperties.DATE, propsHolder
                 .getCreatedProperty());
@@ -92,11 +94,20 @@ public class MetadataExtractor {
                 .getModifiedProperty());
         addProperty(metadata, TikaCoreProperties.MODIFIED, propsHolder
               .getModifiedProperty());
-        addProperty(metadata, Metadata.REVISION_NUMBER, propsHolder
+        addProperty(metadata, OfficeOpenXMLCore.REVISION, propsHolder
                 .getRevisionProperty());
         addProperty(metadata, TikaCoreProperties.SUBJECT, propsHolder
                 .getSubjectProperty());
         addProperty(metadata, TikaCoreProperties.TITLE, propsHolder.getTitleProperty());
+        addProperty(metadata, OfficeOpenXMLCore.VERSION, propsHolder.getVersionProperty());
+        
+        // Legacy Tika-1.0 style stats
+        // TODO Remove these in Tika 2.0
+        addProperty(metadata, Metadata.CATEGORY, propsHolder.getCategoryProperty());
+        addProperty(metadata, Metadata.CONTENT_STATUS, propsHolder
+                .getContentStatusProperty());
+        addProperty(metadata, Metadata.REVISION_NUMBER, propsHolder
+                .getRevisionProperty());
         addProperty(metadata, Metadata.VERSION, propsHolder.getVersionProperty());
     }
 
@@ -104,14 +115,15 @@ public class MetadataExtractor {
             Metadata metadata) {
         CTProperties propsHolder = properties.getUnderlyingProperties();
 
-        addProperty(metadata, Metadata.APPLICATION_NAME, propsHolder.getApplication());
-        addProperty(metadata, Metadata.APPLICATION_VERSION, propsHolder.getAppVersion());
+        addProperty(metadata, OfficeOpenXMLExtended.APPLICATION, propsHolder.getApplication());
+        addProperty(metadata, OfficeOpenXMLExtended.APP_VERSION, propsHolder.getAppVersion());
         addProperty(metadata, TikaCoreProperties.PUBLISHER, propsHolder.getCompany());
-        addProperty(metadata, Metadata.MANAGER, propsHolder.getManager());
-        addProperty(metadata, Metadata.NOTES, propsHolder.getNotes());
-        addProperty(metadata, Metadata.PRESENTATION_FORMAT, propsHolder.getPresentationFormat());
-        addProperty(metadata, Metadata.TEMPLATE, propsHolder.getTemplate());
-        addProperty(metadata, Metadata.TOTAL_TIME, propsHolder.getTotalTime());
+        addProperty(metadata, OfficeOpenXMLExtended.COMPANY, propsHolder.getCompany());
+        addProperty(metadata, OfficeOpenXMLExtended.MANAGER, propsHolder.getManager());
+        addProperty(metadata, OfficeOpenXMLExtended.NOTES, propsHolder.getNotes());
+        addProperty(metadata, OfficeOpenXMLExtended.PRESENTATION_FORMAT, propsHolder.getPresentationFormat());
+        addProperty(metadata, OfficeOpenXMLExtended.TEMPLATE, propsHolder.getTemplate());
+        addProperty(metadata, OfficeOpenXMLExtended.TOTAL_TIME, propsHolder.getTotalTime());
 
         if (propsHolder.getPages() > 0) {
            metadata.set(PagedText.N_PAGES, propsHolder.getPages());
@@ -129,6 +141,14 @@ public class MetadataExtractor {
         addProperty(metadata, Office.CHARACTER_COUNT_WITH_SPACES, propsHolder.getCharactersWithSpaces());
         
         // Legacy Tika-1.0 style stats
+        // TODO Remove these in Tika 2.0
+        addProperty(metadata, Metadata.APPLICATION_NAME, propsHolder.getApplication());
+        addProperty(metadata, Metadata.APPLICATION_VERSION, propsHolder.getAppVersion());
+        addProperty(metadata, Metadata.MANAGER, propsHolder.getManager());
+        addProperty(metadata, Metadata.NOTES, propsHolder.getNotes());
+        addProperty(metadata, Metadata.PRESENTATION_FORMAT, propsHolder.getPresentationFormat());
+        addProperty(metadata, Metadata.TEMPLATE, propsHolder.getTemplate());
+        addProperty(metadata, Metadata.TOTAL_TIME, propsHolder.getTotalTime());
         addProperty(metadata, MSOffice.PAGE_COUNT, propsHolder.getPages());
         addProperty(metadata, MSOffice.SLIDE_COUNT, propsHolder.getSlides());
         addProperty(metadata, MSOffice.PARAGRAPH_COUNT, propsHolder.getParagraphs());
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/rtf/TextExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/rtf/TextExtractor.java
index 8a76cb771..16ea68c93 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/rtf/TextExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/rtf/TextExtractor.java
@@ -32,6 +32,8 @@ import java.util.Map;
 
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.OfficeOpenXMLCore;
+import org.apache.tika.metadata.OfficeOpenXMLExtended;
 import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.sax.XHTMLContentHandler;
 import org.apache.tika.utils.CharsetUtils;
@@ -834,15 +836,15 @@ final class TextExtractor {
                 } else if (equals("keywords")) {
                     nextMetaData = TikaCoreProperties.KEYWORDS.getName();
                 } else if (equals("category")) {
-                    nextMetaData = Metadata.CATEGORY;
+                    nextMetaData = OfficeOpenXMLCore.CATEGORY.getName();
                 } else if (equals("comment")) {
                     nextMetaData = Metadata.COMMENT;
                 } else if (equals("company")) {
-                    nextMetaData = Metadata.COMPANY;
+                    nextMetaData = OfficeOpenXMLExtended.COMPANY.getName();
                 } else if (equals("manager")) {
-                    nextMetaData = Metadata.MANAGER;
+                    nextMetaData = OfficeOpenXMLExtended.MANAGER.getName();
                 } else if (equals("template")) {
-                    nextMetaData = Metadata.TEMPLATE;
+                    nextMetaData = OfficeOpenXMLExtended.TEMPLATE.getName();
                 }
             }
 
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ExcelParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ExcelParserTest.java
index d191ad88f..782564675 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ExcelParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ExcelParserTest.java
@@ -24,6 +24,7 @@ import junit.framework.TestCase;
 import org.apache.tika.detect.DefaultDetector;
 import org.apache.tika.detect.Detector;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.OfficeOpenXMLExtended;
 import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.parser.AutoDetectParser;
@@ -284,7 +285,7 @@ public class ExcelParserTest extends TestCase {
        assertEquals("",                     metadata.get(TikaCoreProperties.LAST_AUTHOR));
        assertEquals("2011-08-22T13:45:54Z", metadata.get(TikaCoreProperties.SAVE_DATE));
        assertEquals("2006-09-12T15:06:44Z", metadata.get(TikaCoreProperties.CREATION_DATE));
-       assertEquals("Microsoft Excel",      metadata.get(Metadata.APPLICATION_NAME));
+       assertEquals("Microsoft Excel",      metadata.get(OfficeOpenXMLExtended.APPLICATION));
        assertEquals("true",                 metadata.get("custom:myCustomBoolean"));
        assertEquals("3",                    metadata.get("custom:myCustomNumber"));
        assertEquals("MyStringValue",        metadata.get("custom:MyCustomString"));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PowerPointParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PowerPointParserTest.java
index 47c820212..bd4dcfb64 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PowerPointParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PowerPointParserTest.java
@@ -102,7 +102,7 @@ public class PowerPointParserTest extends TikaTest {
 
         assertContains("Keyword1 Keyword2", content);
         assertEquals("Keyword1 Keyword2",
-                     metadata.get(Metadata.KEYWORDS));
+                     metadata.get(TikaCoreProperties.KEYWORDS));
 
         assertContains("Subject is here", content);
         assertEquals("Subject is here",
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ProjectParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ProjectParserTest.java
index 8a9ff2c5f..396bfbd4b 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ProjectParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ProjectParserTest.java
@@ -19,6 +19,9 @@ package org.apache.tika.parser.microsoft;
 import java.io.InputStream;
 
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.Office;
+import org.apache.tika.metadata.OfficeOpenXMLCore;
+import org.apache.tika.metadata.OfficeOpenXMLExtended;
 import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.sax.BodyContentHandler;
@@ -69,12 +72,12 @@ public class ProjectParserTest extends TestCase {
        assertEquals("Pangram, fox, dog", metadata.get(TikaCoreProperties.KEYWORDS));
        assertEquals("Comment Vulpes vulpes comment", metadata.get(Metadata.COMMENTS));
        
-       assertEquals("Category1", metadata.get(Metadata.CATEGORY));
-       assertEquals("Mr Burns", metadata.get(Metadata.MANAGER));
-       assertEquals("CompanyA", metadata.get(Metadata.COMPANY));
+       assertEquals("Category1", metadata.get(OfficeOpenXMLCore.CATEGORY));
+       assertEquals("Mr Burns", metadata.get(OfficeOpenXMLExtended.MANAGER));
+       assertEquals("CompanyA", metadata.get(OfficeOpenXMLExtended.COMPANY));
        
-       assertEquals("2011-11-24T10:58:00Z", metadata.get(Metadata.CREATION_DATE));
-       assertEquals("2011-11-24T11:31:00Z", metadata.get(Metadata.LAST_SAVED));
+       assertEquals("2011-11-24T10:58:00Z", metadata.get(TikaCoreProperties.CREATION_DATE));
+       assertEquals("2011-11-24T11:31:00Z", metadata.get(TikaCoreProperties.SAVE_DATE));
        
        // Custom Project metadata is present with prefix
        assertEquals("0%", metadata.get("custom:% Complete"));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/WordParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/WordParserTest.java
index e3cf468b0..ad9853fe0 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/WordParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/WordParserTest.java
@@ -28,6 +28,7 @@ import javax.xml.transform.stream.StreamResult;
 import org.apache.tika.TikaTest;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.Office;
+import org.apache.tika.metadata.OfficeOpenXMLExtended;
 import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.parser.microsoft.ooxml.OOXMLParserTest;
@@ -239,7 +240,7 @@ public class WordParserTest extends TikaTest {
 
         assertContains("Keyword1 Keyword2", content);
         assertEquals("Keyword1 Keyword2",
-                     metadata.get(Metadata.KEYWORDS));
+                     metadata.get(TikaCoreProperties.KEYWORDS));
 
         assertContains("Subject is here", content);
         assertEquals("Subject is here",
@@ -277,15 +278,15 @@ public class WordParserTest extends TikaTest {
        assertEquals("Etienne Jouvin",       metadata.get(TikaCoreProperties.LAST_AUTHOR));
        assertEquals("2012-01-03T22:14:00Z", metadata.get(TikaCoreProperties.SAVE_DATE));
        assertEquals("2010-10-05T09:03:00Z", metadata.get(TikaCoreProperties.CREATION_DATE));
-       assertEquals("Microsoft Office Word",metadata.get(Metadata.APPLICATION_NAME));
+       assertEquals("Microsoft Office Word",metadata.get(OfficeOpenXMLExtended.APPLICATION));
        assertEquals("1",                    metadata.get(Office.PAGE_COUNT));
        assertEquals("2",                    metadata.get(Office.WORD_COUNT));
        assertEquals("My Title",             metadata.get(TikaCoreProperties.TITLE));
        assertEquals("My Keyword",           metadata.get(TikaCoreProperties.KEYWORDS));
-       assertEquals("Normal.dotm",          metadata.get(Metadata.TEMPLATE));
+       assertEquals("Normal.dotm",          metadata.get(OfficeOpenXMLExtended.TEMPLATE));
        assertEquals("My Comments",          metadata.get(Metadata.COMMENTS));
        assertEquals("My subject",           metadata.get(TikaCoreProperties.SUBJECT));
-       assertEquals("EDF-DIT",              metadata.get(Metadata.COMPANY));
+       assertEquals("EDF-DIT",              metadata.get(OfficeOpenXMLExtended.COMPANY));
        assertEquals("MyStringValue",        metadata.get("custom:MyCustomString"));
        assertEquals("2010-12-30T23:00:00Z", metadata.get("custom:MyCustomDate"));
     }
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
index 0f4ec856c..518256030 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
@@ -29,6 +29,7 @@ import org.apache.tika.TikaTest;
 import org.apache.tika.io.TikaInputStream;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.Office;
+import org.apache.tika.metadata.OfficeOpenXMLExtended;
 import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.metadata.TikaMetadataKeys;
 import org.apache.tika.parser.AutoDetectParser;
@@ -732,9 +733,10 @@ public class OOXMLParserTest extends TikaTest {
        assertEquals(null,                   metadata.get(TikaCoreProperties.AUTHOR));
        assertEquals(null,                   metadata.get(TikaCoreProperties.LAST_AUTHOR));
        assertEquals("2006-09-12T15:06:44Z", metadata.get(TikaCoreProperties.DATE));
-       assertEquals("2006-09-12T15:06:44Z", metadata.get(Metadata.CREATION_DATE));
+       assertEquals("2006-09-12T15:06:44Z", metadata.get(TikaCoreProperties.CREATION_DATE));
        assertEquals("2011-08-22T14:24:38Z", metadata.get(Metadata.LAST_MODIFIED));
        assertEquals("Microsoft Excel",      metadata.get(Metadata.APPLICATION_NAME));
+       assertEquals("Microsoft Excel",      metadata.get(OfficeOpenXMLExtended.APPLICATION));
        assertEquals("true",                 metadata.get("custom:myCustomBoolean"));
        assertEquals("3",                    metadata.get("custom:myCustomNumber"));
        assertEquals("MyStringValue",        metadata.get("custom:MyCustomString"));
@@ -764,11 +766,13 @@ public class OOXMLParserTest extends TikaTest {
        assertEquals("2011-07-29T16:52:00Z", metadata.get(TikaCoreProperties.CREATION_DATE));
        assertEquals("2012-01-03T22:14:00Z", metadata.get(TikaCoreProperties.MODIFIED));
        assertEquals("Microsoft Office Word",metadata.get(Metadata.APPLICATION_NAME));
+       assertEquals("Microsoft Office Word",metadata.get(OfficeOpenXMLExtended.APPLICATION));
        assertEquals("1",                    metadata.get(Office.PAGE_COUNT));
        assertEquals("2",                    metadata.get(Office.WORD_COUNT));
        assertEquals("My Title",             metadata.get(TikaCoreProperties.TITLE));
        assertEquals("My Keyword",           metadata.get(TikaCoreProperties.KEYWORDS));
        assertEquals("Normal.dotm",          metadata.get(Metadata.TEMPLATE));
+       assertEquals("Normal.dotm",          metadata.get(OfficeOpenXMLExtended.TEMPLATE));
        assertEquals("My subject",           metadata.get(TikaCoreProperties.SUBJECT));
        assertEquals("EDF-DIT",              metadata.get(TikaCoreProperties.PUBLISHER));
        assertEquals("true",                 metadata.get("custom:myCustomBoolean"));

Commit:
e99be72add5e1b275cdef123f0a721408a5a7662
Jukka Zitting
jukka@apache.org
2012-06-30 10:34:20 +0000
TIKA-941: Detecting KML / KMZ files
diff --git a/CHANGES.txt b/CHANGES.txt
index 5c18fd2e5..9ba6daf11 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -27,7 +27,11 @@ Release 1.2 - Current Development
   * Archive and compression formats: The Commons Compress dependency was
     upgraded from 1.3 to 1.4.1. With this change Tika can now parse also
     Unix dump archives and documents compressed using the XZ and Pack200
-    compression formats.
+    compression formats. (TIKA-932)
+
+  * KML: Tika now has basic support for Keyhole Markup Language documents
+    (KML and KMZ) used by tools like Google Earth. See also
+    http://www.opengeospatial.org/standards/kml/. (TIKA-941)
 
 Release 1.1 - 3/7/2012
 ---------------------------------
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/pkg/ZipContainerDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/pkg/ZipContainerDetector.java
index 7b82b6c6d..283fefb3d 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/pkg/ZipContainerDetector.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/pkg/ZipContainerDetector.java
@@ -19,6 +19,7 @@ package org.apache.tika.parser.pkg;
 import java.io.ByteArrayInputStream;
 import java.io.IOException;
 import java.io.InputStream;
+import java.util.Enumeration;
 import java.util.regex.Pattern;
 
 import org.apache.commons.compress.archivers.ArchiveException;
@@ -287,7 +288,23 @@ public class ZipContainerDetector implements Detector {
     }
 
     private static MediaType detectKmz(ZipFile zip) {
-        if (zip.getEntry("doc.kml") != null) {
+        boolean kmlFound = false;
+
+        Enumeration<ZipArchiveEntry> entries = zip.getEntries();
+        while (entries.hasMoreElements()) {
+            ZipArchiveEntry entry = entries.nextElement();
+            String name = entry.getName();
+            if (!entry.isDirectory()
+                    && name.indexOf('/') == -1 && name.indexOf('\\') == -1) {
+                if (name.endsWith(".kml") && !kmlFound) {
+                    kmlFound = true;
+                } else {
+                    return null;
+                }
+            }
+        }
+
+        if (kmlFound) {
             return MediaType.application("vnd.google-earth.kmz");
         } else {
             return null;

Commit:
f15a7fc82495887f5bddc889864d39555c6775b0
Jukka Zitting
jukka@apache.org
2012-06-30 09:30:14 +0000
TIKA-941: Detecting KML / KMZ files
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 059327e7b..1bc1caf4e 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -920,9 +920,16 @@
   <mime-type type="application/vnd.gmx">
     <glob pattern="*.gmx"/>
   </mime-type>
+
   <mime-type type="application/vnd.google-earth.kml+xml">
+    <root-XML localName="kml"/>
+    <root-XML namespaceURI="http://www.opengis.net/kml/2.2" localName="kml"/>
+    <acronym>KML</acronym>
+    <_comment>Keyhole Markup Language</_comment>
     <glob pattern="*.kml"/>
+    <sub-class-of type="application/xml"/>
   </mime-type>
+
   <mime-type type="application/vnd.google-earth.kmz">
     <glob pattern="*.kmz"/>
   </mime-type>
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/pkg/ZipContainerDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/pkg/ZipContainerDetector.java
index a488ca171..7b82b6c6d 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/pkg/ZipContainerDetector.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/pkg/ZipContainerDetector.java
@@ -138,6 +138,9 @@ public class ZipContainerDetector implements Detector {
                 if (type == null) {
                     type = detectJar(zip);
                 }
+                if (type == null) {
+                    type = detectKmz(zip);
+                }
                 if (type != null) {
                     return type;
                 }
@@ -282,4 +285,13 @@ public class ZipContainerDetector implements Detector {
           return null;
        }
     }
-}
\ No newline at end of file
+
+    private static MediaType detectKmz(ZipFile zip) {
+        if (zip.getEntry("doc.kml") != null) {
+            return MediaType.application("vnd.google-earth.kmz");
+        } else {
+            return null;
+        }
+    }
+
+}

Commit:
1dfc65fefed007b992786201a9ad29a74c3184ed
Jukka Zitting
jukka@apache.org
2012-06-29 22:16:54 +0000
TIKA-932: Upgrade to Commons Compress 1.4.1
diff --git a/tika-app/src/main/appended-resources/META-INF/LICENSE b/tika-app/src/main/appended-resources/META-INF/LICENSE
index 0b67e6cd9..86803f2e9 100644
--- a/tika-app/src/main/appended-resources/META-INF/LICENSE
+++ b/tika-app/src/main/appended-resources/META-INF/LICENSE
@@ -383,3 +383,11 @@ BZip classes inside the NetCDF library
     OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT
     OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
     SUCH DAMAGE.
+
+XZ compression library (xz)
+
+    All the files in this package have been written by Lasse Collin
+    and/or Igor Pavlov. All these files have been put into the
+    public domain. You can do whatever you want with these files.
+
+    This software is provided "as is", without any warranty.
diff --git a/tika-bundle/pom.xml b/tika-bundle/pom.xml
index ed8e038ff..a3a4b3915 100644
--- a/tika-bundle/pom.xml
+++ b/tika-bundle/pom.xml
@@ -114,7 +114,7 @@
             </Bundle-Activator>
             <Embed-Dependency>
               tika-parsers;inline=true,
-              commons-compress, commons-codec, commons-io,
+              commons-compress, xz, commons-codec, commons-io,
               pdfbox,fontbox,jempbox,bcmail-jdk15,bcprov-jdk15,
               poi,poi-scratchpad,poi-ooxml,poi-ooxml-schemas,
               xmlbeans, dom4j,
diff --git a/tika-bundle/src/main/appended-resources/META-INF/LICENSE b/tika-bundle/src/main/appended-resources/META-INF/LICENSE
index 0b67e6cd9..86803f2e9 100644
--- a/tika-bundle/src/main/appended-resources/META-INF/LICENSE
+++ b/tika-bundle/src/main/appended-resources/META-INF/LICENSE
@@ -383,3 +383,11 @@ BZip classes inside the NetCDF library
     OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT
     OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
     SUCH DAMAGE.
+
+XZ compression library (xz)
+
+    All the files in this package have been written by Lasse Collin
+    and/or Igor Pavlov. All these files have been put into the
+    public domain. You can do whatever you want with these files.
+
+    This software is provided "as is", without any warranty.

Commit:
b27912140e53c0a867a658e1b71962d215106042
Jukka Zitting
jukka@apache.org
2012-06-29 21:19:10 +0000
TIKA-932: Upgrade to Commons Compress 1.4.1
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/pkg/CompressorParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/pkg/CompressorParser.java
index 85af34308..59eeae9cd 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/pkg/CompressorParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/pkg/CompressorParser.java
@@ -60,6 +60,20 @@ public class CompressorParser extends AbstractParser {
     private static final Set<MediaType> SUPPORTED_TYPES =
             MediaType.set(BZIP, BZIP2, GZIP, XZ, PACK);
 
+    static MediaType getMediaType(CompressorInputStream stream) {
+        if (stream instanceof BZip2CompressorInputStream) {
+            return BZIP2;
+        } else if (stream instanceof GzipCompressorInputStream) {
+            return GZIP;
+        } else if (stream instanceof XZCompressorInputStream) {
+            return XZ;
+        } else if (stream instanceof Pack200CompressorInputStream) {
+            return PACK;
+        } else {
+            return MediaType.OCTET_STREAM;
+        }
+    }
+
     public Set<MediaType> getSupportedTypes(ParseContext context) {
         return SUPPORTED_TYPES;
     }
@@ -84,14 +98,9 @@ public class CompressorParser extends AbstractParser {
             throw new TikaException("Unable to uncompress document stream", e);
         }
 
-        if (cis instanceof BZip2CompressorInputStream) {
-            metadata.set(CONTENT_TYPE, BZIP2.toString());
-        } else if (cis instanceof GzipCompressorInputStream) {
-            metadata.set(CONTENT_TYPE, GZIP.toString());
-        } else if (cis instanceof XZCompressorInputStream) {
-            metadata.set(CONTENT_TYPE, XZ.toString());
-        } else if (cis instanceof Pack200CompressorInputStream) {
-            metadata.set(CONTENT_TYPE, PACK.toString());
+        MediaType type = getMediaType(cis);
+        if (!type.equals(MediaType.OCTET_STREAM)) {
+            metadata.set(CONTENT_TYPE, type.toString());
         }
 
         XHTMLContentHandler xhtml = new XHTMLContentHandler(handler, metadata);
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/pkg/PackageParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/pkg/PackageParser.java
index 25af330af..4064d3287 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/pkg/PackageParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/pkg/PackageParser.java
@@ -68,6 +68,28 @@ public class PackageParser extends AbstractParser {
     private static final Set<MediaType> SUPPORTED_TYPES =
             MediaType.set(ZIP, JAR, AR, CPIO, DUMP, TAR);
 
+    static MediaType getMediaType(ArchiveInputStream stream) {
+        if (stream instanceof JarArchiveInputStream) {
+            return JAR;
+        } else if (stream instanceof ZipArchiveInputStream) {
+            return ZIP;
+        } else if (stream instanceof ArArchiveInputStream) {
+            return AR;
+        } else if (stream instanceof CpioArchiveInputStream) {
+            return CPIO;
+        } else if (stream instanceof DumpArchiveInputStream) {
+            return DUMP;
+        } else if (stream instanceof TarArchiveInputStream) {
+            return TAR;
+        } else {
+            return MediaType.OCTET_STREAM;
+        }
+    }
+
+    static boolean isZipArchive(MediaType type) {
+        return type.equals(ZIP) || type.equals(JAR);
+    }
+
     public Set<MediaType> getSupportedTypes(ParseContext context) {
         return SUPPORTED_TYPES;
     }
@@ -92,18 +114,9 @@ public class PackageParser extends AbstractParser {
             throw new TikaException("Unable to unpack document stream", e);
         }
 
-        if (ais instanceof JarArchiveInputStream) {
-            metadata.set(CONTENT_TYPE, JAR.toString());
-        } else if (ais instanceof ZipArchiveInputStream) {
-            metadata.set(CONTENT_TYPE, ZIP.toString());
-        } else if (ais instanceof ArArchiveInputStream) {
-            metadata.set(CONTENT_TYPE, AR.toString());
-        } else if (ais instanceof CpioArchiveInputStream) {
-            metadata.set(CONTENT_TYPE, CPIO.toString());
-        } else if (ais instanceof DumpArchiveInputStream) {
-            metadata.set(CONTENT_TYPE, DUMP.toString());
-        } else if (ais instanceof TarArchiveInputStream) {
-            metadata.set(CONTENT_TYPE, TAR.toString());
+        MediaType type = getMediaType(ais);
+        if (!type.equals(MediaType.OCTET_STREAM)) {
+            metadata.set(CONTENT_TYPE, type.toString());
         }
 
         // Use the delegate parser to parse the contained document
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/pkg/ZipContainerDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/pkg/ZipContainerDetector.java
index 8d8190c2b..a488ca171 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/pkg/ZipContainerDetector.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/pkg/ZipContainerDetector.java
@@ -16,12 +16,20 @@
  */
 package org.apache.tika.parser.pkg;
 
+import java.io.ByteArrayInputStream;
 import java.io.IOException;
 import java.io.InputStream;
 import java.util.regex.Pattern;
 
+import org.apache.commons.compress.archivers.ArchiveException;
+import org.apache.commons.compress.archivers.ArchiveInputStream;
+import org.apache.commons.compress.archivers.ArchiveStreamFactory;
+import org.apache.commons.compress.archivers.tar.TarArchiveInputStream;
 import org.apache.commons.compress.archivers.zip.ZipArchiveEntry;
 import org.apache.commons.compress.archivers.zip.ZipFile;
+import org.apache.commons.compress.compressors.CompressorException;
+import org.apache.commons.compress.compressors.CompressorInputStream;
+import org.apache.commons.compress.compressors.CompressorStreamFactory;
 import org.apache.poi.extractor.ExtractorFactory;
 import org.apache.poi.openxml4j.exceptions.InvalidFormatException;
 import org.apache.poi.openxml4j.opc.OPCPackage;
@@ -29,7 +37,9 @@ import org.apache.poi.openxml4j.opc.PackageAccess;
 import org.apache.poi.openxml4j.opc.PackagePart;
 import org.apache.poi.openxml4j.opc.PackageRelationshipCollection;
 import org.apache.tika.detect.Detector;
+import org.apache.tika.exception.TikaException;
 import org.apache.tika.io.IOUtils;
+import org.apache.tika.io.TemporaryResources;
 import org.apache.tika.io.TikaInputStream;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.mime.MediaType;
@@ -37,8 +47,8 @@ import org.apache.tika.parser.iwork.IWorkPackageParser;
 import org.apache.tika.parser.iwork.IWorkPackageParser.IWORKDocumentType;
 
 /**
- * A detector that works on a Zip document
- *  to figure out exactly what the file is
+ * A detector that works on Zip documents and other archive and compression
+ * formats to figure out exactly what the file is.
  */
 public class ZipContainerDetector implements Detector {
     private static final Pattern MACRO_TEMPLATE_PATTERN = Pattern.compile("macroenabledtemplate$", Pattern.CASE_INSENSITIVE);
@@ -53,47 +63,98 @@ public class ZipContainerDetector implements Detector {
             return MediaType.OCTET_STREAM;
         }
 
-        // Check if the document starts with the Zip header
-        input.mark(4);
+        TemporaryResources tmp = new TemporaryResources();
         try {
-            if (input.read() != 'P' || input.read() != 'K'
-                    || input.read() != 3 || input.read() != 4) {
-                return MediaType.OCTET_STREAM;
+            TikaInputStream tis = TikaInputStream.get(input, tmp);
+
+            byte[] prefix = new byte[1024]; // enough for all known formats
+            int length = tis.peek(prefix);
+
+            MediaType type = detectArchiveFormat(prefix, length);
+            if (PackageParser.isZipArchive(type)
+                    && TikaInputStream.isTikaInputStream(input)) {
+                return detectZipFormat(tis);
+            } else if (!type.equals(MediaType.OCTET_STREAM)) {
+                return type;
+            } else {
+                return detectCompressorFormat(prefix, length);
             }
         } finally {
-            input.reset();
+            try {
+                tmp.dispose();
+            } catch (TikaException e) {
+                // ignore
+            }
         }
+    }
 
-        // We can only detect the exact type when given a TikaInputStream
-        TikaInputStream tis = TikaInputStream.cast(input);
-        if (tis != null) {
+    private static MediaType detectCompressorFormat(byte[] prefix, int length) {
+        try {
+            CompressorStreamFactory factory = new CompressorStreamFactory();
+            CompressorInputStream cis = factory.createCompressorInputStream(
+                    new ByteArrayInputStream(prefix, 0, length));
             try {
-                ZipFile zip = new ZipFile(tis.getFile());
+                return CompressorParser.getMediaType(cis);
+            } finally {
+                IOUtils.closeQuietly(cis);
+            }
+        } catch (CompressorException e) {
+            return MediaType.OCTET_STREAM;
+        }
+    }
+
+    private static MediaType detectArchiveFormat(byte[] prefix, int length) {
+        try {
+            ArchiveStreamFactory factory = new ArchiveStreamFactory();
+            ArchiveInputStream ais = factory.createArchiveInputStream(
+                    new ByteArrayInputStream(prefix, 0, length));
+            try {
+                if ((ais instanceof TarArchiveInputStream)
+                        && !TarArchiveInputStream.matches(prefix, length)) {
+                    // ArchiveStreamFactory is too relaxed, see COMPRESS-117
+                    return MediaType.OCTET_STREAM;
+                } else {
+                    return PackageParser.getMediaType(ais);
+                }
+            } finally {
+                IOUtils.closeQuietly(ais);
+            }
+        } catch (ArchiveException e) {
+            return MediaType.OCTET_STREAM;
+        }
+    }
+
+    private static MediaType detectZipFormat(TikaInputStream tis) {
+        try {
+            ZipFile zip = new ZipFile(tis.getFile()); // TODO: hasFile()?
+            try {
+                MediaType type = detectOpenDocument(zip);
+                if (type == null) {
+                    type = detectOfficeOpenXML(zip, tis);
+                }
+                if (type == null) {
+                    type = detectIWork(zip);
+                }
+                if (type == null) {
+                    type = detectJar(zip);
+                }
+                if (type != null) {
+                    return type;
+                }
+            } finally {
+                // TODO: shouldn't we record the open
+                // container so it can be later
+                // reused...?
+                // tis.setOpenContainer(zip);
                 try {
-                    MediaType type = detectOpenDocument(zip);
-                    if (type == null) {
-                        type = detectOfficeOpenXML(zip, tis);
-                    }
-                    if (type == null) {
-                        type = detectIWork(zip);
-                    }
-                    if (type == null) {
-                        type = detectJar(zip); 
-                    }
-                    if (type != null) {
-                        return type;
-                    }
-                } finally {
-                    // TODO: shouldn't we record the open
-                    // container so it can be later
-                    // reused...?
-                    // tis.setOpenContainer(zip);
                     zip.close();
+                } catch (IOException e) {
+                    // ignore
                 }
-            } catch (IOException ignore) {
             }
+        } catch (IOException e) {
+            // ignore
         }
-
         // Fallback: it's still a zip file, we just don't know what kind of one
         return MediaType.APPLICATION_ZIP;
     }

Commit:
689a717dbcf29f5d2b9804b7ebff6162bc3ec288
Jukka Zitting
jukka@apache.org
2012-06-29 19:28:25 +0000
TIKA-932: Upgrade to Commons Compress 1.4.1
diff --git a/CHANGES.txt b/CHANGES.txt
index 7a5844e83..5c18fd2e5 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -24,6 +24,11 @@ Release 1.2 - Current Development
     are now extracted in Numbers documents (TIKA-924).  Content added
     to master slides is also extracted (TIKA-923).
 
+  * Archive and compression formats: The Commons Compress dependency was
+    upgraded from 1.3 to 1.4.1. With this change Tika can now parse also
+    Unix dump archives and documents compressed using the XZ and Pack200
+    compression formats.
+
 Release 1.1 - 3/7/2012
 ---------------------------------
 
diff --git a/tika-core/src/main/java/org/apache/tika/mime/MediaType.java b/tika-core/src/main/java/org/apache/tika/mime/MediaType.java
index b1116e7eb..27c5e9ef8 100644
--- a/tika-core/src/main/java/org/apache/tika/mime/MediaType.java
+++ b/tika-core/src/main/java/org/apache/tika/mime/MediaType.java
@@ -19,8 +19,10 @@ package org.apache.tika.mime;
 import java.io.Serializable;
 import java.util.Collections;
 import java.util.HashMap;
+import java.util.HashSet;
 import java.util.Locale;
 import java.util.Map;
+import java.util.Set;
 import java.util.SortedMap;
 import java.util.TreeMap;
 import java.util.regex.Matcher;
@@ -94,6 +96,43 @@ public final class MediaType implements Comparable<MediaType>, Serializable {
         return MediaType.parse("video/" + type);
     }
 
+    /**
+     * Convenience method that returns an unmodifiable set that contains
+     * all the given media types.
+     *
+     * @since Apache Tika 1.2
+     * @param types media types
+     * @return unmodifiable set of the given types
+     */
+    public static Set<MediaType> set(MediaType... types) {
+        Set<MediaType> set = new HashSet<MediaType>();
+        for (MediaType type : types) {
+            if (type != null) {
+                set.add(type);
+            }
+        }
+        return Collections.unmodifiableSet(set);
+    }
+
+    /**
+     * Convenience method that parses the given media type strings and
+     * returns an unmodifiable set that contains all the parsed types.
+     *
+     * @since Apache Tika 1.2
+     * @param types media type strings
+     * @return unmodifiable set of the parsed types
+     */
+    public static Set<MediaType> set(String... types) {
+        Set<MediaType> set = new HashSet<MediaType>();
+        for (String type : types) {
+            MediaType mt = parse(type);
+            if (mt != null) {
+                set.add(mt);
+            }
+        }
+        return Collections.unmodifiableSet(set);
+    }
+
     /**
      * Parses the given string to a media type. The string is expected
      * to be of the form "type/subtype(; parameter=...)*" as defined in
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index fe7db7ba1..059327e7b 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -176,6 +176,7 @@
     <sub-class-of type="application/zip"/>
     <glob pattern="*.jar"/>
   </mime-type>
+
   <mime-type type="application/vnd.android.package-archive">
     <sub-class-of type="application/java-archive"/>
     <glob pattern="*.apk"/>
@@ -189,6 +190,8 @@
     <glob pattern="*.war"/>
   </mime-type>
 
+  <mime-type type="application/x-tika-unix-dump"/>
+
   <mime-type type="application/java-serialized-object">
     <glob pattern="*.ser"/>
   </mime-type>
@@ -2651,6 +2654,10 @@
     <glob pattern="*.jnlp"/>
   </mime-type>
 
+  <mime-type type="application/x-java-pack200">
+    <glob pattern="*.pack"/>
+  </mime-type>
+
   <mime-type type="application/x-kdelnk">
     <magic priority="50">
       <match value="[KDE\ Desktop\ Entry]" type="string" offset="0"/>
@@ -3031,6 +3038,13 @@
     <glob pattern="*.xpi"/>
   </mime-type>
 
+  <mime-type type="application/x-xz">
+    <glob pattern="*.xz"/>
+    <magic priority="50">
+      <match value="\3757zXZ\000" type="string" offset="0"/>
+    </magic>
+  </mime-type>
+
   <mime-type type="application/x-zoo">
     <magic priority="50">
       <match value="0xfdc4a7dc" type="little32" offset="20"/>
diff --git a/tika-parsers/pom.xml b/tika-parsers/pom.xml
index 3975588db..e64aff363 100644
--- a/tika-parsers/pom.xml
+++ b/tika-parsers/pom.xml
@@ -90,7 +90,7 @@
     <dependency>
       <groupId>org.apache.commons</groupId>
       <artifactId>commons-compress</artifactId>
-      <version>1.3</version>
+      <version>1.4.1</version>
     </dependency>
     <dependency>
       <groupId>commons-codec</groupId>
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/pkg/CompressorParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/pkg/CompressorParser.java
new file mode 100644
index 000000000..85af34308
--- /dev/null
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/pkg/CompressorParser.java
@@ -0,0 +1,136 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.parser.pkg;
+
+import static org.apache.tika.metadata.HttpHeaders.CONTENT_TYPE;
+
+import java.io.BufferedInputStream;
+import java.io.IOException;
+import java.io.InputStream;
+import java.util.Set;
+
+import org.apache.commons.compress.compressors.CompressorException;
+import org.apache.commons.compress.compressors.CompressorInputStream;
+import org.apache.commons.compress.compressors.CompressorStreamFactory;
+import org.apache.commons.compress.compressors.bzip2.BZip2CompressorInputStream;
+import org.apache.commons.compress.compressors.gzip.GzipCompressorInputStream;
+import org.apache.commons.compress.compressors.gzip.GzipUtils;
+import org.apache.commons.compress.compressors.pack200.Pack200CompressorInputStream;
+import org.apache.commons.compress.compressors.xz.XZCompressorInputStream;
+import org.apache.tika.exception.TikaException;
+import org.apache.tika.extractor.EmbeddedDocumentExtractor;
+import org.apache.tika.extractor.ParsingEmbeddedDocumentExtractor;
+import org.apache.tika.io.CloseShieldInputStream;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.mime.MediaType;
+import org.apache.tika.parser.AbstractParser;
+import org.apache.tika.parser.ParseContext;
+import org.apache.tika.sax.XHTMLContentHandler;
+import org.xml.sax.ContentHandler;
+import org.xml.sax.SAXException;
+
+/**
+ * Parser for various compression formats.
+ */
+public class CompressorParser extends AbstractParser {
+
+    /** Serial version UID */
+    private static final long serialVersionUID = 2793565792967222459L;
+
+    private static final MediaType BZIP = MediaType.application("x-bzip");
+    private static final MediaType BZIP2 = MediaType.application("x-bzip2");
+    private static final MediaType GZIP = MediaType.application("x-gzip");
+    private static final MediaType XZ = MediaType.application("x-xz");
+    private static final MediaType PACK = MediaType.application("application/x-java-pack200");
+
+    private static final Set<MediaType> SUPPORTED_TYPES =
+            MediaType.set(BZIP, BZIP2, GZIP, XZ, PACK);
+
+    public Set<MediaType> getSupportedTypes(ParseContext context) {
+        return SUPPORTED_TYPES;
+    }
+
+    public void parse(
+            InputStream stream, ContentHandler handler,
+            Metadata metadata, ParseContext context)
+            throws IOException, SAXException, TikaException {
+        // At the end we want to close the compression stream to release
+        // any associated resources, but the underlying document stream
+        // should not be closed
+        stream = new CloseShieldInputStream(stream);
+
+        // Ensure that the stream supports the mark feature
+        stream = new BufferedInputStream(stream);
+
+        CompressorInputStream cis;
+        try {
+            CompressorStreamFactory factory = new CompressorStreamFactory();
+            cis = factory.createCompressorInputStream(stream);
+        } catch (CompressorException e) {
+            throw new TikaException("Unable to uncompress document stream", e);
+        }
+
+        if (cis instanceof BZip2CompressorInputStream) {
+            metadata.set(CONTENT_TYPE, BZIP2.toString());
+        } else if (cis instanceof GzipCompressorInputStream) {
+            metadata.set(CONTENT_TYPE, GZIP.toString());
+        } else if (cis instanceof XZCompressorInputStream) {
+            metadata.set(CONTENT_TYPE, XZ.toString());
+        } else if (cis instanceof Pack200CompressorInputStream) {
+            metadata.set(CONTENT_TYPE, PACK.toString());
+        }
+
+        XHTMLContentHandler xhtml = new XHTMLContentHandler(handler, metadata);
+        xhtml.startDocument();
+
+        try {
+            Metadata entrydata = new Metadata();
+            String name = metadata.get(Metadata.RESOURCE_NAME_KEY);
+            if (name != null) {
+                if (name.endsWith(".tbz")) {
+                    name = name.substring(0, name.length() - 4) + ".tar";
+                } else if (name.endsWith(".tbz2")) {
+                    name = name.substring(0, name.length() - 5) + ".tar";
+                } else if (name.endsWith(".bz")) {
+                    name = name.substring(0, name.length() - 3);
+                } else if (name.endsWith(".bz2")) {
+                    name = name.substring(0, name.length() - 4);
+                } else if (name.endsWith(".xz")) {
+                    name = name.substring(0, name.length() - 3);
+                } else if (name.endsWith(".pack")) {
+                    name = name.substring(0, name.length() - 5);
+                } else if (name.length() > 0) {
+                    name = GzipUtils.getUncompressedFilename(name);
+                }
+                entrydata.set(Metadata.RESOURCE_NAME_KEY, name);
+            }
+
+            // Use the delegate parser to parse the compressed document
+            EmbeddedDocumentExtractor extractor = context.get(
+                    EmbeddedDocumentExtractor.class,
+                    new ParsingEmbeddedDocumentExtractor(context));
+            if (extractor.shouldParseEmbedded(entrydata)) {
+                extractor.parseEmbedded(cis, xhtml, entrydata, true);
+            }
+        } finally {
+            cis.close();
+        }
+
+        xhtml.endDocument();
+    }
+
+}
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/pkg/PackageExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/pkg/PackageExtractor.java
deleted file mode 100644
index f84a0f4b1..000000000
--- a/tika-parsers/src/main/java/org/apache/tika/parser/pkg/PackageExtractor.java
+++ /dev/null
@@ -1,191 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.tika.parser.pkg;
-
-import java.io.BufferedInputStream;
-import java.io.IOException;
-import java.io.InputStream;
-import java.util.zip.GZIPInputStream;
-
-import org.apache.commons.compress.archivers.ArchiveEntry;
-import org.apache.commons.compress.archivers.ArchiveInputStream;
-import org.apache.commons.compress.archivers.ar.ArArchiveInputStream;
-import org.apache.commons.compress.archivers.cpio.CpioArchiveInputStream;
-import org.apache.commons.compress.archivers.tar.TarArchiveInputStream;
-import org.apache.commons.compress.archivers.zip.ZipArchiveInputStream;
-import org.apache.commons.compress.compressors.bzip2.BZip2CompressorInputStream;
-import org.apache.commons.compress.compressors.gzip.GzipUtils;
-import org.apache.tika.exception.TikaException;
-import org.apache.tika.extractor.EmbeddedDocumentExtractor;
-import org.apache.tika.extractor.ParsingEmbeddedDocumentExtractor;
-import org.apache.tika.io.CloseShieldInputStream;
-import org.apache.tika.io.TemporaryResources;
-import org.apache.tika.io.TikaInputStream;
-import org.apache.tika.metadata.Metadata;
-import org.apache.tika.parser.ParseContext;
-import org.apache.tika.sax.XHTMLContentHandler;
-import org.xml.sax.ContentHandler;
-import org.xml.sax.SAXException;
-
-/**
- * Extractor for packaging and compression formats.
- */
-class PackageExtractor {
-
-    private final ContentHandler handler;
-
-    private final Metadata metadata;
-
-    private final EmbeddedDocumentExtractor extractor;
-
-    public PackageExtractor(
-            ContentHandler handler, Metadata metadata, ParseContext context) {
-        this.handler = handler;
-        this.metadata = metadata;
-
-        EmbeddedDocumentExtractor ex = context.get(EmbeddedDocumentExtractor.class);
-
-        if (ex==null) {
-            this.extractor = new ParsingEmbeddedDocumentExtractor(context);
-        } else {
-            this.extractor = ex;
-        }
-
-    }
-
-    public void parse(InputStream stream)
-            throws IOException, SAXException, TikaException {
-        XHTMLContentHandler xhtml = new XHTMLContentHandler(handler, metadata);
-        xhtml.startDocument();
-
-        // At the end we want to close the package/compression stream to
-        // release any associated resources, but the underlying document
-        // stream should not be closed
-        stream = new CloseShieldInputStream(stream);
-
-        // Capture two bytes to determine the packaging/compression format
-        if (!stream.markSupported()) {
-            stream = new BufferedInputStream(stream);
-        }
-        stream.mark(2);
-        int a = stream.read();
-        int b = stream.read();
-        stream.reset();
-
-        // Select decompression or unpacking mechanism based on the two bytes
-        if (a == 'B' && b == 'Z') {
-            metadata.set(Metadata.CONTENT_TYPE, "application/x-bzip");
-            decompress(new BZip2CompressorInputStream(stream), xhtml);
-        } else if (a == 0x1f && b == 0x8b) {
-            metadata.set(Metadata.CONTENT_TYPE, "application/x-gzip");
-            decompress(new GZIPInputStream(stream), xhtml);
-        } else if (a == 'P' && b == 'K') {
-            metadata.set(Metadata.CONTENT_TYPE, "application/zip");
-            unpack(new ZipArchiveInputStream(stream), xhtml);
-        } else if ((a == '0' && b == '7')
-                || (a == 0x71 && b == 0xc7)
-                || (a == 0xc7 && b == 0x71)) {
-            metadata.set(Metadata.CONTENT_TYPE, "application/x-cpio");
-            unpack(new CpioArchiveInputStream(stream), xhtml);
-        } else if ((a == '=' || a == '!') && (b == '<')) {
-            metadata.set(Metadata.CONTENT_TYPE, "application/x-archive");
-            unpack(new ArArchiveInputStream(stream), xhtml);
-        } else {
-            metadata.set(Metadata.CONTENT_TYPE, "application/x-tar");
-            unpack(new TarArchiveInputStream(stream), xhtml);
-        }
-
-        xhtml.endDocument();
-    }
-
-    private void decompress(InputStream stream, XHTMLContentHandler xhtml)
-            throws IOException, SAXException, TikaException {
-        try {
-            Metadata entrydata = new Metadata();
-            String name = metadata.get(Metadata.RESOURCE_NAME_KEY);
-            if (name != null) {
-                if (name.endsWith(".tbz")) {
-                    name = name.substring(0, name.length() - 4) + ".tar";
-                } else if (name.endsWith(".tbz2")) {
-                    name = name.substring(0, name.length() - 5) + ".tar";
-                } else if (name.endsWith(".bz")) {
-                    name = name.substring(0, name.length() - 3);
-                } else if (name.endsWith(".bz2")) {
-                    name = name.substring(0, name.length() - 4);
-                } else if (name.length() > 0) {
-                    name = GzipUtils.getUncompressedFilename(name);
-                }
-                entrydata.set(Metadata.RESOURCE_NAME_KEY, name);
-            }
-
-            // Use the delegate parser to parse the compressed document
-            if (extractor.shouldParseEmbedded(entrydata)) {
-                extractor.parseEmbedded(stream, xhtml, entrydata, true);
-            }
-        } finally {
-            stream.close();
-        }
-    }
-
-    /**
-     * Parses the given stream as a package of multiple underlying files.
-     * The package entries are parsed using the delegate parser instance.
-     * It is not an error if the entry can not be parsed, in that case
-     * just the entry name (if given) is emitted.
-     *
-     * @param archive package stream
-     * @param xhtml content handler
-     * @throws IOException if an IO error occurs
-     * @throws SAXException if a SAX error occurs
-     * @throws TikaException if another error occurs
-     */
-    public void unpack(ArchiveInputStream archive, XHTMLContentHandler xhtml)
-            throws IOException, SAXException, TikaException {
-        try {
-            ArchiveEntry entry = archive.getNextEntry();
-            while (entry != null) {
-                if (!entry.isDirectory()) {
-                    String name = entry.getName();
-
-                    if (archive.canReadEntryData(entry)) {
-                        Metadata entrydata = new Metadata();
-                        if (name != null && name.length() > 0) {
-                            entrydata.set(Metadata.RESOURCE_NAME_KEY, name);
-                        }
-                        if (extractor.shouldParseEmbedded(entrydata)) {
-                            // For detectors to work, we need a mark/reset supporting
-                            //  InputStream, which ArchiveInputStream isn't, so wrap
-                            TemporaryResources tmp = new TemporaryResources();
-                            try {
-                                TikaInputStream stream = TikaInputStream.get(archive, tmp);
-                                extractor.parseEmbedded(stream, xhtml, entrydata, true);
-                            } finally {
-                                tmp.dispose();
-                            }
-                        }
-                    } else if (name != null && name.length() > 0) {
-                        xhtml.element("p", name);
-                    }
-                }
-                entry = archive.getNextEntry();
-            }
-        } finally {
-            archive.close();
-        }
-    }
-
-}
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/pkg/PackageParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/pkg/PackageParser.java
index 9ac447fab..25af330af 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/pkg/PackageParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/pkg/PackageParser.java
@@ -16,42 +16,57 @@
  */
 package org.apache.tika.parser.pkg;
 
+import static org.apache.tika.metadata.HttpHeaders.CONTENT_TYPE;
+
+import java.io.BufferedInputStream;
 import java.io.IOException;
 import java.io.InputStream;
-import java.util.Arrays;
-import java.util.Collections;
-import java.util.HashSet;
 import java.util.Set;
 
+import org.apache.commons.compress.archivers.ArchiveEntry;
+import org.apache.commons.compress.archivers.ArchiveException;
+import org.apache.commons.compress.archivers.ArchiveInputStream;
+import org.apache.commons.compress.archivers.ArchiveStreamFactory;
+import org.apache.commons.compress.archivers.ar.ArArchiveInputStream;
+import org.apache.commons.compress.archivers.cpio.CpioArchiveInputStream;
+import org.apache.commons.compress.archivers.dump.DumpArchiveInputStream;
+import org.apache.commons.compress.archivers.jar.JarArchiveInputStream;
+import org.apache.commons.compress.archivers.tar.TarArchiveInputStream;
+import org.apache.commons.compress.archivers.zip.ZipArchiveInputStream;
 import org.apache.tika.exception.TikaException;
+import org.apache.tika.extractor.EmbeddedDocumentExtractor;
+import org.apache.tika.extractor.ParsingEmbeddedDocumentExtractor;
+import org.apache.tika.io.CloseShieldInputStream;
+import org.apache.tika.io.TemporaryResources;
+import org.apache.tika.io.TikaInputStream;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.parser.AbstractParser;
 import org.apache.tika.parser.ParseContext;
+import org.apache.tika.sax.XHTMLContentHandler;
 import org.xml.sax.ContentHandler;
 import org.xml.sax.SAXException;
 
 /**
- * Parser for various packaging and compression formats. Package entries will
- * be written to the XHTML event stream as &lt;div class="package-entry"&gt;
- * elements that contain the (optional) entry name as a &lt;h1&gt; element
- * and the full structured body content of the parsed entry.
+ * Parser for various packaging formats. Package entries will be written to
+ * the XHTML event stream as &lt;div class="package-entry"&gt; elements that
+ * contain the (optional) entry name as a &lt;h1&gt; element and the full
+ * structured body content of the parsed entry.
  */
 public class PackageParser extends AbstractParser {
 
     /** Serial version UID */
     private static final long serialVersionUID = -5331043266963888708L;
 
+    private static final MediaType ZIP = MediaType.APPLICATION_ZIP;
+    private static final MediaType JAR = MediaType.application("java-archive");
+    private static final MediaType AR = MediaType.application("x-archive");
+    private static final MediaType CPIO = MediaType.application("x-cpio");
+    private static final MediaType DUMP = MediaType.application("x-tika-unix-dump");
+    private static final MediaType TAR = MediaType.application("x-tar");
+
     private static final Set<MediaType> SUPPORTED_TYPES =
-        Collections.unmodifiableSet(new HashSet<MediaType>(Arrays.asList(
-                MediaType.application("x-archive"),
-                MediaType.application("x-bzip"),
-                MediaType.application("x-bzip2"),
-                MediaType.application("x-cpio"),
-                MediaType.application("x-gtar"),
-                MediaType.application("x-gzip"),
-                MediaType.application("x-tar"),
-                MediaType.application("zip"))));
+            MediaType.set(ZIP, JAR, AR, CPIO, DUMP, TAR);
 
     public Set<MediaType> getSupportedTypes(ParseContext context) {
         return SUPPORTED_TYPES;
@@ -61,7 +76,83 @@ public class PackageParser extends AbstractParser {
             InputStream stream, ContentHandler handler,
             Metadata metadata, ParseContext context)
             throws IOException, SAXException, TikaException {
-        new PackageExtractor(handler, metadata, context).parse(stream);
+        // At the end we want to close the archive stream to release
+        // any associated resources, but the underlying document stream
+        // should not be closed
+        stream = new CloseShieldInputStream(stream);
+
+        // Ensure that the stream supports the mark feature
+        stream = new BufferedInputStream(stream);
+
+        ArchiveInputStream ais;
+        try {
+            ArchiveStreamFactory factory = new ArchiveStreamFactory();
+            ais = factory.createArchiveInputStream(stream);
+        } catch (ArchiveException e) {
+            throw new TikaException("Unable to unpack document stream", e);
+        }
+
+        if (ais instanceof JarArchiveInputStream) {
+            metadata.set(CONTENT_TYPE, JAR.toString());
+        } else if (ais instanceof ZipArchiveInputStream) {
+            metadata.set(CONTENT_TYPE, ZIP.toString());
+        } else if (ais instanceof ArArchiveInputStream) {
+            metadata.set(CONTENT_TYPE, AR.toString());
+        } else if (ais instanceof CpioArchiveInputStream) {
+            metadata.set(CONTENT_TYPE, CPIO.toString());
+        } else if (ais instanceof DumpArchiveInputStream) {
+            metadata.set(CONTENT_TYPE, DUMP.toString());
+        } else if (ais instanceof TarArchiveInputStream) {
+            metadata.set(CONTENT_TYPE, TAR.toString());
+        }
+
+        // Use the delegate parser to parse the contained document
+        EmbeddedDocumentExtractor extractor = context.get(
+                EmbeddedDocumentExtractor.class,
+                new ParsingEmbeddedDocumentExtractor(context));
+
+        XHTMLContentHandler xhtml = new XHTMLContentHandler(handler, metadata);
+        xhtml.startDocument();
+
+        try {
+            ArchiveEntry entry = ais.getNextEntry();
+            while (entry != null) {
+                if (!entry.isDirectory()) {
+                    parseEntry(ais, entry, extractor, xhtml);
+                }
+                entry = ais.getNextEntry();
+            }
+        } finally {
+            ais.close();
+        }
+
+        xhtml.endDocument();
+    }
+
+    private void parseEntry(
+            ArchiveInputStream archive, ArchiveEntry entry,
+            EmbeddedDocumentExtractor extractor, XHTMLContentHandler xhtml)
+            throws SAXException, IOException, TikaException {
+        String name = entry.getName();
+        if (archive.canReadEntryData(entry)) {
+            Metadata entrydata = new Metadata();
+            if (name != null && name.length() > 0) {
+                entrydata.set(Metadata.RESOURCE_NAME_KEY, name);
+            }
+            if (extractor.shouldParseEmbedded(entrydata)) {
+                // For detectors to work, we need a mark/reset supporting
+                // InputStream, which ArchiveInputStream isn't, so wrap
+                TemporaryResources tmp = new TemporaryResources();
+                try {
+                    TikaInputStream tis = TikaInputStream.get(archive, tmp);
+                    extractor.parseEmbedded(tis, xhtml, entrydata, true);
+                } finally {
+                    tmp.dispose();
+                }
+            }
+        } else if (name != null && name.length() > 0) {
+            xhtml.element("p", name);
+        }
     }
 
 }
diff --git a/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.parser.Parser b/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.parser.Parser
index 284751525..fcdf75b22 100644
--- a/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.parser.Parser
+++ b/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.parser.Parser
@@ -40,6 +40,7 @@ org.apache.tika.parser.hdf.HDFParser
 org.apache.tika.parser.netcdf.NetCDFParser
 org.apache.tika.parser.odf.OpenDocumentParser
 org.apache.tika.parser.pdf.PDFParser
+org.apache.tika.parser.pkg.CompressorParser
 org.apache.tika.parser.pkg.PackageParser
 org.apache.tika.parser.rtf.RTFParser
 org.apache.tika.parser.txt.TXTParser
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/pkg/Bzip2ParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/pkg/Bzip2ParserTest.java
index 6994e7868..0f84edd88 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/pkg/Bzip2ParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/pkg/Bzip2ParserTest.java
@@ -42,7 +42,7 @@ public class Bzip2ParserTest extends AbstractPkgTest {
             stream.close();
         }
 
-        assertEquals("application/x-bzip", metadata.get(Metadata.CONTENT_TYPE));
+        assertEquals("application/x-bzip2", metadata.get(Metadata.CONTENT_TYPE));
         String content = handler.toString();
         assertTrue(content.contains("test-documents/testEXCEL.xls"));
         assertTrue(content.contains("Sample Excel Worksheet"));

Commit:
12c4ad280f267f8cdae8d93086f485729c0d78b7
Jukka Zitting
jukka@apache.org
2012-06-29 16:19:58 +0000
TIKA-935: TikaException thrown when trying to parse archive (*.ar) files
diff --git a/.gitattributes b/.gitattributes
new file mode 100644
index 000000000..4244bb0a5
--- /dev/null
+++ b/.gitattributes
@@ -0,0 +1 @@
+tika-parsers/src/test/resources/test-documents/testARofText.ar eol=lf

Commit:
46f742fa5a567ebf5fc07d428de43ea97eefedfb
Nick Burch
nick@apache.org
2012-06-21 17:19:40 +0000
TIKA-940 Mime Magic and unit test for 7zip
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 36253c46d..fe7db7ba1 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -3117,6 +3117,18 @@
     <glob pattern="*.zip"/>
   </mime-type>
 
+  <mime-type type="application/x-7z-compressed">
+    <acronym>7zip</acronym>
+    <_comment>7-zip archive</_comment>
+    <magic priority="50">
+      <!-- Magic: '7', 'z', 0xBC, 0xAF, 0x27, 0x1C -->
+      <match value="7z" type="string" offset="0:1" >
+        <match value="0xBCAF271C" type="string" offset="2:5" />
+      </match>
+    </magic>
+    <glob pattern="*.7z" />
+  </mime-type>
+
   <mime-type type="audio/32kadpcm"/>
   <mime-type type="audio/3gpp"/>
   <mime-type type="audio/3gpp2"/>
diff --git a/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java b/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
index 81c9eb455..06827ea14 100644
--- a/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
+++ b/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
@@ -27,9 +27,7 @@ import junit.framework.TestCase;
 
 import org.apache.tika.Tika;
 import org.apache.tika.config.TikaConfig;
-import org.apache.tika.detect.DefaultDetector;
 import org.apache.tika.metadata.Metadata;
-import org.apache.tika.parser.microsoft.POIFSContainerDetector;
 
 /**
  * 
@@ -579,6 +577,12 @@ public class TestMimeTypes extends TestCase {
         assertType("application/x-font-ttf", "testTrueType.ttf");
     }
     
+    public void test7ZipDetection() throws Exception {
+       assertTypeByName("application/x-7z-compressed","test-documents.7z");
+       assertTypeByData("application/x-7z-compressed","test-documents.7z");
+       assertTypeByNameAndData("application/x-7z-compressed", "test-documents.7z");
+   }
+
     public void testWebArchiveDetection() throws Exception {
         assertTypeByName("application/x-webarchive","x.webarchive");
         assertTypeByData("application/x-bplist","testWEBARCHIVE.webarchive");

Commit:
e58890a90c1cf3cce400f1457ffad0b0c4bb908f
Nick Burch
nick@apache.org
2012-06-21 17:14:18 +0000
TIKA-940 Sample 7zip (7z) file, based on the zip example
diff --git a/tika-parsers/src/test/resources/test-documents/test-documents.7z b/tika-parsers/src/test/resources/test-documents/test-documents.7z
new file mode 100644
index 000000000..94d62d356
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/test-documents.7z differ

Commit:
ffe67b3852ac83b18543b47a84ec2bd561141398
Nick Burch
nick@apache.org
2012-06-13 15:40:02 +0000
Fix the case of the .ar files in the unit tests (TIKA-935) - case must match that stored in SVN or tests will fail on case-sensitive file systems
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/pkg/ArParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/pkg/ArParserTest.java
index eff81f2bc..389378152 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/pkg/ArParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/pkg/ArParserTest.java
@@ -33,7 +33,7 @@ public class ArParserTest extends AbstractPkgTest {
 		Metadata metadata = new Metadata();
 
 		InputStream stream = ArParserTest.class
-				.getResourceAsStream("/test-documents/testAROfText.ar");
+				.getResourceAsStream("/test-documents/testARofText.ar");
 		try {
 			parser.parse(stream, handler, metadata, recursingContext);
 		} finally {
@@ -48,7 +48,7 @@ public class ArParserTest extends AbstractPkgTest {
 		assertTrue(content.contains("http://www.apache.org"));
 
 		stream = ArParserTest.class
-				.getResourceAsStream("/test-documents/testAROfSND.ar");
+				.getResourceAsStream("/test-documents/testARofSND.ar");
 		try {
 			parser.parse(stream, handler, metadata, recursingContext);
 		} finally {
@@ -71,7 +71,7 @@ public class ArParserTest extends AbstractPkgTest {
 		Metadata metadata = new Metadata();
 
 		InputStream stream = ArParserTest.class
-				.getResourceAsStream("/test-documents/testAROfText.ar");
+				.getResourceAsStream("/test-documents/testARofText.ar");
 		try {
 			parser.parse(stream, handler, metadata, trackingContext);
 		} finally {
@@ -89,7 +89,7 @@ public class ArParserTest extends AbstractPkgTest {
 
 		tracker.reset();
 		stream = ArParserTest.class
-				.getResourceAsStream("/test-documents/testAROfSND.ar");
+				.getResourceAsStream("/test-documents/testARofSND.ar");
 		try {
 			parser.parse(stream, handler, metadata, trackingContext);
 		} finally {

Commit:
6e8f9ea6232844a1bf4625b54deb275f137b7f6f
Nick Burch
nick@apache.org
2012-06-13 15:36:09 +0000
TIKA-939 Another WMV codec to look out for, to specialise an ASF to WMV
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 8302e9c31..36253c46d 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -4547,6 +4547,7 @@
     <glob pattern="*.wmv"/>
     <magic priority="60">
        <match value="Windows Media Video" type="unicodeLE" offset="0:8192" />
+       <match value="VC-1 Advanced Profile" type="unicodeLE" offset="0:8192" />
     </magic>
   </mime-type>
   <mime-type type="video/x-ms-wmx">

Commit:
914cafdbbe3748003cfc766c5d9b99339d08ce79
Chris Mattmann
mattmann@apache.org
2012-05-28 04:18:21 +0000
- fix for TIKA-935 TikaException thrown when trying to parse archive (*.ar) files contributed by Josh Mastarone
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/pkg/PackageExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/pkg/PackageExtractor.java
index 8c9c63885..f84a0f4b1 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/pkg/PackageExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/pkg/PackageExtractor.java
@@ -101,7 +101,7 @@ class PackageExtractor {
                 || (a == 0xc7 && b == 0x71)) {
             metadata.set(Metadata.CONTENT_TYPE, "application/x-cpio");
             unpack(new CpioArchiveInputStream(stream), xhtml);
-        } else if (a == '=' && (b == '<' || b == '!')) {
+        } else if ((a == '=' || a == '!') && (b == '<')) {
             metadata.set(Metadata.CONTENT_TYPE, "application/x-archive");
             unpack(new ArArchiveInputStream(stream), xhtml);
         } else {
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/pkg/ArParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/pkg/ArParserTest.java
new file mode 100644
index 000000000..eff81f2bc
--- /dev/null
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/pkg/ArParserTest.java
@@ -0,0 +1,107 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.parser.pkg;
+
+import java.io.InputStream;
+
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.parser.AutoDetectParser;
+import org.apache.tika.parser.Parser;
+import org.apache.tika.sax.BodyContentHandler;
+import org.xml.sax.ContentHandler;
+
+public class ArParserTest extends AbstractPkgTest {
+	public void testArParsing() throws Exception {
+		Parser parser = new AutoDetectParser();
+
+		ContentHandler handler = new BodyContentHandler();
+		Metadata metadata = new Metadata();
+
+		InputStream stream = ArParserTest.class
+				.getResourceAsStream("/test-documents/testAROfText.ar");
+		try {
+			parser.parse(stream, handler, metadata, recursingContext);
+		} finally {
+			stream.close();
+		}
+
+		assertEquals("application/x-archive",
+				metadata.get(Metadata.CONTENT_TYPE));
+		String content = handler.toString();
+		assertTrue(content.contains("testTXT.txt"));
+		assertTrue(content.contains("Test d'indexation de Txt"));
+		assertTrue(content.contains("http://www.apache.org"));
+
+		stream = ArParserTest.class
+				.getResourceAsStream("/test-documents/testAROfSND.ar");
+		try {
+			parser.parse(stream, handler, metadata, recursingContext);
+		} finally {
+			stream.close();
+		}
+
+		assertEquals("application/x-archive",
+				metadata.get(Metadata.CONTENT_TYPE));
+		content = handler.toString();
+		assertTrue(content.contains("testAU.au"));
+	}
+
+	/**
+	 * Tests that the ParseContext parser is correctly fired for all the
+	 * embedded entries.
+	 */
+	public void testEmbedded() throws Exception {
+		Parser parser = new AutoDetectParser(); // Should auto-detect!
+		ContentHandler handler = new BodyContentHandler();
+		Metadata metadata = new Metadata();
+
+		InputStream stream = ArParserTest.class
+				.getResourceAsStream("/test-documents/testAROfText.ar");
+		try {
+			parser.parse(stream, handler, metadata, trackingContext);
+		} finally {
+			stream.close();
+		}
+
+		assertEquals(1, tracker.filenames.size());
+		assertEquals(1, tracker.mediatypes.size());
+
+		assertEquals("testTXT.txt", tracker.filenames.get(0));
+
+		for (String type : tracker.mediatypes) {
+			assertNull(type);
+		}
+
+		tracker.reset();
+		stream = ArParserTest.class
+				.getResourceAsStream("/test-documents/testAROfSND.ar");
+		try {
+			parser.parse(stream, handler, metadata, trackingContext);
+		} finally {
+			stream.close();
+		}
+
+		assertEquals(1, tracker.filenames.size());
+		assertEquals(1, tracker.mediatypes.size());
+		assertEquals("testAU.au", tracker.filenames.get(0));
+
+		for (String type : tracker.mediatypes) {
+			assertNull(type);
+		}
+	}
+}

Commit:
8fd2a5298a5dbb2272279ea6b01087e9a96237ad
Michael McCandless
mikemccand@apache.org
2012-05-25 18:13:52 +0000
TIKA-923: extract items from Keynote master slides too
diff --git a/CHANGES.txt b/CHANGES.txt
index 50d809fb6..7a5844e83 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -21,7 +21,8 @@ Release 1.2 - Current Development
     yet (TIKA-903).  Text extracted from Keynote text boxes and bullet
     points no longer runs together (TIKA-910). Also extract text for
     Pages documents created in layout mode (TIKA-904).  Table names
-    are now extracted in Numbers documents (TIKA-924).
+    are now extracted in Numbers documents (TIKA-924).  Content added
+    to master slides is also extracted (TIKA-923).
 
 Release 1.1 - 3/7/2012
 ---------------------------------
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/KeynoteContentHandler.java b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/KeynoteContentHandler.java
index b1bc41351..c19394923 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/KeynoteContentHandler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/KeynoteContentHandler.java
@@ -67,6 +67,9 @@ class KeynoteContentHandler extends DefaultHandler {
             inSlide = true;
             numberOfSlides++;
             xhtml.startElement("div");
+        } else if ("key:master-slide".equals(qName)) {
+            inSlide = true;
+            xhtml.startElement("div");
         } else if ("key:title-placeholder".equals(qName) && inSlide) {
             inTitle = true;
             xhtml.startElement("h1");
@@ -117,6 +120,9 @@ class KeynoteContentHandler extends DefaultHandler {
         } else if ("key:slide".equals(qName)) {
             inSlide = false;
             xhtml.endElement("div");
+        } else if ("key:master-slide".equals(qName)) {
+            inSlide = false;
+            xhtml.endElement("div");
         } else if ("key:title-placeholder".equals(qName) && inSlide) {
             inTitle = false;
             xhtml.endElement("h1");
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
index 3ca2510b0..440672cbb 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
@@ -124,6 +124,20 @@ public class IWorkParserTest extends TestCase {
         assertTrue(content.contains("row 1 row 2 row 3"));
     }
 
+    // TIKA-923
+    public void testKeynoteMasterSlideTable() throws Exception {
+        InputStream input = IWorkParserTest.class.getResourceAsStream("/test-documents/testMasterSlideTable.key");
+        Metadata metadata = new Metadata();
+        ContentHandler handler = new BodyContentHandler();
+        iWorkParser.parse(input, handler, metadata, parseContext);
+
+        String content = handler.toString();
+        content = content.replaceAll("\\s+", " ");
+        assertTrue(content.contains("master row 1"));
+        assertTrue(content.contains("master row 2"));
+        assertTrue(content.contains("master row 3"));
+    }
+
     public void testParsePages() throws Exception {
         InputStream input = IWorkParserTest.class.getResourceAsStream("/test-documents/testPages.pages");
         Metadata metadata = new Metadata();
diff --git a/tika-parsers/src/test/resources/test-documents/testMasterSlideTable.key b/tika-parsers/src/test/resources/test-documents/testMasterSlideTable.key
new file mode 100644
index 000000000..26277708a
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testMasterSlideTable.key differ

Commit:
2e6b1bccfd5425f424da9ae8ceca7225a247b3f1
Michael McCandless
mikemccand@apache.org
2012-05-23 10:24:33 +0000
PDFBOX-1320: fix NPE when visiting embedded files
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java
index e535f381a..6940cc73d 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java
@@ -177,25 +177,29 @@ public class PDFParser extends AbstractParser {
                     embeddedExtractor = new ParsingEmbeddedDocumentExtractor(context);
                 }
 
-                for (Map.Entry<String,Object> ent : embeddedFiles.getNames().entrySet()) {
-                    PDComplexFileSpecification spec = (PDComplexFileSpecification) ent.getValue();
-                    PDEmbeddedFile file = spec.getEmbeddedFile();
-
-                    Metadata metadata = new Metadata();
-                    // TODO: other metadata?
-                    metadata.set(Metadata.RESOURCE_NAME_KEY, ent.getKey());
-                    metadata.set(Metadata.CONTENT_TYPE, file.getSubtype());
-                    metadata.set(Metadata.CONTENT_LENGTH, Long.toString(file.getSize()));
-
-                    if (embeddedExtractor.shouldParseEmbedded(metadata)) {
-                        TikaInputStream stream = TikaInputStream.get(file.createInputStream());
-                        try {
-                            embeddedExtractor.parseEmbedded(
-                                    stream,
-                                    new EmbeddedContentHandler(handler),
-                                    metadata, false);
-                        } finally {
-                            stream.close();
+                Map<String,Object> embeddedFileNames = embeddedFiles.getNames();
+
+                if (embeddedFileNames != null) {
+                    for (Map.Entry<String,Object> ent : embeddedFileNames.entrySet()) {
+                        PDComplexFileSpecification spec = (PDComplexFileSpecification) ent.getValue();
+                        PDEmbeddedFile file = spec.getEmbeddedFile();
+
+                        Metadata metadata = new Metadata();
+                        // TODO: other metadata?
+                        metadata.set(Metadata.RESOURCE_NAME_KEY, ent.getKey());
+                        metadata.set(Metadata.CONTENT_TYPE, file.getSubtype());
+                        metadata.set(Metadata.CONTENT_LENGTH, Long.toString(file.getSize()));
+
+                        if (embeddedExtractor.shouldParseEmbedded(metadata)) {
+                            TikaInputStream stream = TikaInputStream.get(file.createInputStream());
+                            try {
+                                embeddedExtractor.parseEmbedded(
+                                                                stream,
+                                                                new EmbeddedContentHandler(handler),
+                                                                metadata, false);
+                            } finally {
+                                stream.close();
+                            }
                         }
                     }
                 }

Commit:
ddf2c2a1be1f3b0b8bd792fd5025f1eb7e6b8d71
Jukka Zitting
jukka@apache.org
2012-05-22 13:16:26 +0000
TIKA-931: Tika's PDFParser fails to parse documents embedded in a PDF Package
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java
index 1d5dc3fd0..e535f381a 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java
@@ -22,6 +22,7 @@ import java.util.Arrays;
 import java.util.Calendar;
 import java.util.Collections;
 import java.util.List;
+import java.util.Map;
 import java.util.Set;
 
 import org.apache.pdfbox.cos.COSArray;
@@ -31,8 +32,15 @@ import org.apache.pdfbox.cos.COSString;
 import org.apache.pdfbox.io.RandomAccess;
 import org.apache.pdfbox.io.RandomAccessFile;
 import org.apache.pdfbox.pdmodel.PDDocument;
+import org.apache.pdfbox.pdmodel.PDDocumentCatalog;
 import org.apache.pdfbox.pdmodel.PDDocumentInformation;
+import org.apache.pdfbox.pdmodel.PDDocumentNameDictionary;
+import org.apache.pdfbox.pdmodel.PDEmbeddedFilesNameTreeNode;
+import org.apache.pdfbox.pdmodel.common.filespecification.PDComplexFileSpecification;
+import org.apache.pdfbox.pdmodel.common.filespecification.PDEmbeddedFile;
 import org.apache.tika.exception.TikaException;
+import org.apache.tika.extractor.EmbeddedDocumentExtractor;
+import org.apache.tika.extractor.ParsingEmbeddedDocumentExtractor;
 import org.apache.tika.io.CloseShieldInputStream;
 import org.apache.tika.io.TemporaryResources;
 import org.apache.tika.io.TikaInputStream;
@@ -44,6 +52,7 @@ import org.apache.tika.mime.MediaType;
 import org.apache.tika.parser.AbstractParser;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.parser.PasswordProvider;
+import org.apache.tika.sax.EmbeddedContentHandler;
 import org.xml.sax.ContentHandler;
 import org.xml.sax.SAXException;
 
@@ -53,7 +62,10 @@ import org.xml.sax.SAXException;
  * This parser can process also encrypted PDF documents if the required
  * password is given as a part of the input metadata associated with a
  * document. If no password is given, then this parser will try decrypting
- * the document using the empty password that's often used with PDFs.
+ * the document using the empty password that's often used with PDFs. If
+ * the PDF contains any embedded documents (for example as part of a PDF
+ * package) then this parser will use the {@link EmbeddedDocumentExtractor}
+ * to handle them.
  */
 public class PDFParser extends AbstractParser {
 
@@ -141,6 +153,8 @@ public class PDFParser extends AbstractParser {
             PDF2XHTML.process(pdfDocument, handler, metadata,
                               extractAnnotationText, enableAutoSpace,
                               suppressDuplicateOverlappingText, sortByPosition);
+
+            extractEmbeddedDocuments(context, pdfDocument, handler);
         } finally {
             if (pdfDocument != null) {
                pdfDocument.close();
@@ -149,6 +163,46 @@ public class PDFParser extends AbstractParser {
         }
     }
 
+    private void extractEmbeddedDocuments(ParseContext context, PDDocument document, ContentHandler handler)
+            throws IOException, SAXException, TikaException {
+        PDDocumentCatalog catalog = document.getDocumentCatalog();
+        PDDocumentNameDictionary names = catalog.getNames();
+        if (names != null) {
+
+            PDEmbeddedFilesNameTreeNode embeddedFiles = names.getEmbeddedFiles();
+            if (embeddedFiles != null) {
+
+                EmbeddedDocumentExtractor embeddedExtractor = context.get(EmbeddedDocumentExtractor.class);
+                if (embeddedExtractor == null) {
+                    embeddedExtractor = new ParsingEmbeddedDocumentExtractor(context);
+                }
+
+                for (Map.Entry<String,Object> ent : embeddedFiles.getNames().entrySet()) {
+                    PDComplexFileSpecification spec = (PDComplexFileSpecification) ent.getValue();
+                    PDEmbeddedFile file = spec.getEmbeddedFile();
+
+                    Metadata metadata = new Metadata();
+                    // TODO: other metadata?
+                    metadata.set(Metadata.RESOURCE_NAME_KEY, ent.getKey());
+                    metadata.set(Metadata.CONTENT_TYPE, file.getSubtype());
+                    metadata.set(Metadata.CONTENT_LENGTH, Long.toString(file.getSize()));
+
+                    if (embeddedExtractor.shouldParseEmbedded(metadata)) {
+                        TikaInputStream stream = TikaInputStream.get(file.createInputStream());
+                        try {
+                            embeddedExtractor.parseEmbedded(
+                                    stream,
+                                    new EmbeddedContentHandler(handler),
+                                    metadata, false);
+                        } finally {
+                            stream.close();
+                        }
+                    }
+                }
+            }
+        }
+    }
+
     private void extractMetadata(PDDocument document, Metadata metadata)
             throws TikaException {
         PDDocumentInformation info = document.getDocumentInformation();
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java
index 8a7f659c4..9ab709649 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java
@@ -288,6 +288,12 @@ public class PDFParserTest extends TikaTest {
                      substringCount("</p>", xml));
     }
 
+    public void testEmbeddedPDFs() throws Exception {
+        String xml = getXML("testPDFPackage.pdf").xml;
+        assertContains("PDF1", xml);
+        assertContains("PDF2", xml);
+    }
+
     private static int substringCount(String needle, String haystack) {
         int upto = -1;
         int count = 0;
@@ -441,10 +447,12 @@ public class PDFParserTest extends TikaTest {
         handler.getTransformer().setOutputProperty(OutputKeys.INDENT, "no");
         handler.setResult(new StreamResult(sw));
 
+        ParseContext context = new ParseContext();
+        context.set(Parser.class, parser);
         // Try with a document containing various tables and formattings
         InputStream input = getResourceAsStream("/test-documents/" + filename);
         try {
-            parser.parse(input, handler, metadata, new ParseContext());
+            parser.parse(input, handler, metadata, context);
             return new XMLResult(sw.toString(), metadata);
         } finally {
             input.close();
diff --git a/tika-parsers/src/test/resources/test-documents/testPDFPackage.pdf b/tika-parsers/src/test/resources/test-documents/testPDFPackage.pdf
new file mode 100644
index 000000000..0cd2d487a
--- /dev/null
+++ b/tika-parsers/src/test/resources/test-documents/testPDFPackage.pdf
@@ -0,0 +1,17 @@
+        Multiple files are bound together in this PDF Package.
+
+Adobe recommends using Adobe Reader or Adobe Acrobat version 8 or later to work with
+documents contained within a PDF Package. By updating to the latest version, youll enjoy
+the following benefits:
+
+            Efficient, integrated PDF viewing
+            Easy printing
+            Quick searches
+
+               Dont have the latest version of Adobe Reader?
+
+      Click here to download the latest version of Adobe Reader
+
+                      If you already have Adobe Reader 8,
+                    click a file in this PDF Package to view it.
+
\ No newline at end of file

Commit:
527f3d72120f6be58735c437d1f6453029485b15
Michael McCandless
mikemccand@apache.org
2012-05-21 18:03:01 +0000
TIKA-924: extract table names from iWork Numbers docs
diff --git a/CHANGES.txt b/CHANGES.txt
index 1b34e9e59..50d809fb6 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -20,7 +20,8 @@ Release 1.2 - Current Development
     protected iWork files, even though we can't parse their contents
     yet (TIKA-903).  Text extracted from Keynote text boxes and bullet
     points no longer runs together (TIKA-910). Also extract text for
-    Pages documents created in layout mode (TIKA-904). 
+    Pages documents created in layout mode (TIKA-904).  Table names
+    are now extracted in Numbers documents (TIKA-924).
 
 Release 1.1 - 3/7/2012
 ---------------------------------
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/NumbersContentHandler.java b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/NumbersContentHandler.java
index 994e4228d..b8c7b4fda 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/NumbersContentHandler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/NumbersContentHandler.java
@@ -97,11 +97,14 @@ class NumbersContentHandler extends DefaultHandler {
         }
 
         if ("sf:tabular-model".equals(qName)) {
+            String tableName = attributes.getValue("sf:name");
+            xhtml.startElement("div");
+            xhtml.characters(tableName);
+            xhtml.endElement("div");
             inTable = true;
             xhtml.startElement("table");
             xhtml.startElement("tr");
             currentColumn = 0;
-//            String tableName = attributes.getValue("sf:name");
         }
 
         if ("sf:menu-choices".equals(qName)) {
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
index ef40ce07c..3ca2510b0 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
@@ -225,6 +225,16 @@ public class IWorkParserTest extends TestCase {
         assertTrue(content.contains("Try adding your own account transactions to this table."));
     }
 
+    // TIKA- 924
+    public void testParseNumbersTableNames() throws Exception {
+        InputStream input = IWorkParserTest.class.getResourceAsStream("/test-documents/tableNames.numbers");
+        Metadata metadata = new Metadata();
+        ContentHandler handler = new BodyContentHandler();
+        iWorkParser.parse(input, handler, metadata, parseContext);
+        String content = handler.toString();
+        assertTrue(content.contains("This is the main table"));
+    }
+        
     public void testParseNumbersTableHeaders() throws Exception {
         InputStream input = IWorkParserTest.class.getResourceAsStream("/test-documents/tableHeaders.numbers");
         Metadata metadata = new Metadata();
diff --git a/tika-parsers/src/test/resources/test-documents/tableNames.numbers b/tika-parsers/src/test/resources/test-documents/tableNames.numbers
new file mode 100644
index 000000000..4c27f4aab
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/tableNames.numbers differ

Commit:
fb7f940ddefc80bbc2da15a271ad0a77e91f3056
Michael McCandless
mikemccand@apache.org
2012-05-18 09:52:53 +0000
TIKA-904: handle iWork Pages documents created in layout mode
diff --git a/CHANGES.txt b/CHANGES.txt
index a21ed58c9..1b34e9e59 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -19,7 +19,8 @@ Release 1.2 - Current Development
     (TIKA-906).  Don't throw NullPointerException on passsword
     protected iWork files, even though we can't parse their contents
     yet (TIKA-903).  Text extracted from Keynote text boxes and bullet
-    points no longer runs together (TIKA-910).
+    points no longer runs together (TIKA-910). Also extract text for
+    Pages documents created in layout mode (TIKA-904). 
 
 Release 1.1 - 3/7/2012
 ---------------------------------
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/PagesContentHandler.java b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/PagesContentHandler.java
index cd2093bb7..f73b4c9e0 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/PagesContentHandler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/PagesContentHandler.java
@@ -42,9 +42,11 @@ class PagesContentHandler extends DefaultHandler {
        FOOTNOTES, ANNOTATIONS;
     }
     private DocumentPart inPart = null;
-    
+    private boolean ghostText;
+
     private boolean parseProperty = false;
     private int pageCount = 0;
+    private int slPageCount = 0;
 
     private HeaderFooter headers = null;
     private HeaderFooter footers = null;
@@ -94,17 +96,23 @@ class PagesContentHandler extends DefaultHandler {
             inPart = DocumentPart.METADATA;
         } else if ("sf:metadata".equals(qName)) {
            inPart = DocumentPart.METADATA;
-        } else if ("sf:page-start".equals(qName)) {
+        } else if ("sf:page-start".equals(qName) || "sl:page-group".equals(qName)) {
             if (pageCount > 0) {
                 doFooter();
                 xhtml.endElement("div");
             }
             xhtml.startElement("div");
-            pageCount++;
+            if ("sl:page-group".equals(qName)) {
+                slPageCount++;
+            } else {
+                pageCount++;
+            }
             doHeader();
-        } else if ("sf:p".equals(qName) && pageCount > 0) {
+        } else if ("sf:p".equals(qName)) {
+          if (pageCount+slPageCount > 0) {
             inPart = DocumentPart.PARSABLE_TEXT;
             xhtml.startElement("p");
+          }
         } else if ("sf:attachment".equals(qName)) {
             String kind = attributes.getValue("sf:kind");
             if ("tabular-attachment".equals(kind)) {
@@ -155,6 +163,8 @@ class PagesContentHandler extends DefaultHandler {
               xhtml.characters(annotationText);
               xhtml.endElement("div");
            }
+        } else if ("sf:ghost-text".equals(qName)) {
+            ghostText = true;
         }
 
         if (activeTableId != null) {
@@ -180,15 +190,17 @@ class PagesContentHandler extends DefaultHandler {
             inPart = null;
         } else if ("sf:metadata".equals(qName)) {
             inPart = null;
-        } else if ("sf:p".equals(qName) && pageCount > 0) {
+        } else if ("sf:p".equals(qName) && (pageCount+slPageCount) > 0) {
             inPart = null;
             xhtml.endElement("p");
         } else if ("sf:attachment".equals(qName)) {
             activeTableId = null;
         } else if ("sf:annotation".equals(qName) && inPart == DocumentPart.ANNOTATIONS) {
-           annotations.end();
+            annotations.end();
         } else if ("sf:annotation-field".equals(qName) && inPart == DocumentPart.PARSABLE_TEXT) {
-           xhtml.endElement("div");
+            xhtml.endElement("div");
+        } else if ("sf:ghost-text".equals(qName)) {
+            ghostText = false;
         }
     }
 
@@ -196,7 +208,9 @@ class PagesContentHandler extends DefaultHandler {
     public void characters(char[] ch, int start, int length) throws SAXException {
         if (length > 0) {
            if (inPart == DocumentPart.PARSABLE_TEXT) {
-              xhtml.characters(ch, start, length);
+               if (!ghostText) {
+                   xhtml.characters(ch, start, length);
+               }
           } else if(inPart != null) {
               String str = new String(ch, start, length);
               if (inPart == DocumentPart.HEADER_FIRST) headers.defaultFirst = str;
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
index 0910e80c5..ef40ce07c 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
@@ -171,6 +171,22 @@ public class IWorkParserTest extends TestCase {
         assertTrue(content.contains("Extensible Markup Language")); // ...
     }
 
+    // TIKA-904
+    public void testPagesLayoutMode() throws Exception {
+        InputStream input = IWorkParserTest.class.getResourceAsStream("/test-documents/testPagesLayout.pages");
+        Metadata metadata = new Metadata();
+        ContentHandler handler = new BodyContentHandler();
+
+        iWorkParser.parse(input, handler, metadata, parseContext);
+
+        String content = handler.toString();
+        assertTrue(content.contains("text box 1 - here is some text"));
+        assertTrue(content.contains("created in a text box in layout mode"));
+        assertTrue(content.contains("text box 2 - more text!@!$@#"));
+        assertTrue(content.contains("this is text inside of a green box"));
+        assertTrue(content.contains("text inside of a green circle"));
+    }
+
     public void testParseNumbers() throws Exception {
         InputStream input = IWorkParserTest.class.getResourceAsStream("/test-documents/testNumbers.numbers");
         Metadata metadata = new Metadata();
diff --git a/tika-parsers/src/test/resources/test-documents/testPagesLayout.pages b/tika-parsers/src/test/resources/test-documents/testPagesLayout.pages
new file mode 100644
index 000000000..46d8a40a4
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testPagesLayout.pages differ

Commit:
5eb3dc1d76fe98ccdf522a0beb69f3d123ccfe98
Michael McCandless
mikemccand@apache.org
2012-05-18 09:47:47 +0000
TIKA-910: fix text in Keynote text boxes and bullet points to not run together
diff --git a/CHANGES.txt b/CHANGES.txt
index 5adea2301..a21ed58c9 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -18,7 +18,8 @@ Release 1.2 - Current Development
     Headers, footers and footnotes in Pages files are now extracted
     (TIKA-906).  Don't throw NullPointerException on passsword
     protected iWork files, even though we can't parse their contents
-    yet (TIKA-903).
+    yet (TIKA-903).  Text extracted from Keynote text boxes and bullet
+    points no longer runs together (TIKA-910).
 
 Release 1.1 - 3/7/2012
 ---------------------------------
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/KeynoteContentHandler.java b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/KeynoteContentHandler.java
index 47edb182e..b1bc41351 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/KeynoteContentHandler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/KeynoteContentHandler.java
@@ -104,6 +104,8 @@ class KeynoteContentHandler extends DefaultHandler {
             parseTableData(attributes.getValue("sfa:s"));
         } else if (tableId != null && "sf:n".equals(qName)) {
             parseTableData(attributes.getValue("sf:v"));
+        } else if ("sf:p".equals(qName)) {
+            xhtml.startElement("p");
         }
     }
 
@@ -138,6 +140,8 @@ class KeynoteContentHandler extends DefaultHandler {
             tableId = null;
             numberOfColumns = null;
             currentColumn = null;
+        } else if ("sf:p".equals(qName)) {
+            xhtml.endElement("p");
         }
     }
 
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
index c7995807e..0910e80c5 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
@@ -90,6 +90,28 @@ public class IWorkParserTest extends TestCase {
         assertTrue(content.contains("5/5/1985"));
     }
 
+    // TIKA-910
+    public void testKeynoteTextBoxes() throws Exception {
+        InputStream input = IWorkParserTest.class.getResourceAsStream("/test-documents/testTextBoxes.key");
+        Metadata metadata = new Metadata();
+        ContentHandler handler = new BodyContentHandler();
+        iWorkParser.parse(input, handler, metadata, parseContext);
+
+        String content = handler.toString();
+        assertTrue(content.replaceAll("\\s+", " ").contains("text1 text2 text3"));
+    }
+
+    // TIKA-910
+    public void testKeynoteBulletPoints() throws Exception {
+        InputStream input = IWorkParserTest.class.getResourceAsStream("/test-documents/testBulletPoints.key");
+        Metadata metadata = new Metadata();
+        ContentHandler handler = new BodyContentHandler();
+        iWorkParser.parse(input, handler, metadata, parseContext);
+
+        String content = handler.toString();
+        assertTrue(content.replaceAll("\\s+", " ").contains("bullet point 1 bullet point 2 bullet point 3"));
+    }
+
     // TIKA-923
     public void testKeynoteTables() throws Exception {
         InputStream input = IWorkParserTest.class.getResourceAsStream("/test-documents/testTables.key");
diff --git a/tika-parsers/src/test/resources/test-documents/testBulletPoints.key b/tika-parsers/src/test/resources/test-documents/testBulletPoints.key
new file mode 100644
index 000000000..f2525c44d
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testBulletPoints.key differ
diff --git a/tika-parsers/src/test/resources/test-documents/testTextBoxes.key b/tika-parsers/src/test/resources/test-documents/testTextBoxes.key
new file mode 100644
index 000000000..20e289336
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testTextBoxes.key differ

Commit:
edf26d44b961e28d6aeff6f0d03c6554dd8bb144
Michael McCandless
mikemccand@apache.org
2012-05-18 09:42:15 +0000
TIKA-923: add test case
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
index 0059bd9d1..c7995807e 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
@@ -90,6 +90,18 @@ public class IWorkParserTest extends TestCase {
         assertTrue(content.contains("5/5/1985"));
     }
 
+    // TIKA-923
+    public void testKeynoteTables() throws Exception {
+        InputStream input = IWorkParserTest.class.getResourceAsStream("/test-documents/testTables.key");
+        Metadata metadata = new Metadata();
+        ContentHandler handler = new BodyContentHandler();
+        iWorkParser.parse(input, handler, metadata, parseContext);
+
+        String content = handler.toString();
+        content = content.replaceAll("\\s+", " ");
+        assertTrue(content.contains("row 1 row 2 row 3"));
+    }
+
     public void testParsePages() throws Exception {
         InputStream input = IWorkParserTest.class.getResourceAsStream("/test-documents/testPages.pages");
         Metadata metadata = new Metadata();
diff --git a/tika-parsers/src/test/resources/test-documents/testTables.key b/tika-parsers/src/test/resources/test-documents/testTables.key
new file mode 100644
index 000000000..72596760d
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testTables.key differ

Commit:
4a01b485567a750d7482f119586aa9ca29c38cbc
Michael McCandless
mikemccand@apache.org
2012-05-18 09:36:28 +0000
TIKA-903, TIKA-906, TIKA-907: add some CHANGES.txt entries
diff --git a/CHANGES.txt b/CHANGES.txt
index c9944515e..5adea2301 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -14,6 +14,12 @@ Release 1.2 - Current Development
 
   * Images: Fixed file handle leak in ImageParser. (TIKA-875)
 
+  * iWork: Comments in Pages files are now extracted (TIKA-907).
+    Headers, footers and footnotes in Pages files are now extracted
+    (TIKA-906).  Don't throw NullPointerException on passsword
+    protected iWork files, even though we can't parse their contents
+    yet (TIKA-903).
+
 Release 1.1 - 3/7/2012
 ---------------------------------
 

Commit:
32033ded8671f9a3d5fd638c652de44c60f3a659
Nick Burch
nick@apache.org
2012-05-18 01:55:18 +0000
TIKA-842 Patch from Ray Gauss to tidy up a few property names
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/IPTC.java b/tika-core/src/main/java/org/apache/tika/metadata/IPTC.java
index 95d1bf3ae..19ec895ea 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/IPTC.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/IPTC.java
@@ -504,7 +504,7 @@ public interface IPTC {
     *
     * @deprecated
     */
-   Property PHOTOSHOP_URGENCY = Photoshop.URGENCY;
+   Property URGENCY = Photoshop.URGENCY;
 
    /**
     * As this metadata element was earmarked as deprecated already for IIM 4.1,
@@ -516,7 +516,7 @@ public interface IPTC {
     *
     * @deprecated
     */
-   Property PHOTOSHOP_CATEGORY = Photoshop.CATEGORY;
+   Property CATEGORY = Photoshop.CATEGORY;
 
    /**
     * As this metadata element was earmarked as deprecated already for IIM 4.1,
@@ -526,7 +526,7 @@ public interface IPTC {
     *
     * @deprecated
     */
-   Property PHOTOSHOP_SUPPLEMENTAL_CATEGORIES = Photoshop.SUPPLEMENTAL_CATEGORIES;
+   Property SUPPLEMENTAL_CATEGORIES = Photoshop.SUPPLEMENTAL_CATEGORIES;
 
    /**
     * Information about the ethnicity and other facets of the model(s) in a

Commit:
c5084471e00852abbeb9e4986f2a391f7a827d44
Nick Burch
nick@apache.org
2012-05-18 01:30:57 +0000
TIKA-929 Ensure backwards compatibility on the Office document statistics
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/SummaryExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/SummaryExtractor.java
index 4322534a4..6a4a2940f 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/SummaryExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/SummaryExtractor.java
@@ -32,6 +32,7 @@ import org.apache.poi.poifs.filesystem.DocumentEntry;
 import org.apache.poi.poifs.filesystem.DocumentInputStream;
 import org.apache.poi.poifs.filesystem.NPOIFSFileSystem;
 import org.apache.tika.exception.TikaException;
+import org.apache.tika.metadata.MSOffice;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.Office;
 import org.apache.tika.metadata.PagedText;
@@ -105,13 +106,20 @@ class SummaryExtractor {
         set(TikaCoreProperties.SAVE_DATE, summary.getLastSaveDateTime());
         set(TikaCoreProperties.PRINT_DATE, summary.getLastPrinted());
         set(Metadata.EDIT_TIME, summary.getEditTime());
+        set(Metadata.SECURITY, summary.getSecurity());
+        
+        // New style counts
+        set(Office.WORD_COUNT, summary.getWordCount());
         set(Office.CHARACTER_COUNT, summary.getCharCount());
         set(Office.PAGE_COUNT, summary.getPageCount());
         if (summary.getPageCount() > 0) {
             metadata.set(PagedText.N_PAGES, summary.getPageCount());
         }
-        set(Metadata.SECURITY, summary.getSecurity());
-        set(Office.WORD_COUNT, summary.getWordCount());
+        
+        // Old style, Tika 1.0 counts
+        set(MSOffice.WORD_COUNT, summary.getWordCount());
+        set(MSOffice.CHARACTER_COUNT, summary.getCharCount());
+        set(MSOffice.PAGE_COUNT, summary.getPageCount());
     }
 
     private void parse(DocumentSummaryInformation summary) {
@@ -119,10 +127,14 @@ class SummaryExtractor {
         set(Metadata.MANAGER, summary.getManager());
         set(TikaCoreProperties.LANGUAGE, getLanguage(summary));
         set(Metadata.CATEGORY, summary.getCategory());
+        
+        // New style counts
         set(Office.SLIDE_COUNT, summary.getSlideCount());
         if (summary.getSlideCount() > 0) {
             metadata.set(PagedText.N_PAGES, summary.getSlideCount());
         }
+        // Old style, Tika 1.0 counts
+        set(MSOffice.SLIDE_COUNT, summary.getSlideCount());
         
         parse(summary.getCustomProperties());
     }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java
index 08491ce29..ec9b64b16 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java
@@ -27,6 +27,7 @@ import org.apache.poi.openxml4j.opc.internal.PackagePropertiesPart;
 import org.apache.poi.openxml4j.util.Nullable;
 import org.apache.poi.xssf.extractor.XSSFEventBasedExcelExtractor;
 import org.apache.tika.exception.TikaException;
+import org.apache.tika.metadata.MSOffice;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.Office;
 import org.apache.tika.metadata.PagedText;
@@ -103,31 +104,38 @@ public class MetadataExtractor {
             Metadata metadata) {
         CTProperties propsHolder = properties.getUnderlyingProperties();
 
-        addProperty(metadata, Metadata.APPLICATION_NAME, propsHolder
-                .getApplication());
-        addProperty(metadata, Metadata.APPLICATION_VERSION, propsHolder
-                .getAppVersion());
-        addProperty(metadata, Office.CHARACTER_COUNT, propsHolder
-                .getCharacters());
-        addProperty(metadata, Office.CHARACTER_COUNT_WITH_SPACES, propsHolder
-                .getCharactersWithSpaces());
+        addProperty(metadata, Metadata.APPLICATION_NAME, propsHolder.getApplication());
+        addProperty(metadata, Metadata.APPLICATION_VERSION, propsHolder.getAppVersion());
         addProperty(metadata, TikaCoreProperties.PUBLISHER, propsHolder.getCompany());
-        addProperty(metadata, Office.LINE_COUNT, propsHolder.getLines());
         addProperty(metadata, Metadata.MANAGER, propsHolder.getManager());
         addProperty(metadata, Metadata.NOTES, propsHolder.getNotes());
-        addProperty(metadata, Office.PAGE_COUNT, propsHolder.getPages());
+        addProperty(metadata, Metadata.PRESENTATION_FORMAT, propsHolder.getPresentationFormat());
+        addProperty(metadata, Metadata.TEMPLATE, propsHolder.getTemplate());
+        addProperty(metadata, Metadata.TOTAL_TIME, propsHolder.getTotalTime());
+
         if (propsHolder.getPages() > 0) {
-            metadata.set(PagedText.N_PAGES, propsHolder.getPages());
+           metadata.set(PagedText.N_PAGES, propsHolder.getPages());
         } else if (propsHolder.getSlides() > 0) {
-            metadata.set(PagedText.N_PAGES, propsHolder.getSlides());
+           metadata.set(PagedText.N_PAGES, propsHolder.getSlides());
         }
-        addProperty(metadata, Office.PARAGRAPH_COUNT, propsHolder.getParagraphs());
-        addProperty(metadata, Metadata.PRESENTATION_FORMAT, propsHolder
-                .getPresentationFormat());
+
+        // Process the document statistics
+        addProperty(metadata, Office.PAGE_COUNT, propsHolder.getPages());
         addProperty(metadata, Office.SLIDE_COUNT, propsHolder.getSlides());
-        addProperty(metadata, Metadata.TEMPLATE, propsHolder.getTemplate());
-        addProperty(metadata, Metadata.TOTAL_TIME, propsHolder.getTotalTime());
+        addProperty(metadata, Office.PARAGRAPH_COUNT, propsHolder.getParagraphs());
+        addProperty(metadata, Office.LINE_COUNT, propsHolder.getLines());
         addProperty(metadata, Office.WORD_COUNT, propsHolder.getWords());
+        addProperty(metadata, Office.CHARACTER_COUNT, propsHolder.getCharacters());
+        addProperty(metadata, Office.CHARACTER_COUNT_WITH_SPACES, propsHolder.getCharactersWithSpaces());
+        
+        // Legacy Tika-1.0 style stats
+        addProperty(metadata, MSOffice.PAGE_COUNT, propsHolder.getPages());
+        addProperty(metadata, MSOffice.SLIDE_COUNT, propsHolder.getSlides());
+        addProperty(metadata, MSOffice.PARAGRAPH_COUNT, propsHolder.getParagraphs());
+        addProperty(metadata, MSOffice.LINE_COUNT, propsHolder.getLines());
+        addProperty(metadata, MSOffice.WORD_COUNT, propsHolder.getWords());
+        addProperty(metadata, MSOffice.CHARACTER_COUNT, propsHolder.getCharacters());
+        addProperty(metadata, MSOffice.CHARACTER_COUNT_WITH_SPACES, propsHolder.getCharactersWithSpaces());
     }
 
     private void extractMetadata(CustomProperties properties,

Commit:
923ef5d6b2101a7500955b9709967c7277ff5674
Nick Burch
nick@apache.org
2012-05-17 21:23:18 +0000
TIKA-929 Fix up parsers to use the new style TikaCoreProperties.AUTHOR, along with fixing a few other deprecated bits in the process
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/Office.java b/tika-core/src/main/java/org/apache/tika/metadata/Office.java
index c095d7777..b0e1cb333 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/Office.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/Office.java
@@ -61,9 +61,9 @@ public interface Office {
          PREFIX_DOC_META + Metadata.NAMESPACE_PREFIX_DELIMITER + "last-author");
 
    /**
-    * Name of the principal author of a document
+    * Name of the principal author(s) of a document
     */
-   Property AUTHOR = Property.internalText(
+   Property AUTHOR = Property.internalTextBag(
          PREFIX_DOC_META + Metadata.NAMESPACE_PREFIX_DELIMITER + "author");
 
    
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/TikaCoreProperties.java b/tika-core/src/main/java/org/apache/tika/metadata/TikaCoreProperties.java
index 20fd51923..320baf7c9 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/TikaCoreProperties.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/TikaCoreProperties.java
@@ -74,7 +74,8 @@ public interface TikaCoreProperties {
     /**
      * @see Office#AUTHOR
      */
-    public static final Property AUTHOR = Office.AUTHOR;
+    public static final Property AUTHOR = Property.composite(Office.AUTHOR,
+          new Property[] { Property.internalText(MSOffice.AUTHOR) });
 
     /**
      * @see Office#LAST_AUTHOR
@@ -158,7 +159,7 @@ public interface TikaCoreProperties {
      * @see DublinCore#MODIFIED
      */
      public static final Property MODIFIED = Property.composite(DublinCore.MODIFIED, 
-             new Property[] { Property.internalText(Metadata.MODIFIED) });
+             new Property[] { Property.internalText(Metadata.MODIFIED), Property.internalText("Last-Modified") });
      
      /** @see Office#CREATION_DATE */
      public static final Property CREATION_DATE = Property.composite(Office.CREATION_DATE,
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/dwg/DWGParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/dwg/DWGParser.java
index 32fd12d71..aff4cacc2 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/dwg/DWGParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/dwg/DWGParser.java
@@ -56,7 +56,7 @@ public class DWGParser extends AbstractParser {
     private static final Property[] HEADER_PROPERTIES_ENTRIES = {
         TikaCoreProperties.TITLE, 
         TikaCoreProperties.SUBJECT,
-        Property.internalText(Metadata.AUTHOR),
+        TikaCoreProperties.AUTHOR,
         TikaCoreProperties.KEYWORDS,
         Property.internalText(Metadata.COMMENTS),
         TikaCoreProperties.LAST_AUTHOR,
@@ -70,7 +70,7 @@ public class DWGParser extends AbstractParser {
        TikaCoreProperties.RELATION, // 0x01
        TikaCoreProperties.TITLE,    // 0x02
        TikaCoreProperties.SUBJECT,  // 0x03
-       Property.internalText(Metadata.AUTHOR),  // 0x04
+       TikaCoreProperties.AUTHOR,   // 0x04
        null,
        Property.internalText(Metadata.COMMENTS),// 0x06 
        TikaCoreProperties.KEYWORDS,    // 0x07
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/image/ImageMetadataExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/image/ImageMetadataExtractor.java
index 3f6f47a00..6a01c404d 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/image/ImageMetadataExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/image/ImageMetadataExtractor.java
@@ -453,7 +453,7 @@ public class ImageMetadataExtractor {
                 metadata.set(TikaCoreProperties.TITLE, directory.getString(IptcDirectory.TAG_OBJECT_NAME));
             }
             if (directory.containsTag(IptcDirectory.TAG_BY_LINE)) {
-                metadata.set(Metadata.AUTHOR, directory.getString(IptcDirectory.TAG_BY_LINE));
+                metadata.set(TikaCoreProperties.AUTHOR, directory.getString(IptcDirectory.TAG_BY_LINE));
             }
             if (directory.containsTag(IptcDirectory.TAG_CAPTION)) {
                 metadata.set(TikaCoreProperties.DESCRIPTION,
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/iptc/IptcAnpaParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/iptc/IptcAnpaParser.java
index 726bbc61c..b1661bcf1 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/iptc/IptcAnpaParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/iptc/IptcAnpaParser.java
@@ -772,8 +772,8 @@ public class IptcAnpaParser implements Parser {
       metadata.set(Metadata.CONTENT_TYPE,  clean("text/anpa-1312"));
       metadata.set(TikaCoreProperties.TITLE,         clean(properties.get("title")));
       metadata.set(TikaCoreProperties.SUBJECT,       clean(properties.get("subject")));
-      metadata.set(Metadata.AUTHOR,        clean(properties.get("author")));
-      metadata.set(Metadata.CREATION_DATE, clean(properties.get("created")));
+      metadata.set(TikaCoreProperties.AUTHOR,        clean(properties.get("author")));
+      metadata.set(TikaCoreProperties.CREATION_DATE, clean(properties.get("created")));
       metadata.set(TikaCoreProperties.MODIFIED,      clean(properties.get("modified")));
       metadata.set(TikaCoreProperties.SOURCE,      clean(properties.get("source")));
 //      metadata.set(TikaCoreProperties.PUBLISHER,     clean(properties.get("publisher")));
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/KeynoteContentHandler.java b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/KeynoteContentHandler.java
index 14550e00a..47edb182e 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/KeynoteContentHandler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/KeynoteContentHandler.java
@@ -93,7 +93,7 @@ class KeynoteContentHandler extends DefaultHandler {
         } else if (inMetaDataTitle && "key:string".equals(qName)) {
             metadata.set(TikaCoreProperties.TITLE, attributes.getValue("sfa:string"));
         } else if (inMetaDataAuthors && "key:string".equals(qName)) {
-            metadata.add(Metadata.AUTHOR, attributes.getValue("sfa:string"));
+            metadata.add(TikaCoreProperties.AUTHOR, attributes.getValue("sfa:string"));
         } else if (inSlide && "sf:tabular-model".equals(qName)) {
             tableId = attributes.getValue("sfa:ID");
             xhtml.startElement("table");
@@ -161,4 +161,4 @@ class KeynoteContentHandler extends DefaultHandler {
       }
     }
 
-}
\ No newline at end of file
+}
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/NumbersContentHandler.java b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/NumbersContentHandler.java
index b502b97e4..994e4228d 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/NumbersContentHandler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/NumbersContentHandler.java
@@ -206,11 +206,11 @@ class NumbersContentHandler extends DefaultHandler {
 
     private Property resolveMetadataKey(String localName) {
         if ("authors".equals(localName)) {
-            return Property.internalText(Metadata.AUTHOR);
+            return TikaCoreProperties.AUTHOR;
         }
         if ("title".equals(localName)) {
             return TikaCoreProperties.TITLE;
         }
         return Property.internalText(localName);
     }
-}
\ No newline at end of file
+}
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/PagesContentHandler.java b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/PagesContentHandler.java
index 3f49a6143..cd2093bb7 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/PagesContentHandler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/PagesContentHandler.java
@@ -251,11 +251,11 @@ class PagesContentHandler extends DefaultHandler {
     private Object resolveMetaDataKey(String metaDataLocalName) {
         Object metaDataKey = metaDataLocalName;
         if ("sf:authors".equals(metaDataQName)) {
-            metaDataKey = Metadata.AUTHOR;
+            metaDataKey = TikaCoreProperties.AUTHOR;
         } else if ("sf:title".equals(metaDataQName)) {
             metaDataKey = TikaCoreProperties.TITLE;
         } else if ("sl:SLCreationDateProperty".equals(metaDataQName)) {
-            metaDataKey = Metadata.CREATION_DATE;
+            metaDataKey = TikaCoreProperties.CREATION_DATE;
         } else if ("sl:SLLastModifiedDateProperty".equals(metaDataQName)) {
             metaDataKey = Metadata.LAST_MODIFIED;
         } else if ("sl:language".equals(metaDataQName)) {
@@ -400,4 +400,4 @@ class PagesContentHandler extends DefaultHandler {
           }
        }
     }
-}
\ No newline at end of file
+}
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mail/MailContentHandler.java b/tika-parsers/src/main/java/org/apache/tika/parser/mail/MailContentHandler.java
index e741ee9de..1df6032ee 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mail/MailContentHandler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mail/MailContentHandler.java
@@ -147,7 +147,7 @@ class MailContentHandler implements ContentHandler {
                     for (int i = 0; i < mailboxList.size(); i++) {
                         String from = getDisplayString(mailboxList.get(i));
                         metadata.add(Metadata.MESSAGE_FROM, from);
-                        metadata.add(Metadata.AUTHOR, from);
+                        metadata.add(TikaCoreProperties.AUTHOR, from);
                     }
                 } else {
                     String from = stripOutFieldPrefix(field, "From:");
@@ -158,7 +158,7 @@ class MailContentHandler implements ContentHandler {
                         from = from.substring(0, from.length() - 1);
                     }
                     metadata.add(Metadata.MESSAGE_FROM, from);
-                    metadata.add(Metadata.AUTHOR, from);
+                    metadata.add(TikaCoreProperties.AUTHOR, from);
                 }
             } else if (fieldname.equalsIgnoreCase("Subject")) {
                 metadata.add(TikaCoreProperties.SUBJECT,
@@ -246,4 +246,4 @@ class MailContentHandler implements ContentHandler {
         return temp.substring(loc);
     }
 
-}
\ No newline at end of file
+}
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mbox/MboxParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/mbox/MboxParser.java
index 615a3a95d..ca5e3e989 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mbox/MboxParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mbox/MboxParser.java
@@ -198,7 +198,7 @@ public class MboxParser extends AbstractParser {
         String headerContent = headerMatcher.group(2);
 
         if (headerTag.equalsIgnoreCase("From")) {
-            metadata.add(Metadata.AUTHOR, headerContent);
+            metadata.add(TikaCoreProperties.AUTHOR, headerContent);
             metadata.set(TikaCoreProperties.CREATOR, headerContent);
         } else if (headerTag.equalsIgnoreCase("To") ||
         	headerTag.equalsIgnoreCase("Cc") ||
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OutlookExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OutlookExtractor.java
index 715feecd1..3d0fdb902 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OutlookExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OutlookExtractor.java
@@ -97,7 +97,7 @@ public class OutlookExtractor extends AbstractPOIFSExtractor {
            String subject = msg.getSubject();
            String from = msg.getDisplayFrom();
    
-           metadata.set(Metadata.AUTHOR, from);
+           metadata.set(TikaCoreProperties.AUTHOR, from);
            metadata.set(Metadata.MESSAGE_FROM, from);
            metadata.set(Metadata.MESSAGE_TO, msg.getDisplayTo());
            metadata.set(Metadata.MESSAGE_CC, msg.getDisplayCC());
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/SummaryExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/SummaryExtractor.java
index d82506bc3..4322534a4 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/SummaryExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/SummaryExtractor.java
@@ -33,6 +33,7 @@ import org.apache.poi.poifs.filesystem.DocumentInputStream;
 import org.apache.poi.poifs.filesystem.NPOIFSFileSystem;
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.Office;
 import org.apache.tika.metadata.PagedText;
 import org.apache.tika.metadata.Property;
 import org.apache.tika.metadata.TikaCoreProperties;
@@ -92,25 +93,25 @@ class SummaryExtractor {
 
     private void parse(SummaryInformation summary) {
         set(TikaCoreProperties.TITLE, summary.getTitle());
-        set(Metadata.AUTHOR, summary.getAuthor());
-        set(Metadata.KEYWORDS, summary.getKeywords());
+        set(TikaCoreProperties.AUTHOR, summary.getAuthor());
+        set(TikaCoreProperties.KEYWORDS, summary.getKeywords());
         set(TikaCoreProperties.SUBJECT, summary.getSubject());
-        set(Metadata.LAST_AUTHOR, summary.getLastAuthor());
+        set(TikaCoreProperties.LAST_AUTHOR, summary.getLastAuthor());
         set(Metadata.COMMENTS, summary.getComments());
         set(Metadata.TEMPLATE, summary.getTemplate());
         set(Metadata.APPLICATION_NAME, summary.getApplicationName());
         set(Metadata.REVISION_NUMBER, summary.getRevNumber());
-        set(Metadata.CREATION_DATE, summary.getCreateDateTime());
-        set(Metadata.CHARACTER_COUNT, summary.getCharCount());
+        set(TikaCoreProperties.CREATION_DATE, summary.getCreateDateTime());
+        set(TikaCoreProperties.SAVE_DATE, summary.getLastSaveDateTime());
+        set(TikaCoreProperties.PRINT_DATE, summary.getLastPrinted());
         set(Metadata.EDIT_TIME, summary.getEditTime());
-        set(Metadata.LAST_SAVED, summary.getLastSaveDateTime());
-        set(Metadata.PAGE_COUNT, summary.getPageCount());
+        set(Office.CHARACTER_COUNT, summary.getCharCount());
+        set(Office.PAGE_COUNT, summary.getPageCount());
         if (summary.getPageCount() > 0) {
             metadata.set(PagedText.N_PAGES, summary.getPageCount());
         }
         set(Metadata.SECURITY, summary.getSecurity());
-        set(Metadata.WORD_COUNT, summary.getWordCount());
-        set(Metadata.LAST_PRINTED, summary.getLastPrinted());
+        set(Office.WORD_COUNT, summary.getWordCount());
     }
 
     private void parse(DocumentSummaryInformation summary) {
@@ -118,7 +119,7 @@ class SummaryExtractor {
         set(Metadata.MANAGER, summary.getManager());
         set(TikaCoreProperties.LANGUAGE, getLanguage(summary));
         set(Metadata.CATEGORY, summary.getCategory());
-        set(Metadata.SLIDE_COUNT, summary.getSlideCount());
+        set(Office.SLIDE_COUNT, summary.getSlideCount());
         if (summary.getSlideCount() > 0) {
             metadata.set(PagedText.N_PAGES, summary.getSlideCount());
         }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java
index 857c34523..08491ce29 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java
@@ -28,6 +28,7 @@ import org.apache.poi.openxml4j.util.Nullable;
 import org.apache.poi.xssf.extractor.XSSFEventBasedExcelExtractor;
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.Office;
 import org.apache.tika.metadata.PagedText;
 import org.apache.tika.metadata.Property;
 import org.apache.tika.metadata.TikaCoreProperties;
@@ -68,26 +69,28 @@ public class MetadataExtractor {
                 .getContentStatusProperty());
         addProperty(metadata, TikaCoreProperties.DATE, propsHolder
                 .getCreatedProperty());
-        addProperty(metadata, Metadata.CREATION_DATE, propsHolder
+        addProperty(metadata, TikaCoreProperties.CREATION_DATE, propsHolder
                 .getCreatedProperty());
         addProperty(metadata, TikaCoreProperties.CREATOR, propsHolder
                 .getCreatorProperty());
-        addProperty(metadata, Metadata.AUTHOR, propsHolder
+        addProperty(metadata, TikaCoreProperties.AUTHOR, propsHolder
                 .getCreatorProperty());
         addProperty(metadata, TikaCoreProperties.DESCRIPTION, propsHolder
                 .getDescriptionProperty());
         addProperty(metadata, TikaCoreProperties.IDENTIFIER, propsHolder
                 .getIdentifierProperty());
-        addProperty(metadata, Metadata.KEYWORDS, propsHolder
+        addProperty(metadata, TikaCoreProperties.KEYWORDS, propsHolder
                 .getKeywordsProperty());
         addProperty(metadata, TikaCoreProperties.LANGUAGE, propsHolder
                 .getLanguageProperty());
-        addProperty(metadata, Metadata.LAST_AUTHOR, propsHolder
+        addProperty(metadata, TikaCoreProperties.LAST_AUTHOR, propsHolder
                 .getLastModifiedByProperty());
-        addProperty(metadata, Metadata.LAST_PRINTED, propsHolder
+        addProperty(metadata, TikaCoreProperties.PRINT_DATE, propsHolder
                 .getLastPrintedProperty());
         addProperty(metadata, Metadata.LAST_MODIFIED, propsHolder
                 .getModifiedProperty());
+        addProperty(metadata, TikaCoreProperties.MODIFIED, propsHolder
+              .getModifiedProperty());
         addProperty(metadata, Metadata.REVISION_NUMBER, propsHolder
                 .getRevisionProperty());
         addProperty(metadata, TikaCoreProperties.SUBJECT, propsHolder
@@ -104,27 +107,27 @@ public class MetadataExtractor {
                 .getApplication());
         addProperty(metadata, Metadata.APPLICATION_VERSION, propsHolder
                 .getAppVersion());
-        addProperty(metadata, Metadata.CHARACTER_COUNT, propsHolder
+        addProperty(metadata, Office.CHARACTER_COUNT, propsHolder
                 .getCharacters());
-        addProperty(metadata, Metadata.CHARACTER_COUNT_WITH_SPACES, propsHolder
+        addProperty(metadata, Office.CHARACTER_COUNT_WITH_SPACES, propsHolder
                 .getCharactersWithSpaces());
         addProperty(metadata, TikaCoreProperties.PUBLISHER, propsHolder.getCompany());
-        addProperty(metadata, Metadata.LINE_COUNT, propsHolder.getLines());
+        addProperty(metadata, Office.LINE_COUNT, propsHolder.getLines());
         addProperty(metadata, Metadata.MANAGER, propsHolder.getManager());
         addProperty(metadata, Metadata.NOTES, propsHolder.getNotes());
-        addProperty(metadata, Metadata.PAGE_COUNT, propsHolder.getPages());
+        addProperty(metadata, Office.PAGE_COUNT, propsHolder.getPages());
         if (propsHolder.getPages() > 0) {
             metadata.set(PagedText.N_PAGES, propsHolder.getPages());
         } else if (propsHolder.getSlides() > 0) {
             metadata.set(PagedText.N_PAGES, propsHolder.getSlides());
         }
-        addProperty(metadata, Metadata.PARAGRAPH_COUNT, propsHolder.getParagraphs());
+        addProperty(metadata, Office.PARAGRAPH_COUNT, propsHolder.getParagraphs());
         addProperty(metadata, Metadata.PRESENTATION_FORMAT, propsHolder
                 .getPresentationFormat());
-        addProperty(metadata, Metadata.SLIDE_COUNT, propsHolder.getSlides());
+        addProperty(metadata, Office.SLIDE_COUNT, propsHolder.getSlides());
         addProperty(metadata, Metadata.TEMPLATE, propsHolder.getTemplate());
         addProperty(metadata, Metadata.TOTAL_TIME, propsHolder.getTotalTime());
-        addProperty(metadata, Metadata.WORD_COUNT, propsHolder.getWords());
+        addProperty(metadata, Office.WORD_COUNT, propsHolder.getWords());
     }
 
     private void extractMetadata(CustomProperties properties,
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/Mp3Parser.java b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/Mp3Parser.java
index f80f8fa5a..3fde7946a 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/Mp3Parser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/Mp3Parser.java
@@ -73,7 +73,7 @@ public class Mp3Parser extends AbstractParser {
            CompositeTagHandler tag = new CompositeTagHandler(audioAndTags.tags);
 
            metadata.set(TikaCoreProperties.TITLE, tag.getTitle());
-           metadata.set(Metadata.AUTHOR, tag.getArtist());
+           metadata.set(TikaCoreProperties.AUTHOR, tag.getArtist());
            metadata.set(XMPDM.ARTIST, tag.getArtist());
            metadata.set(XMPDM.COMPOSER, tag.getComposer());
            metadata.set(XMPDM.ALBUM, tag.getAlbum());
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java b/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java
index 66e0508e7..13088a6ca 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java
@@ -185,7 +185,7 @@ public class MP4Parser extends AbstractParser {
            TrackHeaderBox header = track.getTrackHeaderBox();
            // Get the creation and modification dates
            metadata.set(
-                 Metadata.CREATION_DATE, 
+                 TikaCoreProperties.CREATION_DATE, 
                  MP4TimeToDate(header.getCreationTime())
            );
            metadata.set(
@@ -229,7 +229,7 @@ public class MP4Parser extends AbstractParser {
 
               // Artist
               AppleArtistBox artist = getOrNull(apple, AppleArtistBox.class);
-              addMetadata(Metadata.AUTHOR, metadata, artist);
+              addMetadata(TikaCoreProperties.AUTHOR, metadata, artist);
               addMetadata(XMPDM.ARTIST, metadata, artist);
               
               // Album
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java
index 56094b317..1d5dc3fd0 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java
@@ -154,21 +154,22 @@ public class PDFParser extends AbstractParser {
         PDDocumentInformation info = document.getDocumentInformation();
         metadata.set(PagedText.N_PAGES, document.getNumberOfPages());
         addMetadata(metadata, TikaCoreProperties.TITLE, info.getTitle());
-        addMetadata(metadata, Metadata.AUTHOR, info.getAuthor());
+        addMetadata(metadata, TikaCoreProperties.AUTHOR, info.getAuthor());
         addMetadata(metadata, TikaCoreProperties.CREATOR, info.getCreator());
-        addMetadata(metadata, Metadata.KEYWORDS, info.getKeywords());
+        addMetadata(metadata, TikaCoreProperties.KEYWORDS, info.getKeywords());
         addMetadata(metadata, "producer", info.getProducer());
         addMetadata(metadata, TikaCoreProperties.SUBJECT, info.getSubject());
         addMetadata(metadata, "trapped", info.getTrapped());
         try {
             addMetadata(metadata, "created", info.getCreationDate());
-            addMetadata(metadata, Metadata.CREATION_DATE, info.getCreationDate());
+            addMetadata(metadata, TikaCoreProperties.CREATION_DATE, info.getCreationDate());
         } catch (IOException e) {
             // Invalid date format, just ignore
         }
         try {
             Calendar modified = info.getModificationDate(); 
             addMetadata(metadata, Metadata.LAST_MODIFIED, modified);
+            addMetadata(metadata, TikaCoreProperties.MODIFIED, modified);
         } catch (IOException e) {
             // Invalid date format, just ignore
         }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/rtf/TextExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/rtf/TextExtractor.java
index f41f13c86..8a76cb771 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/rtf/TextExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/rtf/TextExtractor.java
@@ -826,13 +826,13 @@ final class TextExtractor {
                 // \printim, \version, \nofpages, \nofwords,
                 // \nofchars, etc.
                 if (equals("author")) {
-                    nextMetaData = Metadata.AUTHOR;
+                    nextMetaData = TikaCoreProperties.AUTHOR.getName();
                 } else if (equals("title")) {
                     nextMetaData = TikaCoreProperties.TITLE.getName();
                 } else if (equals("subject")) {
                     nextMetaData = TikaCoreProperties.SUBJECT.getName();
                 } else if (equals("keywords")) {
-                    nextMetaData = Metadata.KEYWORDS;
+                    nextMetaData = TikaCoreProperties.KEYWORDS.getName();
                 } else if (equals("category")) {
                     nextMetaData = Metadata.CATEGORY;
                 } else if (equals("comment")) {
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/AutoDetectParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/AutoDetectParserTest.java
index abd1194b7..ad62dc417 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/AutoDetectParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/AutoDetectParserTest.java
@@ -28,6 +28,7 @@ import org.apache.tika.config.TikaConfig;
 import org.apache.tika.detect.Detector;
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.metadata.XMPDM;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.sax.BodyContentHandler;
@@ -277,6 +278,8 @@ public class AutoDetectParserTest extends TestCase {
              // Check some of the common metadata
              assertEquals("Test Artist", metadata.get(Metadata.AUTHOR));
              assertEquals("Test Title", metadata.get(Metadata.TITLE));
+//             assertEquals("Test Artist", metadata.get(TikaCoreProperties.AUTHOR));
+//             assertEquals("Test Title", metadata.get(TikaCoreProperties.TITLE));
              
              // Check some of the XMPDM metadata
              assertEquals("Test Album", metadata.get(XMPDM.ALBUM));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/dwg/DWGParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/dwg/DWGParserTest.java
index ca2735ba0..1ddd7dc1e 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/dwg/DWGParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/dwg/DWGParserTest.java
@@ -81,9 +81,9 @@ public class DWGParserTest extends TestCase {
             assertEquals("Gym class featuring a brown fox and lazy dog",
                     metadata.get(TikaCoreProperties.SUBJECT));
             assertEquals("Nevin Nollop",
-                    metadata.get(Metadata.AUTHOR));
+                    metadata.get(TikaCoreProperties.AUTHOR));
             assertEquals("Pangram, fox, dog",
-                    metadata.get(Metadata.KEYWORDS));
+                    metadata.get(TikaCoreProperties.KEYWORDS));
             assertEquals("Lorem ipsum",
                     metadata.get(Metadata.COMMENTS).substring(0,11));
             assertEquals("http://www.alfresco.com",
@@ -114,8 +114,8 @@ public class DWGParserTest extends TestCase {
             
             assertNull(metadata.get(TikaCoreProperties.TITLE));
             assertNull(metadata.get(TikaCoreProperties.SUBJECT));
-            assertNull(metadata.get(Metadata.AUTHOR));
-            assertNull(metadata.get(Metadata.KEYWORDS));
+            assertNull(metadata.get(TikaCoreProperties.AUTHOR));
+            assertNull(metadata.get(TikaCoreProperties.KEYWORDS));
             assertNull(metadata.get(Metadata.COMMENTS));
             assertNull(metadata.get(TikaCoreProperties.RELATION));
 
@@ -139,9 +139,9 @@ public class DWGParserTest extends TestCase {
             assertEquals("Test Subject",
                     metadata.get(TikaCoreProperties.SUBJECT));
             assertEquals("My Author",
-                    metadata.get(Metadata.AUTHOR));
+                    metadata.get(TikaCoreProperties.AUTHOR));
             assertEquals("My keyword1, MyKeyword2",
-                    metadata.get(Metadata.KEYWORDS));
+                    metadata.get(TikaCoreProperties.KEYWORDS));
             assertEquals("This is a comment",
                     metadata.get(Metadata.COMMENTS));
             assertEquals("bejanpol",
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
index b53b4963c..0059bd9d1 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
@@ -23,6 +23,7 @@ import java.util.List;
 import junit.framework.TestCase;
 
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.Office;
 import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.AutoDetectParser;
 import org.apache.tika.parser.ParseContext;
@@ -57,15 +58,16 @@ public class IWorkParserTest extends TestCase {
         List<String> metadataKeys = Arrays.asList(metadata.names());
         assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.CONTENT_TYPE));
         assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.SLIDE_COUNT.getName()));
-        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.AUTHOR));
-        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.TITLE));
+//        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Office.SLIDE_COUNT.getName()));
+        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(TikaCoreProperties.AUTHOR.getName()));
+        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(TikaCoreProperties.TITLE.getName()));
         
         // Check the metadata values
         assertEquals("application/vnd.apple.keynote", metadata.get(Metadata.CONTENT_TYPE));
         assertEquals("3", metadata.get(Metadata.SLIDE_COUNT));
         assertEquals("1024", metadata.get(KeynoteContentHandler.PRESENTATION_WIDTH));
         assertEquals("768", metadata.get(KeynoteContentHandler.PRESENTATION_HEIGHT));
-        assertEquals("Tika user", metadata.get(Metadata.AUTHOR));
+        assertEquals("Tika user", metadata.get(TikaCoreProperties.AUTHOR));
         assertEquals("Apache tika", metadata.get(TikaCoreProperties.TITLE));
 
         String content = handler.toString();
@@ -100,14 +102,14 @@ public class IWorkParserTest extends TestCase {
         List<String> metadataKeys = Arrays.asList(metadata.names());
         assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.CONTENT_TYPE));
         assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.PAGE_COUNT.getName()));
-        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.AUTHOR));
-        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.TITLE));
+        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(TikaCoreProperties.AUTHOR.getName()));
+        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(TikaCoreProperties.TITLE.getName()));
         assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.LAST_MODIFIED.getName()));
         assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.LANGUAGE));
         
         // Check the metadata values
         assertEquals("application/vnd.apple.pages", metadata.get(Metadata.CONTENT_TYPE));
-        assertEquals("Tika user", metadata.get(Metadata.AUTHOR));
+        assertEquals("Tika user", metadata.get(TikaCoreProperties.AUTHOR));
         assertEquals("Apache tika", metadata.get(TikaCoreProperties.TITLE));
         assertEquals("2010-05-09T21:34:38+0200", metadata.get(Metadata.CREATION_DATE));
         assertEquals("2010-05-09T23:50:36+0200", metadata.get(Metadata.LAST_MODIFIED));
@@ -148,14 +150,14 @@ public class IWorkParserTest extends TestCase {
         List<String> metadataKeys = Arrays.asList(metadata.names());
         assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.CONTENT_TYPE));
         assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.PAGE_COUNT.getName()));
-        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.AUTHOR));
+        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(TikaCoreProperties.AUTHOR.getName()));
         assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.COMMENT));
         assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.TITLE));
         assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(TikaCoreProperties.TITLE.getName()));
         
         // Check the metadata values
         assertEquals("2", metadata.get(Metadata.PAGE_COUNT));
-        assertEquals("Tika User", metadata.get(Metadata.AUTHOR));
+        assertEquals("Tika User", metadata.get(TikaCoreProperties.AUTHOR));
         assertEquals("Account checking", metadata.get(TikaCoreProperties.TITLE));
         assertEquals("a comment", metadata.get(Metadata.COMMENT));
 
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/jpeg/JpegParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/jpeg/JpegParserTest.java
index 64d5ee835..f5e249562 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/jpeg/JpegParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/jpeg/JpegParserTest.java
@@ -144,7 +144,7 @@ public class JpegParserTest extends TestCase {
         // embedded comments with non-ascii characters
         assertEquals("Tosteberga \u00C4ngar", metadata.get(TikaCoreProperties.TITLE));
         assertEquals("Bird site in north eastern Sk\u00E5ne, Sweden.\n(new line)", metadata.get(TikaCoreProperties.DESCRIPTION));
-        assertEquals("Some Tourist", metadata.get(Metadata.AUTHOR));
+        assertEquals("Some Tourist", metadata.get(TikaCoreProperties.AUTHOR));
         assertEquals("Some Tourist", metadata.get(TikaCoreProperties.CREATOR)); // Dublin Core
         // xmp handles spaces in keywords, returns "bird watching, nature reserve, coast, grazelands"
         // but we have to replace them with underscore
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/mail/RFC822ParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/mail/RFC822ParserTest.java
index 872e2476d..5d53ec126 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/mail/RFC822ParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/mail/RFC822ParserTest.java
@@ -59,7 +59,7 @@ public class RFC822ParserTest extends TestCase {
             verify(handler, never()).endElement(XHTMLContentHandler.XHTML, "div", "div");
             verify(handler).endDocument();
             //note no leading spaces, and no quotes
-            assertEquals("Julien Nioche (JIRA) <jira@apache.org>", metadata.get(Metadata.AUTHOR));
+            assertEquals("Julien Nioche (JIRA) <jira@apache.org>", metadata.get(TikaCoreProperties.AUTHOR));
             assertEquals("[jira] Commented: (TIKA-461) RFC822 messages not parsed", metadata.get(TikaCoreProperties.SUBJECT));
         } catch (Exception e) {
             fail("Exception thrown: " + e.getMessage());
@@ -147,7 +147,7 @@ public class RFC822ParserTest extends TestCase {
             parser.parse(stream, handler, metadata, new ParseContext());
             //tests correct decoding of internationalized headers, both
             //quoted-printable (Q) and Base64 (B).
-            assertEquals("Keld J\u00F8rn Simonsen <keld@dkuug.dk>", metadata.get(Metadata.AUTHOR));
+            assertEquals("Keld J\u00F8rn Simonsen <keld@dkuug.dk>", metadata.get(TikaCoreProperties.AUTHOR));
             assertEquals("If you can read this you understand the example.", metadata.get(TikaCoreProperties.SUBJECT));
         } catch (Exception e) {
             fail("Exception thrown: " + e.getMessage());
@@ -165,7 +165,7 @@ public class RFC822ParserTest extends TestCase {
        ContentHandler handler = mock(DefaultHandler.class);
 
        parser.parse(stream, handler, metadata, new ParseContext());
-       assertEquals("Saved by Windows Internet Explorer 7", metadata.get(Metadata.AUTHOR));
+       assertEquals("Saved by Windows Internet Explorer 7", metadata.get(TikaCoreProperties.AUTHOR));
        assertEquals("Air Permit Programs | Air & Radiation | US EPA", metadata.get(TikaCoreProperties.SUBJECT));
     }
 
@@ -199,7 +199,7 @@ public class RFC822ParserTest extends TestCase {
         context.set(MimeConfig.class, config);
         parser.parse(
                 new ByteArrayInputStream(data), handler, metadata, context);
-        assertEquals(name.trim(), metadata.get(Metadata.AUTHOR));
+        assertEquals(name.trim(), metadata.get(TikaCoreProperties.AUTHOR));
     }
     
     /**
@@ -212,9 +212,9 @@ public class RFC822ParserTest extends TestCase {
        ContentHandler handler = new BodyContentHandler();
 
        parser.parse(stream, handler, metadata, new ParseContext());
-       assertEquals(true, metadata.isMultiValued(Metadata.AUTHOR));
-       assertEquals("xyz", metadata.getValues(Metadata.AUTHOR)[0]);
-       assertEquals("abc", metadata.getValues(Metadata.AUTHOR)[1]);
+       assertEquals(true, metadata.isMultiValued(TikaCoreProperties.AUTHOR));
+       assertEquals("xyz", metadata.getValues(TikaCoreProperties.AUTHOR)[0]);
+       assertEquals("abc", metadata.getValues(TikaCoreProperties.AUTHOR)[1]);
        assertEquals(true, metadata.isMultiValued(Metadata.MESSAGE_FROM));
        assertEquals("xyz", metadata.getValues(Metadata.MESSAGE_FROM)[0]);
        assertEquals("abc", metadata.getValues(Metadata.MESSAGE_FROM)[1]);
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/mbox/MboxParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/mbox/MboxParserTest.java
index fe77bc82f..982f8874e 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/mbox/MboxParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/mbox/MboxParserTest.java
@@ -72,7 +72,7 @@ public class MboxParserTest extends TestCase {
 
             assertEquals("subject", metadata.get(TikaCoreProperties.TITLE));
             assertEquals("subject", metadata.get(TikaCoreProperties.SUBJECT));
-            assertEquals("<author@domain.com>", metadata.get(Metadata.AUTHOR));
+            assertEquals("<author@domain.com>", metadata.get(TikaCoreProperties.AUTHOR));
             assertEquals("<author@domain.com>", metadata.get(TikaCoreProperties.CREATOR));
             assertEquals(null, metadata.get(Metadata.MESSAGE_RECIPIENT_ADDRESS));
             assertEquals("<name@domain.com>", metadata.get("MboxParser-return-path"));
@@ -136,7 +136,7 @@ public class MboxParserTest extends TestCase {
 
             assertEquals("Re: question about when shuffle/sort start working", metadata.get(TikaCoreProperties.TITLE));
             assertEquals("Re: question about when shuffle/sort start working", metadata.get(TikaCoreProperties.SUBJECT));
-            assertEquals("Jothi Padmanabhan <jothipn@yahoo-inc.com>", metadata.get(Metadata.AUTHOR));
+            assertEquals("Jothi Padmanabhan <jothipn@yahoo-inc.com>", metadata.get(TikaCoreProperties.AUTHOR));
             assertEquals("Jothi Padmanabhan <jothipn@yahoo-inc.com>", metadata.get(TikaCoreProperties.CREATOR));
             assertEquals("core-user@hadoop.apache.org", metadata.get(Metadata.MESSAGE_RECIPIENT_ADDRESS));
             
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ExcelParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ExcelParserTest.java
index 2bab716af..d191ad88f 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ExcelParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ExcelParserTest.java
@@ -47,13 +47,13 @@ public class ExcelParserTest extends TestCase {
                     "application/vnd.ms-excel",
                     metadata.get(Metadata.CONTENT_TYPE));
             assertEquals("Simple Excel document", metadata.get(TikaCoreProperties.TITLE));
-            assertEquals("Keith Bennett", metadata.get(Metadata.AUTHOR));
+            assertEquals("Keith Bennett", metadata.get(TikaCoreProperties.AUTHOR));
             
             // Mon Oct 01 17:13:56 BST 2007
-            assertEquals("2007-10-01T16:13:56Z", metadata.get(Metadata.CREATION_DATE));
+            assertEquals("2007-10-01T16:13:56Z", metadata.get(TikaCoreProperties.CREATION_DATE));
             
             // Mon Oct 01 17:31:43 BST 2007
-            assertEquals("2007-10-01T16:31:43Z", metadata.get(Metadata.LAST_SAVED));
+            assertEquals("2007-10-01T16:31:43Z", metadata.get(TikaCoreProperties.SAVE_DATE));
             
             String content = handler.toString();
             assertTrue(content.contains("Sample Excel Worksheet"));
@@ -280,10 +280,10 @@ public class ExcelParserTest extends TestCase {
        }
        
        assertEquals("application/vnd.ms-excel", metadata.get(Metadata.CONTENT_TYPE));
-       assertEquals("",                     metadata.get(Metadata.AUTHOR));
-       assertEquals("",                     metadata.get(Metadata.LAST_AUTHOR));
-       assertEquals("2011-08-22T13:45:54Z", metadata.get(Metadata.LAST_SAVED));
-       assertEquals("2006-09-12T15:06:44Z", metadata.get(Metadata.CREATION_DATE));
+       assertEquals("",                     metadata.get(TikaCoreProperties.AUTHOR));
+       assertEquals("",                     metadata.get(TikaCoreProperties.LAST_AUTHOR));
+       assertEquals("2011-08-22T13:45:54Z", metadata.get(TikaCoreProperties.SAVE_DATE));
+       assertEquals("2006-09-12T15:06:44Z", metadata.get(TikaCoreProperties.CREATION_DATE));
        assertEquals("Microsoft Excel",      metadata.get(Metadata.APPLICATION_NAME));
        assertEquals("true",                 metadata.get("custom:myCustomBoolean"));
        assertEquals("3",                    metadata.get("custom:myCustomNumber"));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/OutlookParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/OutlookParserTest.java
index 3ba40655d..d9b397447 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/OutlookParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/OutlookParserTest.java
@@ -65,7 +65,7 @@ public class OutlookParserTest extends TestCase {
                 metadata.get(Metadata.MESSAGE_RECIPIENT_ADDRESS));
         assertEquals(
                 "L'\u00C9quipe Microsoft Outlook Express",
-                metadata.get(Metadata.AUTHOR));
+                metadata.get(TikaCoreProperties.AUTHOR));
         
         // Stored as Thu, 5 Apr 2007 09:26:06 -0700
         assertEquals(
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PowerPointParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PowerPointParserTest.java
index 27617dde8..47c820212 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PowerPointParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PowerPointParserTest.java
@@ -21,6 +21,7 @@ import java.util.Locale;
 
 import org.apache.tika.TikaTest;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.Office;
 import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.sax.BodyContentHandler;
@@ -40,7 +41,7 @@ public class PowerPointParserTest extends TikaTest {
                     "application/vnd.ms-powerpoint",
                     metadata.get(Metadata.CONTENT_TYPE));
             assertEquals("Sample Powerpoint Slide", metadata.get(TikaCoreProperties.TITLE));
-            assertEquals("Keith Bennett", metadata.get(Metadata.AUTHOR));
+            assertEquals("Keith Bennett", metadata.get(TikaCoreProperties.AUTHOR));
             String content = handler.toString();
             assertTrue(content.contains("Sample Powerpoint Slide"));
             assertTrue(content.contains("Powerpoint X for Mac"));
@@ -198,12 +199,12 @@ public class PowerPointParserTest extends TikaTest {
        }
        
        assertEquals("application/vnd.ms-powerpoint", metadata.get(Metadata.CONTENT_TYPE));
-       assertEquals("JOUVIN ETIENNE",       metadata.get(Metadata.AUTHOR));
-       assertEquals("EJ04325S",             metadata.get(Metadata.LAST_AUTHOR));
-       assertEquals("2011-08-22T13:32:58Z", metadata.get(Metadata.LAST_SAVED));
-       assertEquals("2011-08-22T13:30:53Z", metadata.get(Metadata.CREATION_DATE));
-       assertEquals("1",                    metadata.get(Metadata.SLIDE_COUNT));
-       assertEquals("3",                    metadata.get(Metadata.WORD_COUNT));
+       assertEquals("JOUVIN ETIENNE",       metadata.get(TikaCoreProperties.AUTHOR));
+       assertEquals("EJ04325S",             metadata.get(TikaCoreProperties.LAST_AUTHOR));
+       assertEquals("2011-08-22T13:32:58Z", metadata.get(TikaCoreProperties.SAVE_DATE));
+       assertEquals("2011-08-22T13:30:53Z", metadata.get(TikaCoreProperties.CREATION_DATE));
+       assertEquals("1",                    metadata.get(Office.SLIDE_COUNT));
+       assertEquals("3",                    metadata.get(Office.WORD_COUNT));
        assertEquals("Test extraction properties pptx", metadata.get(TikaCoreProperties.TITLE));
        assertEquals("true",                 metadata.get("custom:myCustomBoolean"));
        assertEquals("3",                    metadata.get("custom:myCustomNumber"));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ProjectParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ProjectParserTest.java
index 696f2f057..8a9ff2c5f 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ProjectParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ProjectParserTest.java
@@ -64,9 +64,9 @@ public class ProjectParserTest extends TestCase {
        
        assertEquals("The quick brown fox jumps over the lazy dog", metadata.get(TikaCoreProperties.TITLE));
        assertEquals("Gym class featuring a brown fox and lazy dog", metadata.get(TikaCoreProperties.SUBJECT));
-       assertEquals("Nevin Nollop", metadata.get(Metadata.AUTHOR));
-       assertEquals("", metadata.get(Metadata.LAST_AUTHOR));
-       assertEquals("Pangram, fox, dog", metadata.get(Metadata.KEYWORDS));
+       assertEquals("Nevin Nollop", metadata.get(TikaCoreProperties.AUTHOR));
+       assertEquals("", metadata.get(TikaCoreProperties.LAST_AUTHOR));
+       assertEquals("Pangram, fox, dog", metadata.get(TikaCoreProperties.KEYWORDS));
        assertEquals("Comment Vulpes vulpes comment", metadata.get(Metadata.COMMENTS));
        
        assertEquals("Category1", metadata.get(Metadata.CATEGORY));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PublisherParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PublisherParserTest.java
index b31d8eb8b..27de34f11 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PublisherParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PublisherParserTest.java
@@ -40,7 +40,7 @@ public class PublisherParserTest extends TestCase {
                     "application/x-mspublisher",
                     metadata.get(Metadata.CONTENT_TYPE));
             assertEquals(null, metadata.get(TikaCoreProperties.TITLE));
-            assertEquals("Nick Burch", metadata.get(Metadata.AUTHOR));
+            assertEquals("Nick Burch", metadata.get(TikaCoreProperties.AUTHOR));
             String content = handler.toString();
             assertTrue(content.contains("0123456789"));
             assertTrue(content.contains("abcdef"));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/VisioParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/VisioParserTest.java
index 6a026aaaa..0b5507028 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/VisioParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/VisioParserTest.java
@@ -40,7 +40,7 @@ public class VisioParserTest extends TestCase {
                     "application/vnd.visio",
                     metadata.get(Metadata.CONTENT_TYPE));
             assertEquals("", metadata.get(TikaCoreProperties.TITLE));
-            assertEquals("Hogwarts", metadata.get(Metadata.AUTHOR));
+            assertEquals("Hogwarts", metadata.get(TikaCoreProperties.AUTHOR));
             String content = handler.toString();
             assertTrue(content.contains("Some random text, on a page"));
         } finally {
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/WordParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/WordParserTest.java
index c8e8e5f69..e3cf468b0 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/WordParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/WordParserTest.java
@@ -27,6 +27,7 @@ import javax.xml.transform.stream.StreamResult;
 
 import org.apache.tika.TikaTest;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.Office;
 import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.parser.microsoft.ooxml.OOXMLParserTest;
@@ -47,7 +48,7 @@ public class WordParserTest extends TikaTest {
                     "application/msword",
                     metadata.get(Metadata.CONTENT_TYPE));
             assertEquals("Sample Word Document", metadata.get(TikaCoreProperties.TITLE));
-            assertEquals("Keith Bennett", metadata.get(Metadata.AUTHOR));
+            assertEquals("Keith Bennett", metadata.get(TikaCoreProperties.AUTHOR));
             assertTrue(handler.toString().contains("Sample Word Document"));
         } finally {
             input.close();
@@ -116,7 +117,7 @@ public class WordParserTest extends TikaTest {
                      "application/msword",
                      metadata.get(Metadata.CONTENT_TYPE));
         assertEquals("Sample Word Document", metadata.get(TikaCoreProperties.TITLE));
-        assertEquals("Keith Bennett", metadata.get(Metadata.AUTHOR));
+        assertEquals("Keith Bennett", metadata.get(TikaCoreProperties.AUTHOR));
         assertTrue(xml.contains("Sample Word Document"));
 
         // Check that custom headings came through
@@ -179,7 +180,7 @@ public class WordParserTest extends TikaTest {
                     metadata.get(Metadata.CONTENT_TYPE));
             assertEquals("The quick brown fox jumps over the lazy dog", metadata.get(TikaCoreProperties.TITLE));
             assertEquals("Gym class featuring a brown fox and lazy dog", metadata.get(TikaCoreProperties.SUBJECT));
-            assertEquals("Nevin Nollop", metadata.get(Metadata.AUTHOR));
+            assertEquals("Nevin Nollop", metadata.get(TikaCoreProperties.AUTHOR));
             assertTrue(handler.toString().contains("The quick brown fox jumps over the lazy dog"));
         } finally {
             input.close();
@@ -272,15 +273,15 @@ public class WordParserTest extends TikaTest {
        }
        
        assertEquals("application/msword",   metadata.get(Metadata.CONTENT_TYPE));
-       assertEquals("EJ04325S",             metadata.get(Metadata.AUTHOR));
-       assertEquals("Etienne Jouvin",       metadata.get(Metadata.LAST_AUTHOR));
-       assertEquals("2012-01-03T22:14:00Z", metadata.get(Metadata.LAST_SAVED));
-       assertEquals("2010-10-05T09:03:00Z", metadata.get(Metadata.CREATION_DATE));
+       assertEquals("EJ04325S",             metadata.get(TikaCoreProperties.AUTHOR));
+       assertEquals("Etienne Jouvin",       metadata.get(TikaCoreProperties.LAST_AUTHOR));
+       assertEquals("2012-01-03T22:14:00Z", metadata.get(TikaCoreProperties.SAVE_DATE));
+       assertEquals("2010-10-05T09:03:00Z", metadata.get(TikaCoreProperties.CREATION_DATE));
        assertEquals("Microsoft Office Word",metadata.get(Metadata.APPLICATION_NAME));
-       assertEquals("1",                    metadata.get(Metadata.PAGE_COUNT));
-       assertEquals("2",                    metadata.get(Metadata.WORD_COUNT));
+       assertEquals("1",                    metadata.get(Office.PAGE_COUNT));
+       assertEquals("2",                    metadata.get(Office.WORD_COUNT));
        assertEquals("My Title",             metadata.get(TikaCoreProperties.TITLE));
-       assertEquals("My Keyword",           metadata.get(Metadata.KEYWORDS));
+       assertEquals("My Keyword",           metadata.get(TikaCoreProperties.KEYWORDS));
        assertEquals("Normal.dotm",          metadata.get(Metadata.TEMPLATE));
        assertEquals("My Comments",          metadata.get(Metadata.COMMENTS));
        assertEquals("My subject",           metadata.get(TikaCoreProperties.SUBJECT));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
index 1f90e1bef..0f4ec856c 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
@@ -28,6 +28,7 @@ import javax.xml.transform.stream.StreamResult;
 import org.apache.tika.TikaTest;
 import org.apache.tika.io.TikaInputStream;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.Office;
 import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.metadata.TikaMetadataKeys;
 import org.apache.tika.parser.AutoDetectParser;
@@ -59,7 +60,7 @@ public class OOXMLParserTest extends TikaTest {
                     "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                     metadata.get(Metadata.CONTENT_TYPE));
             assertEquals("Simple Excel document", metadata.get(TikaCoreProperties.TITLE));
-            assertEquals("Keith Bennett", metadata.get(Metadata.AUTHOR));
+            assertEquals("Keith Bennett", metadata.get(TikaCoreProperties.AUTHOR));
             String content = handler.toString();
             assertTrue(content.contains("Sample Excel Worksheet"));
             assertTrue(content.contains("Numbers and their Squares"));
@@ -186,7 +187,7 @@ public class OOXMLParserTest extends TikaTest {
                         mimeTypes[i],
                         metadata.get(Metadata.CONTENT_TYPE));
                 assertEquals("Attachment Test", metadata.get(TikaCoreProperties.TITLE));
-                assertEquals("Rajiv", metadata.get(Metadata.AUTHOR));
+                assertEquals("Rajiv", metadata.get(TikaCoreProperties.AUTHOR));
                 
                 String content = handler.toString();
                 // Theme files don't have the text in them
@@ -275,7 +276,7 @@ public class OOXMLParserTest extends TikaTest {
                     "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                     metadata.get(Metadata.CONTENT_TYPE));
             assertEquals("Sample Word Document", metadata.get(TikaCoreProperties.TITLE));
-            assertEquals("Keith Bennett", metadata.get(Metadata.AUTHOR));
+            assertEquals("Keith Bennett", metadata.get(TikaCoreProperties.AUTHOR));
             assertTrue(handler.toString().contains("Sample Word Document"));
         } finally {
             input.close();
@@ -346,7 +347,7 @@ public class OOXMLParserTest extends TikaTest {
                    "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                    metadata.get(Metadata.CONTENT_TYPE));
       assertEquals("Sample Word Document", metadata.get(TikaCoreProperties.TITLE));
-      assertEquals("Keith Bennett", metadata.get(Metadata.AUTHOR));
+      assertEquals("Keith Bennett", metadata.get(TikaCoreProperties.AUTHOR));
       assertTrue(xml.contains("Sample Word Document"));
             
       // Check that custom headings came through
@@ -728,8 +729,8 @@ public class OOXMLParserTest extends TikaTest {
        assertEquals(
              "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", 
              metadata.get(Metadata.CONTENT_TYPE));
-       assertEquals(null,                   metadata.get(Metadata.AUTHOR));
-       assertEquals(null,                   metadata.get(Metadata.LAST_AUTHOR));
+       assertEquals(null,                   metadata.get(TikaCoreProperties.AUTHOR));
+       assertEquals(null,                   metadata.get(TikaCoreProperties.LAST_AUTHOR));
        assertEquals("2006-09-12T15:06:44Z", metadata.get(TikaCoreProperties.DATE));
        assertEquals("2006-09-12T15:06:44Z", metadata.get(Metadata.CREATION_DATE));
        assertEquals("2011-08-22T14:24:38Z", metadata.get(Metadata.LAST_MODIFIED));
@@ -757,16 +758,16 @@ public class OOXMLParserTest extends TikaTest {
        assertEquals(
              "application/vnd.openxmlformats-officedocument.wordprocessingml.document", 
              metadata.get(Metadata.CONTENT_TYPE));
-       assertEquals("EJ04325S",             metadata.get(Metadata.AUTHOR));
-       assertEquals("Etienne Jouvin",       metadata.get(Metadata.LAST_AUTHOR));
+       assertEquals("EJ04325S",             metadata.get(TikaCoreProperties.AUTHOR));
+       assertEquals("Etienne Jouvin",       metadata.get(TikaCoreProperties.LAST_AUTHOR));
        assertEquals("2011-07-29T16:52:00Z", metadata.get(TikaCoreProperties.DATE));
-       assertEquals("2011-07-29T16:52:00Z", metadata.get(Metadata.CREATION_DATE));
-       assertEquals("2012-01-03T22:14:00Z", metadata.get(Metadata.LAST_MODIFIED));
+       assertEquals("2011-07-29T16:52:00Z", metadata.get(TikaCoreProperties.CREATION_DATE));
+       assertEquals("2012-01-03T22:14:00Z", metadata.get(TikaCoreProperties.MODIFIED));
        assertEquals("Microsoft Office Word",metadata.get(Metadata.APPLICATION_NAME));
-       assertEquals("1",                    metadata.get(Metadata.PAGE_COUNT));
-       assertEquals("2",                    metadata.get(Metadata.WORD_COUNT));
+       assertEquals("1",                    metadata.get(Office.PAGE_COUNT));
+       assertEquals("2",                    metadata.get(Office.WORD_COUNT));
        assertEquals("My Title",             metadata.get(TikaCoreProperties.TITLE));
-       assertEquals("My Keyword",           metadata.get(Metadata.KEYWORDS));
+       assertEquals("My Keyword",           metadata.get(TikaCoreProperties.KEYWORDS));
        assertEquals("Normal.dotm",          metadata.get(Metadata.TEMPLATE));
        assertEquals("My subject",           metadata.get(TikaCoreProperties.SUBJECT));
        assertEquals("EDF-DIT",              metadata.get(TikaCoreProperties.PUBLISHER));
@@ -793,13 +794,13 @@ public class OOXMLParserTest extends TikaTest {
        assertEquals(
              "application/vnd.openxmlformats-officedocument.presentationml.presentation", 
              metadata.get(Metadata.CONTENT_TYPE));
-       assertEquals("JOUVIN ETIENNE",       metadata.get(Metadata.AUTHOR));
-       assertEquals("EJ04325S",             metadata.get(Metadata.LAST_AUTHOR));
+       assertEquals("JOUVIN ETIENNE",       metadata.get(TikaCoreProperties.AUTHOR));
+       assertEquals("EJ04325S",             metadata.get(TikaCoreProperties.LAST_AUTHOR));
        assertEquals("2011-08-22T13:30:53Z", metadata.get(TikaCoreProperties.DATE));
-       assertEquals("2011-08-22T13:30:53Z", metadata.get(Metadata.CREATION_DATE));
-       assertEquals("2011-08-22T13:32:49Z", metadata.get(Metadata.LAST_MODIFIED));
-       assertEquals("1",                    metadata.get(Metadata.SLIDE_COUNT));
-       assertEquals("3",                    metadata.get(Metadata.WORD_COUNT));
+       assertEquals("2011-08-22T13:30:53Z", metadata.get(TikaCoreProperties.CREATION_DATE));
+       assertEquals("2011-08-22T13:32:49Z", metadata.get(TikaCoreProperties.MODIFIED));
+       assertEquals("1",                    metadata.get(Office.SLIDE_COUNT));
+       assertEquals("3",                    metadata.get(Office.WORD_COUNT));
        assertEquals("Test extraction properties pptx", metadata.get(TikaCoreProperties.TITLE));
        assertEquals("true",                 metadata.get("custom:myCustomBoolean"));
        assertEquals("3",                    metadata.get("custom:myCustomNumber"));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/mp3/Mp3ParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/mp3/Mp3ParserTest.java
index be528287c..12bba017c 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/mp3/Mp3ParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/mp3/Mp3ParserTest.java
@@ -53,7 +53,7 @@ public class Mp3ParserTest extends TestCase {
 
         assertEquals("audio/mpeg", metadata.get(Metadata.CONTENT_TYPE));
         assertEquals("Test Title", metadata.get(TikaCoreProperties.TITLE));
-        assertEquals("Test Artist", metadata.get(Metadata.AUTHOR));
+        assertEquals("Test Artist", metadata.get(TikaCoreProperties.AUTHOR));
 
         String content = handler.toString();
         assertTrue(content.contains("Test Title"));
@@ -88,7 +88,7 @@ public class Mp3ParserTest extends TestCase {
         // Check core properties
         assertEquals("audio/mpeg", metadata.get(Metadata.CONTENT_TYPE));
         assertEquals("Test Title", metadata.get(TikaCoreProperties.TITLE));
-        assertEquals("Test Artist", metadata.get(Metadata.AUTHOR));
+        assertEquals("Test Artist", metadata.get(TikaCoreProperties.AUTHOR));
 
         // Check the textual contents
         String content = handler.toString();
@@ -137,7 +137,7 @@ public class Mp3ParserTest extends TestCase {
 
         assertEquals("audio/mpeg", metadata.get(Metadata.CONTENT_TYPE));
         assertEquals("Test Title", metadata.get(TikaCoreProperties.TITLE));
-        assertEquals("Test Artist", metadata.get(Metadata.AUTHOR));
+        assertEquals("Test Artist", metadata.get(TikaCoreProperties.AUTHOR));
 
         String content = handler.toString();
         assertTrue(content.contains("Test Title"));
@@ -171,7 +171,7 @@ public class Mp3ParserTest extends TestCase {
 
         assertEquals("audio/mpeg", metadata.get(Metadata.CONTENT_TYPE));
         assertEquals("Test Title", metadata.get(TikaCoreProperties.TITLE));
-        assertEquals("Test Artist", metadata.get(Metadata.AUTHOR));
+        assertEquals("Test Artist", metadata.get(TikaCoreProperties.AUTHOR));
 
         String content = handler.toString();
         assertTrue(content.contains("Test Title"));
@@ -205,7 +205,7 @@ public class Mp3ParserTest extends TestCase {
 
        assertEquals("audio/mpeg", metadata.get(Metadata.CONTENT_TYPE));
        assertEquals("Une chason en Fran\u00e7ais", metadata.get(TikaCoreProperties.TITLE));
-       assertEquals("Test Artist \u2468\u2460", metadata.get(Metadata.AUTHOR));
+       assertEquals("Test Artist \u2468\u2460", metadata.get(TikaCoreProperties.AUTHOR));
        assertEquals("Test Artist \u2468\u2460", metadata.get(XMPDM.ARTIST));
        assertEquals("Test Album \u2460\u2468", metadata.get(XMPDM.ALBUM));
 
@@ -243,7 +243,7 @@ public class Mp3ParserTest extends TestCase {
 
         assertEquals("audio/mpeg", metadata.get(Metadata.CONTENT_TYPE));
         assertEquals("Test Title", metadata.get(TikaCoreProperties.TITLE));
-        assertEquals("Test Artist", metadata.get(Metadata.AUTHOR));
+        assertEquals("Test Artist", metadata.get(TikaCoreProperties.AUTHOR));
 
         String content = handler.toString();
         assertTrue(content.contains("Test Title"));
@@ -308,7 +308,7 @@ public class Mp3ParserTest extends TestCase {
 
        assertEquals("audio/mpeg", metadata.get(Metadata.CONTENT_TYPE));
        assertEquals("Plus loin vers l'ouest", metadata.get(TikaCoreProperties.TITLE));
-       assertEquals("Merzhin", metadata.get(Metadata.AUTHOR));
+       assertEquals("Merzhin", metadata.get(TikaCoreProperties.AUTHOR));
 
        String content = handler.toString();
        assertTrue(content.contains("Plus loin vers l'ouest"));
@@ -343,7 +343,7 @@ public class Mp3ParserTest extends TestCase {
        // Check we coud get the headers from the start
        assertEquals("audio/mpeg", metadata.get(Metadata.CONTENT_TYPE));
        assertEquals("Girl you have no faith in medicine", metadata.get(TikaCoreProperties.TITLE));
-       assertEquals("The White Stripes", metadata.get(Metadata.AUTHOR));
+       assertEquals("The White Stripes", metadata.get(TikaCoreProperties.AUTHOR));
 
        String content = handler.toString();
        assertTrue(content.contains("Girl you have no faith in medicine"));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/mp4/MP4ParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/mp4/MP4ParserTest.java
index 396db5b02..2a69e9613 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/mp4/MP4ParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/mp4/MP4ParserTest.java
@@ -54,8 +54,8 @@ public class MP4ParserTest extends TestCase {
         // Check core properties
         assertEquals("audio/mp4", metadata.get(Metadata.CONTENT_TYPE));
         assertEquals("Test Title", metadata.get(TikaCoreProperties.TITLE));
-        assertEquals("Test Artist", metadata.get(Metadata.AUTHOR));
-        assertEquals("2012-01-28T18:39:18Z", metadata.get(Metadata.CREATION_DATE));
+        assertEquals("Test Artist", metadata.get(TikaCoreProperties.AUTHOR));
+        assertEquals("2012-01-28T18:39:18Z", metadata.get(TikaCoreProperties.CREATION_DATE));
         assertEquals("2012-01-28T18:40:25Z", metadata.get(TikaCoreProperties.MODIFIED));
 
         // Check the textual contents
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java
index 17d8278c4..8a7f659c4 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java
@@ -53,7 +53,7 @@ public class PDFParserTest extends TikaTest {
         }
 
         assertEquals("application/pdf", metadata.get(Metadata.CONTENT_TYPE));
-        assertEquals("Bertrand Delacr\u00e9taz", metadata.get(Metadata.AUTHOR));
+        assertEquals("Bertrand Delacr\u00e9taz", metadata.get(TikaCoreProperties.AUTHOR));
         assertEquals("Apache Tika - Apache Tika", metadata.get(TikaCoreProperties.TITLE));
         
         // Can't reliably test dates yet - see TIKA-451 
@@ -87,7 +87,7 @@ public class PDFParserTest extends TikaTest {
         }
 
         assertEquals("application/pdf", metadata.get(Metadata.CONTENT_TYPE));
-        assertEquals("Document author", metadata.get(Metadata.AUTHOR));
+        assertEquals("Document author", metadata.get(TikaCoreProperties.AUTHOR));
         assertEquals("Document title", metadata.get(TikaCoreProperties.TITLE));
         
         assertEquals("Custom Value", metadata.get("Custom Property"));
@@ -120,7 +120,7 @@ public class PDFParserTest extends TikaTest {
        }
 
        assertEquals("application/pdf", metadata.get(Metadata.CONTENT_TYPE));
-       assertEquals("The Bank of England", metadata.get(Metadata.AUTHOR));
+       assertEquals("The Bank of England", metadata.get(TikaCoreProperties.AUTHOR));
        assertEquals("Speeches by Andrew G Haldane", metadata.get(TikaCoreProperties.SUBJECT));
        assertEquals("Rethinking the Financial Network, Speech by Andrew G Haldane, Executive Director, Financial Stability delivered at the Financial Student Association, Amsterdam on 28 April 2009", metadata.get(TikaCoreProperties.TITLE));
 
@@ -150,7 +150,7 @@ public class PDFParserTest extends TikaTest {
        }
 
        assertEquals("application/pdf", metadata.get(Metadata.CONTENT_TYPE));
-       assertEquals("The Bank of England", metadata.get(Metadata.AUTHOR));
+       assertEquals("The Bank of England", metadata.get(TikaCoreProperties.AUTHOR));
        assertEquals("Speeches by Andrew G Haldane", metadata.get(TikaCoreProperties.SUBJECT));
        assertEquals("Rethinking the Financial Network, Speech by Andrew G Haldane, Executive Director, Financial Stability delivered at the Financial Student Association, Amsterdam on 28 April 2009", metadata.get(TikaCoreProperties.TITLE));
 
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/rtf/RTFParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/rtf/RTFParserTest.java
index f1f6387e8..6615a2a44 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/rtf/RTFParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/rtf/RTFParserTest.java
@@ -155,7 +155,7 @@ public class RTFParserTest extends TikaTest {
         // title info field:
         assertEquals("\u30be\u30eb\u30b2\u3068\u5c3e\u5d0e\u3001\u6de1\u3005\u3068\u6700\u671f\u3000",
                      r.metadata.get(TikaCoreProperties.TITLE));
-        assertEquals("VMazel", r.metadata.get(Metadata.AUTHOR));
+        assertEquals("VMazel", r.metadata.get(TikaCoreProperties.AUTHOR));
         assertEquals("StarWriter", r.metadata.get(Metadata.COMMENT));
         assertContains("1.", content);
         assertContains("4.", content);
@@ -264,7 +264,7 @@ public class RTFParserTest extends TikaTest {
 
         assertContains("Keyword1 Keyword2", content);
         assertEquals("Keyword1 Keyword2",
-                     r.metadata.get(Metadata.KEYWORDS));
+                     r.metadata.get(TikaCoreProperties.KEYWORDS));
 
         assertContains("Subject is here", content);
         assertEquals("Subject is here",

Commit:
a0e2a5e1fda9e321ea725dabf2c6219af9a0d6ec
Nick Burch
nick@apache.org
2012-05-17 20:56:05 +0000
TIKA-929 Bring across MSOffice.AUTHOR in the same way as initial and last authors
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/MSOffice.java b/tika-core/src/main/java/org/apache/tika/metadata/MSOffice.java
index caf84fedb..5b748090d 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/MSOffice.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/MSOffice.java
@@ -30,14 +30,14 @@ public interface MSOffice {
 
     @Deprecated String LAST_AUTHOR = "Last-Author";
 
+    @Deprecated String AUTHOR = "Author";
+
     String APPLICATION_NAME = "Application-Name";
 
     String REVISION_NUMBER = "Revision-Number";
 
     String TEMPLATE = "Template";
 
-    String AUTHOR = "Author";
-
     String TOTAL_TIME = "Total-Time";
 
     String PRESENTATION_FORMAT = "Presentation-Format";
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/Office.java b/tika-core/src/main/java/org/apache/tika/metadata/Office.java
index fce76a608..c095d7777 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/Office.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/Office.java
@@ -60,6 +60,12 @@ public interface Office {
    Property LAST_AUTHOR = Property.internalText(
          PREFIX_DOC_META + Metadata.NAMESPACE_PREFIX_DELIMITER + "last-author");
 
+   /**
+    * Name of the principal author of a document
+    */
+   Property AUTHOR = Property.internalText(
+         PREFIX_DOC_META + Metadata.NAMESPACE_PREFIX_DELIMITER + "author");
+
    
    /** When was the document created? */
    Property CREATION_DATE = Property.internalDate(
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/TikaCoreProperties.java b/tika-core/src/main/java/org/apache/tika/metadata/TikaCoreProperties.java
index d23f11629..20fd51923 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/TikaCoreProperties.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/TikaCoreProperties.java
@@ -71,6 +71,11 @@ public interface TikaCoreProperties {
      */
     public static final Property INITIAL_AUTHOR = Office.INITIAL_AUTHOR;
 
+    /**
+     * @see Office#AUTHOR
+     */
+    public static final Property AUTHOR = Office.AUTHOR;
+
     /**
      * @see Office#LAST_AUTHOR
      */

Commit:
a63b29900a9bc4543c5d5c0eb31c2735ebd65e25
Nick Burch
nick@apache.org
2012-05-17 20:31:58 +0000
TIKA-842 Patch from Ray Gauss to split out the Photoshop and XMP Rights namespaces, and updates IPTC to use the new DublinCore properties (plus fix inconsistent indents)
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/IPTC.java b/tika-core/src/main/java/org/apache/tika/metadata/IPTC.java
index 2e3b3cddd..95d1bf3ae 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/IPTC.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/IPTC.java
@@ -21,1270 +21,1274 @@
 package org.apache.tika.metadata;
 
 /**
- * IPTC Photo Metadata schema. This is a collection of
- * {@link Property property definition} constants for the Photo Metadata
+ * IPTC photo metadata schema.
+ * 
+ * A collection of
+ * {@link Property property definition} constants for the photo metadata
  * properties defined in the IPTC standard.
  * 
- * Note - the Properties with the _DCPROPERTY are expected to change shortly
- *
  * @since Apache Tika 1.1
  * @see <a href="http://www.iptc.org/std/photometadata/specification/IPTC-PhotoMetadata-201007_1.pdf">IPTC Photo Metadata</a>
  */
 public interface IPTC {
 
-	String NAMESPACE_URI_DC = "http://purl.org/dc/elements/1.1/";
-	String NAMESPACE_URI_IPTC_CORE = "http://iptc.org/std/Iptc4xmpCore/1.0/xmlns/";
-	String NAMESPACE_URI_IPTC_EXT = "http://iptc.org/std/Iptc4xmpExt/2008-02-29/";
-	String NAMESPACE_URI_PHOTOSHOP = "http://ns.adobe.com/photoshop/1.0/";
-	String NAMESPACE_URI_PLUS = "http://ns.useplus.org/ldf/xmp/1.0/";
-	String NAMESPACE_URI_XMP_RIGHTS = "http://ns.adobe.com/xap/1.0/rights/";
-
-	String PREFIX_DC = "dc";
-	String PREFIX_IPTC_CORE = "Iptc4xmpCore";
-	String PREFIX_IPTC_EXT = "Iptc4xmpExt";
-	String PREFIX_PHOTOSHOP = "photoshop";
-	String PREFIX_PLUS = "plus";
-	String PREFIX_XMP_RIGHTS = "xmpRights";
-
-	String PREFIX_DELIMITER = ":";
-
-	/**
-	 * Name of the city the content is focussing on -- either the place shown
-	 * in visual media or referenced by text or audio media. This element is at
-	 * the third level of a top-down geographical hierarchy.
-	 * <p>
-	 * This is a detail of a location with blurred semantics as it does not
-	 * clearly indicate whether it is the location in the image or the location
-	 * the photo was taken - which can be different. Two more concise properties
-	 * are available in IPTC Extension with Location Created and Location Shown
-	 * in the Image.
-	 * <p>
-	 * Maps to this IIM property: 2:90 City
-	 */
-	Property CITY = Property.internalText(
-			PREFIX_PHOTOSHOP + PREFIX_DELIMITER + "City");
-
-	/**
-	 * Full name of the country the content is focussing on -- either the
-	 * country shown in visual media or referenced in text or audio media. This
-	 * element is at the top/first level of a top- down geographical hierarchy.
-	 * The full name should be expressed as a verbal name and not as a code, a
-	 * code should go to the element "CountryCode"
-	 * <p>
-	 * This is a detail of a location with blurred semantics as it does not
-	 * clearly indicate whether it is the location in the image or the location
-	 * the photo was taken - which can be different. Two more concise properties
-	 * are available in IPTC Extension with Location Created and Location Shown
-	 * in the Image.
-	 * <p>
-	 * Maps to this IIM property: 2:101 Country/Primary Location Name
-	 */
-	Property COUNTRY = Property.internalText(
-			PREFIX_PHOTOSHOP + PREFIX_DELIMITER + "Country");
-
-	/**
-	 * Code of the country the content is focussing on -- either the country
-	 * shown in visual media or referenced in text or audio media. This element
-	 * is at the top/first level of a top-down geographical hierarchy. The code
-	 * should be taken from ISO 3166 two or three letter code. The full name of
-	 * a country should go to the "Country" element.
-	 * <p>
-	 * This is a detail of a location with blurred semantics as it does not
-	 * clearly indicate whether it is the location in the image or the location
-	 * the photo was taken - which can be different. Two more concise properties
-	 * are available in IPTC Extension with Location Created and Location Shown
-	 * in the Image.
-	 * <p>
-	 * Maps to this IIM property: 2:100 Country/Primary Location Code
-	 */
-	Property COUNTRY_CODE = Property.internalText(
-			PREFIX_IPTC_CORE + PREFIX_DELIMITER + "CountryCode");
-
-	/**
-	 * A textual description, including captions, of the item's content,
-	 * particularly used where the object is not text.
-	 * <p>
-	 * Note: the XMP property (dc:description) which stores the value of this
-	 * IPTC Core property is of type Lang Alt. Hence any software agent dealing
-	 * with this property must abide to the processing rules for
-	 * Lang Alt value type as specified by the XMP specifications.
-	 * <p>
-	 * Maps to this IIM property: 2:120 Caption/Abstract
-	 */
-	Property DESCRIPTION_DCPROPERTY = Property.internalText(
-			PREFIX_DC + PREFIX_DELIMITER + "description");
-
-	/**
-	 * A brief synopsis of the caption. Headline is not the same as Title.
-	 * <p>
-	 * Maps to this IIM property: 2:105 Headline
-	 */
-	Property HEADLINE = Property.internalText(
-			PREFIX_PHOTOSHOP + PREFIX_DELIMITER + "Headline");
-
-	/**
-	 * Describes the nature, intellectual, artistic or journalistic
-	 * characteristic of a item, not specifically its content.
-	 * <p>
-	 * The IPTC recognizes that the corresponding IPTC Genre NewsCodes needs
-	 * photo specific extension to be better usable with this field (as of the
-	 * release of this standard in the year 2008).
-	 * <p>
-	 * Maps to this IIM property: 2:04 Object Attribute Reference
-	 */
-	Property INTELLECTUAL_GENRE = Property.internalText(
-			PREFIX_IPTC_CORE + PREFIX_DELIMITER + "IntellectualGenre");
-
-	/**
-	 * Keywords to express the subject of the content. Keywords may be free
-	 * text and don't have to be taken from a controlled vocabulary. Codes from
-	 * the controlled vocabulary IPTC Subject NewsCodes must go to the
-	 * "Subject Code" field.
-	 * <p>
-	 * Single values of this field should not be restricted to single words
-	 * but must allow for phrases as well.
-	 * <p>
-	 * Maps to this IIM property: 2:25 Keywords
-	 */
-	Property KEYWORDS_DCPROPERTY = Property.internalTextBag(
-			PREFIX_DC + PREFIX_DELIMITER + "subject");
-
-	/**
-	 * Name of the subregion of a country -- either called province or state or
-	 * anything else -- the content is focussing on -- either the subregion
-	 * shown in visual media or referenced by text or audio media. This element
-	 * is at the second level of a top-down geographical hierarchy.
-	 * <p>
-	 * This is a detail of a location with blurred semantics as it does not
-	 * clearly indicate whether it is the location in the image or the location
-	 * the photo was taken - which can be different. Two more concise properties
-	 * are available in IPTC Extension with Location Created and Location Shown
-	 * in the Image.
-	 * <p>
-	 * Maps to this IIM property: 2:95 Province/State
-	 */
-	Property PROVINCE_OR_STATE = Property.internalText(
-			PREFIX_PHOTOSHOP + PREFIX_DELIMITER + "State");
-
-	/**
-	 * Describes the scene of a news content. Specifies one or more terms
-	 * from the IPTC "Scene-NewsCodes". Each Scene is represented as a string of
-	 * 6 digits in an unordered list.
-	 * <p>
-	 * Note: Only Scene values from this IPTC taxonomy should be used here. More
-	 * about the IPTC Scene-NewsCodes at www.newscodes.org.
-	 */
-	Property SCENE_CODE = Property.internalText(
-			PREFIX_IPTC_CORE + PREFIX_DELIMITER + "Scene");
-
-	/**
-	 * Specifies one or more Subjects from the IPTC Subject-NewsCodes taxonomy
-	 * to categorise the content. Each Subject is represented as a string of 8
-	 * digits in an unordered list.
-	 * <p>
-	 * Note: Only Subjects from a controlled vocabulary should be used here,
-	 * free text has to be put into the Keyword element. More about
-	 * IPTC Subject-NewsCodes at www.newscodes.org.
-	 */
-	Property SUBJECT_CODE = Property.internalTextBag(
-			PREFIX_IPTC_CORE + PREFIX_DELIMITER + "SubjectCode");
-
-	/**
-	 * Name of a sublocation the content is focussing on -- either the
-	 * location shown in visual media or referenced by text or audio media. This
-	 * location name could either be the name of a sublocation to a city or the
-	 * name of a well known location or (natural) monument outside a city. In
-	 * the sense of a sublocation to a city this element is at the fourth level
-	 * of a top-down geographical hierarchy.
-	 * <p>
-	 * This is a detail of a location with blurred semantics as it does not
-	 * clearly indicate whether it is the location in the image or the location
-	 * the photo was taken - which can be different. Two more concise properties
-	 * are available in IPTC Extension with Location Created and Location Shown
-	 * in the Image.
-	 * <p>
-	 * Maps to this IIM property: 2:92 Sublocation
-	 */
-	Property SUBLOCATION = Property.internalText(
-			PREFIX_IPTC_CORE + PREFIX_DELIMITER + "Location");
-
-	/**
-	 * Designates the date and optionally the time the intellectual content was
-	 * created rather than the date of the creation of the physical
-	 * representation.
-	 * <p>
-	 * If a software system requires explicit time values and no time is given
-	 * by the Date Created property the software system should default the time
-	 * to 00:00:00. If the software system does not require an explicit time
-	 * value the time part should be left empty as it is.
-	 * <p>
-	 * Note 1: Any content of the IIM dataset 2:60, Time Created, should be
-	 * merged to this element.
-	 * Note 2: Implementers are encouraged to provide
-	 * the creation date and time from the EXIF data of a digital
-	 * camera to the user for entering this date for the first time.
-	 * <p>
-	 * Maps to this IIM property: 2:55 Date Created
-	 */
-	Property DATE_CREATED = Property.internalDate(
-			PREFIX_PHOTOSHOP + PREFIX_DELIMITER + "DateCreated");
-
-	/**
-	 * Identifier or the name of the person involved in writing, editing or
-	 * correcting the description of the content.
-	 * <p>
-	 * Maps to this IIM property: 2:122 Writer/Editor
-	 */
-	Property DESCRIPTION_WRITER = Property.internalText(
-			PREFIX_PHOTOSHOP + PREFIX_DELIMITER + "CaptionWriter");
-
-	/**
-	 * Any of a number of instructions from the provider or creator to the
-	 * receiver of the item.
-	 * <p>
-	 * Maps to this IIM property: 2:40 Special Instruction
-	 */
-	Property INSTRUCTIONS = Property.internalText(
-			PREFIX_PHOTOSHOP + PREFIX_DELIMITER + "Instructions");
-
-	/**
-	 * Number or identifier for the purpose of improved workflow handling. This
-	 * is a user created identifier related to the job for which the item is
-	 * supplied.
-	 * <p>
-	 * Note: As this identifier references a job of the receiver's workflow it
-	 * must first be issued by the receiver, then transmitted to the creator or
-	 * provider of the news object and finally added by the creator
-	 * to this field.
-	 * <p>
-	 * Maps to this IIM property: 2:103 Original Transmission Reference
-	 */
-	Property JOB_ID = Property.internalText(
-			PREFIX_PHOTOSHOP + PREFIX_DELIMITER + "TransmissionReference");
-
-	/**
-	 * A shorthand reference for the item. Title provides a short human readable
-	 * name which can be a text and/or numeric reference. It is not the same as
-	 * Headline.
-	 * <p>
-	 * Many use the Title field to store the filename of the image, though the
-	 * field may be used in many ways. Formal identifiers are provided by the
-	 * Digital Image Id, or the Registry Entry property of the IPTC Extension.
-	 * <p>
-	 * Note 1: This element aligns with the use of Dublin Core's "Title"
-	 * element.
-	 * Note 2: the XMP property (dc:title) which stores the value of
-	 * this IPTC Core property is of type Lang Alt. Hence any software agent
-	 * dealing with this property must abide to the processing rules for Lang
-	 * Alt value type as specified by the XMP specifications.
-	 * <p>
-	 * Maps to this IIM property: 2:05 Object Name
-	 */
-	Property TITLE_DCPROPERTY = Property.internalText(
-			PREFIX_DC + PREFIX_DELIMITER + "title");
-
-	/**
-	 * Contains any necessary copyright notice for claiming the intellectual
-	 * property for this item and should identify the current owner of the
-	 * copyright for the item. Other entities like the creator of the item may
-	 * be added in the corresponding field. Notes on usage rights should be
-	 * provided in "Rights usage terms".
-	 * <p>
-	 * Copyright ownership can be expressed in a more controlled way using the
-	 * PLUS fields "Copyright Owner", "Copyright Owner ID",
-	 * "Copyright Owner Name" of the IPTC Extension. It is the user's
-	 * responsibility to keep the values of the four fields in sync.
-	 * <p>
-	 * Note: the XMP property (dc:rights) which stores the value of this IPTC
-	 * Core property is of type Lang Alt. Hence any software agent dealing with
-	 * this property must abide to the processing rules for Lang Alt
-	 * value type as specified by the XMP specifications.
-	 * <p>
-	 * Maps to this IIM property: 2:116 Copyright Notice
-	 */
-	Property COPYRIGHT_NOTICE = Property.internalText(
-			PREFIX_DC + PREFIX_DELIMITER + "rights");
-
-	/**
-	 * Contains the name of the person who created the content of this item, a
-	 * photographer for photos, a graphic artist for graphics, or a writer for
-	 * textual news, but in cases where the photographer should not be
-	 * identified the name of a company or organisation may be appropriate.
-	 * <p>
-	 * The creator can be expressed in a more controlled way using the
-	 * "Image Creator" of PLUS in the IPTC Extension additionally. It is the
-	 * user's responsibility to keep the values of the IPTC Core and the PLUS
-	 * fields in sync.
-	 * <p>
-	 * Maps to this IIM property: 2:80 By-line
-	 */
-	Property CREATOR_DCPROPERTY = Property.internalText(
-			PREFIX_DC + PREFIX_DELIMITER + "creator");
-
-	/**
-	 * The creator's contact information provides all necessary information to
-	 * get in contact with the creator of this item and comprises a set of
-	 * sub-properties for proper addressing.
-	 * <p>
-	 * The IPTC Extension Licensor fields should be used instead of these
-	 * Creator's Contact Info fields if you are using IPTC Extension fields. If
-	 * the creator is also the licensor his or her contact information should be
-	 * provided in the Licensor fields.
-	 * <p>
-	 * Note 1 to user interface implementers: All sub-properties of "Creator's
-	 * contact information" should be shown as group on the form.
-	 * Note 2: the
-	 * CreatorContactInfo sub-properties' naming aligns with the vCard
-	 * specification RFC 2426.
-	 */
-	Property CREATORS_CONTACT_INFO = Property.internalText(
-			PREFIX_IPTC_CORE + PREFIX_DELIMITER + "CreatorContactInfo");
-
-	/**
-	 * Contains the job title of the person who created the content of this
-	 * item. As this is sort of a qualifier the Creator element has to be filled
-	 * in as mandatory prerequisite for using Creator's Jobtitle.
-	 * <p>
-	 * Maps to this IIM property: 2:85 By-line Title
-	 */
-	Property CREATORS_JOB_TITLE = Property.internalText(
-			PREFIX_PHOTOSHOP + PREFIX_DELIMITER + "AuthorsPosition");
-
-	/**
-	 * The credit to person(s) and/or organisation(s) required by the supplier
-	 * of the item to be used when published. This is a free-text field.
-	 * <p>
-	 * Note 1: For more formal identifications of the creator or the owner of
-	 * the copyrights of this image other rights properties may be used.
-	 * Note 2:
-	 * This property was named "Credit" by the IIM metadata, then it was renamed
-	 * to "Provider" in IPTC Core 1.0. In IPTC Core 1.1. it has been renamed to
-	 * "Credit Line" as the field is used for this purpose by many users.
-	 * <p>
-	 * Maps to this IIM property: 2:110 Credit
-	 */
-	Property CREDIT_LINE = Property.internalText(
-			PREFIX_PHOTOSHOP + PREFIX_DELIMITER + "Credit");
-
-	/**
-	 * The licensing parameters of the item expressed in free-text.
-	 * <p>
-	 * The PLUS fields of the IPTC Extension can be used in parallel to express
-	 * the licensed usage in more controlled terms.
-	 */
-	Property RIGHTS_USAGE_TERMS = Property.internalText(
-			PREFIX_XMP_RIGHTS + PREFIX_DELIMITER + "UsageTerms");
-
-	/**
-	 * Identifies the original owner of the copyright for the intellectual
-	 * content of the item. This could be an agency, a member of an agency or an
-	 * individual. Source could be different from Creator and from the entities
-	 * in the CopyrightNotice.
-	 * <p>
-	 * The original owner can never change. For that reason the content of this
-	 * property should never be changed or deleted after the information is
-	 * entered following the news object's initial creation.
-	 * <p>
-	 * Maps to this IIM property: 2:115 Source
-	 */
-	Property SOURCE = Property.internalText(
-			PREFIX_PHOTOSHOP + PREFIX_DELIMITER + "Source");
-
-	/**
-	 * The contact information address part. Comprises an optional company name
-	 * and all required information to locate the building or postbox to which
-	 * mail should be sent. To that end, the address is a multiline field.
-	 * <p>
-	 * Note 1: to user interface implementers: This field should be part of a
-	 * "Contact information" group on the form.
-	 * Note 2: the ContactInfo naming aligns with the vCard specification RFC 2426.
-	 */
-	Property CONTACT_INFO_ADDRESS = Property.internalText(
-			PREFIX_IPTC_CORE + PREFIX_DELIMITER + "CiAdrExtadr");
-
-	/**
-	 * The contact information city part.
-	 * <p>
-	 * Note 1: to user interface implementers: This field should be part of a
-	 * "Contact information" group on the form.
-	 * Note 2: the ContactInfo naming aligns with the vCard specification RFC 2426.
-	 */
-	Property CONTACT_INFO_CITY = Property.internalText(
-			PREFIX_IPTC_CORE + PREFIX_DELIMITER + "CiAdrCity");
-
-	/**
-	 * The contact information country part.
-	 * <p>
-	 * Note 1: to user interface implementers: This field should be part of a
-	 * "Contact information" group on the form.
-	 * Note 2: the ContactInfo naming aligns with the vCard specification RFC 2426.
-	 */
-	Property CONTACT_INFO_COUNTRY = Property.internalText(
-			PREFIX_IPTC_CORE + PREFIX_DELIMITER + "CiAdrCtry");
-
-	/**
-	 * The contact information email address part.
-	 * <p>
-	 * Multiple email addresses can be given. May have to be separated by a
-	 * comma in the user interface.
-	 * <p>
-	 * Note 1: to user interface implementers: This field should be part of a
-	 * "Contact information" group on the form.
-	 * Note 2 to user interface
-	 * implementers: provide sufficient space to fill in multiple e-mail
-	 * addresses.
-	 * Note 3: the ContactInfo naming aligns with the vCard
-	 * specification RFC 2426.
-	 */
-	Property CONTACT_INFO_EMAIL = Property.internalText(
-			PREFIX_IPTC_CORE + PREFIX_DELIMITER + "CiEmailWork");
-
-	/**
-	 * The contact information phone number part.
-	 * <p>
-	 * Multiple numbers can be given. May have to be separated by a
-	 * comma in the user interface.
-	 * <p>
-	 * Note 1: to user interface implementers: This field should be part of a
-	 * "Contact information" group on the form.
-	 * Note 2 to user interface
-	 * implementers: provide sufficient space to fill in multiple international
-	 * numbers.
-	 * Note 3: the ContactInfo naming aligns with the vCard
-	 * specification RFC 2426.
-	 */
-	Property CONTACT_INFO_PHONE = Property.internalText(
-			PREFIX_IPTC_CORE + PREFIX_DELIMITER + "CiTelWork");
-
-	/**
-	 * The contact information part denoting the local postal code.
-	 * <p>
-	 * Note 1: to user interface implementers: This field should be part of a
-	 * "Contact information" group on the form.
-	 * Note 2: the ContactInfo naming aligns with the vCard specification RFC 2426.
-	 */
-	Property CONTACT_INFO_POSTAL_CODE = Property.internalText(
-			PREFIX_IPTC_CORE + PREFIX_DELIMITER + "CiAdrPcode");
-
-	/**
-	 * The contact information part denoting regional information such as state or province.
-	 * <p>
-	 * Note 1: to user interface implementers: This field should be part of a
-	 * "Contact information" group on the form.
-	 * Note 2: the ContactInfo naming aligns with the vCard specification RFC 2426.
-	 */
-	Property CONTACT_INFO_STATE_PROVINCE = Property.internalText(
-			PREFIX_IPTC_CORE + PREFIX_DELIMITER + "CiAdrRegion");
-
-	/**
-	 * The contact information web address part. Multiple addresses can be given, separated by a comma.
-	 * <p>
-	 * Note 1: to user interface implementers: This field should be part of a
-	 * "Contact information" group on the form.
-	 * Note 2 to user interface
-	 * implementers: provide sufficient space to fill in multiple URLs.
-	 * Note 3: the ContactInfo naming aligns with the vCard
-	 * specification RFC 2426.
-	 */
-	Property CONTACT_INFO_WEB_URL = Property.internalText(
-			PREFIX_IPTC_CORE + PREFIX_DELIMITER + "CiUrlWork");
-
-	/**
-	 * As this metadata element pertains to distribution management, it was not
-	 * adopted. However, this data is still synchronised with the XMP property
-	 * [photoshop:Urgency], and hence, available for future use, but outside the
-	 * IPTC Core.
-	 *
-	 * @deprecated
-	 */
-	Property PHOTOSHOP_URGENCY = Property.internalText(
-			PREFIX_PHOTOSHOP + PREFIX_DELIMITER + "Urgency");
-
-	/**
-	 * As this metadata element was earmarked as deprecated already for IIM 4.1,
-	 * it was not adopted. However, this data is still synchronised with the XMP
-	 * property [photoshop:Category], and hence available for future use - but
-	 * outside the IPTC Core. For migrating from Category codes to Subject Codes
-	 * please read the Guideline for mapping Category Codes to Subject NewsCodes
-	 * section below.
-	 *
-	 * @deprecated
-	 */
-	Property PHOTOSHOP_CATEGORY = Property.internalText(
-			PREFIX_PHOTOSHOP + PREFIX_DELIMITER + "Category");
-
-	/**
-	 * As this metadata element was earmarked as deprecated already for IIM 4.1,
-	 * it was not adopted. However, this data is still synchronised with the XMP
-	 * property [photoshop:SupplementalCategories], and hence available for
-	 * future use - but outside the IPTC Core.
-	 *
-	 * @deprecated
-	 */
-	Property PHOTOSHOP_SUPPLEMENTAL_CATEGORIES = Property.internalTextBag(
-			PREFIX_PHOTOSHOP + PREFIX_DELIMITER + "SupplementalCategories");
-
-	/**
-	 * Information about the ethnicity and other facets of the model(s) in a
-	 * model-released image.
-	 * <p>
-	 * Use the Model Age field for the age of model(s).
-	 */
-	Property ADDITIONAL_MODEL_INFO = Property.internalText(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "AddlModelInfo");
-
-	/**
-	 * A set of metadata about artwork or an object in the item
-	 */
-	Property ARTWORK_OR_OBJECT = Property.internalTextBag(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "ArtworkOrObject");
-
-	/**
-	 * A set of metadata about artwork or an object in the item
-	 */
-	Property ORGANISATION_CODE = Property.internalTextBag(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "OrganisationInImageCode");
-
-	/**
-	 * A term to describe the content of the image by a value from a Controlled
-	 * Vocabulary.
-	 * <p>
-	 * This property is part of the Photo Metadata 2008 specifications, but
-	 * should not released to the public on the standard Adobe Custom Panels for
-	 * IPTC metadata or other user interfaces unless agreed by the IPTC.
-	 */
-	Property CONTROLLED_VOCABULARY_TERM = Property.internalTextBag(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "CVterm");
-
-	/**
-	 * A location the content of the item is about. For photos that is a
-	 * location shown in the image.
-	 * <p>
-	 * If the location the image was taken in is different from this location
-	 * the property Location Created should be used too.
-	 */
-	Property LOCATION_SHOWN = Property.internalTextBag(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "LocationShown");
-
-	/**
-	 * Age of the human model(s) at the time this image was taken in a model
-	 * released image.
-	 * <p>
-	 * The user should be aware of any legal implications of providing ages for
-	 * young models. Ages below 18 years should not be included.
-	 */
-	Property MODEL_AGE = Property.internalTextBag(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "ModelAge");
-
-	/**
-	 * Name of the organisation or company which is featured in the content.
-	 * <p>
-	 * May be supplemented by values from a controlled vocabulary in the
-	 * Organisation Code field.
-	 */
-	Property ORGANISATION_NAME = Property.internalTextBag(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "OrganisationInImageName");
-
-	/**
-	 * Name of a person the content of the item is about. For photos that is a
-	 * person shown in the image.
-	 */
-	Property PERSON = Property.internalTextBag(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "PersonInImage");
-
-	/**
-	 * Globally unique identifier for the item. It is created and applied by the
-	 * creator of the item at the time of its creation . This value shall not be
-	 * changed after that time.
-	 * <p>
-	 * The identifier will probably be generated by the technical means of an
-	 * imaging device or software and should be applied to the digital image
-	 * file as early as possible in its life cycle. This identifier does not
-	 * identify any pictured content, particularly in case of a scan of non-
-	 * digital images, only this digital representation.
-	 * <p>
-	 * Any algorithm to create this identifier has to comply with the technical
-	 * requirements to create a globally unique id. Any device creating digital
-	 * images - e.g. still image cameras, video cameras, scanners - should
-	 * create such an identifer right at the time of the creation of the digital
-	 * data and add the id to the set of metadata without compromising
-	 * performance. It is recommended that this image identifier allows
-	 * identifying the device by which the image data and the GUID were created.
-	 * IPTC's basic requirements for unique ids are:
-	 * - It must be globally unique. Algorithms for this purpose exist.
-	 * - It should identify the camera body.
-	 * - It should identify each individual photo from this camera body.
-	 * - It should identify the date and time of the creation of the picture.
-	 * - It should be secured against tampering.
-	 * This field should be implemented in a way to prove it has not been changed since its value has
-	 * been applied. If the identifier has been created by the imaging device
-	 * its type and brand can be found in the Exif/technical metadata.
-	 */
-	Property DIGITAL_IMAGE_GUID = Property.internalText(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "DigImageGUID");
-
-	/**
-	 * The type of the source digital file.
-	 * <p>
-	 * The IPTC recommends not to implement this property any longer.
-	 *
-	 * @deprecated
-	 */
-	Property DIGITAL_SOURCE_FILE_TYPE = Property.internalText(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "DigitalSourcefileType");
-
-	/**
-	 * The type of the source of this digital image
-	 */
-	Property DIGITAL_SOURCE_TYPE = Property.internalText(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "DigitalSourceType");
-
-	/**
-	 * Names or describes the specific event the content relates to.
-	 * <p>
-	 * Examples are: a press conference, dedication ceremony, etc. If this is a
-	 * sub-event of a larger event both can be provided by the field: e.g. XXXIX
-	 * Olympic Summer Games (Beijing): opening ceremony. Unplanned events could
-	 * be named by this property too.
-	 */
-	Property EVENT = Property.internalText(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "Event");
-
-	/**
-	 * Both a Registry Item Id and a Registry Organisation Id to record any
-	 * registration of this item with a registry.
-	 * <p>
-	 * Typically an id from a registry is negotiated and applied after the
-	 * creation of the digital image.
-	 * <p>
-	 * Any user interface implementation must show both sub-properties - Item Id
-	 * and Organisation Id - as corresponding values. Further an input to both
-	 * fields should be made mandatory.
-	 */
-	Property IMAGE_REGISTRY_ENTRY = Property.internalTextBag(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "RegistryId");
-
-	/**
-	 * Identifies the most recent supplier of the item, who is not necessarily
-	 * its owner or creator.
-	 * <p>
-	 * For identifying the supplier either a well known and/or registered
-	 * company name or a URL of the company's web site may be used. This
-	 * property succeeds the Provider property of IPTC Core 1.0 by its semantics
-	 * as that Provider was renamed to Credit Line.
-	 * <p>
-	 * This is a PLUS version 1.2 property included in the IPTC Extension
-	 * schema.
-	 */
-	Property IMAGE_SUPPLIER = Property.internalText(
-			PREFIX_PLUS + PREFIX_DELIMITER + "ImageSupplier");
-
-	/**
-	 * Identifies the most recent supplier of the item, who is not necessarily
-	 * its owner or creator.
-	 * <p>
-	 * For identifying the supplier either a well known and/or registered
-	 * company name or a URL of the company's web site may be used. This
-	 * property succeeds the Provider property of IPTC Core 1.0 by its semantics
-	 * as that Provider was renamed to Credit Line.
-	 * <p>
-	 * This is a PLUS version 1.2 property included in the IPTC Extension
-	 * schema.
-	 */
-	Property IMAGE_SUPPLIER_ID = Property.internalText(
-			PREFIX_PLUS + PREFIX_DELIMITER + "ImageSupplierId");
-
-	/**
-	 * Identifies the most recent supplier of the item, who is not necessarily
-	 * its owner or creator.
-	 * <p>
-	 * For identifying the supplier either a well known and/or registered
-	 * company name or a URL of the company's web site may be used. This
-	 * property succeeds the Provider property of IPTC Core 1.0 by its semantics
-	 * as that Provider was renamed to Credit Line.
-	 * <p>
-	 * This is a PLUS version 1.2 property included in the IPTC Extension
-	 * schema.
-	 */
-	Property IMAGE_SUPPLIER_NAME = Property.internalText(
-			PREFIX_PLUS + PREFIX_DELIMITER + "ImageSupplierName");
-
-	/**
-	 * Optional identifier assigned by the Image Supplier to the image.
-	 * <p>
-	 * This is a PLUS version 1.2 property included in the IPTC Extension
-	 * schema.
-	 */
-	Property IMAGE_SUPPLIER_IMAGE_ID = Property.internalText(
-			PREFIX_PLUS + PREFIX_DELIMITER + "ImageSupplierImageID");
-
-	/**
-	 * The date and optionally time when any of the IPTC photo metadata fields
-	 * has been last edited
-	 * <p>
-	 * The public use of this property is deprecated by IPTC Extension version
-	 * 1.1. It may only still be used by a private user interface for a use
-	 * scoped to a company. If used this field should be a timestamp of the
-	 * latest change applied to any of the fields.
-	 * <p>
-	 * The value of this property should never be set by software. XMP-aware
-	 * software should reflect any changes to metadata by the xmp:MetadataDate
-	 * property of the XMP Basic scheme.
-	 */
-	Property IPTC_LAST_EDITED = Property.internalDate(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "IptcLastEdited");
-
-	/**
-	 * The location the content of the item was created.
-	 * <p>
-	 * If the location in the image is different from the location the photo was
-	 * taken the IPTC Extension property Location Shown in the Image should be
-	 * used.
-	 */
-	Property LOCATION_CREATED = Property.internalTextBag(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "LocationCreated");
-
-	/**
-	 * The maximum available height in pixels of the original photo from which
-	 * this photo has been derived by downsizing.
-	 */
-	Property MAX_AVAIL_HEIGHT = Property.internalInteger(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "MaxAvailHeight");
-
-	/**
-	 * The maximum available width in pixels of the original photo from which
-	 * this photo has been derived by downsizing.
-	 */
-	Property MAX_AVAIL_WIDTH = Property.internalInteger(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "MaxAvailWidth");
-
-	/**
-	 * The version number of the PLUS standards in place at the time of the
-	 * transaction.
-	 * <p>
-	 * This property was included into the IPTC Extension schema from PLUS
-	 * version 1.2 as all other PLUS properties. To reflect this the value of
-	 * "PLUS Version" should be set to the string "1.2.0"
-	 */
-	Property PLUS_VERSION = Property.internalText(
-			PREFIX_PLUS + PREFIX_DELIMITER + "Version");
-
-	/**
-	 * Owner or owners of the copyright in the licensed image.
-	 * <p>
-	 * Serves to identify the rights holder/s for the image. The Copyright
-	 * Owner, Image Creator and Licensor may be the same or different entities.
-	 * <p>
-	 * This is a PLUS version 1.2 property included in the IPTC Extension
-	 * schema.
-	 */
-	Property COPYRIGHT_OWNER = Property.internalTextBag(
-			PREFIX_PLUS + PREFIX_DELIMITER + "CopyrightOwner");
-
-	/**
-	 * The ID of the owner or owners of the copyright in the licensed image.
-	 * <p>
-	 * Serves to identify the rights holder/s for the image. The Copyright
-	 * Owner, Image Creator and Licensor may be the same or different entities.
-	 * <p>
-	 * This is a PLUS version 1.2 property included in the IPTC Extension
-	 * schema.
-	 */
-	Property COPYRIGHT_OWNER_ID = Property.internalTextBag(
-			PREFIX_PLUS + PREFIX_DELIMITER + "CopyrightOwnerId");
-
-	/**
-	 * The name of the owner or owners of the copyright in the licensed image.
-	 * <p>
-	 * Serves to identify the rights holder/s for the image. The Copyright
-	 * Owner, Image Creator and Licensor may be the same or different entities.
-	 * <p>
-	 * This is a PLUS version 1.2 property included in the IPTC Extension
-	 * schema.
-	 */
-	Property COPYRIGHT_OWNER_NAME = Property.internalTextBag(
-			PREFIX_PLUS + PREFIX_DELIMITER + "CopyrightOwnerName");
-
-	/**
-	 * Creator or creators of the image.
-	 * <p>
-	 * The creator can be additionally expressed in free-text using the IPTC
-	 * Core Creator field. In many countries, the Image Creator must be
-	 * attributed in association with any use of the image. The Image Creator,
-	 * Copyright Owner, Image Supplier and Licensor may be the same or different
-	 * entities.
-	 * <p>
-	 * This is a PLUS version 1.2 property included in the IPTC Extension
-	 * schema.
-	 */
-	Property IMAGE_CREATOR = Property.internalTextBag(
-			PREFIX_PLUS + PREFIX_DELIMITER + "ImageCreator");
-
-	/**
-	 * The ID of the creator or creators of the image.
-	 * <p>
-	 * The creator can be additionally expressed in free-text using the IPTC
-	 * Core Creator field. In many countries, the Image Creator must be
-	 * attributed in association with any use of the image. The Image Creator,
-	 * Copyright Owner, Image Supplier and Licensor may be the same or different
-	 * entities.
-	 * <p>
-	 * This is a PLUS version 1.2 property included in the IPTC Extension
-	 * schema.
-	 */
-	Property IMAGE_CREATOR_ID = Property.internalTextBag(
-			PREFIX_PLUS + PREFIX_DELIMITER + "ImageCreatorId");
-
-	/**
-	 * The name of the creator or creators of the image.
-	 * <p>
-	 * The creator can be additionally expressed in free-text using the IPTC
-	 * Core Creator field. In many countries, the Image Creator must be
-	 * attributed in association with any use of the image. The Image Creator,
-	 * Copyright Owner, Image Supplier and Licensor may be the same or different
-	 * entities.
-	 * <p>
-	 * This is a PLUS version 1.2 property included in the IPTC Extension
-	 * schema.
-	 */
-	Property IMAGE_CREATOR_NAME = Property.internalTextBag(
-			PREFIX_PLUS + PREFIX_DELIMITER + "ImageCreatorName");
-
-	/**
-	 * A person or company that should be contacted to obtain a licence for
-	 * using the item or who has licensed the item.
-	 * <p>
-	 * This is a PLUS version 1.2 property included in the IPTC Extension
-	 * schema.
-	 */
-	Property LICENSOR = Property.internalTextBag(
-			PREFIX_PLUS + PREFIX_DELIMITER + "Licensor");
-
-	/**
-	 * The ID of the person or company that should be contacted to obtain a licence for
-	 * using the item or who has licensed the item.
-	 * <p>
-	 * This is a PLUS version 1.2 property included in the IPTC Extension
-	 * schema.
-	 */
-	Property LICENSOR_ID = Property.internalTextBag(
-			PREFIX_PLUS + PREFIX_DELIMITER + "LicensorId");
-
-	/**
-	 * The name of the person or company that should be contacted to obtain a licence for
-	 * using the item or who has licensed the item.
-	 * <p>
-	 * This is a PLUS version 1.2 property included in the IPTC Extension
-	 * schema.
-	 */
-	Property LICENSOR_NAME = Property.internalTextBag(
-			PREFIX_PLUS + PREFIX_DELIMITER + "LicensorName");
-
-	/**
-	 * The city of a person or company that should be contacted to obtain a licence for
-	 * using the item or who has licensed the item.
-	 * <p>
-	 * This is a PLUS version 1.2 property included in the IPTC Extension
-	 * schema.
-	 */
-	Property LICENSOR_CITY = Property.internalTextBag(
-			PREFIX_PLUS + PREFIX_DELIMITER + "LicensorCity");
-
-	/**
-	 * The country of a person or company that should be contacted to obtain a licence for
-	 * using the item or who has licensed the item.
-	 * <p>
-	 * This is a PLUS version 1.2 property included in the IPTC Extension
-	 * schema.
-	 */
-	Property LICENSOR_COUNTRY = Property.internalTextBag(
-			PREFIX_PLUS + PREFIX_DELIMITER + "LicensorCountry");
-
-	/**
-	 * The email of a person or company that should be contacted to obtain a licence for
-	 * using the item or who has licensed the item.
-	 * <p>
-	 * This is a PLUS version 1.2 property included in the IPTC Extension
-	 * schema.
-	 */
-	Property LICENSOR_EMAIL = Property.internalTextBag(
-			PREFIX_PLUS + PREFIX_DELIMITER + "LicensorEmail");
-
-	/**
-	 * The extended address of a person or company that should be contacted to obtain a licence for
-	 * using the item or who has licensed the item.
-	 * <p>
-	 * This is a PLUS version 1.2 property included in the IPTC Extension
-	 * schema.
-	 */
-	Property LICENSOR_EXTENDED_ADDRESS = Property.internalTextBag(
-			PREFIX_PLUS + PREFIX_DELIMITER + "LicensorExtendedAddress");
-
-	/**
-	 * The postal code of a person or company that should be contacted to obtain a licence for
-	 * using the item or who has licensed the item.
-	 * <p>
-	 * This is a PLUS version 1.2 property included in the IPTC Extension
-	 * schema.
-	 */
-	Property LICENSOR_POSTAL_CODE = Property.internalTextBag(
-			PREFIX_PLUS + PREFIX_DELIMITER + "LicensorPostalCode");
-
-	/**
-	 * The region of a person or company that should be contacted to obtain a licence for
-	 * using the item or who has licensed the item.
-	 * <p>
-	 * This is a PLUS version 1.2 property included in the IPTC Extension
-	 * schema.
-	 */
-	Property LICENSOR_REGION = Property.internalTextBag(
-			PREFIX_PLUS + PREFIX_DELIMITER + "LicensorRegion");
-
-	/**
-	 * The street address of a person or company that should be contacted to obtain a licence for
-	 * using the item or who has licensed the item.
-	 * <p>
-	 * This is a PLUS version 1.2 property included in the IPTC Extension
-	 * schema.
-	 */
-	Property LICENSOR_STREET_ADDRESS = Property.internalTextBag(
-			PREFIX_PLUS + PREFIX_DELIMITER + "LicensorStreetAddress");
-
-	/**
-	 * The phone number of a person or company that should be contacted to obtain a licence for
-	 * using the item or who has licensed the item.
-	 * <p>
-	 * This is a PLUS version 1.2 property included in the IPTC Extension
-	 * schema.
-	 */
-	Property LICENSOR_TELEPHONE_1 = Property.internalTextBag(
-			PREFIX_PLUS + PREFIX_DELIMITER + "LicensorTelephone1");
-
-	/**
-	 * The phone number of a person or company that should be contacted to obtain a licence for
-	 * using the item or who has licensed the item.
-	 * <p>
-	 * This is a PLUS version 1.2 property included in the IPTC Extension
-	 * schema.
-	 */
-	Property LICENSOR_TELEPHONE_2 = Property.internalTextBag(
-			PREFIX_PLUS + PREFIX_DELIMITER + "LicensorTelephone2");
-
-	/**
-	 * The URL of a person or company that should be contacted to obtain a licence for
-	 * using the item or who has licensed the item.
-	 * <p>
-	 * This is a PLUS version 1.2 property included in the IPTC Extension
-	 * schema.
-	 */
-	Property LICENSOR_URL = Property.internalTextBag(
-			PREFIX_PLUS + PREFIX_DELIMITER + "LicensorURL");
-
-	/**
-	 * Age of the youngest model pictured in the image, at the time that the
-	 * image was made.
-	 * <p>
-	 * This age should not be displayed to the public on open web portals and
-	 * the like. But it may be used by image repositories in a
-	 * B2B enviroment.
-	 * <p>
-	 * This is a PLUS version 1.2 property included in the IPTC Extension
-	 * schema.
-	 */
-	Property MINOR_MODEL_AGE_DISCLOSURE = Property.internalText(
-			PREFIX_PLUS + PREFIX_DELIMITER + "MinorModelAgeDisclosure");
-
-	/**
-	 * Optional identifier associated with each Model Release.
-	 * <p>
-	 * This is a PLUS version 1.2 property included in the IPTC Extension
-	 * schema.
-	 */
-	Property MODEL_RELEASE_ID = Property.internalTextBag(
-			PREFIX_PLUS + PREFIX_DELIMITER + "ModelReleaseID");
-
-	/**
-	 * Summarizes the availability and scope of model releases authorizing usage
-	 * of the likenesses of persons appearing in the photograph.
-	 * <p>
-	 * It is recommended to apply the PLUS controlled value Unlimited Model
-	 * Releases (MR- UMR) very carefully and to check the wording of the model
-	 * release thoroughly before applying it.
-	 * <p>
-	 * This is a PLUS version 1.2 property included in the IPTC Extension
-	 * schema.
-	 */
-	Property MODEL_RELEASE_STATUS = Property.internalText(
-			PREFIX_PLUS + PREFIX_DELIMITER + "ModelReleaseStatus");
-
-	/**
-	 * Optional identifier associated with each Property Release.
-	 * <p>
-	 * This is a PLUS version 1.2 property included in the IPTC Extension
-	 * schema.
-	 */
-	Property PROPERTY_RELEASE_ID = Property.internalTextBag(
-			PREFIX_PLUS + PREFIX_DELIMITER + "PropertyReleaseID");
-
-	/**
-	 * Summarises the availability and scope of property releases authorizing
-	 * usage of the properties appearing in the photograph.
-	 * <p>
-	 * It is recommended to apply the value PR-UPR very carefully and to check
-	 * the wording of the property release thoroughly before applying it.
-	 * <p>
-	 * This is a PLUS version 1.2 property included in the IPTC Extension
-	 * schema.
-	 */
-	Property PROPERTY_RELEASE_STATUS = Property.internalText(
-			PREFIX_PLUS + PREFIX_DELIMITER + "PropertyReleaseStatus");
-
-	/**
-	 * Contains any necessary copyright notice for claiming the intellectual
-	 * property for artwork or an object in the image and should identify the
-	 * current owner of the copyright of this work with associated intellectual
-	 * property rights.
-	 */
-	Property ARTWORK_OR_OBJECT_DETAIL_COPYRIGHT_NOTICE = Property.internalText(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "AOCopyrightNotice");
-
-	/**
-	 * Contains the name of the artist who has created artwork or an object in the image.
-	 */
-	Property ARTWORK_OR_OBJECT_DETAIL_CREATOR = Property.internalText(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "AOCreator");
-
-	/**
-	 * Designates the date and optionally the time the artwork or object in the
-	 * image was created. This relates to artwork or objects with associated
-	 * intellectual property rights.
-	 */
-	Property ARTWORK_OR_OBJECT_DETAIL_DATE_CREATED = Property.internalDate(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "AODateCreated");
-
-	/**
-	 * The organisation or body holding and registering the artwork or object in
-	 * the image for inventory purposes.
-	 */
-	Property ARTWORK_OR_OBJECT_DETAIL_SOURCE = Property.internalText(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "AOSource");
-
-	/**
-	 * The inventory number issued by the organisation or body holding and
-	 * registering the artwork or object in the image.
-	 */
-	Property ARTWORK_OR_OBJECT_DETAIL_SOURCE_INVENTORY_NUMBER = Property.internalText(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "AOSourceInvNo");
-
-	/**
-	 * A reference for the artwork or object in the image.
-	 */
-	Property ARTWORK_OR_OBJECT_DETAIL_TITLE = Property.internalText(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "AOTitle");
-
-	/**
-	 * Name of the city of a location. This element is at the fourth level of a
-	 * top-down geographical hierarchy.
-	 */
-	Property LOCATION_SHOWN_CITY = Property.internalText(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "LocationShownCity");
-
-	/**
-	 * The ISO code of a country of a location. This element is at the second
-	 * level of a top-down geographical hierarchy.
-	 * <p>
-	 * Note 1: an implementer would have to derive from the length of the value
-	 * string whether this is the country code from the two or three letter
-	 * scheme as no explicit indication can be provided.
-	 */
-	Property LOCATION_SHOWN_COUNTRY_CODE = Property.internalText(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "LocationShownCountryCode");
-
-	/**
-	 * The name of a country of a location. This element is at the second level
-	 * of a top-down geographical hierarchy.
-	 */
-	Property LOCATION_SHOWN_COUNTRY_NAME = Property.internalText(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "LocationShownCountryName");
-
-	/**
-	 * The name of a subregion of a country - a province or state - of a
-	 * location. This element is at the third level of a top-down geographical
-	 * hierarchy.
-	 */
-	Property LOCATION_SHOWN_PROVINCE_OR_STATE = Property.internalText(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "LocationShownProvinceState");
-
-	/**
-	 * Name of a sublocation. This sublocation name could either be the name of
-	 * a sublocation to a city or the name of a well known location or (natural)
-	 * monument outside a city. In the sense of a sublocation to a city this
-	 * element is at the fifth level of a top-down geographical hierarchy.
-	 */
-	Property LOCATION_SHOWN_SUBLOCATION = Property.internalText(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "LocationShownSublocation");
-
-	/**
-	 * The name of a world region of a location. This element is at the first
-	 * (topI) level of a top- down geographical hierarchy.
-	 */
-	Property LOCATION_SHOWN_WORLD_REGION = Property.internalText(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "LocationShownWorldRegion");
-
-	/**
-	 * Name of the city of a location. This element is at the fourth level of a
-	 * top-down geographical hierarchy.
-	 */
-	Property LOCATION_CREATED_CITY = Property.internalText(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "LocationCreatedCity");
-
-	/**
-	 * The ISO code of a country of a location. This element is at the second
-	 * level of a top-down geographical hierarchy.
-	 * <p>
-	 * Note 1: an implementer would have to derive from the length of the value
-	 * string whether this is the country code from the two or three letter
-	 * scheme as no explicit indication can be provided.
-	 */
-	Property LOCATION_CREATED_COUNTRY_CODE = Property.internalText(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "LocationCreatedCountryCode");
-
-	/**
-	 * The name of a country of a location. This element is at the second level
-	 * of a top-down geographical hierarchy.
-	 */
-	Property LOCATION_CREATED_COUNTRY_NAME = Property.internalText(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "LocationCreatedCountryName");
-
-	/**
-	 * The name of a subregion of a country - a province or state - of a
-	 * location. This element is at the third level of a top-down geographical
-	 * hierarchy.
-	 */
-	Property LOCATION_CREATED_PROVINCE_OR_STATE = Property.internalText(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "LocationCreatedProvinceState");
-
-	/**
-	 * Name of a sublocation. This sublocation name could either be the name of
-	 * a sublocation to a city or the name of a well known location or (natural)
-	 * monument outside a city. In the sense of a sublocation to a city this
-	 * element is at the fifth level of a top-down geographical hierarchy.
-	 */
-	Property LOCATION_CREATED_SUBLOCATION = Property.internalText(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "LocationCreatedSublocation");
-
-	/**
-	 * The name of a world region of a location. This element is at the first
-	 * (topI) level of a top- down geographical hierarchy.
-	 */
-	Property LOCATION_CREATED_WORLD_REGION = Property.internalText(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "LocationCreatedWorldRegion");
-
-	/**
-	 * A unique identifier created by a registry and applied by the creator of
-	 * the item. This value shall not be changed after being applied. This
-	 * identifier is linked to a corresponding Registry Organisation Identifier.
-	 */
-	Property REGISTRY_ENTRY_CREATED_ITEM_ID = Property.internalText(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "RegItemId");
-
-	/**
-	 * An identifier for the registry which issued the corresponding Registry Image Id.
-	 */
-	Property REGISTRY_ENTRY_CREATED_ORGANISATION_ID = Property.internalText(
-			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "RegOrgId");
-
-
-	Property[] PROPERTY_GROUP_IPTC_CORE = new Property[] {
-		CITY,
-		COUNTRY,
-		COUNTRY_CODE,
-		DESCRIPTION_DCPROPERTY,
-		HEADLINE,
-		INTELLECTUAL_GENRE,
-		KEYWORDS_DCPROPERTY,
-		PROVINCE_OR_STATE,
-		SCENE_CODE,
-		SUBJECT_CODE,
-		SUBLOCATION,
-		DATE_CREATED,
-		DESCRIPTION_WRITER,
-		INSTRUCTIONS,
-		JOB_ID,
-		TITLE_DCPROPERTY,
-		COPYRIGHT_NOTICE,
-		CREATOR_DCPROPERTY,
-		CREATORS_JOB_TITLE,
-		CREDIT_LINE,
-		RIGHTS_USAGE_TERMS,
-		SOURCE,
-		CONTACT_INFO_ADDRESS,
-		CONTACT_INFO_CITY,
-		CONTACT_INFO_COUNTRY,
-		CONTACT_INFO_EMAIL,
-		CONTACT_INFO_PHONE,
-		CONTACT_INFO_POSTAL_CODE,
-		CONTACT_INFO_STATE_PROVINCE,
-		CONTACT_INFO_WEB_URL
-	};
-
-	Property[] PROPERTY_GROUP_IPTC_EXT = new Property[] {
-		ADDITIONAL_MODEL_INFO,
-		ORGANISATION_CODE,
-		CONTROLLED_VOCABULARY_TERM,
-		MODEL_AGE,
-		ORGANISATION_NAME,
-		PERSON,
-		DIGITAL_IMAGE_GUID,
-		DIGITAL_SOURCE_TYPE,
-		EVENT,
-		IMAGE_SUPPLIER_ID,
-		IMAGE_SUPPLIER_NAME,
-		IMAGE_SUPPLIER_IMAGE_ID,
-		IPTC_LAST_EDITED,
-		MAX_AVAIL_HEIGHT,
-		MAX_AVAIL_WIDTH,
-		PLUS_VERSION,
-		COPYRIGHT_OWNER_ID,
-		COPYRIGHT_OWNER_NAME,
-		IMAGE_CREATOR_ID,
-		IMAGE_CREATOR_NAME,
-		LICENSOR_ID,
-		LICENSOR_NAME,
-		LICENSOR_CITY,
-		LICENSOR_COUNTRY,
-		LICENSOR_EMAIL,
-		LICENSOR_EXTENDED_ADDRESS,
-		LICENSOR_POSTAL_CODE,
-		LICENSOR_REGION,
-		LICENSOR_STREET_ADDRESS,
-		LICENSOR_TELEPHONE_1,
-		LICENSOR_TELEPHONE_2,
-		LICENSOR_URL,
-		MINOR_MODEL_AGE_DISCLOSURE,
-		MODEL_RELEASE_ID,
-		MODEL_RELEASE_STATUS,
-		PROPERTY_RELEASE_ID,
-		PROPERTY_RELEASE_STATUS,
-		ARTWORK_OR_OBJECT_DETAIL_COPYRIGHT_NOTICE,
-		ARTWORK_OR_OBJECT_DETAIL_CREATOR,
-		ARTWORK_OR_OBJECT_DETAIL_DATE_CREATED,
-		ARTWORK_OR_OBJECT_DETAIL_SOURCE,
-		ARTWORK_OR_OBJECT_DETAIL_SOURCE_INVENTORY_NUMBER,
-		ARTWORK_OR_OBJECT_DETAIL_TITLE,
-		LOCATION_SHOWN_CITY,
-		LOCATION_SHOWN_COUNTRY_CODE,
-		LOCATION_SHOWN_COUNTRY_NAME,
-		LOCATION_SHOWN_PROVINCE_OR_STATE,
-		LOCATION_SHOWN_SUBLOCATION,
-		LOCATION_SHOWN_WORLD_REGION,
-		LOCATION_CREATED_CITY,
-		LOCATION_CREATED_COUNTRY_CODE,
-		LOCATION_CREATED_COUNTRY_NAME,
-		LOCATION_CREATED_PROVINCE_OR_STATE,
-		LOCATION_CREATED_SUBLOCATION,
-		LOCATION_CREATED_WORLD_REGION,
-		REGISTRY_ENTRY_CREATED_ITEM_ID,
-		REGISTRY_ENTRY_CREATED_ORGANISATION_ID
-	};
+   String NAMESPACE_URI_IPTC_CORE = "http://iptc.org/std/Iptc4xmpCore/1.0/xmlns/";
+   String NAMESPACE_URI_IPTC_EXT = "http://iptc.org/std/Iptc4xmpExt/2008-02-29/";
+   String NAMESPACE_URI_PLUS = "http://ns.useplus.org/ldf/xmp/1.0/";
+
+   String PREFIX_IPTC_CORE = "Iptc4xmpCore";
+   String PREFIX_IPTC_EXT = "Iptc4xmpExt";
+   String PREFIX_PLUS = "plus";
+
+   /**
+    * Name of the city the content is focussing on -- either the place shown
+    * in visual media or referenced by text or audio media. This element is at
+    * the third level of a top-down geographical hierarchy.
+    * <p>
+    * This is a detail of a location with blurred semantics as it does not
+    * clearly indicate whether it is the location in the image or the location
+    * the photo was taken - which can be different. Two more concise properties
+    * are available in IPTC Extension with Location Created and Location Shown
+    * in the Image.
+    * <p>
+    * Maps to this IIM property: 2:90 City
+    * 
+    * @see Photoshop#CITY
+    */
+   Property CITY = Photoshop.CITY;
+
+   /**
+    * Full name of the country the content is focussing on -- either the
+    * country shown in visual media or referenced in text or audio media. This
+    * element is at the top/first level of a top- down geographical hierarchy.
+    * The full name should be expressed as a verbal name and not as a code, a
+    * code should go to the element "CountryCode"
+    * <p>
+    * This is a detail of a location with blurred semantics as it does not
+    * clearly indicate whether it is the location in the image or the location
+    * the photo was taken - which can be different. Two more concise properties
+    * are available in IPTC Extension with Location Created and Location Shown
+    * in the Image.
+    * <p>
+    * Maps to this IIM property: 2:101 Country/Primary Location Name
+    * 
+    * @see Photoshop#COUNTRY
+    */
+   Property COUNTRY = Photoshop.COUNTRY;
+
+   /**
+    * Code of the country the content is focussing on -- either the country
+    * shown in visual media or referenced in text or audio media. This element
+    * is at the top/first level of a top-down geographical hierarchy. The code
+    * should be taken from ISO 3166 two or three letter code. The full name of
+    * a country should go to the "Country" element.
+    * <p>
+    * This is a detail of a location with blurred semantics as it does not
+    * clearly indicate whether it is the location in the image or the location
+    * the photo was taken - which can be different. Two more concise properties
+    * are available in IPTC Extension with Location Created and Location Shown
+    * in the Image.
+    * <p>
+    * Maps to this IIM property: 2:100 Country/Primary Location Code
+    */
+   Property COUNTRY_CODE = Property.internalText(
+         PREFIX_IPTC_CORE + Metadata.NAMESPACE_PREFIX_DELIMITER + "CountryCode");
+
+   /**
+    * A textual description, including captions, of the item's content,
+    * particularly used where the object is not text.
+    * <p>
+    * Note: the XMP property (dc:description) which stores the value of this
+    * IPTC Core property is of type Lang Alt. Hence any software agent dealing
+    * with this property must abide to the processing rules for
+    * Lang Alt value type as specified by the XMP specifications.
+    * <p>
+    * Maps to this IIM property: 2:120 Caption/Abstract
+    * 
+    * @see DublinCore#DESCRIPTION
+    */
+   Property DESCRIPTION = DublinCore.DESCRIPTION;
+
+   /**
+    * A brief synopsis of the caption. Headline is not the same as Title.
+    * <p>
+    * Maps to this IIM property: 2:105 Headline
+    * 
+    * @see Photoshop#HEADLINE
+    */
+   Property HEADLINE = Photoshop.HEADLINE;
+
+   /**
+    * Describes the nature, intellectual, artistic or journalistic
+    * characteristic of a item, not specifically its content.
+    * <p>
+    * The IPTC recognizes that the corresponding IPTC Genre NewsCodes needs
+    * photo specific extension to be better usable with this field (as of the
+    * release of this standard in the year 2008).
+    * <p>
+    * Maps to this IIM property: 2:04 Object Attribute Reference
+    */
+   Property INTELLECTUAL_GENRE = Property.internalText(
+         PREFIX_IPTC_CORE + Metadata.NAMESPACE_PREFIX_DELIMITER + "IntellectualGenre");
+
+   /**
+    * Keywords to express the subject of the content. Keywords may be free
+    * text and don't have to be taken from a controlled vocabulary. Codes from
+    * the controlled vocabulary IPTC Subject NewsCodes must go to the
+    * "Subject Code" field.
+    * <p>
+    * Single values of this field should not be restricted to single words
+    * but must allow for phrases as well.
+    * <p>
+    * Maps to this IIM property: 2:25 Keywords
+    * 
+    * @see DublinCore#SUBJECT
+    */
+   Property KEYWORDS = DublinCore.SUBJECT;
+
+   /**
+    * Name of the subregion of a country -- either called province or state or
+    * anything else -- the content is focussing on -- either the subregion
+    * shown in visual media or referenced by text or audio media. This element
+    * is at the second level of a top-down geographical hierarchy.
+    * <p>
+    * This is a detail of a location with blurred semantics as it does not
+    * clearly indicate whether it is the location in the image or the location
+    * the photo was taken - which can be different. Two more concise properties
+    * are available in IPTC Extension with Location Created and Location Shown
+    * in the Image.
+    * <p>
+    * Maps to this IIM property: 2:95 Province/State
+    * 
+    * @see Photoshop#STATE
+    */
+   Property PROVINCE_OR_STATE = Photoshop.STATE;
+
+   /**
+    * Describes the scene of a news content. Specifies one or more terms
+    * from the IPTC "Scene-NewsCodes". Each Scene is represented as a string of
+    * 6 digits in an unordered list.
+    * <p>
+    * Note: Only Scene values from this IPTC taxonomy should be used here. More
+    * about the IPTC Scene-NewsCodes at www.newscodes.org.
+    */
+   Property SCENE_CODE = Property.internalText(
+         PREFIX_IPTC_CORE + Metadata.NAMESPACE_PREFIX_DELIMITER + "Scene");
+
+   /**
+    * Specifies one or more Subjects from the IPTC Subject-NewsCodes taxonomy
+    * to categorise the content. Each Subject is represented as a string of 8
+    * digits in an unordered list.
+    * <p>
+    * Note: Only Subjects from a controlled vocabulary should be used here,
+    * free text has to be put into the Keyword element. More about
+    * IPTC Subject-NewsCodes at www.newscodes.org.
+    */
+   Property SUBJECT_CODE = Property.internalTextBag(
+         PREFIX_IPTC_CORE + Metadata.NAMESPACE_PREFIX_DELIMITER + "SubjectCode");
+
+   /**
+    * Name of a sublocation the content is focussing on -- either the
+    * location shown in visual media or referenced by text or audio media. This
+    * location name could either be the name of a sublocation to a city or the
+    * name of a well known location or (natural) monument outside a city. In
+    * the sense of a sublocation to a city this element is at the fourth level
+    * of a top-down geographical hierarchy.
+    * <p>
+    * This is a detail of a location with blurred semantics as it does not
+    * clearly indicate whether it is the location in the image or the location
+    * the photo was taken - which can be different. Two more concise properties
+    * are available in IPTC Extension with Location Created and Location Shown
+    * in the Image.
+    * <p>
+    * Maps to this IIM property: 2:92 Sublocation
+    */
+   Property SUBLOCATION = Property.internalText(
+         PREFIX_IPTC_CORE + Metadata.NAMESPACE_PREFIX_DELIMITER + "Location");
+
+   /**
+    * Designates the date and optionally the time the intellectual content was
+    * created rather than the date of the creation of the physical
+    * representation.
+    * <p>
+    * If a software system requires explicit time values and no time is given
+    * by the Date Created property the software system should default the time
+    * to 00:00:00. If the software system does not require an explicit time
+    * value the time part should be left empty as it is.
+    * <p>
+    * Note 1: Any content of the IIM dataset 2:60, Time Created, should be
+    * merged to this element.
+    * Note 2: Implementers are encouraged to provide
+    * the creation date and time from the EXIF data of a digital
+    * camera to the user for entering this date for the first time.
+    * <p>
+    * Maps to this IIM property: 2:55 Date Created
+    * 
+    * @see Photoshop#DATE_CREATED
+    */
+   Property DATE_CREATED = Photoshop.DATE_CREATED;
+
+   /**
+    * Identifier or the name of the person involved in writing, editing or
+    * correcting the description of the content.
+    * <p>
+    * Maps to this IIM property: 2:122 Writer/Editor
+    * 
+    * @see Photoshop#CAPTION_WRITER
+    */
+   Property DESCRIPTION_WRITER = Photoshop.CAPTION_WRITER;
+
+   /**
+    * Any of a number of instructions from the provider or creator to the
+    * receiver of the item.
+    * <p>
+    * Maps to this IIM property: 2:40 Special Instruction
+    * 
+    * @see Photoshop#INSTRUCTIONS
+    */
+   Property INSTRUCTIONS = Photoshop.INSTRUCTIONS;
+
+   /**
+    * Number or identifier for the purpose of improved workflow handling. This
+    * is a user created identifier related to the job for which the item is
+    * supplied.
+    * <p>
+    * Note: As this identifier references a job of the receiver's workflow it
+    * must first be issued by the receiver, then transmitted to the creator or
+    * provider of the news object and finally added by the creator
+    * to this field.
+    * <p>
+    * Maps to this IIM property: 2:103 Original Transmission Reference
+    * 
+    * @see Photoshop#TRANSMISSION_REFERENCE
+    */
+   Property JOB_ID = Photoshop.TRANSMISSION_REFERENCE;
+
+   /**
+    * A shorthand reference for the item. Title provides a short human readable
+    * name which can be a text and/or numeric reference. It is not the same as
+    * Headline.
+    * <p>
+    * Many use the Title field to store the filename of the image, though the
+    * field may be used in many ways. Formal identifiers are provided by the
+    * Digital Image Id, or the Registry Entry property of the IPTC Extension.
+    * <p>
+    * Note 1: This element aligns with the use of Dublin Core's "Title"
+    * element.
+    * Note 2: the XMP property (dc:title) which stores the value of
+    * this IPTC Core property is of type Lang Alt. Hence any software agent
+    * dealing with this property must abide to the processing rules for Lang
+    * Alt value type as specified by the XMP specifications.
+    * <p>
+    * Maps to this IIM property: 2:05 Object Name
+    * 
+    * @see DublinCore#TITLE
+    */
+   Property TITLE = DublinCore.TITLE;
+
+   /**
+    * Contains any necessary copyright notice for claiming the intellectual
+    * property for this item and should identify the current owner of the
+    * copyright for the item. Other entities like the creator of the item may
+    * be added in the corresponding field. Notes on usage rights should be
+    * provided in "Rights usage terms".
+    * <p>
+    * Copyright ownership can be expressed in a more controlled way using the
+    * PLUS fields "Copyright Owner", "Copyright Owner ID",
+    * "Copyright Owner Name" of the IPTC Extension. It is the user's
+    * responsibility to keep the values of the four fields in sync.
+    * <p>
+    * Note: the XMP property (dc:rights) which stores the value of this IPTC
+    * Core property is of type Lang Alt. Hence any software agent dealing with
+    * this property must abide to the processing rules for Lang Alt
+    * value type as specified by the XMP specifications.
+    * <p>
+    * Maps to this IIM property: 2:116 Copyright Notice
+    * 
+    * @see DublinCore#RIGHTS
+    */
+   Property COPYRIGHT_NOTICE = DublinCore.RIGHTS;
+
+   /**
+    * Contains the name of the person who created the content of this item, a
+    * photographer for photos, a graphic artist for graphics, or a writer for
+    * textual news, but in cases where the photographer should not be
+    * identified the name of a company or organisation may be appropriate.
+    * <p>
+    * The creator can be expressed in a more controlled way using the
+    * "Image Creator" of PLUS in the IPTC Extension additionally. It is the
+    * user's responsibility to keep the values of the IPTC Core and the PLUS
+    * fields in sync.
+    * <p>
+    * Maps to this IIM property: 2:80 By-line
+    * 
+    * @see DublinCore#CREATOR
+    */
+   Property CREATOR = DublinCore.CREATOR;
+
+   /**
+    * The creator's contact information provides all necessary information to
+    * get in contact with the creator of this item and comprises a set of
+    * sub-properties for proper addressing.
+    * <p>
+    * The IPTC Extension Licensor fields should be used instead of these
+    * Creator's Contact Info fields if you are using IPTC Extension fields. If
+    * the creator is also the licensor his or her contact information should be
+    * provided in the Licensor fields.
+    * <p>
+    * Note 1 to user interface implementers: All sub-properties of "Creator's
+    * contact information" should be shown as group on the form.
+    * Note 2: the
+    * CreatorContactInfo sub-properties' naming aligns with the vCard
+    * specification RFC 2426.
+    */
+   Property CREATORS_CONTACT_INFO = Property.internalText(
+         PREFIX_IPTC_CORE + Metadata.NAMESPACE_PREFIX_DELIMITER + "CreatorContactInfo");
+
+   /**
+    * Contains the job title of the person who created the content of this
+    * item. As this is sort of a qualifier the Creator element has to be filled
+    * in as mandatory prerequisite for using Creator's Jobtitle.
+    * <p>
+    * Maps to this IIM property: 2:85 By-line Title
+    * 
+    * @see Photoshop#AUTHORS_POSITION
+    */
+   Property CREATORS_JOB_TITLE = Photoshop.AUTHORS_POSITION;
+
+   /**
+    * The credit to person(s) and/or organisation(s) required by the supplier
+    * of the item to be used when published. This is a free-text field.
+    * <p>
+    * Note 1: For more formal identifications of the creator or the owner of
+    * the copyrights of this image other rights properties may be used.
+    * Note 2:
+    * This property was named "Credit" by the IIM metadata, then it was renamed
+    * to "Provider" in IPTC Core 1.0. In IPTC Core 1.1. it has been renamed to
+    * "Credit Line" as the field is used for this purpose by many users.
+    * <p>
+    * Maps to this IIM property: 2:110 Credit
+    * 
+    * @see Photoshop#CREDIT_LINE
+    */
+   Property CREDIT_LINE = Photoshop.CREDIT;
+
+   /**
+    * The licensing parameters of the item expressed in free-text.
+    * <p>
+    * The PLUS fields of the IPTC Extension can be used in parallel to express
+    * the licensed usage in more controlled terms.
+    */
+   Property RIGHTS_USAGE_TERMS = XMPRights.USAGE_TERMS;
+
+   /**
+    * Identifies the original owner of the copyright for the intellectual
+    * content of the item. This could be an agency, a member of an agency or an
+    * individual. Source could be different from Creator and from the entities
+    * in the CopyrightNotice.
+    * <p>
+    * The original owner can never change. For that reason the content of this
+    * property should never be changed or deleted after the information is
+    * entered following the news object's initial creation.
+    * <p>
+    * Maps to this IIM property: 2:115 Source
+    * 
+    * @see Photoshop#SOURCE
+    */
+   Property SOURCE = Photoshop.SOURCE;
+
+   /**
+    * The contact information address part. Comprises an optional company name
+    * and all required information to locate the building or postbox to which
+    * mail should be sent. To that end, the address is a multiline field.
+    * <p>
+    * Note 1: to user interface implementers: This field should be part of a
+    * "Contact information" group on the form.
+    * Note 2: the ContactInfo naming aligns with the vCard specification RFC 2426.
+    */
+   Property CONTACT_INFO_ADDRESS = Property.internalText(
+         PREFIX_IPTC_CORE + Metadata.NAMESPACE_PREFIX_DELIMITER + "CiAdrExtadr");
+
+   /**
+    * The contact information city part.
+    * <p>
+    * Note 1: to user interface implementers: This field should be part of a
+    * "Contact information" group on the form.
+    * Note 2: the ContactInfo naming aligns with the vCard specification RFC 2426.
+    */
+   Property CONTACT_INFO_CITY = Property.internalText(
+         PREFIX_IPTC_CORE + Metadata.NAMESPACE_PREFIX_DELIMITER + "CiAdrCity");
+
+   /**
+    * The contact information country part.
+    * <p>
+    * Note 1: to user interface implementers: This field should be part of a
+    * "Contact information" group on the form.
+    * Note 2: the ContactInfo naming aligns with the vCard specification RFC 2426.
+    */
+   Property CONTACT_INFO_COUNTRY = Property.internalText(
+         PREFIX_IPTC_CORE + Metadata.NAMESPACE_PREFIX_DELIMITER + "CiAdrCtry");
+
+   /**
+    * The contact information email address part.
+    * <p>
+    * Multiple email addresses can be given. May have to be separated by a
+    * comma in the user interface.
+    * <p>
+    * Note 1: to user interface implementers: This field should be part of a
+    * "Contact information" group on the form.
+    * Note 2 to user interface
+    * implementers: provide sufficient space to fill in multiple e-mail
+    * addresses.
+    * Note 3: the ContactInfo naming aligns with the vCard
+    * specification RFC 2426.
+    */
+   Property CONTACT_INFO_EMAIL = Property.internalText(
+         PREFIX_IPTC_CORE + Metadata.NAMESPACE_PREFIX_DELIMITER + "CiEmailWork");
+
+   /**
+    * The contact information phone number part.
+    * <p>
+    * Multiple numbers can be given. May have to be separated by a
+    * comma in the user interface.
+    * <p>
+    * Note 1: to user interface implementers: This field should be part of a
+    * "Contact information" group on the form.
+    * Note 2 to user interface
+    * implementers: provide sufficient space to fill in multiple international
+    * numbers.
+    * Note 3: the ContactInfo naming aligns with the vCard
+    * specification RFC 2426.
+    */
+   Property CONTACT_INFO_PHONE = Property.internalText(
+         PREFIX_IPTC_CORE + Metadata.NAMESPACE_PREFIX_DELIMITER + "CiTelWork");
+
+   /**
+    * The contact information part denoting the local postal code.
+    * <p>
+    * Note 1: to user interface implementers: This field should be part of a
+    * "Contact information" group on the form.
+    * Note 2: the ContactInfo naming aligns with the vCard specification RFC 2426.
+    */
+   Property CONTACT_INFO_POSTAL_CODE = Property.internalText(
+         PREFIX_IPTC_CORE + Metadata.NAMESPACE_PREFIX_DELIMITER + "CiAdrPcode");
+
+   /**
+    * The contact information part denoting regional information such as state or province.
+    * <p>
+    * Note 1: to user interface implementers: This field should be part of a
+    * "Contact information" group on the form.
+    * Note 2: the ContactInfo naming aligns with the vCard specification RFC 2426.
+    */
+   Property CONTACT_INFO_STATE_PROVINCE = Property.internalText(
+         PREFIX_IPTC_CORE + Metadata.NAMESPACE_PREFIX_DELIMITER + "CiAdrRegion");
+
+   /**
+    * The contact information web address part. Multiple addresses can be given, separated by a comma.
+    * <p>
+    * Note 1: to user interface implementers: This field should be part of a
+    * "Contact information" group on the form.
+    * Note 2 to user interface
+    * implementers: provide sufficient space to fill in multiple URLs.
+    * Note 3: the ContactInfo naming aligns with the vCard
+    * specification RFC 2426.
+    */
+   Property CONTACT_INFO_WEB_URL = Property.internalText(
+         PREFIX_IPTC_CORE + Metadata.NAMESPACE_PREFIX_DELIMITER + "CiUrlWork");
+
+   /**
+    * As this metadata element pertains to distribution management, it was not
+    * adopted. However, this data is still synchronised with the XMP property
+    * [photoshop:Urgency], and hence, available for future use, but outside the
+    * IPTC Core.
+    *
+    * @deprecated
+    */
+   Property PHOTOSHOP_URGENCY = Photoshop.URGENCY;
+
+   /**
+    * As this metadata element was earmarked as deprecated already for IIM 4.1,
+    * it was not adopted. However, this data is still synchronised with the XMP
+    * property [photoshop:Category], and hence available for future use - but
+    * outside the IPTC Core. For migrating from Category codes to Subject Codes
+    * please read the Guideline for mapping Category Codes to Subject NewsCodes
+    * section below.
+    *
+    * @deprecated
+    */
+   Property PHOTOSHOP_CATEGORY = Photoshop.CATEGORY;
+
+   /**
+    * As this metadata element was earmarked as deprecated already for IIM 4.1,
+    * it was not adopted. However, this data is still synchronised with the XMP
+    * property [photoshop:SupplementalCategories], and hence available for
+    * future use - but outside the IPTC Core.
+    *
+    * @deprecated
+    */
+   Property PHOTOSHOP_SUPPLEMENTAL_CATEGORIES = Photoshop.SUPPLEMENTAL_CATEGORIES;
+
+   /**
+    * Information about the ethnicity and other facets of the model(s) in a
+    * model-released image.
+    * <p>
+    * Use the Model Age field for the age of model(s).
+    */
+   Property ADDITIONAL_MODEL_INFO = Property.internalText(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "AddlModelInfo");
+
+   /**
+    * A set of metadata about artwork or an object in the item
+    */
+   Property ARTWORK_OR_OBJECT = Property.internalTextBag(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "ArtworkOrObject");
+
+   /**
+    * A set of metadata about artwork or an object in the item
+    */
+   Property ORGANISATION_CODE = Property.internalTextBag(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "OrganisationInImageCode");
+
+   /**
+    * A term to describe the content of the image by a value from a Controlled
+    * Vocabulary.
+    * <p>
+    * This property is part of the Photo Metadata 2008 specifications, but
+    * should not released to the public on the standard Adobe Custom Panels for
+    * IPTC metadata or other user interfaces unless agreed by the IPTC.
+    */
+   Property CONTROLLED_VOCABULARY_TERM = Property.internalTextBag(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "CVterm");
+
+   /**
+    * A location the content of the item is about. For photos that is a
+    * location shown in the image.
+    * <p>
+    * If the location the image was taken in is different from this location
+    * the property Location Created should be used too.
+    */
+   Property LOCATION_SHOWN = Property.internalTextBag(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "LocationShown");
+
+   /**
+    * Age of the human model(s) at the time this image was taken in a model
+    * released image.
+    * <p>
+    * The user should be aware of any legal implications of providing ages for
+    * young models. Ages below 18 years should not be included.
+    */
+   Property MODEL_AGE = Property.internalTextBag(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "ModelAge");
+
+   /**
+    * Name of the organisation or company which is featured in the content.
+    * <p>
+    * May be supplemented by values from a controlled vocabulary in the
+    * Organisation Code field.
+    */
+   Property ORGANISATION_NAME = Property.internalTextBag(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "OrganisationInImageName");
+
+   /**
+    * Name of a person the content of the item is about. For photos that is a
+    * person shown in the image.
+    */
+   Property PERSON = Property.internalTextBag(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "PersonInImage");
+
+   /**
+    * Globally unique identifier for the item. It is created and applied by the
+    * creator of the item at the time of its creation . This value shall not be
+    * changed after that time.
+    * <p>
+    * The identifier will probably be generated by the technical means of an
+    * imaging device or software and should be applied to the digital image
+    * file as early as possible in its life cycle. This identifier does not
+    * identify any pictured content, particularly in case of a scan of non-
+    * digital images, only this digital representation.
+    * <p>
+    * Any algorithm to create this identifier has to comply with the technical
+    * requirements to create a globally unique id. Any device creating digital
+    * images - e.g. still image cameras, video cameras, scanners - should
+    * create such an identifer right at the time of the creation of the digital
+    * data and add the id to the set of metadata without compromising
+    * performance. It is recommended that this image identifier allows
+    * identifying the device by which the image data and the GUID were created.
+    * IPTC's basic requirements for unique ids are:
+    * - It must be globally unique. Algorithms for this purpose exist.
+    * - It should identify the camera body.
+    * - It should identify each individual photo from this camera body.
+    * - It should identify the date and time of the creation of the picture.
+    * - It should be secured against tampering.
+    * This field should be implemented in a way to prove it has not been changed since its value has
+    * been applied. If the identifier has been created by the imaging device
+    * its type and brand can be found in the Exif/technical metadata.
+    */
+   Property DIGITAL_IMAGE_GUID = Property.internalText(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "DigImageGUID");
+
+   /**
+    * The type of the source digital file.
+    * <p>
+    * The IPTC recommends not to implement this property any longer.
+    *
+    * @deprecated
+    */
+   Property DIGITAL_SOURCE_FILE_TYPE = Property.internalText(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "DigitalSourcefileType");
+
+   /**
+    * The type of the source of this digital image
+    */
+   Property DIGITAL_SOURCE_TYPE = Property.internalText(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "DigitalSourceType");
+
+   /**
+    * Names or describes the specific event the content relates to.
+    * <p>
+    * Examples are: a press conference, dedication ceremony, etc. If this is a
+    * sub-event of a larger event both can be provided by the field: e.g. XXXIX
+    * Olympic Summer Games (Beijing): opening ceremony. Unplanned events could
+    * be named by this property too.
+    */
+   Property EVENT = Property.internalText(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "Event");
+
+   /**
+    * Both a Registry Item Id and a Registry Organisation Id to record any
+    * registration of this item with a registry.
+    * <p>
+    * Typically an id from a registry is negotiated and applied after the
+    * creation of the digital image.
+    * <p>
+    * Any user interface implementation must show both sub-properties - Item Id
+    * and Organisation Id - as corresponding values. Further an input to both
+    * fields should be made mandatory.
+    */
+   Property IMAGE_REGISTRY_ENTRY = Property.internalTextBag(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "RegistryId");
+
+   /**
+    * Identifies the most recent supplier of the item, who is not necessarily
+    * its owner or creator.
+    * <p>
+    * For identifying the supplier either a well known and/or registered
+    * company name or a URL of the company's web site may be used. This
+    * property succeeds the Provider property of IPTC Core 1.0 by its semantics
+    * as that Provider was renamed to Credit Line.
+    * <p>
+    * This is a PLUS version 1.2 property included in the IPTC Extension
+    * schema.
+    */
+   Property IMAGE_SUPPLIER = Property.internalText(
+         PREFIX_PLUS + Metadata.NAMESPACE_PREFIX_DELIMITER + "ImageSupplier");
+
+   /**
+    * Identifies the most recent supplier of the item, who is not necessarily
+    * its owner or creator.
+    * <p>
+    * For identifying the supplier either a well known and/or registered
+    * company name or a URL of the company's web site may be used. This
+    * property succeeds the Provider property of IPTC Core 1.0 by its semantics
+    * as that Provider was renamed to Credit Line.
+    * <p>
+    * This is a PLUS version 1.2 property included in the IPTC Extension
+    * schema.
+    */
+   Property IMAGE_SUPPLIER_ID = Property.internalText(
+         PREFIX_PLUS + Metadata.NAMESPACE_PREFIX_DELIMITER + "ImageSupplierId");
+
+   /**
+    * Identifies the most recent supplier of the item, who is not necessarily
+    * its owner or creator.
+    * <p>
+    * For identifying the supplier either a well known and/or registered
+    * company name or a URL of the company's web site may be used. This
+    * property succeeds the Provider property of IPTC Core 1.0 by its semantics
+    * as that Provider was renamed to Credit Line.
+    * <p>
+    * This is a PLUS version 1.2 property included in the IPTC Extension
+    * schema.
+    */
+   Property IMAGE_SUPPLIER_NAME = Property.internalText(
+         PREFIX_PLUS + Metadata.NAMESPACE_PREFIX_DELIMITER + "ImageSupplierName");
+
+   /**
+    * Optional identifier assigned by the Image Supplier to the image.
+    * <p>
+    * This is a PLUS version 1.2 property included in the IPTC Extension
+    * schema.
+    */
+   Property IMAGE_SUPPLIER_IMAGE_ID = Property.internalText(
+         PREFIX_PLUS + Metadata.NAMESPACE_PREFIX_DELIMITER + "ImageSupplierImageID");
+
+   /**
+    * The date and optionally time when any of the IPTC photo metadata fields
+    * has been last edited
+    * <p>
+    * The public use of this property is deprecated by IPTC Extension version
+    * 1.1. It may only still be used by a private user interface for a use
+    * scoped to a company. If used this field should be a timestamp of the
+    * latest change applied to any of the fields.
+    * <p>
+    * The value of this property should never be set by software. XMP-aware
+    * software should reflect any changes to metadata by the xmp:MetadataDate
+    * property of the XMP Basic scheme.
+    */
+   Property IPTC_LAST_EDITED = Property.internalDate(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "IptcLastEdited");
+
+   /**
+    * The location the content of the item was created.
+    * <p>
+    * If the location in the image is different from the location the photo was
+    * taken the IPTC Extension property Location Shown in the Image should be
+    * used.
+    */
+   Property LOCATION_CREATED = Property.internalTextBag(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "LocationCreated");
+
+   /**
+    * The maximum available height in pixels of the original photo from which
+    * this photo has been derived by downsizing.
+    */
+   Property MAX_AVAIL_HEIGHT = Property.internalInteger(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "MaxAvailHeight");
+
+   /**
+    * The maximum available width in pixels of the original photo from which
+    * this photo has been derived by downsizing.
+    */
+   Property MAX_AVAIL_WIDTH = Property.internalInteger(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "MaxAvailWidth");
+
+   /**
+    * The version number of the PLUS standards in place at the time of the
+    * transaction.
+    * <p>
+    * This property was included into the IPTC Extension schema from PLUS
+    * version 1.2 as all other PLUS properties. To reflect this the value of
+    * "PLUS Version" should be set to the string "1.2.0"
+    */
+   Property PLUS_VERSION = Property.internalText(
+         PREFIX_PLUS + Metadata.NAMESPACE_PREFIX_DELIMITER + "Version");
+
+   /**
+    * Owner or owners of the copyright in the licensed image.
+    * <p>
+    * Serves to identify the rights holder/s for the image. The Copyright
+    * Owner, Image Creator and Licensor may be the same or different entities.
+    * <p>
+    * This is a PLUS version 1.2 property included in the IPTC Extension
+    * schema.
+    */
+   Property COPYRIGHT_OWNER = Property.internalTextBag(
+         PREFIX_PLUS + Metadata.NAMESPACE_PREFIX_DELIMITER + "CopyrightOwner");
+
+   /**
+    * The ID of the owner or owners of the copyright in the licensed image.
+    * <p>
+    * Serves to identify the rights holder/s for the image. The Copyright
+    * Owner, Image Creator and Licensor may be the same or different entities.
+    * <p>
+    * This is a PLUS version 1.2 property included in the IPTC Extension
+    * schema.
+    */
+   Property COPYRIGHT_OWNER_ID = Property.internalTextBag(
+         PREFIX_PLUS + Metadata.NAMESPACE_PREFIX_DELIMITER + "CopyrightOwnerId");
+
+   /**
+    * The name of the owner or owners of the copyright in the licensed image.
+    * <p>
+    * Serves to identify the rights holder/s for the image. The Copyright
+    * Owner, Image Creator and Licensor may be the same or different entities.
+    * <p>
+    * This is a PLUS version 1.2 property included in the IPTC Extension
+    * schema.
+    */
+   Property COPYRIGHT_OWNER_NAME = Property.internalTextBag(
+         PREFIX_PLUS + Metadata.NAMESPACE_PREFIX_DELIMITER + "CopyrightOwnerName");
+
+   /**
+    * Creator or creators of the image.
+    * <p>
+    * The creator can be additionally expressed in free-text using the IPTC
+    * Core Creator field. In many countries, the Image Creator must be
+    * attributed in association with any use of the image. The Image Creator,
+    * Copyright Owner, Image Supplier and Licensor may be the same or different
+    * entities.
+    * <p>
+    * This is a PLUS version 1.2 property included in the IPTC Extension
+    * schema.
+    */
+   Property IMAGE_CREATOR = Property.internalTextBag(
+         PREFIX_PLUS + Metadata.NAMESPACE_PREFIX_DELIMITER + "ImageCreator");
+
+   /**
+    * The ID of the creator or creators of the image.
+    * <p>
+    * The creator can be additionally expressed in free-text using the IPTC
+    * Core Creator field. In many countries, the Image Creator must be
+    * attributed in association with any use of the image. The Image Creator,
+    * Copyright Owner, Image Supplier and Licensor may be the same or different
+    * entities.
+    * <p>
+    * This is a PLUS version 1.2 property included in the IPTC Extension
+    * schema.
+    */
+   Property IMAGE_CREATOR_ID = Property.internalTextBag(
+         PREFIX_PLUS + Metadata.NAMESPACE_PREFIX_DELIMITER + "ImageCreatorId");
+
+   /**
+    * The name of the creator or creators of the image.
+    * <p>
+    * The creator can be additionally expressed in free-text using the IPTC
+    * Core Creator field. In many countries, the Image Creator must be
+    * attributed in association with any use of the image. The Image Creator,
+    * Copyright Owner, Image Supplier and Licensor may be the same or different
+    * entities.
+    * <p>
+    * This is a PLUS version 1.2 property included in the IPTC Extension
+    * schema.
+    */
+   Property IMAGE_CREATOR_NAME = Property.internalTextBag(
+         PREFIX_PLUS + Metadata.NAMESPACE_PREFIX_DELIMITER + "ImageCreatorName");
+
+   /**
+    * A person or company that should be contacted to obtain a licence for
+    * using the item or who has licensed the item.
+    * <p>
+    * This is a PLUS version 1.2 property included in the IPTC Extension
+    * schema.
+    */
+   Property LICENSOR = Property.internalTextBag(
+         PREFIX_PLUS + Metadata.NAMESPACE_PREFIX_DELIMITER + "Licensor");
+
+   /**
+    * The ID of the person or company that should be contacted to obtain a licence for
+    * using the item or who has licensed the item.
+    * <p>
+    * This is a PLUS version 1.2 property included in the IPTC Extension
+    * schema.
+    */
+   Property LICENSOR_ID = Property.internalTextBag(
+         PREFIX_PLUS + Metadata.NAMESPACE_PREFIX_DELIMITER + "LicensorId");
+
+   /**
+    * The name of the person or company that should be contacted to obtain a licence for
+    * using the item or who has licensed the item.
+    * <p>
+    * This is a PLUS version 1.2 property included in the IPTC Extension
+    * schema.
+    */
+   Property LICENSOR_NAME = Property.internalTextBag(
+         PREFIX_PLUS + Metadata.NAMESPACE_PREFIX_DELIMITER + "LicensorName");
+
+   /**
+    * The city of a person or company that should be contacted to obtain a licence for
+    * using the item or who has licensed the item.
+    * <p>
+    * This is a PLUS version 1.2 property included in the IPTC Extension
+    * schema.
+    */
+   Property LICENSOR_CITY = Property.internalTextBag(
+         PREFIX_PLUS + Metadata.NAMESPACE_PREFIX_DELIMITER + "LicensorCity");
+
+   /**
+    * The country of a person or company that should be contacted to obtain a licence for
+    * using the item or who has licensed the item.
+    * <p>
+    * This is a PLUS version 1.2 property included in the IPTC Extension
+    * schema.
+    */
+   Property LICENSOR_COUNTRY = Property.internalTextBag(
+         PREFIX_PLUS + Metadata.NAMESPACE_PREFIX_DELIMITER + "LicensorCountry");
+
+   /**
+    * The email of a person or company that should be contacted to obtain a licence for
+    * using the item or who has licensed the item.
+    * <p>
+    * This is a PLUS version 1.2 property included in the IPTC Extension
+    * schema.
+    */
+   Property LICENSOR_EMAIL = Property.internalTextBag(
+         PREFIX_PLUS + Metadata.NAMESPACE_PREFIX_DELIMITER + "LicensorEmail");
+
+   /**
+    * The extended address of a person or company that should be contacted to obtain a licence for
+    * using the item or who has licensed the item.
+    * <p>
+    * This is a PLUS version 1.2 property included in the IPTC Extension
+    * schema.
+    */
+   Property LICENSOR_EXTENDED_ADDRESS = Property.internalTextBag(
+         PREFIX_PLUS + Metadata.NAMESPACE_PREFIX_DELIMITER + "LicensorExtendedAddress");
+
+   /**
+    * The postal code of a person or company that should be contacted to obtain a licence for
+    * using the item or who has licensed the item.
+    * <p>
+    * This is a PLUS version 1.2 property included in the IPTC Extension
+    * schema.
+    */
+   Property LICENSOR_POSTAL_CODE = Property.internalTextBag(
+         PREFIX_PLUS + Metadata.NAMESPACE_PREFIX_DELIMITER + "LicensorPostalCode");
+
+   /**
+    * The region of a person or company that should be contacted to obtain a licence for
+    * using the item or who has licensed the item.
+    * <p>
+    * This is a PLUS version 1.2 property included in the IPTC Extension
+    * schema.
+    */
+   Property LICENSOR_REGION = Property.internalTextBag(
+         PREFIX_PLUS + Metadata.NAMESPACE_PREFIX_DELIMITER + "LicensorRegion");
+
+   /**
+    * The street address of a person or company that should be contacted to obtain a licence for
+    * using the item or who has licensed the item.
+    * <p>
+    * This is a PLUS version 1.2 property included in the IPTC Extension
+    * schema.
+    */
+   Property LICENSOR_STREET_ADDRESS = Property.internalTextBag(
+         PREFIX_PLUS + Metadata.NAMESPACE_PREFIX_DELIMITER + "LicensorStreetAddress");
+
+   /**
+    * The phone number of a person or company that should be contacted to obtain a licence for
+    * using the item or who has licensed the item.
+    * <p>
+    * This is a PLUS version 1.2 property included in the IPTC Extension
+    * schema.
+    */
+   Property LICENSOR_TELEPHONE_1 = Property.internalTextBag(
+         PREFIX_PLUS + Metadata.NAMESPACE_PREFIX_DELIMITER + "LicensorTelephone1");
+
+   /**
+    * The phone number of a person or company that should be contacted to obtain a licence for
+    * using the item or who has licensed the item.
+    * <p>
+    * This is a PLUS version 1.2 property included in the IPTC Extension
+    * schema.
+    */
+   Property LICENSOR_TELEPHONE_2 = Property.internalTextBag(
+         PREFIX_PLUS + Metadata.NAMESPACE_PREFIX_DELIMITER + "LicensorTelephone2");
+
+   /**
+    * The URL of a person or company that should be contacted to obtain a licence for
+    * using the item or who has licensed the item.
+    * <p>
+    * This is a PLUS version 1.2 property included in the IPTC Extension
+    * schema.
+    */
+   Property LICENSOR_URL = Property.internalTextBag(
+         PREFIX_PLUS + Metadata.NAMESPACE_PREFIX_DELIMITER + "LicensorURL");
+
+   /**
+    * Age of the youngest model pictured in the image, at the time that the
+    * image was made.
+    * <p>
+    * This age should not be displayed to the public on open web portals and
+    * the like. But it may be used by image repositories in a
+    * B2B enviroment.
+    * <p>
+    * This is a PLUS version 1.2 property included in the IPTC Extension
+    * schema.
+    */
+   Property MINOR_MODEL_AGE_DISCLOSURE = Property.internalText(
+         PREFIX_PLUS + Metadata.NAMESPACE_PREFIX_DELIMITER + "MinorModelAgeDisclosure");
+
+   /**
+    * Optional identifier associated with each Model Release.
+    * <p>
+    * This is a PLUS version 1.2 property included in the IPTC Extension
+    * schema.
+    */
+   Property MODEL_RELEASE_ID = Property.internalTextBag(
+         PREFIX_PLUS + Metadata.NAMESPACE_PREFIX_DELIMITER + "ModelReleaseID");
+
+   /**
+    * Summarizes the availability and scope of model releases authorizing usage
+    * of the likenesses of persons appearing in the photograph.
+    * <p>
+    * It is recommended to apply the PLUS controlled value Unlimited Model
+    * Releases (MR- UMR) very carefully and to check the wording of the model
+    * release thoroughly before applying it.
+    * <p>
+    * This is a PLUS version 1.2 property included in the IPTC Extension
+    * schema.
+    */
+   Property MODEL_RELEASE_STATUS = Property.internalText(
+         PREFIX_PLUS + Metadata.NAMESPACE_PREFIX_DELIMITER + "ModelReleaseStatus");
+
+   /**
+    * Optional identifier associated with each Property Release.
+    * <p>
+    * This is a PLUS version 1.2 property included in the IPTC Extension
+    * schema.
+    */
+   Property PROPERTY_RELEASE_ID = Property.internalTextBag(
+         PREFIX_PLUS + Metadata.NAMESPACE_PREFIX_DELIMITER + "PropertyReleaseID");
+
+   /**
+    * Summarises the availability and scope of property releases authorizing
+    * usage of the properties appearing in the photograph.
+    * <p>
+    * It is recommended to apply the value PR-UPR very carefully and to check
+    * the wording of the property release thoroughly before applying it.
+    * <p>
+    * This is a PLUS version 1.2 property included in the IPTC Extension
+    * schema.
+    */
+   Property PROPERTY_RELEASE_STATUS = Property.internalText(
+         PREFIX_PLUS + Metadata.NAMESPACE_PREFIX_DELIMITER + "PropertyReleaseStatus");
+
+   /**
+    * Contains any necessary copyright notice for claiming the intellectual
+    * property for artwork or an object in the image and should identify the
+    * current owner of the copyright of this work with associated intellectual
+    * property rights.
+    */
+   Property ARTWORK_OR_OBJECT_DETAIL_COPYRIGHT_NOTICE = Property.internalText(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "AOCopyrightNotice");
+
+   /**
+    * Contains the name of the artist who has created artwork or an object in the image.
+    */
+   Property ARTWORK_OR_OBJECT_DETAIL_CREATOR = Property.internalText(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "AOCreator");
+
+   /**
+    * Designates the date and optionally the time the artwork or object in the
+    * image was created. This relates to artwork or objects with associated
+    * intellectual property rights.
+    */
+   Property ARTWORK_OR_OBJECT_DETAIL_DATE_CREATED = Property.internalDate(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "AODateCreated");
+
+   /**
+    * The organisation or body holding and registering the artwork or object in
+    * the image for inventory purposes.
+    */
+   Property ARTWORK_OR_OBJECT_DETAIL_SOURCE = Property.internalText(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "AOSource");
+
+   /**
+    * The inventory number issued by the organisation or body holding and
+    * registering the artwork or object in the image.
+    */
+   Property ARTWORK_OR_OBJECT_DETAIL_SOURCE_INVENTORY_NUMBER = Property.internalText(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "AOSourceInvNo");
+
+   /**
+    * A reference for the artwork or object in the image.
+    */
+   Property ARTWORK_OR_OBJECT_DETAIL_TITLE = Property.internalText(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "AOTitle");
+
+   /**
+    * Name of the city of a location. This element is at the fourth level of a
+    * top-down geographical hierarchy.
+    */
+   Property LOCATION_SHOWN_CITY = Property.internalText(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "LocationShownCity");
+
+   /**
+    * The ISO code of a country of a location. This element is at the second
+    * level of a top-down geographical hierarchy.
+    * <p>
+    * Note 1: an implementer would have to derive from the length of the value
+    * string whether this is the country code from the two or three letter
+    * scheme as no explicit indication can be provided.
+    */
+   Property LOCATION_SHOWN_COUNTRY_CODE = Property.internalText(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "LocationShownCountryCode");
+
+   /**
+    * The name of a country of a location. This element is at the second level
+    * of a top-down geographical hierarchy.
+    */
+   Property LOCATION_SHOWN_COUNTRY_NAME = Property.internalText(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "LocationShownCountryName");
+
+   /**
+    * The name of a subregion of a country - a province or state - of a
+    * location. This element is at the third level of a top-down geographical
+    * hierarchy.
+    */
+   Property LOCATION_SHOWN_PROVINCE_OR_STATE = Property.internalText(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "LocationShownProvinceState");
+
+   /**
+    * Name of a sublocation. This sublocation name could either be the name of
+    * a sublocation to a city or the name of a well known location or (natural)
+    * monument outside a city. In the sense of a sublocation to a city this
+    * element is at the fifth level of a top-down geographical hierarchy.
+    */
+   Property LOCATION_SHOWN_SUBLOCATION = Property.internalText(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "LocationShownSublocation");
+
+   /**
+    * The name of a world region of a location. This element is at the first
+    * (topI) level of a top- down geographical hierarchy.
+    */
+   Property LOCATION_SHOWN_WORLD_REGION = Property.internalText(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "LocationShownWorldRegion");
+
+   /**
+    * Name of the city of a location. This element is at the fourth level of a
+    * top-down geographical hierarchy.
+    */
+   Property LOCATION_CREATED_CITY = Property.internalText(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "LocationCreatedCity");
+
+   /**
+    * The ISO code of a country of a location. This element is at the second
+    * level of a top-down geographical hierarchy.
+    * <p>
+    * Note 1: an implementer would have to derive from the length of the value
+    * string whether this is the country code from the two or three letter
+    * scheme as no explicit indication can be provided.
+    */
+   Property LOCATION_CREATED_COUNTRY_CODE = Property.internalText(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "LocationCreatedCountryCode");
+
+   /**
+    * The name of a country of a location. This element is at the second level
+    * of a top-down geographical hierarchy.
+    */
+   Property LOCATION_CREATED_COUNTRY_NAME = Property.internalText(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "LocationCreatedCountryName");
+
+   /**
+    * The name of a subregion of a country - a province or state - of a
+    * location. This element is at the third level of a top-down geographical
+    * hierarchy.
+    */
+   Property LOCATION_CREATED_PROVINCE_OR_STATE = Property.internalText(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "LocationCreatedProvinceState");
+
+   /**
+    * Name of a sublocation. This sublocation name could either be the name of
+    * a sublocation to a city or the name of a well known location or (natural)
+    * monument outside a city. In the sense of a sublocation to a city this
+    * element is at the fifth level of a top-down geographical hierarchy.
+    */
+   Property LOCATION_CREATED_SUBLOCATION = Property.internalText(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "LocationCreatedSublocation");
+
+   /**
+    * The name of a world region of a location. This element is at the first
+    * (topI) level of a top- down geographical hierarchy.
+    */
+   Property LOCATION_CREATED_WORLD_REGION = Property.internalText(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "LocationCreatedWorldRegion");
+
+   /**
+    * A unique identifier created by a registry and applied by the creator of
+    * the item. This value shall not be changed after being applied. This
+    * identifier is linked to a corresponding Registry Organisation Identifier.
+    */
+   Property REGISTRY_ENTRY_CREATED_ITEM_ID = Property.internalText(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "RegItemId");
+
+   /**
+    * An identifier for the registry which issued the corresponding Registry Image Id.
+    */
+   Property REGISTRY_ENTRY_CREATED_ORGANISATION_ID = Property.internalText(
+         PREFIX_IPTC_EXT + Metadata.NAMESPACE_PREFIX_DELIMITER + "RegOrgId");
+
+
+   Property[] PROPERTY_GROUP_IPTC_CORE = new Property[] {
+         CITY,
+         COUNTRY,
+         COUNTRY_CODE,
+         DESCRIPTION,
+         HEADLINE,
+         INTELLECTUAL_GENRE,
+         KEYWORDS,
+         PROVINCE_OR_STATE,
+         SCENE_CODE,
+         SUBJECT_CODE,
+         SUBLOCATION,
+         DATE_CREATED,
+         DESCRIPTION_WRITER,
+         INSTRUCTIONS,
+         JOB_ID,
+         TITLE,
+         COPYRIGHT_NOTICE,
+         CREATOR,
+         CREATORS_JOB_TITLE,
+         CREDIT_LINE,
+         RIGHTS_USAGE_TERMS,
+         SOURCE,
+         CONTACT_INFO_ADDRESS,
+         CONTACT_INFO_CITY,
+         CONTACT_INFO_COUNTRY,
+         CONTACT_INFO_EMAIL,
+         CONTACT_INFO_PHONE,
+         CONTACT_INFO_POSTAL_CODE,
+         CONTACT_INFO_STATE_PROVINCE,
+         CONTACT_INFO_WEB_URL
+   };
+
+   Property[] PROPERTY_GROUP_IPTC_EXT = new Property[] {
+         ADDITIONAL_MODEL_INFO,
+         ORGANISATION_CODE,
+         CONTROLLED_VOCABULARY_TERM,
+         MODEL_AGE,
+         ORGANISATION_NAME,
+         PERSON,
+         DIGITAL_IMAGE_GUID,
+         DIGITAL_SOURCE_TYPE,
+         EVENT,
+         IMAGE_SUPPLIER_ID,
+         IMAGE_SUPPLIER_NAME,
+         IMAGE_SUPPLIER_IMAGE_ID,
+         IPTC_LAST_EDITED,
+         MAX_AVAIL_HEIGHT,
+         MAX_AVAIL_WIDTH,
+         PLUS_VERSION,
+         COPYRIGHT_OWNER_ID,
+         COPYRIGHT_OWNER_NAME,
+         IMAGE_CREATOR_ID,
+         IMAGE_CREATOR_NAME,
+         LICENSOR_ID,
+         LICENSOR_NAME,
+         LICENSOR_CITY,
+         LICENSOR_COUNTRY,
+         LICENSOR_EMAIL,
+         LICENSOR_EXTENDED_ADDRESS,
+         LICENSOR_POSTAL_CODE,
+         LICENSOR_REGION,
+         LICENSOR_STREET_ADDRESS,
+         LICENSOR_TELEPHONE_1,
+         LICENSOR_TELEPHONE_2,
+         LICENSOR_URL,
+         MINOR_MODEL_AGE_DISCLOSURE,
+         MODEL_RELEASE_ID,
+         MODEL_RELEASE_STATUS,
+         PROPERTY_RELEASE_ID,
+         PROPERTY_RELEASE_STATUS,
+         ARTWORK_OR_OBJECT_DETAIL_COPYRIGHT_NOTICE,
+         ARTWORK_OR_OBJECT_DETAIL_CREATOR,
+         ARTWORK_OR_OBJECT_DETAIL_DATE_CREATED,
+         ARTWORK_OR_OBJECT_DETAIL_SOURCE,
+         ARTWORK_OR_OBJECT_DETAIL_SOURCE_INVENTORY_NUMBER,
+         ARTWORK_OR_OBJECT_DETAIL_TITLE,
+         LOCATION_SHOWN_CITY,
+         LOCATION_SHOWN_COUNTRY_CODE,
+         LOCATION_SHOWN_COUNTRY_NAME,
+         LOCATION_SHOWN_PROVINCE_OR_STATE,
+         LOCATION_SHOWN_SUBLOCATION,
+         LOCATION_SHOWN_WORLD_REGION,
+         LOCATION_CREATED_CITY,
+         LOCATION_CREATED_COUNTRY_CODE,
+         LOCATION_CREATED_COUNTRY_NAME,
+         LOCATION_CREATED_PROVINCE_OR_STATE,
+         LOCATION_CREATED_SUBLOCATION,
+         LOCATION_CREATED_WORLD_REGION,
+         REGISTRY_ENTRY_CREATED_ITEM_ID,
+         REGISTRY_ENTRY_CREATED_ORGANISATION_ID
+   };
 }
\ No newline at end of file
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/Office.java b/tika-core/src/main/java/org/apache/tika/metadata/Office.java
index 6fc992fac..fce76a608 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/Office.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/Office.java
@@ -25,6 +25,8 @@ package org.apache.tika.metadata;
  * 
  * Note that some of the legacy properties from the {@link MSOffice}
  *  collection still need to be migrated over
+ *  
+ * @since Apache Tika 1.2
  */
 public interface Office {
    // These are taken from the OpenDocumentFormat specification
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/Photoshop.java b/tika-core/src/main/java/org/apache/tika/metadata/Photoshop.java
new file mode 100644
index 000000000..918bb3796
--- /dev/null
+++ b/tika-core/src/main/java/org/apache/tika/metadata/Photoshop.java
@@ -0,0 +1,80 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * IPTC Metadata Descriptions taken from the IPTC Photo Metadata (July 2010) 
+ * standard. These parts Copyright 2010 International Press Telecommunications 
+ * Council.
+ */
+package org.apache.tika.metadata;
+
+/**
+ * XMP Photoshop metadata schema. 
+ * 
+ * A collection of property constants for the 
+ * Photo Metadata properties defined in the XMP Photoshop
+ * standard.
+ * 
+ * @since Apache Tika 1.2
+ * @see <a href="http://partners.adobe.com/public/developer/en/xmp/sdk/XMPspecification.pdf">XMP Photoshop</a>
+ */
+public interface Photoshop {
+
+    String NAMESPACE_URI_PHOTOSHOP = "http://ns.adobe.com/photoshop/1.0/";
+    String PREFIX_PHOTOSHOP = "photoshop";
+
+    Property AUTHORS_POSITION = Property.internalText(
+            PREFIX_PHOTOSHOP + Metadata.NAMESPACE_PREFIX_DELIMITER + "AuthorsPosition");
+
+    Property CAPTION_WRITER = Property.internalText(
+            PREFIX_PHOTOSHOP + Metadata.NAMESPACE_PREFIX_DELIMITER + "CaptionWriter");
+
+    Property CATEGORY = Property.internalText(
+            PREFIX_PHOTOSHOP + Metadata.NAMESPACE_PREFIX_DELIMITER + "Category");
+
+    Property CITY = Property.internalText(
+            PREFIX_PHOTOSHOP + Metadata.NAMESPACE_PREFIX_DELIMITER + "City");
+
+    Property COUNTRY = Property.internalText(
+            PREFIX_PHOTOSHOP + Metadata.NAMESPACE_PREFIX_DELIMITER + "Country");
+
+    Property CREDIT = Property.internalText(
+            PREFIX_PHOTOSHOP + Metadata.NAMESPACE_PREFIX_DELIMITER + "Credit");
+
+    Property DATE_CREATED = Property.internalDate(
+            PREFIX_PHOTOSHOP + Metadata.NAMESPACE_PREFIX_DELIMITER + "DateCreated");
+
+    Property HEADLINE = Property.internalText(
+            PREFIX_PHOTOSHOP + Metadata.NAMESPACE_PREFIX_DELIMITER + "Headline");
+
+    Property INSTRUCTIONS = Property.internalText(
+            PREFIX_PHOTOSHOP + Metadata.NAMESPACE_PREFIX_DELIMITER + "Instructions");
+
+    Property SOURCE = Property.internalText(
+            PREFIX_PHOTOSHOP + Metadata.NAMESPACE_PREFIX_DELIMITER + "Source");
+
+    Property STATE = Property.internalText(
+            PREFIX_PHOTOSHOP + Metadata.NAMESPACE_PREFIX_DELIMITER + "State");
+
+    Property SUPPLEMENTAL_CATEGORIES = Property.internalTextBag(
+            PREFIX_PHOTOSHOP + Metadata.NAMESPACE_PREFIX_DELIMITER + "SupplementalCategories");
+
+    Property TRANSMISSION_REFERENCE = Property.internalText(
+            PREFIX_PHOTOSHOP + Metadata.NAMESPACE_PREFIX_DELIMITER + "TransmissionReference");
+
+    Property URGENCY = Property.internalText(
+            PREFIX_PHOTOSHOP + Metadata.NAMESPACE_PREFIX_DELIMITER + "Urgency");
+
+}
\ No newline at end of file
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/TikaCoreProperties.java b/tika-core/src/main/java/org/apache/tika/metadata/TikaCoreProperties.java
index b1d11cb4c..d23f11629 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/TikaCoreProperties.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/TikaCoreProperties.java
@@ -31,6 +31,8 @@ package org.apache.tika.metadata;
  * For now, most of these properties are composite ones including the deprecated
  *  non-prefixed String properties from the Metadata class. In Tika 2.0, most
  *  of these will revert back to simple assignments.
+ * 
+ * @since Apache Tika 1.2
  */
 @SuppressWarnings("deprecation")
 public interface TikaCoreProperties {
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/XMPRights.java b/tika-core/src/main/java/org/apache/tika/metadata/XMPRights.java
new file mode 100644
index 000000000..e2800b02c
--- /dev/null
+++ b/tika-core/src/main/java/org/apache/tika/metadata/XMPRights.java
@@ -0,0 +1,53 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * IPTC Metadata Descriptions taken from the IPTC Photo Metadata (July 2010) 
+ * standard. These parts Copyright 2010 International Press Telecommunications 
+ * Council.
+ */
+package org.apache.tika.metadata;
+
+/**
+ * XMP Rights management schema. 
+ * 
+ * A collection of property constants for the 
+ * rights management properties defined in the XMP 
+ * standard.
+ * 
+ * @since Apache Tika 1.2
+ * @see <a href="http://partners.adobe.com/public/developer/en/xmp/sdk/XMPspecification.pdf">XMP Photoshop</a>
+ */
+public interface XMPRights {
+
+    String NAMESPACE_URI_XMP_RIGHTS = "http://ns.adobe.com/xap/1.0/rights/";
+    String PREFIX_XMP_RIGHTS = "xmpRights";
+    
+    Property CERTIFICATE = Property.internalText(
+            PREFIX_XMP_RIGHTS + Metadata.NAMESPACE_PREFIX_DELIMITER + "Certificate");
+    
+    Property MARKED = Property.internalBoolean(
+            PREFIX_XMP_RIGHTS + Metadata.NAMESPACE_PREFIX_DELIMITER + "Marked");
+    
+    Property OWNER = Property.internalTextBag(
+            PREFIX_XMP_RIGHTS + Metadata.NAMESPACE_PREFIX_DELIMITER + "Owner");
+    
+    Property USAGE_TERMS = Property.internalText(
+            PREFIX_XMP_RIGHTS + Metadata.NAMESPACE_PREFIX_DELIMITER + "UsageTerms");
+    
+    Property WEB_STATEMENT = Property.internalText(
+            PREFIX_XMP_RIGHTS + Metadata.NAMESPACE_PREFIX_DELIMITER + "WebStatement");
+
+}
\ No newline at end of file

Commit:
89dc4d725fc4a1dd3406c462bb0e2b8575c5d34f
Nick Burch
nick@apache.org
2012-05-17 20:05:20 +0000
TIKA-928 Epic patch from Ray Gauss - Update parsers and unit tests to use the new style TikaCoreProperties for setting (which supports aliasing for backwards compatibility), rather than old string based ones
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/asm/XHTMLClassVisitor.java b/tika-parsers/src/main/java/org/apache/tika/parser/asm/XHTMLClassVisitor.java
index cdc9a8194..20fae511a 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/asm/XHTMLClassVisitor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/asm/XHTMLClassVisitor.java
@@ -21,6 +21,7 @@ import java.io.InputStream;
 
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.sax.XHTMLContentHandler;
 import org.objectweb.asm.AnnotationVisitor;
 import org.objectweb.asm.Attribute;
@@ -78,7 +79,7 @@ class XHTMLClassVisitor implements ClassVisitor {
             className = className.substring(dot + 1);
         }
 
-        metadata.set(Metadata.TITLE, className);
+        metadata.set(TikaCoreProperties.TITLE, className);
         metadata.set(Metadata.RESOURCE_NAME_KEY, className + ".class");
 
         try {
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/feed/FeedParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/feed/FeedParser.java
index b71e9271c..fccb65973 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/feed/FeedParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/feed/FeedParser.java
@@ -26,6 +26,7 @@ import java.util.Set;
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.io.CloseShieldInputStream;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.parser.AbstractParser;
 import org.apache.tika.parser.ParseContext;
@@ -72,8 +73,8 @@ public class FeedParser extends AbstractParser {
             String title = stripTags(feed.getTitleEx());
             String description = stripTags(feed.getDescriptionEx());
 
-            metadata.set(Metadata.TITLE, title);
-            metadata.set(Metadata.DESCRIPTION, description);
+            metadata.set(TikaCoreProperties.TITLE, title);
+            metadata.set(TikaCoreProperties.DESCRIPTION, description);
             // store the other fields in the metadata
 
             XHTMLContentHandler xhtml =
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/font/AdobeFontMetricParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/font/AdobeFontMetricParser.java
index 29f26348f..fa81feba6 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/font/AdobeFontMetricParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/font/AdobeFontMetricParser.java
@@ -27,6 +27,7 @@ import org.apache.fontbox.afm.FontMetric;
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.Property;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.parser.AbstractParser;
 import org.apache.tika.parser.ParseContext;
@@ -67,7 +68,7 @@ public class AdobeFontMetricParser extends AbstractParser {
        extractCreationDate( metadata, comments );
 
        metadata.set( Metadata.CONTENT_TYPE, AFM_TYPE.toString() );
-       metadata.set( Metadata.TITLE, fontMetrics.getFullName() );
+       metadata.set( TikaCoreProperties.TITLE, fontMetrics.getFullName() );
 
        // Add metadata associated with the font type
        addMetadataByString( metadata, "AvgCharacterWidth", Float.toString( fontMetrics.getAverageCharacterWidth() ) );
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/font/TrueTypeParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/font/TrueTypeParser.java
index fa1f7089f..d295f57b8 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/font/TrueTypeParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/font/TrueTypeParser.java
@@ -25,9 +25,8 @@ import org.apache.fontbox.ttf.TTFParser;
 import org.apache.fontbox.ttf.TrueTypeFont;
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.io.TikaInputStream;
-import org.apache.tika.metadata.DublinCore;
 import org.apache.tika.metadata.Metadata;
-import org.apache.tika.metadata.Property;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.parser.AbstractParser;
 import org.apache.tika.parser.ParseContext;
@@ -67,9 +66,9 @@ public class TrueTypeParser extends AbstractParser {
         }
 
         metadata.set(Metadata.CONTENT_TYPE, TYPE.toString());
-        metadata.set(Metadata.DATE, font.getHeader().getCreated().getTime());
+        metadata.set(TikaCoreProperties.DATE, font.getHeader().getCreated().getTime());
         metadata.set(
-                Property.internalDate(Metadata.MODIFIED),
+                TikaCoreProperties.MODIFIED,
                 font.getHeader().getModified().getTime());
 
         XHTMLContentHandler xhtml = new XHTMLContentHandler(handler, metadata);
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlHandler.java b/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlHandler.java
index fbd86258f..26679a695 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlHandler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlHandler.java
@@ -26,6 +26,7 @@ import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.sax.TextContentHandler;
 import org.apache.tika.sax.XHTMLContentHandler;
@@ -233,7 +234,7 @@ class HtmlHandler extends TextContentHandler {
         if (titleLevel > 0) {
             titleLevel--;
             if (titleLevel == 0) {
-                metadata.set(Metadata.TITLE, title.toString().trim());
+                metadata.set(TikaCoreProperties.TITLE, title.toString().trim());
             }
         }
         if (bodyLevel > 0) {
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlParser.java
index 60e22cc25..ffaf5c42b 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/html/HtmlParser.java
@@ -148,7 +148,7 @@ public class HtmlParser extends AbstractParser {
                 String language = match.getLanguage();
                 if (language != null) {
                     metadata.set(Metadata.CONTENT_LANGUAGE, match.getLanguage());
-                    metadata.set(Metadata.LANGUAGE, match.getLanguage());
+                    metadata.set(TikaCoreProperties.LANGUAGE, match.getLanguage());
                 }
                 */
                 
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/image/ImageMetadataExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/image/ImageMetadataExtractor.java
index d171790cf..3f6f47a00 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/image/ImageMetadataExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/image/ImageMetadataExtractor.java
@@ -33,6 +33,7 @@ import org.apache.tika.exception.TikaException;
 import org.apache.tika.metadata.Geographic;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.Property;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.xml.sax.SAXException;
 
 import com.drew.imaging.jpeg.JpegProcessingException;
@@ -300,9 +301,9 @@ public class ImageMetadataExtractor {
          * Use IPTC for other annotation fields, and XMP for unicode support.
          */
         public void handleCommentTags(Directory directory, Metadata metadata) {
-            if (metadata.get(Metadata.DESCRIPTION) == null &&
+            if (metadata.get(TikaCoreProperties.DESCRIPTION) == null &&
                     directory.containsTag(ExifDirectory.TAG_IMAGE_DESCRIPTION)) {
-                metadata.set(Metadata.DESCRIPTION, directory.getString(ExifDirectory.TAG_IMAGE_DESCRIPTION));
+                metadata.set(TikaCoreProperties.DESCRIPTION, directory.getString(ExifDirectory.TAG_IMAGE_DESCRIPTION));
             }
         }
         /**
@@ -415,7 +416,7 @@ public class ImageMetadataExtractor {
                 // Unless we have GPS time we don't know the time zone so date must be set
                 // as ISO 8601 datetime without timezone suffix (no Z or +/-)
                 String datetimeNoTimeZone = DATE_UNSPECIFIED_TZ.format(original); // Same time zone as Metadata Extractor uses
-                metadata.set(Metadata.DATE, datetimeNoTimeZone);
+                metadata.set(TikaCoreProperties.DATE, datetimeNoTimeZone);
                 metadata.set(Metadata.ORIGINAL_DATE, datetimeNoTimeZone);
             }
             if (directory.containsTag(ExifDirectory.TAG_DATETIME)) {
@@ -424,7 +425,7 @@ public class ImageMetadataExtractor {
                 metadata.set(Metadata.LAST_MODIFIED, datetimeNoTimeZone);
                 // If Date/Time Original does not exist this might be creation date
                 if (original == null) {
-                    metadata.set(Metadata.DATE, datetimeNoTimeZone);
+                    metadata.set(TikaCoreProperties.DATE, datetimeNoTimeZone);
                 }
             }
         }
@@ -447,15 +448,15 @@ public class ImageMetadataExtractor {
                 }
             }
             if (directory.containsTag(IptcDirectory.TAG_HEADLINE)) {
-                metadata.set(Metadata.TITLE, directory.getString(IptcDirectory.TAG_HEADLINE));
+                metadata.set(TikaCoreProperties.TITLE, directory.getString(IptcDirectory.TAG_HEADLINE));
             } else if (directory.containsTag(IptcDirectory.TAG_OBJECT_NAME)) {
-                metadata.set(Metadata.TITLE, directory.getString(IptcDirectory.TAG_OBJECT_NAME));
+                metadata.set(TikaCoreProperties.TITLE, directory.getString(IptcDirectory.TAG_OBJECT_NAME));
             }
             if (directory.containsTag(IptcDirectory.TAG_BY_LINE)) {
                 metadata.set(Metadata.AUTHOR, directory.getString(IptcDirectory.TAG_BY_LINE));
             }
             if (directory.containsTag(IptcDirectory.TAG_CAPTION)) {
-                metadata.set(Metadata.DESCRIPTION,
+                metadata.set(TikaCoreProperties.DESCRIPTION,
                         // Looks like metadata extractor returns IPTC newlines as a single carriage return,
                         // but the exiv2 command does not so we change to line feed here because that is less surprising to users                        
                         directory.getString(IptcDirectory.TAG_CAPTION).replaceAll("\r\n?", "\n"));
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/image/MetadataFields.java b/tika-parsers/src/main/java/org/apache/tika/parser/image/MetadataFields.java
index c2f0910d2..611b1e054 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/image/MetadataFields.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/image/MetadataFields.java
@@ -22,6 +22,7 @@ import java.util.HashSet;
 
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.Property;
+import org.apache.tika.metadata.TikaCoreProperties;
 
 /**
  * Knowns about all declared {@link Metadata} fields.
@@ -32,9 +33,8 @@ public abstract class MetadataFields {
     
     private static HashSet<String> known;
     
-    static {
-        known = new HashSet<String>();
-        Field[] fields = Metadata.class.getFields();
+    private static void setKnownForClass(Class<?> clazz) {
+        Field[] fields = clazz.getFields();
         for (Field f : fields) {
             int mod = f.getModifiers();
             if (Modifier.isPublic(mod) && Modifier.isStatic(mod) && Modifier.isFinal(mod)) {
@@ -67,8 +67,18 @@ public abstract class MetadataFields {
         }
     }
     
+    static {
+        known = new HashSet<String>();
+        setKnownForClass(TikaCoreProperties.class);
+        setKnownForClass(Metadata.class);
+    }
+    
     public static boolean isMetadataField(String name) {
         return known.contains(name);
     }
     
+    public static boolean isMetadataField(Property property) {
+        return known.contains(property.getName());
+    }
+    
 }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/image/PSDParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/image/PSDParser.java
index c4b0cc499..39bcc7788 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/image/PSDParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/image/PSDParser.java
@@ -29,6 +29,7 @@ import org.apache.tika.exception.TikaException;
 import org.apache.tika.io.EndianUtils;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.TIFF;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.parser.AbstractParser;
 import org.apache.tika.parser.ParseContext;
@@ -114,7 +115,7 @@ public class PSDParser extends AbstractParser {
            
            // Is it one we can do something useful with?
            if(rb.id == ResourceBlock.ID_CAPTION) {
-              metadata.add(Metadata.DESCRIPTION, rb.getDataAsString()); 
+              metadata.add(TikaCoreProperties.DESCRIPTION, rb.getDataAsString()); 
            } else if(rb.id == ResourceBlock.ID_EXIF_1) {
               // TODO Parse the EXIF info
            } else if(rb.id == ResourceBlock.ID_EXIF_3) {
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/image/xmp/JempboxExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/image/xmp/JempboxExtractor.java
index b537fe81a..c1e7b360d 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/image/xmp/JempboxExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/image/xmp/JempboxExtractor.java
@@ -28,8 +28,8 @@ import java.util.List;
 import org.apache.jempbox.xmp.XMPMetadata;
 import org.apache.jempbox.xmp.XMPSchemaDublinCore;
 import org.apache.tika.exception.TikaException;
-import org.apache.tika.metadata.DublinCore;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.xml.sax.InputSource;
 
 public class JempboxExtractor {
@@ -59,18 +59,18 @@ public class JempboxExtractor {
             XMPSchemaDublinCore dc = xmp.getDublinCoreSchema();
             if (dc != null) {
                 if (dc.getTitle() != null) {
-                    metadata.set(Metadata.TITLE, dc.getTitle());
+                    metadata.set(TikaCoreProperties.TITLE, dc.getTitle());
                 }
                 if (dc.getDescription() != null) {
-                    metadata.set(Metadata.DESCRIPTION, dc.getDescription());
+                    metadata.set(TikaCoreProperties.DESCRIPTION, dc.getDescription());
                 }
                 if (dc.getCreators() != null && dc.getCreators().size() > 0) {
-                    metadata.set(Metadata.CREATOR, joinCreators(dc.getCreators()));
+                    metadata.set(TikaCoreProperties.CREATOR, joinCreators(dc.getCreators()));
                 }
                 if (dc.getSubjects() != null && dc.getSubjects().size() > 0) {
                     Iterator<String> keywords = dc.getSubjects().iterator();
                     while (keywords.hasNext()) {
-                        metadata.add(Metadata.SUBJECT, keywords.next());
+                        metadata.add(TikaCoreProperties.SUBJECT, keywords.next());
                     }
                     // TODO should we set KEYWORDS too?
                     // All tested photo managers set the same in Iptc.Application2.Keywords and Xmp.dc.subject
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/iptc/IptcAnpaParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/iptc/IptcAnpaParser.java
index da5e8f1c8..726bbc61c 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/iptc/IptcAnpaParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/iptc/IptcAnpaParser.java
@@ -18,8 +18,6 @@ package org.apache.tika.parser.iptc;
 
 import java.io.IOException;
 import java.io.InputStream;
-import java.io.UnsupportedEncodingException;
-import java.nio.charset.Charset;
 import java.text.ParseException;
 import java.text.SimpleDateFormat;
 import java.util.Collections;
@@ -29,8 +27,8 @@ import java.util.Set;
 import java.util.TimeZone;
 
 import org.apache.tika.exception.TikaException;
-import org.apache.tika.metadata.DublinCore;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.parser.Parser;
@@ -772,19 +770,19 @@ public class IptcAnpaParser implements Parser {
       // every property that gets set must be non-null, or it will cause NPE
       // in other consuming applications, like Lucene
       metadata.set(Metadata.CONTENT_TYPE,  clean("text/anpa-1312"));
-      metadata.set(Metadata.TITLE,         clean(properties.get("title")));
-      metadata.set(Metadata.SUBJECT,       clean(properties.get("subject")));
+      metadata.set(TikaCoreProperties.TITLE,         clean(properties.get("title")));
+      metadata.set(TikaCoreProperties.SUBJECT,       clean(properties.get("subject")));
       metadata.set(Metadata.AUTHOR,        clean(properties.get("author")));
       metadata.set(Metadata.CREATION_DATE, clean(properties.get("created")));
-      metadata.set(Metadata.MODIFIED,      clean(properties.get("modified")));
-      metadata.set(Metadata.SOURCE,      clean(properties.get("source")));
-//      metadata.set(Metadata.PUBLISHER,     clean(properties.get("publisher")));
-      metadata.set(Metadata.PUBLISHER,     clean(this.getFormatName()));
+      metadata.set(TikaCoreProperties.MODIFIED,      clean(properties.get("modified")));
+      metadata.set(TikaCoreProperties.SOURCE,      clean(properties.get("source")));
+//      metadata.set(TikaCoreProperties.PUBLISHER,     clean(properties.get("publisher")));
+      metadata.set(TikaCoreProperties.PUBLISHER,     clean(this.getFormatName()));
 
 /*
-        metadata.set(Metadata.DATE, font.getHeader().getCreated().getTime());
+        metadata.set(TikaCoreProperties.DATE, font.getHeader().getCreated().getTime());
         metadata.set(
-                Property.internalDate(Metadata.MODIFIED),
+                Property.internalDate(TikaCoreProperties.MODIFIED),
                 font.getHeader().getModified().getTime());
 */
    }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/KeynoteContentHandler.java b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/KeynoteContentHandler.java
index 1538d410d..14550e00a 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/KeynoteContentHandler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/KeynoteContentHandler.java
@@ -17,6 +17,7 @@
 package org.apache.tika.parser.iwork;
 
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.sax.XHTMLContentHandler;
 import org.xml.sax.Attributes;
 import org.xml.sax.SAXException;
@@ -90,7 +91,7 @@ class KeynoteContentHandler extends DefaultHandler {
         } else if (inMetadata && "key:authors".equals(qName)) {
             inMetaDataAuthors = true;
         } else if (inMetaDataTitle && "key:string".equals(qName)) {
-            metadata.set(Metadata.TITLE, attributes.getValue("sfa:string"));
+            metadata.set(TikaCoreProperties.TITLE, attributes.getValue("sfa:string"));
         } else if (inMetaDataAuthors && "key:string".equals(qName)) {
             metadata.add(Metadata.AUTHOR, attributes.getValue("sfa:string"));
         } else if (inSlide && "sf:tabular-model".equals(qName)) {
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/NumbersContentHandler.java b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/NumbersContentHandler.java
index e40925cce..b502b97e4 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/NumbersContentHandler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/NumbersContentHandler.java
@@ -17,6 +17,8 @@
 package org.apache.tika.parser.iwork;
 
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.Property;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.sax.XHTMLContentHandler;
 import org.xml.sax.Attributes;
 import org.xml.sax.SAXException;
@@ -36,7 +38,7 @@ class NumbersContentHandler extends DefaultHandler {
     private boolean parseText = false;
 
     private boolean inMetadata = false;
-    private String metadataKey;
+    private Property metadataKey;
     private String metadataPropertyQName;
 
     private boolean inTable = false;
@@ -202,11 +204,13 @@ class NumbersContentHandler extends DefaultHandler {
         }
     }
 
-    private String resolveMetadataKey(String localName) {
+    private Property resolveMetadataKey(String localName) {
         if ("authors".equals(localName)) {
-            return Metadata.AUTHOR;
+            return Property.internalText(Metadata.AUTHOR);
         }
-
-        return localName;
+        if ("title".equals(localName)) {
+            return TikaCoreProperties.TITLE;
+        }
+        return Property.internalText(localName);
     }
 }
\ No newline at end of file
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/PagesContentHandler.java b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/PagesContentHandler.java
index 26cdd512c..3f49a6143 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/PagesContentHandler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/PagesContentHandler.java
@@ -18,6 +18,7 @@ package org.apache.tika.parser.iwork;
 
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.Property;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.sax.XHTMLContentHandler;
 import org.xml.sax.Attributes;
 import org.xml.sax.SAXException;
@@ -252,13 +253,13 @@ class PagesContentHandler extends DefaultHandler {
         if ("sf:authors".equals(metaDataQName)) {
             metaDataKey = Metadata.AUTHOR;
         } else if ("sf:title".equals(metaDataQName)) {
-            metaDataKey = Metadata.TITLE;
+            metaDataKey = TikaCoreProperties.TITLE;
         } else if ("sl:SLCreationDateProperty".equals(metaDataQName)) {
             metaDataKey = Metadata.CREATION_DATE;
         } else if ("sl:SLLastModifiedDateProperty".equals(metaDataQName)) {
             metaDataKey = Metadata.LAST_MODIFIED;
         } else if ("sl:language".equals(metaDataQName)) {
-            metaDataKey = Metadata.LANGUAGE;
+            metaDataKey = TikaCoreProperties.LANGUAGE;
         }
         return metaDataKey;
     }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mail/MailContentHandler.java b/tika-parsers/src/main/java/org/apache/tika/parser/mail/MailContentHandler.java
index 8919d59b7..e741ee9de 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mail/MailContentHandler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mail/MailContentHandler.java
@@ -24,7 +24,6 @@ import org.apache.james.mime4j.codec.DecodeMonitor;
 import org.apache.james.mime4j.codec.DecoderUtil;
 import org.apache.james.mime4j.dom.address.Address;
 import org.apache.james.mime4j.dom.address.AddressList;
-import org.apache.james.mime4j.dom.address.Group;
 import org.apache.james.mime4j.dom.address.Mailbox;
 import org.apache.james.mime4j.dom.address.MailboxList;
 import org.apache.james.mime4j.dom.field.AddressListField;
@@ -38,6 +37,7 @@ import org.apache.james.mime4j.stream.BodyDescriptor;
 import org.apache.james.mime4j.stream.Field;
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.AutoDetectParser;
 import org.apache.tika.sax.BodyContentHandler;
 import org.apache.tika.sax.EmbeddedContentHandler;
@@ -161,7 +161,7 @@ class MailContentHandler implements ContentHandler {
                     metadata.add(Metadata.AUTHOR, from);
                 }
             } else if (fieldname.equalsIgnoreCase("Subject")) {
-                metadata.add(Metadata.SUBJECT,
+                metadata.add(TikaCoreProperties.SUBJECT,
                         ((UnstructuredField) parsedField).getValue());
             } else if (fieldname.equalsIgnoreCase("To")) {
                 processAddressList(parsedField, "To:", Metadata.MESSAGE_TO);
@@ -171,7 +171,7 @@ class MailContentHandler implements ContentHandler {
                 processAddressList(parsedField, "Bcc:", Metadata.MESSAGE_BCC);
             } else if (fieldname.equalsIgnoreCase("Date")) {
                 DateTimeField dateField = (DateTimeField) parsedField;
-                metadata.set(Metadata.DATE, dateField.getDate());
+                metadata.set(TikaCoreProperties.DATE, dateField.getDate());
                 metadata.set(Metadata.CREATION_DATE, dateField.getDate());
             }
         } catch (RuntimeException me) {
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mbox/MboxParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/mbox/MboxParser.java
index 3baa0a32b..615a3a95d 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mbox/MboxParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mbox/MboxParser.java
@@ -32,6 +32,7 @@ import java.util.regex.Pattern;
 
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.parser.AbstractParser;
 import org.apache.tika.parser.ParseContext;
@@ -198,7 +199,7 @@ public class MboxParser extends AbstractParser {
 
         if (headerTag.equalsIgnoreCase("From")) {
             metadata.add(Metadata.AUTHOR, headerContent);
-            metadata.add(Metadata.CREATOR, headerContent);
+            metadata.set(TikaCoreProperties.CREATOR, headerContent);
         } else if (headerTag.equalsIgnoreCase("To") ||
         	headerTag.equalsIgnoreCase("Cc") ||
         	headerTag.equalsIgnoreCase("Bcc")) {
@@ -217,26 +218,26 @@ public class MboxParser extends AbstractParser {
             }
             metadata.add(property, headerContent);
         } else if (headerTag.equalsIgnoreCase("Subject")) {
-            metadata.add(Metadata.SUBJECT, headerContent);
-            metadata.add(Metadata.TITLE, headerContent);
+            metadata.add(TikaCoreProperties.SUBJECT, headerContent);
+            metadata.set(TikaCoreProperties.TITLE, headerContent);
         } else if (headerTag.equalsIgnoreCase("Date")) {
             try {
                 Date date = parseDate(headerContent);
-                metadata.set(Metadata.DATE, date);
+                metadata.set(TikaCoreProperties.DATE, date);
                 metadata.set(Metadata.CREATION_DATE, date);
             } catch (ParseException e) {
                 // ignoring date because format was not understood
             }
         } else if (headerTag.equalsIgnoreCase("Message-Id")) {
-            metadata.add(Metadata.IDENTIFIER, headerContent);
+            metadata.set(TikaCoreProperties.IDENTIFIER, headerContent);
         } else if (headerTag.equalsIgnoreCase("In-Reply-To")) {
-            metadata.add(Metadata.RELATION, headerContent);
+            metadata.set(TikaCoreProperties.RELATION, headerContent);
         } else if (headerTag.equalsIgnoreCase("Content-Type")) {
             // TODO - key off content-type in headers to
             // set mapping to use for content and convert if necessary.
 
             metadata.add(Metadata.CONTENT_TYPE, headerContent);
-            metadata.add(Metadata.FORMAT, headerContent);
+            metadata.set(TikaCoreProperties.FORMAT, headerContent);
         } else {
             metadata.add(EMAIL_HEADER_METADATA_PREFIX + headerTag, headerContent);
         }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OutlookExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OutlookExtractor.java
index 491d528f7..715feecd1 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OutlookExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OutlookExtractor.java
@@ -35,6 +35,7 @@ import org.apache.poi.poifs.filesystem.NPOIFSFileSystem;
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.io.TikaInputStream;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.parser.html.HtmlParser;
 import org.apache.tika.parser.mbox.MboxParser;
@@ -102,8 +103,8 @@ public class OutlookExtractor extends AbstractPOIFSExtractor {
            metadata.set(Metadata.MESSAGE_CC, msg.getDisplayCC());
            metadata.set(Metadata.MESSAGE_BCC, msg.getDisplayBCC());
            
-           metadata.set(Metadata.TITLE, subject);
-           metadata.set(Metadata.SUBJECT, msg.getConversationTopic());
+           metadata.set(TikaCoreProperties.TITLE, subject);
+           metadata.set(TikaCoreProperties.SUBJECT, msg.getConversationTopic());
            
            try {
            for(String recipientAddress : msg.getRecipientEmailAddressList()) {
@@ -115,7 +116,7 @@ public class OutlookExtractor extends AbstractPOIFSExtractor {
            // Date - try two ways to find it
            // First try via the proper chunk
            if(msg.getMessageDate() != null) {
-              metadata.set(Metadata.DATE, msg.getMessageDate().getTime());
+              metadata.set(TikaCoreProperties.DATE, msg.getMessageDate().getTime());
               metadata.set(Metadata.CREATION_DATE, msg.getMessageDate().getTime());
               metadata.set(Metadata.LAST_SAVED, msg.getMessageDate().getTime());
            } else {
@@ -130,12 +131,12 @@ public class OutlookExtractor extends AbstractPOIFSExtractor {
                             // See if we can parse it as a normal mail date
                             try {
                                Date d = MboxParser.parseDate(date);
-                               metadata.set(Metadata.DATE, d);
+                               metadata.set(TikaCoreProperties.DATE, d);
                                metadata.set(Metadata.CREATION_DATE, d);
                                metadata.set(Metadata.LAST_SAVED, d);
                             } catch(ParseException e) {
                                // Store it as-is, and hope for the best...
-                               metadata.set(Metadata.DATE, date);
+                               metadata.set(TikaCoreProperties.DATE, date);
                                metadata.set(Metadata.CREATION_DATE, date);
                                metadata.set(Metadata.LAST_SAVED, date);
                             }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/SummaryExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/SummaryExtractor.java
index fba7dcdcf..d82506bc3 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/SummaryExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/SummaryExtractor.java
@@ -35,6 +35,7 @@ import org.apache.tika.exception.TikaException;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.PagedText;
 import org.apache.tika.metadata.Property;
+import org.apache.tika.metadata.TikaCoreProperties;
 
 /**
  * Outlook Message Parser.
@@ -90,10 +91,10 @@ class SummaryExtractor {
     }
 
     private void parse(SummaryInformation summary) {
-        set(Metadata.TITLE, summary.getTitle());
+        set(TikaCoreProperties.TITLE, summary.getTitle());
         set(Metadata.AUTHOR, summary.getAuthor());
         set(Metadata.KEYWORDS, summary.getKeywords());
-        set(Metadata.SUBJECT, summary.getSubject());
+        set(TikaCoreProperties.SUBJECT, summary.getSubject());
         set(Metadata.LAST_AUTHOR, summary.getLastAuthor());
         set(Metadata.COMMENTS, summary.getComments());
         set(Metadata.TEMPLATE, summary.getTemplate());
@@ -115,7 +116,7 @@ class SummaryExtractor {
     private void parse(DocumentSummaryInformation summary) {
         set(Metadata.COMPANY, summary.getCompany());
         set(Metadata.MANAGER, summary.getManager());
-        set(Metadata.LANGUAGE, getLanguage(summary));
+        set(TikaCoreProperties.LANGUAGE, getLanguage(summary));
         set(Metadata.CATEGORY, summary.getCategory());
         set(Metadata.SLIDE_COUNT, summary.getSlideCount());
         if (summary.getSlideCount() > 0) {
@@ -175,6 +176,12 @@ class SummaryExtractor {
             metadata.set(name, value);
         }
     }
+    
+    private void set(Property property, String value) {
+        if (value != null) {
+            metadata.set(property, value);
+        }
+    }
 
     private void set(Property property, Date value) {
         if (value != null) {
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/TNEFParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/TNEFParser.java
index fa9a48a3f..bc8525061 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/TNEFParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/TNEFParser.java
@@ -33,6 +33,7 @@ import org.apache.tika.extractor.EmbeddedDocumentExtractor;
 import org.apache.tika.extractor.ParsingEmbeddedDocumentExtractor;
 import org.apache.tika.io.TikaInputStream;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.parser.AbstractParser;
 import org.apache.tika.parser.ParseContext;
@@ -81,7 +82,7 @@ public class TNEFParser extends AbstractParser {
        // Set the message subject if known
        String subject = msg.getSubject();
        if(subject != null && subject.length() > 0) {
-          metadata.set(Metadata.SUBJECT, subject);
+          metadata.set(TikaCoreProperties.SUBJECT, subject);
        }
        
        // Recurse into the message body RTF
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java
index b0188d973..857c34523 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java
@@ -30,6 +30,7 @@ import org.apache.tika.exception.TikaException;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.PagedText;
 import org.apache.tika.metadata.Property;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.openxmlformats.schemas.officeDocument.x2006.customProperties.CTProperty;
 import org.openxmlformats.schemas.officeDocument.x2006.extendedProperties.CTProperties;
 
@@ -65,21 +66,21 @@ public class MetadataExtractor {
         addProperty(metadata, Metadata.CATEGORY, propsHolder.getCategoryProperty());
         addProperty(metadata, Metadata.CONTENT_STATUS, propsHolder
                 .getContentStatusProperty());
-        addProperty(metadata, Metadata.DATE, propsHolder
+        addProperty(metadata, TikaCoreProperties.DATE, propsHolder
                 .getCreatedProperty());
         addProperty(metadata, Metadata.CREATION_DATE, propsHolder
                 .getCreatedProperty());
-        addProperty(metadata, Metadata.CREATOR, propsHolder
+        addProperty(metadata, TikaCoreProperties.CREATOR, propsHolder
                 .getCreatorProperty());
         addProperty(metadata, Metadata.AUTHOR, propsHolder
                 .getCreatorProperty());
-        addProperty(metadata, Metadata.DESCRIPTION, propsHolder
+        addProperty(metadata, TikaCoreProperties.DESCRIPTION, propsHolder
                 .getDescriptionProperty());
-        addProperty(metadata, Metadata.IDENTIFIER, propsHolder
+        addProperty(metadata, TikaCoreProperties.IDENTIFIER, propsHolder
                 .getIdentifierProperty());
         addProperty(metadata, Metadata.KEYWORDS, propsHolder
                 .getKeywordsProperty());
-        addProperty(metadata, Metadata.LANGUAGE, propsHolder
+        addProperty(metadata, TikaCoreProperties.LANGUAGE, propsHolder
                 .getLanguageProperty());
         addProperty(metadata, Metadata.LAST_AUTHOR, propsHolder
                 .getLastModifiedByProperty());
@@ -89,9 +90,9 @@ public class MetadataExtractor {
                 .getModifiedProperty());
         addProperty(metadata, Metadata.REVISION_NUMBER, propsHolder
                 .getRevisionProperty());
-        addProperty(metadata, Metadata.SUBJECT, propsHolder
+        addProperty(metadata, TikaCoreProperties.SUBJECT, propsHolder
                 .getSubjectProperty());
-        addProperty(metadata, Metadata.TITLE, propsHolder.getTitleProperty());
+        addProperty(metadata, TikaCoreProperties.TITLE, propsHolder.getTitleProperty());
         addProperty(metadata, Metadata.VERSION, propsHolder.getVersionProperty());
     }
 
@@ -107,7 +108,7 @@ public class MetadataExtractor {
                 .getCharacters());
         addProperty(metadata, Metadata.CHARACTER_COUNT_WITH_SPACES, propsHolder
                 .getCharactersWithSpaces());
-        addProperty(metadata, Metadata.PUBLISHER, propsHolder.getCompany());
+        addProperty(metadata, TikaCoreProperties.PUBLISHER, propsHolder.getCompany());
         addProperty(metadata, Metadata.LINE_COUNT, propsHolder.getLines());
         addProperty(metadata, Metadata.MANAGER, propsHolder.getManager());
         addProperty(metadata, Metadata.NOTES, propsHolder.getNotes());
@@ -234,9 +235,18 @@ public class MetadataExtractor {
        }
     }
     
-    private void addProperty(Metadata metadata, Property property, Nullable<Date> value) {
-        if (value.getValue() != null) {
-            metadata.set(property, value.getValue());
+    private <T> void addProperty(Metadata metadata, Property property, Nullable<T> nullableValue) {
+        T value = nullableValue.getValue();
+        if (value != null) {
+            if (value instanceof Date) {
+                metadata.set(property, (Date) value);
+            } else if (value instanceof String) {
+                metadata.set(property, (String) value);
+            } else if (value instanceof Integer) {
+                metadata.set(property, (Integer) value);
+            } else if (value instanceof Double) {
+                metadata.set(property, (Double) value);
+            }
         }
     }
 
@@ -245,6 +255,12 @@ public class MetadataExtractor {
             addProperty(metadata, name, value.getValue().toString());
         }
     }
+    
+    private void addProperty(Metadata metadata, Property property, String value) {
+        if (value != null) {
+            metadata.set(property, value);
+        }
+    }
 
     private void addProperty(Metadata metadata, String name, String value) {
         if (value != null) {
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/Mp3Parser.java b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/Mp3Parser.java
index 91493d6f9..f80f8fa5a 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/Mp3Parser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/Mp3Parser.java
@@ -25,6 +25,7 @@ import java.util.Set;
 
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.metadata.XMPDM;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.parser.AbstractParser;
@@ -71,7 +72,7 @@ public class Mp3Parser extends AbstractParser {
         if (audioAndTags.tags.length > 0) {
            CompositeTagHandler tag = new CompositeTagHandler(audioAndTags.tags);
 
-           metadata.set(Metadata.TITLE, tag.getTitle());
+           metadata.set(TikaCoreProperties.TITLE, tag.getTitle());
            metadata.set(Metadata.AUTHOR, tag.getArtist());
            metadata.set(XMPDM.ARTIST, tag.getArtist());
            metadata.set(XMPDM.COMPOSER, tag.getComposer());
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java b/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java
index 4f1169f25..66e0508e7 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java
@@ -30,6 +30,7 @@ import org.apache.tika.exception.TikaException;
 import org.apache.tika.io.TikaInputStream;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.Property;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.metadata.XMPDM;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.parser.AbstractParser;
@@ -162,7 +163,7 @@ public class MP4Parser extends AbstractParser {
                  MP4TimeToDate(mHeader.getCreationTime())
            );
            metadata.set(
-                 Property.externalDate(Metadata.MODIFIED), // TODO Should be a real property
+                 TikaCoreProperties.MODIFIED,
                  MP4TimeToDate(mHeader.getModificationTime())
            );
            
@@ -188,7 +189,7 @@ public class MP4Parser extends AbstractParser {
                  MP4TimeToDate(header.getCreationTime())
            );
            metadata.set(
-                 Property.externalDate(Metadata.MODIFIED), // TODO Should be a real property
+                 TikaCoreProperties.MODIFIED,
                  MP4TimeToDate(header.getModificationTime())
            );
            
@@ -224,7 +225,7 @@ public class MP4Parser extends AbstractParser {
            if (apple != null) {
               // Title
               AppleTrackTitleBox title = getOrNull(apple, AppleTrackTitleBox.class);
-              addMetadata(Metadata.TITLE, metadata, title);
+              addMetadata(TikaCoreProperties.TITLE, metadata, title);
 
               // Artist
               AppleArtistBox artist = getOrNull(apple, AppleArtistBox.class);
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/netcdf/NetCDFParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/netcdf/NetCDFParser.java
index 5cece9395..37e897841 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/netcdf/NetCDFParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/netcdf/NetCDFParser.java
@@ -26,6 +26,8 @@ import java.util.Set;
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.io.IOUtils;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.Property;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.parser.AbstractParser;
 import org.apache.tika.parser.ParseContext;
@@ -86,12 +88,12 @@ public class NetCDFParser extends AbstractParser {
 
             // first parse out the set of global attributes
             for (Attribute attr : ncFile.getGlobalAttributes()) {
-                String attrName = attr.getName();
+                Property property = resolveMetadataKey(attr.getName());
                 if (attr.getDataType().isString()) {
-                    metadata.add(attrName, attr.getStringValue());
+                    metadata.add(property, attr.getStringValue());
                 } else if (attr.getDataType().isNumeric()) {
                     int value = attr.getNumericValue().intValue();
-                    metadata.add(attrName, String.valueOf(value));
+                    metadata.add(property, String.valueOf(value));
                 }
             }
         } catch (IOException e) {
@@ -102,5 +104,12 @@ public class NetCDFParser extends AbstractParser {
         xhtml.startDocument();
         xhtml.endDocument();
     }
+    
+    private Property resolveMetadataKey(String localName) {
+        if ("title".equals(localName)) {
+            return TikaCoreProperties.TITLE;
+        }
+        return Property.internalText(localName);
+    }
 
 }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java
index 523a06e5f..56094b317 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java
@@ -39,6 +39,7 @@ import org.apache.tika.io.TikaInputStream;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.PagedText;
 import org.apache.tika.metadata.Property;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.parser.AbstractParser;
 import org.apache.tika.parser.ParseContext;
@@ -152,12 +153,12 @@ public class PDFParser extends AbstractParser {
             throws TikaException {
         PDDocumentInformation info = document.getDocumentInformation();
         metadata.set(PagedText.N_PAGES, document.getNumberOfPages());
-        addMetadata(metadata, Metadata.TITLE, info.getTitle());
+        addMetadata(metadata, TikaCoreProperties.TITLE, info.getTitle());
         addMetadata(metadata, Metadata.AUTHOR, info.getAuthor());
-        addMetadata(metadata, Metadata.CREATOR, info.getCreator());
+        addMetadata(metadata, TikaCoreProperties.CREATOR, info.getCreator());
         addMetadata(metadata, Metadata.KEYWORDS, info.getKeywords());
         addMetadata(metadata, "producer", info.getProducer());
-        addMetadata(metadata, Metadata.SUBJECT, info.getSubject());
+        addMetadata(metadata, TikaCoreProperties.SUBJECT, info.getSubject());
         addMetadata(metadata, "trapped", info.getTrapped());
         try {
             addMetadata(metadata, "created", info.getCreationDate());
@@ -186,6 +187,12 @@ public class PDFParser extends AbstractParser {
         }
     }
 
+    private void addMetadata(Metadata metadata, Property property, String value) {
+        if (value != null) {
+            metadata.add(property, value);
+        }
+    }
+    
     private void addMetadata(Metadata metadata, String name, String value) {
         if (value != null) {
             metadata.add(name, value);
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/prt/PRTParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/prt/PRTParser.java
index 02480e8c8..09a192277 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/prt/PRTParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/prt/PRTParser.java
@@ -26,6 +26,7 @@ import org.apache.poi.util.IOUtils;
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.io.EndianUtils;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.parser.AbstractParser;
 import org.apache.tika.parser.ParseContext;
@@ -85,7 +86,7 @@ public class PRTParser extends AbstractParser {
              "-" + dateStr.substring(6,8) + "T" + dateStr.substring(8,10) + ":" +
              dateStr.substring(10, 12) + ":00";
           metadata.set(Metadata.CREATION_DATE, formattedDate);
-          metadata.set(Metadata.DATE, formattedDate);
+          metadata.set(TikaCoreProperties.DATE, formattedDate);
        }
        metadata.set(Metadata.CONTENT_TYPE, PRT_MIME_TYPE);
        
@@ -94,7 +95,7 @@ public class PRTParser extends AbstractParser {
        IOUtils.readFully(stream, desc);
        String description = extractText(desc, true);
        if(description.length() > 0) {
-          metadata.set(Metadata.DESCRIPTION, description);
+          metadata.set(TikaCoreProperties.DESCRIPTION, description);
        }
        
        // Now look for text
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/rtf/TextExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/rtf/TextExtractor.java
index 7d2287d5b..f41f13c86 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/rtf/TextExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/rtf/TextExtractor.java
@@ -32,6 +32,7 @@ import java.util.Map;
 
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.sax.XHTMLContentHandler;
 import org.apache.tika.utils.CharsetUtils;
 import org.xml.sax.SAXException;
@@ -827,9 +828,9 @@ final class TextExtractor {
                 if (equals("author")) {
                     nextMetaData = Metadata.AUTHOR;
                 } else if (equals("title")) {
-                    nextMetaData = Metadata.TITLE;
+                    nextMetaData = TikaCoreProperties.TITLE.getName();
                 } else if (equals("subject")) {
-                    nextMetaData = Metadata.SUBJECT;
+                    nextMetaData = TikaCoreProperties.SUBJECT.getName();
                 } else if (equals("keywords")) {
                     nextMetaData = Metadata.KEYWORDS;
                 } else if (equals("category")) {
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/xml/DcXMLParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/xml/DcXMLParser.java
index d2cff4b8e..57bfb346b 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/xml/DcXMLParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/xml/DcXMLParser.java
@@ -16,8 +16,9 @@
  */
 package org.apache.tika.parser.xml;
 
-import org.apache.tika.metadata.DublinCore;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.Property;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.sax.TeeContentHandler;
 import org.xml.sax.ContentHandler;
@@ -31,28 +32,28 @@ public class DcXMLParser extends XMLParser {
     private static final long serialVersionUID = 4905318835463880819L;
 
     private static ContentHandler getDublinCoreHandler(
-            Metadata metadata, String name, String element) {
+            Metadata metadata, Property property, String element) {
         return new ElementMetadataHandler(
                 "http://purl.org/dc/elements/1.1/", element,
-                metadata, name);
+                metadata, property);
     }
 
     protected ContentHandler getContentHandler(
             ContentHandler handler, Metadata metadata, ParseContext context) {
         return new TeeContentHandler(
                 super.getContentHandler(handler, metadata, context),
-                getDublinCoreHandler(metadata, Metadata.TITLE, "title"),
-                getDublinCoreHandler(metadata, Metadata.SUBJECT, "subject"),
-                getDublinCoreHandler(metadata, Metadata.CREATOR, "creator"),
-                getDublinCoreHandler(metadata, Metadata.DESCRIPTION, "description"),
-                getDublinCoreHandler(metadata, Metadata.PUBLISHER, "publisher"),
-                getDublinCoreHandler(metadata, Metadata.CONTRIBUTOR, "contributor"),
-                getDublinCoreHandler(metadata, Metadata.DATE.getName(), "date"),
-                getDublinCoreHandler(metadata, Metadata.TYPE, "type"),
-                getDublinCoreHandler(metadata, Metadata.FORMAT, "format"),
-                getDublinCoreHandler(metadata, Metadata.IDENTIFIER, "identifier"),
-                getDublinCoreHandler(metadata, Metadata.LANGUAGE, "language"),
-                getDublinCoreHandler(metadata, Metadata.RIGHTS, "rights"));
+                getDublinCoreHandler(metadata, TikaCoreProperties.TITLE, "title"),
+                getDublinCoreHandler(metadata, TikaCoreProperties.SUBJECT, "subject"),
+                getDublinCoreHandler(metadata, TikaCoreProperties.CREATOR, "creator"),
+                getDublinCoreHandler(metadata, TikaCoreProperties.DESCRIPTION, "description"),
+                getDublinCoreHandler(metadata, TikaCoreProperties.PUBLISHER, "publisher"),
+                getDublinCoreHandler(metadata, TikaCoreProperties.CONTRIBUTOR, "contributor"),
+                getDublinCoreHandler(metadata, TikaCoreProperties.DATE, "date"),
+                getDublinCoreHandler(metadata, TikaCoreProperties.TYPE, "type"),
+                getDublinCoreHandler(metadata, TikaCoreProperties.FORMAT, "format"),
+                getDublinCoreHandler(metadata, TikaCoreProperties.IDENTIFIER, "identifier"),
+                getDublinCoreHandler(metadata, TikaCoreProperties.LANGUAGE, "language"),
+                getDublinCoreHandler(metadata, TikaCoreProperties.RIGHTS, "rights"));
     }
 
 }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/xml/ElementMetadataHandler.java b/tika-parsers/src/main/java/org/apache/tika/parser/xml/ElementMetadataHandler.java
index 48d54dad9..57fc1a05e 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/xml/ElementMetadataHandler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/xml/ElementMetadataHandler.java
@@ -82,7 +82,7 @@ public class ElementMetadataHandler extends AbstractMetadataHandler {
 
     public ElementMetadataHandler(
             String uri, String localName, Metadata metadata, Property targetProperty) {
-    	super(metadata, targetProperty.getName());
+        super(metadata, targetProperty);
         this.uri = uri;
         this.localName = localName;
         this.metadata = metadata;
@@ -164,12 +164,11 @@ public class ElementMetadataHandler extends AbstractMetadataHandler {
         if (logger.isTraceEnabled()) {
             logger.trace("adding " + name + "=" + value);
         }
-        if (targetProperty != null && targetProperty.getPropertyType() != null &&
-             targetProperty.getPropertyType() == Property.PropertyType.BAG) {
+        if (targetProperty != null && targetProperty.isMultiValuePermitted()) {
             if (value != null && value.length() > 0) {
                 String[] previous = metadata.getValues(name);
                 if (previous == null || !Arrays.asList(previous).contains(value)) {
-                    metadata.add(name, value);
+                    metadata.add(targetProperty, value);
                 }
             }
         } else {
diff --git a/tika-parsers/src/test/java/org/apache/tika/TestParsers.java b/tika-parsers/src/test/java/org/apache/tika/TestParsers.java
index 19f51cd55..2eae64f88 100644
--- a/tika-parsers/src/test/java/org/apache/tika/TestParsers.java
+++ b/tika-parsers/src/test/java/org/apache/tika/TestParsers.java
@@ -22,6 +22,7 @@ import java.io.InputStream;
 
 import org.apache.tika.config.TikaConfig;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.parser.Parser;
 import org.xml.sax.helpers.DefaultHandler;
@@ -51,7 +52,7 @@ public class TestParsers extends TikaTest {
         } finally {
             stream.close();
         }
-        assertEquals("Sample Word Document", metadata.get(Metadata.TITLE));
+        assertEquals("Sample Word Document", metadata.get(TikaCoreProperties.TITLE));
     }
 
     public void testEXCELExtraction() throws Exception {
@@ -69,7 +70,7 @@ public class TestParsers extends TikaTest {
         } finally {
             stream.close();
         }
-        assertEquals("Simple Excel document", metadata.get(Metadata.TITLE));
+        assertEquals("Simple Excel document", metadata.get(TikaCoreProperties.TITLE));
     }
 
     public void testOptionalHyphen() throws Exception {
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/ParsingReaderTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/ParsingReaderTest.java
index 6421ee984..9f161f341 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/ParsingReaderTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/ParsingReaderTest.java
@@ -21,6 +21,7 @@ import java.io.InputStream;
 import java.io.Reader;
 
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 
 import junit.framework.TestCase;
 
@@ -83,7 +84,7 @@ public class ParsingReaderTest extends TestCase {
                 new AutoDetectParser(), stream, metadata, new ParseContext());
         try {
             // Metadata should already be available
-            assertEquals("Simple Excel document", metadata.get(Metadata.TITLE));
+            assertEquals("Simple Excel document", metadata.get(TikaCoreProperties.TITLE));
             // Check that the internal buffering isn't broken
             assertEquals('F', (char) reader.read());
             assertEquals('e', (char) reader.read());
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/asm/ClassParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/asm/ClassParserTest.java
index 6792ee977..e17709d12 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/asm/ClassParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/asm/ClassParserTest.java
@@ -20,6 +20,7 @@ import junit.framework.TestCase;
 
 import org.apache.tika.Tika;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 
 /**
  * Test case for parsing Java class files.
@@ -32,7 +33,7 @@ public class ClassParserTest extends TestCase {
         String content = new Tika().parseToString(
                 ClassParserTest.class.getResourceAsStream(path), metadata);
 
-        assertEquals("AutoDetectParser", metadata.get(Metadata.TITLE));
+        assertEquals("AutoDetectParser", metadata.get(TikaCoreProperties.TITLE));
         assertEquals(
                 "AutoDetectParser.class",
                 metadata.get(Metadata.RESOURCE_NAME_KEY));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/epub/EpubParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/epub/EpubParserTest.java
index b9029f300..720af80cd 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/epub/EpubParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/epub/EpubParserTest.java
@@ -21,6 +21,7 @@ import java.io.InputStream;
 import junit.framework.TestCase;
 
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.sax.BodyContentHandler;
 import org.xml.sax.ContentHandler;
@@ -38,11 +39,11 @@ public class EpubParserTest extends TestCase {
             assertEquals("application/epub+zip",
                     metadata.get(Metadata.CONTENT_TYPE));
             assertEquals("en",
-                    metadata.get(Metadata.LANGUAGE));
+                    metadata.get(TikaCoreProperties.LANGUAGE));
             assertEquals("This is an ePub test publication for Tika.",
-                    metadata.get(Metadata.DESCRIPTION));
+                    metadata.get(TikaCoreProperties.DESCRIPTION));
             assertEquals("Apache",
-                    metadata.get(Metadata.PUBLISHER));
+                    metadata.get(TikaCoreProperties.PUBLISHER));
 
             String content = handler.toString();
             assertTrue(content.contains("Plus a simple div"));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/feed/FeedParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/feed/FeedParserTest.java
index 54f8fa965..cd6d74b5c 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/feed/FeedParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/feed/FeedParserTest.java
@@ -21,6 +21,7 @@ import java.io.InputStream;
 import junit.framework.TestCase;
 
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.sax.BodyContentHandler;
 import org.xml.sax.ContentHandler;
@@ -41,8 +42,8 @@ public class FeedParserTest extends TestCase {
             assertFalse(content == null);
 
             assertEquals("Sample RSS File for Junit test",
-                    metadata.get(Metadata.DESCRIPTION));
-            assertEquals("TestChannel", metadata.get(Metadata.TITLE));
+                    metadata.get(TikaCoreProperties.DESCRIPTION));
+            assertEquals("TestChannel", metadata.get(TikaCoreProperties.TITLE));
 
             // TODO find a way of testing the paragraphs and anchors
 
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/font/AdobeFontMetricParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/font/AdobeFontMetricParserTest.java
index a8150094d..4538f3f90 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/font/AdobeFontMetricParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/font/AdobeFontMetricParserTest.java
@@ -19,6 +19,7 @@ package org.apache.tika.parser.font;
 import junit.framework.TestCase;
 
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.AutoDetectParser;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.parser.Parser;
@@ -46,7 +47,7 @@ public class AdobeFontMetricParserTest extends TestCase {
         }
 
         assertEquals("application/x-font-adobe-metric", metadata.get(Metadata.CONTENT_TYPE));
-        assertEquals("TestFullName", metadata.get(Metadata.TITLE));
+        assertEquals("TestFullName", metadata.get(TikaCoreProperties.TITLE));
         assertEquals("Fri Jul 15 17:50:51 2011", metadata.get(Metadata.CREATION_DATE));
         
         assertEquals("TestFontName", metadata.get("FontName"));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/html/HtmlParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/html/HtmlParserTest.java
index 2a13a1cd9..881f575ee 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/html/HtmlParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/html/HtmlParserTest.java
@@ -36,6 +36,7 @@ import org.apache.tika.Tika;
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.metadata.Geographic;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.sax.BodyContentHandler;
 import org.apache.tika.sax.TeeContentHandler;
@@ -76,7 +77,7 @@ public class HtmlParserTest extends TestCase {
         }
 
         assertEquals(
-                "Title : Test Indexation Html", metadata.get(Metadata.TITLE));
+                "Title : Test Indexation Html", metadata.get(TikaCoreProperties.TITLE));
         assertEquals("Tika Developers", metadata.get("Author"));
         assertEquals("5", metadata.get("refresh"));
         
@@ -120,7 +121,7 @@ public class HtmlParserTest extends TestCase {
                 HtmlParserTest.class.getResourceAsStream(path), metadata);
 
         assertEquals("application/xhtml+xml", metadata.get(Metadata.CONTENT_TYPE));
-        assertEquals("XHTML test document", metadata.get(Metadata.TITLE));
+        assertEquals("XHTML test document", metadata.get(TikaCoreProperties.TITLE));
 
         assertEquals("Tika Developers", metadata.get("Author"));
         assertEquals("5", metadata.get("refresh"));
@@ -258,7 +259,7 @@ public class HtmlParserTest extends TestCase {
         new HtmlParser().parse (
                 new ByteArrayInputStream(test.getBytes("UTF-8")),
                 new BodyContentHandler(),  metadata, new ParseContext());
-        assertEquals("\u017d", metadata.get(Metadata.TITLE));
+        assertEquals("\u017d", metadata.get(TikaCoreProperties.TITLE));
     }
 
     /**
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/ibooks/iBooksParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/ibooks/iBooksParserTest.java
index c15eaed44..07b3c2641 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/ibooks/iBooksParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/ibooks/iBooksParserTest.java
@@ -21,6 +21,7 @@ import java.io.InputStream;
 import junit.framework.TestCase;
 
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.parser.epub.EpubParser;
 import org.apache.tika.sax.BodyContentHandler;
@@ -39,11 +40,11 @@ public class iBooksParserTest extends TestCase {
             assertEquals("application/x-ibooks+zip",
                     metadata.get(Metadata.CONTENT_TYPE));
             assertEquals("en-GB",
-                    metadata.get(Metadata.LANGUAGE));
+                    metadata.get(TikaCoreProperties.LANGUAGE));
             assertEquals("iBooks Author v1.0",
-                    metadata.get(Metadata.CONTRIBUTOR));
+                    metadata.get(TikaCoreProperties.CONTRIBUTOR));
             assertEquals("Apache",
-                    metadata.get(Metadata.CREATOR));
+                    metadata.get(TikaCoreProperties.CREATOR));
 
             /* TODO For some reason, the xhtml files in iBooks-style ePub are not parsed properly, and the content comes back empty.git che
             String content = handler.toString();
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/image/ImageMetadataExtractorTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/image/ImageMetadataExtractorTest.java
index 3773d348d..7c3e02570 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/image/ImageMetadataExtractorTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/image/ImageMetadataExtractorTest.java
@@ -20,8 +20,8 @@ import java.util.Arrays;
 import java.util.GregorianCalendar;
 import java.util.Iterator;
 
-import org.apache.tika.metadata.DublinCore;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 
 import com.drew.metadata.Directory;
 import com.drew.metadata.MetadataException;
@@ -66,7 +66,7 @@ public class ImageMetadataExtractorTest extends TestCase {
         Metadata metadata = new Metadata();
         
         new ImageMetadataExtractor.ExifHandler().handle(exif, metadata);
-        assertEquals("Should be ISO date without time zone", "2000-01-01T00:00:00", metadata.get(Metadata.DATE));
+        assertEquals("Should be ISO date without time zone", "2000-01-01T00:00:00", metadata.get(TikaCoreProperties.DATE));
     }
 
     public void testExifHandlerParseDateFallback() throws MetadataException {
@@ -77,7 +77,7 @@ public class ImageMetadataExtractorTest extends TestCase {
         Metadata metadata = new Metadata();
         
         new ImageMetadataExtractor.ExifHandler().handle(exif, metadata);
-        assertEquals("Should try EXIF Date/Time if Original is not set", "1999-01-01T00:00:00", metadata.get(Metadata.DATE));
+        assertEquals("Should try EXIF Date/Time if Original is not set", "1999-01-01T00:00:00", metadata.get(TikaCoreProperties.DATE));
     }
     
     public void testExifHandlerParseDateError() throws MetadataException {
@@ -88,7 +88,7 @@ public class ImageMetadataExtractorTest extends TestCase {
         Metadata metadata = new Metadata();
         
         new ImageMetadataExtractor.ExifHandler().handle(exif, metadata);
-        assertEquals("Parsing should proceed without date", null, metadata.get(Metadata.DATE));
+        assertEquals("Parsing should proceed without date", null, metadata.get(TikaCoreProperties.DATE));
     }
     
     public void testCopyUnknownFieldsHandler() throws MetadataException {
@@ -100,7 +100,7 @@ public class ImageMetadataExtractorTest extends TestCase {
         when(t2.getTagName()).thenReturn(Metadata.KEYWORDS);
         when(t2.getDescription()).thenReturn("known");
         Tag t3 = mock(Tag.class);
-        when(t3.getTagName()).thenReturn(Metadata.DESCRIPTION);
+        when(t3.getTagName()).thenReturn(TikaCoreProperties.DESCRIPTION.getName());
         when(t3.getDescription()).thenReturn("known");
         Iterator<Tag> tags = Arrays.asList(t1, t2, t3).iterator();
         when(d.getTagIterator()).thenReturn(tags);
@@ -109,7 +109,7 @@ public class ImageMetadataExtractorTest extends TestCase {
         assertEquals("t1", metadata.get("Image Description"));
         assertNull("keywords should be excluded from bulk copy because it is a defined field",
                 metadata.get(Metadata.KEYWORDS));
-        assertNull(metadata.get(Metadata.DESCRIPTION));
+        assertNull(metadata.get(TikaCoreProperties.DESCRIPTION));
     }
     
 }
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/image/MetadataFieldsTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/image/MetadataFieldsTest.java
index c16e865bf..968e1e250 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/image/MetadataFieldsTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/image/MetadataFieldsTest.java
@@ -16,8 +16,8 @@
  */
 package org.apache.tika.parser.image;
 
-import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.TIFF;
+import org.apache.tika.metadata.TikaCoreProperties;
 
 import junit.framework.TestCase;
 
@@ -26,7 +26,7 @@ public class MetadataFieldsTest extends TestCase {
     public void testIsMetadataField() {
         assertFalse(MetadataFields.isMetadataField("random string that is not a field"));
         assertFalse(MetadataFields.isMetadataField("xyz"));
-        assertTrue(MetadataFields.isMetadataField(Metadata.SUBJECT));
+        assertTrue(MetadataFields.isMetadataField(TikaCoreProperties.SUBJECT));
         assertTrue(MetadataFields.isMetadataField(TIFF.F_NUMBER.getName()));
     }
 
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/image/TiffParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/image/TiffParserTest.java
index f2adde14c..6eeadc7e7 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/image/TiffParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/image/TiffParserTest.java
@@ -22,6 +22,7 @@ import org.apache.tika.parser.ParseContext;
 import org.apache.tika.parser.Parser;
 import org.apache.tika.parser.image.TiffParser;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.xml.sax.helpers.DefaultHandler;
 
 import java.io.InputStream;
@@ -41,7 +42,7 @@ public class TiffParserTest extends TestCase {
         assertEquals("Licensed to the Apache Software Foundation (ASF) under one or " +
         		"more contributor license agreements.  See the NOTICE file " +
         		"distributed with this work for additional information regarding " +
-        		"copyright ownership.", metadata.get(Metadata.DESCRIPTION));
+        		"copyright ownership.", metadata.get(TikaCoreProperties.DESCRIPTION));
         
         // All EXIF/TIFF tags
         assertEquals("Inch", metadata.get(Metadata.RESOLUTION_UNIT));
@@ -53,7 +54,7 @@ public class TiffParserTest extends TestCase {
         assertEquals("3", metadata.get(Metadata.SAMPLES_PER_PIXEL));
         
         // Embedded XMP
-        List<String> subject = Arrays.asList(metadata.getValues(Metadata.SUBJECT));
+        List<String> subject = Arrays.asList(metadata.getValues(TikaCoreProperties.SUBJECT));
         assertTrue("got " + subject, subject.contains("cat"));
         assertTrue("got " + subject, subject.contains("garden"));
     }
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/image/xmp/JempboxExtractorTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/image/xmp/JempboxExtractorTest.java
index c9291ce74..af0a72e38 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/image/xmp/JempboxExtractorTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/image/xmp/JempboxExtractorTest.java
@@ -23,6 +23,7 @@ import java.util.Collection;
 
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.image.xmp.JempboxExtractor;
 
 import junit.framework.TestCase;
@@ -33,20 +34,20 @@ public class JempboxExtractorTest extends TestCase {
         Metadata metadata = new Metadata();
         InputStream stream = getClass().getResourceAsStream("/test-documents/testJPEG_commented.jpg");
         // set some values before extraction to see that they are overridden
-        metadata.set(Metadata.TITLE, "old title");
-        metadata.set(Metadata.DESCRIPTION, "old description");
-        metadata.set(Metadata.CREATOR, "previous author");
+        metadata.set(TikaCoreProperties.TITLE, "old title");
+        metadata.set(TikaCoreProperties.DESCRIPTION, "old description");
+        metadata.set(TikaCoreProperties.CREATOR, "previous author");
         // ... or kept in case the field is multi-value
-        metadata.add(Metadata.SUBJECT, "oldkeyword");
+        metadata.add(TikaCoreProperties.SUBJECT, "oldkeyword");
         
         JempboxExtractor extractor = new JempboxExtractor(metadata);
         extractor.parse(stream);
         
         // DublinCore fields
-        assertEquals("Tosteberga \u00C4ngar", metadata.get(Metadata.TITLE));
-        assertEquals("Bird site in north eastern Sk\u00E5ne, Sweden.\n(new line)", metadata.get(Metadata.DESCRIPTION));
-        assertEquals("Some Tourist", metadata.get(Metadata.CREATOR));
-        Collection<String> keywords = Arrays.asList(metadata.getValues(Metadata.SUBJECT));  
+        assertEquals("Tosteberga \u00C4ngar", metadata.get(TikaCoreProperties.TITLE));
+        assertEquals("Bird site in north eastern Sk\u00E5ne, Sweden.\n(new line)", metadata.get(TikaCoreProperties.DESCRIPTION));
+        assertEquals("Some Tourist", metadata.get(TikaCoreProperties.CREATOR));
+        Collection<String> keywords = Arrays.asList(metadata.getValues(TikaCoreProperties.SUBJECT));  
         assertTrue(keywords.contains("oldkeyword"));
         assertTrue(keywords.contains("grazelands"));
         assertTrue(keywords.contains("nature reserve"));
@@ -62,10 +63,10 @@ public class JempboxExtractorTest extends TestCase {
         extractor.parse(stream);
         
         // DublinCore fields
-        assertEquals("Tosteberga \u00C4ngar", metadata.get(Metadata.TITLE));
-        assertEquals("Bird site in north eastern Sk\u00E5ne, Sweden.\n(new line)", metadata.get(Metadata.DESCRIPTION));
-        assertEquals("Some Tourist", metadata.get(Metadata.CREATOR));
-        Collection<String> keywords = Arrays.asList(metadata.getValues(Metadata.SUBJECT));  
+        assertEquals("Tosteberga \u00C4ngar", metadata.get(TikaCoreProperties.TITLE));
+        assertEquals("Bird site in north eastern Sk\u00E5ne, Sweden.\n(new line)", metadata.get(TikaCoreProperties.DESCRIPTION));
+        assertEquals("Some Tourist", metadata.get(TikaCoreProperties.CREATOR));
+        Collection<String> keywords = Arrays.asList(metadata.getValues(TikaCoreProperties.SUBJECT));  
         assertTrue(keywords.contains("bird watching"));
         assertTrue(keywords.contains("coast"));
     }
@@ -78,8 +79,8 @@ public class JempboxExtractorTest extends TestCase {
         extractor.parse(stream);
         
         // XnViewMp fields not understood by Jempbox
-        assertEquals("Bird site in north eastern Sk\u00E5ne, Sweden.\n(new line)", metadata.get(Metadata.DESCRIPTION));
-        Collection<String> keywords = Arrays.asList(metadata.getValues(Metadata.SUBJECT));
+        assertEquals("Bird site in north eastern Sk\u00E5ne, Sweden.\n(new line)", metadata.get(TikaCoreProperties.DESCRIPTION));
+        Collection<String> keywords = Arrays.asList(metadata.getValues(TikaCoreProperties.SUBJECT));
         assertTrue(keywords.contains("coast"));
         assertTrue(keywords.contains("nature reserve"));
     }
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
index 1bb180512..b53b4963c 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
@@ -17,10 +17,13 @@
 package org.apache.tika.parser.iwork;
 
 import java.io.InputStream;
+import java.util.Arrays;
+import java.util.List;
 
 import junit.framework.TestCase;
 
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.AutoDetectParser;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.parser.Parser;
@@ -48,13 +51,22 @@ public class IWorkParserTest extends TestCase {
         ContentHandler handler = new BodyContentHandler();
         iWorkParser.parse(input, handler, metadata, parseContext);
 
-        assertEquals(6, metadata.size());
+        // Make sure enough keys came through
+        // (Exact numbers will vary based on composites)
+        assertTrue("Insufficient metadata found " + metadata.size(), metadata.size() >= 6);
+        List<String> metadataKeys = Arrays.asList(metadata.names());
+        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.CONTENT_TYPE));
+        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.SLIDE_COUNT.getName()));
+        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.AUTHOR));
+        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.TITLE));
+        
+        // Check the metadata values
         assertEquals("application/vnd.apple.keynote", metadata.get(Metadata.CONTENT_TYPE));
         assertEquals("3", metadata.get(Metadata.SLIDE_COUNT));
         assertEquals("1024", metadata.get(KeynoteContentHandler.PRESENTATION_WIDTH));
         assertEquals("768", metadata.get(KeynoteContentHandler.PRESENTATION_HEIGHT));
         assertEquals("Tika user", metadata.get(Metadata.AUTHOR));
-        assertEquals("Apache tika", metadata.get(Metadata.TITLE));
+        assertEquals("Apache tika", metadata.get(TikaCoreProperties.TITLE));
 
         String content = handler.toString();
         assertTrue(content.contains("A sample presentation"));
@@ -82,13 +94,24 @@ public class IWorkParserTest extends TestCase {
         ContentHandler handler = new BodyContentHandler();
         iWorkParser.parse(input, handler, metadata, parseContext);
 
-        assertEquals(51, metadata.size());
+        // Make sure enough keys came through
+        // (Exact numbers will vary based on composites)
+        assertTrue("Insufficient metadata found " + metadata.size(), metadata.size() >= 50);
+        List<String> metadataKeys = Arrays.asList(metadata.names());
+        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.CONTENT_TYPE));
+        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.PAGE_COUNT.getName()));
+        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.AUTHOR));
+        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.TITLE));
+        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.LAST_MODIFIED.getName()));
+        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.LANGUAGE));
+        
+        // Check the metadata values
         assertEquals("application/vnd.apple.pages", metadata.get(Metadata.CONTENT_TYPE));
         assertEquals("Tika user", metadata.get(Metadata.AUTHOR));
-        assertEquals("Apache tika", metadata.get(Metadata.TITLE));
+        assertEquals("Apache tika", metadata.get(TikaCoreProperties.TITLE));
         assertEquals("2010-05-09T21:34:38+0200", metadata.get(Metadata.CREATION_DATE));
         assertEquals("2010-05-09T23:50:36+0200", metadata.get(Metadata.LAST_MODIFIED));
-        assertEquals("en", metadata.get(Metadata.LANGUAGE));
+        assertEquals("en", metadata.get(TikaCoreProperties.LANGUAGE));
         assertEquals("2", metadata.get(Metadata.PAGE_COUNT));
 
         String content = handler.toString();
@@ -119,13 +142,24 @@ public class IWorkParserTest extends TestCase {
 
         iWorkParser.parse(input, handler, metadata, parseContext);
 
-        String content = handler.toString();
-        assertEquals(9, metadata.size());
+        // Make sure enough keys came through
+        // (Exact numbers will vary based on composites)
+        assertTrue("Insufficient metadata found " + metadata.size(), metadata.size() >= 8);
+        List<String> metadataKeys = Arrays.asList(metadata.names());
+        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.CONTENT_TYPE));
+        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.PAGE_COUNT.getName()));
+        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.AUTHOR));
+        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.COMMENT));
+        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(Metadata.TITLE));
+        assertTrue("Metadata not found in " + metadataKeys, metadataKeys.contains(TikaCoreProperties.TITLE.getName()));
+        
+        // Check the metadata values
         assertEquals("2", metadata.get(Metadata.PAGE_COUNT));
         assertEquals("Tika User", metadata.get(Metadata.AUTHOR));
-        assertEquals("Account checking", metadata.get(Metadata.TITLE));
+        assertEquals("Account checking", metadata.get(TikaCoreProperties.TITLE));
         assertEquals("a comment", metadata.get(Metadata.COMMENT));
 
+        String content = handler.toString();
         assertTrue(content.contains("Category"));
         assertTrue(content.contains("Home"));
         assertTrue(content.contains("-226"));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/jpeg/JpegParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/jpeg/JpegParserTest.java
index cccbe35a2..64d5ee835 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/jpeg/JpegParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/jpeg/JpegParserTest.java
@@ -24,6 +24,7 @@ import junit.framework.TestCase;
 
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.TIFF;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.parser.Parser;
 import org.xml.sax.helpers.DefaultHandler;
@@ -65,8 +66,8 @@ public class JpegParserTest extends TestCase {
         // Common tags
         //assertEquals("2009-10-02T23:02:49", metadata.get(Metadata.LAST_MODIFIED));
         assertEquals("Date/Time Original for when the photo was taken, unspecified time zone",
-                "2009-08-11T09:09:45", metadata.get(Metadata.DATE));
-        List<String> keywords = Arrays.asList(metadata.getValues(Metadata.SUBJECT));
+                "2009-08-11T09:09:45", metadata.get(TikaCoreProperties.DATE));
+        List<String> keywords = Arrays.asList(metadata.getValues(TikaCoreProperties.SUBJECT));
         assertTrue("'canon-55-250' expected in " + keywords, keywords.contains("canon-55-250"));
         assertTrue("'moscow-birds' expected in " + keywords, keywords.contains("moscow-birds")); 
         assertTrue("'serbor' expected in " + keywords, keywords.contains("serbor"));
@@ -108,7 +109,7 @@ public class JpegParserTest extends TestCase {
         
         // Common tags
         assertEquals("Date/Time Original for when the photo was taken, unspecified time zone",
-                "2009-08-11T09:09:45", metadata.get(Metadata.DATE));
+                "2009-08-11T09:09:45", metadata.get(TikaCoreProperties.DATE));
         assertEquals("This image has different Date/Time than Date/Time Original, so it is probably modification date",
                 "2009-10-02T23:02:49", metadata.get(Metadata.LAST_MODIFIED));
         assertEquals("Date/Time Original should be stored in EXIF field too",
@@ -141,17 +142,17 @@ public class JpegParserTest extends TestCase {
         parser.parse(stream, new DefaultHandler(), metadata, new ParseContext());
           
         // embedded comments with non-ascii characters
-        assertEquals("Tosteberga \u00C4ngar", metadata.get(Metadata.TITLE));
-        assertEquals("Bird site in north eastern Sk\u00E5ne, Sweden.\n(new line)", metadata.get(Metadata.DESCRIPTION));
+        assertEquals("Tosteberga \u00C4ngar", metadata.get(TikaCoreProperties.TITLE));
+        assertEquals("Bird site in north eastern Sk\u00E5ne, Sweden.\n(new line)", metadata.get(TikaCoreProperties.DESCRIPTION));
         assertEquals("Some Tourist", metadata.get(Metadata.AUTHOR));
-        assertEquals("Some Tourist", metadata.get(Metadata.CREATOR)); // Dublin Core
+        assertEquals("Some Tourist", metadata.get(TikaCoreProperties.CREATOR)); // Dublin Core
         // xmp handles spaces in keywords, returns "bird watching, nature reserve, coast, grazelands"
         // but we have to replace them with underscore
         
         List<String> keywords = Arrays.asList(metadata.getValues(Metadata.KEYWORDS));
         assertTrue(keywords.contains("coast"));
         assertTrue(keywords.contains("bird watching"));
-        assertEquals(keywords, Arrays.asList(metadata.getValues(Metadata.SUBJECT)));
+        assertEquals(keywords, Arrays.asList(metadata.getValues(TikaCoreProperties.SUBJECT)));
         
         // Core EXIF/TIFF tags
         assertEquals("103", metadata.get(Metadata.IMAGE_WIDTH));
@@ -180,10 +181,10 @@ public class JpegParserTest extends TestCase {
         parser.parse(stream, new DefaultHandler(), metadata, new ParseContext());
           
         // embedded comments with non-ascii characters
-        assertEquals("Tosteberga \u00C4ngar", metadata.get(Metadata.TITLE));
-        assertEquals("Bird site in north eastern Sk\u00E5ne, Sweden.\n(new line)", metadata.get(Metadata.DESCRIPTION));
-        assertEquals("Some Tourist", metadata.get(Metadata.CREATOR));
-        List<String> subject = Arrays.asList(metadata.getValues(Metadata.SUBJECT));
+        assertEquals("Tosteberga \u00C4ngar", metadata.get(TikaCoreProperties.TITLE));
+        assertEquals("Bird site in north eastern Sk\u00E5ne, Sweden.\n(new line)", metadata.get(TikaCoreProperties.DESCRIPTION));
+        assertEquals("Some Tourist", metadata.get(TikaCoreProperties.CREATOR));
+        List<String> subject = Arrays.asList(metadata.getValues(TikaCoreProperties.SUBJECT));
         assertTrue("got " + subject, subject.contains("bird watching")); 
     }
     
@@ -196,10 +197,10 @@ public class JpegParserTest extends TestCase {
           
         // XnViewMp's default comment dialog has only comment, not headline.
         // Comment is embedded only if "Write comments in XMP" is enabled in settings
-        assertEquals("Bird site in north eastern Sk\u00E5ne, Sweden.\n(new line)", metadata.get(Metadata.DESCRIPTION));
+        assertEquals("Bird site in north eastern Sk\u00E5ne, Sweden.\n(new line)", metadata.get(TikaCoreProperties.DESCRIPTION));
         // xmp handles spaces in keywords, returns "bird watching, nature reserve, coast, grazelands"
         // but we have to replace them with underscore
-        String[] subject = metadata.getValues(Metadata.SUBJECT);
+        String[] subject = metadata.getValues(TikaCoreProperties.SUBJECT);
         List<String> keywords = Arrays.asList(subject);
         assertTrue("'coast'" + " not in " + keywords, keywords.contains("coast"));
         assertTrue("'nature reserve'" + " not in " + keywords, keywords.contains("nature reserve"));     
@@ -212,8 +213,8 @@ public class JpegParserTest extends TestCase {
            getClass().getResourceAsStream("/test-documents/testJPEG_oddTagComponent.jpg");
        parser.parse(stream, new DefaultHandler(), metadata, new ParseContext());
        
-       assertEquals(null, metadata.get(Metadata.TITLE));
-       assertEquals(null, metadata.get(Metadata.DESCRIPTION));
+       assertEquals(null, metadata.get(TikaCoreProperties.TITLE));
+       assertEquals(null, metadata.get(TikaCoreProperties.DESCRIPTION));
        assertEquals("251", metadata.get(Metadata.IMAGE_WIDTH));
        assertEquals("384", metadata.get(Metadata.IMAGE_LENGTH));
     }
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/mail/RFC822ParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/mail/RFC822ParserTest.java
index 5cfd1a4bd..872e2476d 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/mail/RFC822ParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/mail/RFC822ParserTest.java
@@ -31,6 +31,7 @@ import junit.framework.TestCase;
 import org.apache.james.mime4j.stream.MimeConfig;
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.parser.Parser;
 import org.apache.tika.sax.BodyContentHandler;
@@ -59,7 +60,7 @@ public class RFC822ParserTest extends TestCase {
             verify(handler).endDocument();
             //note no leading spaces, and no quotes
             assertEquals("Julien Nioche (JIRA) <jira@apache.org>", metadata.get(Metadata.AUTHOR));
-            assertEquals("[jira] Commented: (TIKA-461) RFC822 messages not parsed", metadata.get(Metadata.SUBJECT));
+            assertEquals("[jira] Commented: (TIKA-461) RFC822 messages not parsed", metadata.get(TikaCoreProperties.SUBJECT));
         } catch (Exception e) {
             fail("Exception thrown: " + e.getMessage());
         }
@@ -147,7 +148,7 @@ public class RFC822ParserTest extends TestCase {
             //tests correct decoding of internationalized headers, both
             //quoted-printable (Q) and Base64 (B).
             assertEquals("Keld J\u00F8rn Simonsen <keld@dkuug.dk>", metadata.get(Metadata.AUTHOR));
-            assertEquals("If you can read this you understand the example.", metadata.get(Metadata.SUBJECT));
+            assertEquals("If you can read this you understand the example.", metadata.get(TikaCoreProperties.SUBJECT));
         } catch (Exception e) {
             fail("Exception thrown: " + e.getMessage());
         }
@@ -165,7 +166,7 @@ public class RFC822ParserTest extends TestCase {
 
        parser.parse(stream, handler, metadata, new ParseContext());
        assertEquals("Saved by Windows Internet Explorer 7", metadata.get(Metadata.AUTHOR));
-       assertEquals("Air Permit Programs | Air & Radiation | US EPA", metadata.get(Metadata.SUBJECT));
+       assertEquals("Air Permit Programs | Air & Radiation | US EPA", metadata.get(TikaCoreProperties.SUBJECT));
     }
 
     /**
@@ -220,7 +221,7 @@ public class RFC822ParserTest extends TestCase {
        assertEquals(true, metadata.isMultiValued(Metadata.MESSAGE_TO));
        assertEquals("abc", metadata.getValues(Metadata.MESSAGE_TO)[0]);
        assertEquals("def", metadata.getValues(Metadata.MESSAGE_TO)[1]);
-       assertEquals("abcd", metadata.get(Metadata.SUBJECT));
+       assertEquals("abcd", metadata.get(TikaCoreProperties.SUBJECT));
        assertTrue(handler.toString().contains("bar biz bat"));
     }
 
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/mbox/MboxParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/mbox/MboxParserTest.java
index 0af7941c0..fe77bc82f 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/mbox/MboxParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/mbox/MboxParserTest.java
@@ -27,6 +27,7 @@ import java.io.InputStream;
 import junit.framework.TestCase;
 
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.parser.Parser;
 import org.apache.tika.sax.XHTMLContentHandler;
@@ -69,14 +70,14 @@ public class MboxParserTest extends TestCase {
             verify(handler).characters(new String("Test content").toCharArray(), 0, 12);
             verify(handler).endDocument();
 
-            assertEquals("subject", metadata.get(Metadata.TITLE));
-            assertEquals("subject", metadata.get(Metadata.SUBJECT));
+            assertEquals("subject", metadata.get(TikaCoreProperties.TITLE));
+            assertEquals("subject", metadata.get(TikaCoreProperties.SUBJECT));
             assertEquals("<author@domain.com>", metadata.get(Metadata.AUTHOR));
-            assertEquals("<author@domain.com>", metadata.get(Metadata.CREATOR));
+            assertEquals("<author@domain.com>", metadata.get(TikaCoreProperties.CREATOR));
             assertEquals(null, metadata.get(Metadata.MESSAGE_RECIPIENT_ADDRESS));
             assertEquals("<name@domain.com>", metadata.get("MboxParser-return-path"));
             assertEquals("Should be ISO date in UTC, converted from 'Tue, 9 Jun 2009 23:58:45 -0400'", 
-                    "2009-06-10T03:58:45Z", metadata.get(Metadata.DATE));
+                    "2009-06-10T03:58:45Z", metadata.get(TikaCoreProperties.DATE));
         } catch (Exception e) {
             fail("Exception thrown: " + e.getMessage());
         }
@@ -133,10 +134,10 @@ public class MboxParserTest extends TestCase {
         try {
             parser.parse(stream, handler, metadata, new ParseContext());
 
-            assertEquals("Re: question about when shuffle/sort start working", metadata.get(Metadata.TITLE));
-            assertEquals("Re: question about when shuffle/sort start working", metadata.get(Metadata.SUBJECT));
+            assertEquals("Re: question about when shuffle/sort start working", metadata.get(TikaCoreProperties.TITLE));
+            assertEquals("Re: question about when shuffle/sort start working", metadata.get(TikaCoreProperties.SUBJECT));
             assertEquals("Jothi Padmanabhan <jothipn@yahoo-inc.com>", metadata.get(Metadata.AUTHOR));
-            assertEquals("Jothi Padmanabhan <jothipn@yahoo-inc.com>", metadata.get(Metadata.CREATOR));
+            assertEquals("Jothi Padmanabhan <jothipn@yahoo-inc.com>", metadata.get(TikaCoreProperties.CREATOR));
             assertEquals("core-user@hadoop.apache.org", metadata.get(Metadata.MESSAGE_RECIPIENT_ADDRESS));
             
             verify(handler).startDocument();
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ExcelParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ExcelParserTest.java
index d4371a020..2bab716af 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ExcelParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ExcelParserTest.java
@@ -24,6 +24,7 @@ import junit.framework.TestCase;
 import org.apache.tika.detect.DefaultDetector;
 import org.apache.tika.detect.Detector;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.parser.AutoDetectParser;
 import org.apache.tika.parser.ParseContext;
@@ -45,7 +46,7 @@ public class ExcelParserTest extends TestCase {
             assertEquals(
                     "application/vnd.ms-excel",
                     metadata.get(Metadata.CONTENT_TYPE));
-            assertEquals("Simple Excel document", metadata.get(Metadata.TITLE));
+            assertEquals("Simple Excel document", metadata.get(TikaCoreProperties.TITLE));
             assertEquals("Keith Bennett", metadata.get(Metadata.AUTHOR));
             
             // Mon Oct 01 17:13:56 BST 2007
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/OutlookParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/OutlookParserTest.java
index 6d18859bf..3ba40655d 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/OutlookParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/OutlookParserTest.java
@@ -29,6 +29,7 @@ import javax.xml.transform.stream.StreamResult;
 import junit.framework.TestCase;
 
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.AutoDetectParser;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.parser.Parser;
@@ -58,7 +59,7 @@ public class OutlookParserTest extends TestCase {
                 metadata.get(Metadata.CONTENT_TYPE));
         assertEquals(
                 "Microsoft Outlook Express 6",
-                metadata.get(Metadata.TITLE));
+                metadata.get(TikaCoreProperties.TITLE));
         assertEquals(
                 "Nouvel utilisateur de Outlook Express",
                 metadata.get(Metadata.MESSAGE_RECIPIENT_ADDRESS));
@@ -69,7 +70,7 @@ public class OutlookParserTest extends TestCase {
         // Stored as Thu, 5 Apr 2007 09:26:06 -0700
         assertEquals(
                 "2007-04-05T16:26:06Z",
-                metadata.get(Metadata.DATE));
+                metadata.get(TikaCoreProperties.DATE));
 
         String content = handler.toString();
         assertTrue(content.contains(""));
@@ -131,7 +132,7 @@ public class OutlookParserTest extends TestCase {
                 metadata.get(Metadata.CONTENT_TYPE));
         assertEquals(
                 "Welcome to Microsoft Office Outlook 2003",
-                metadata.get(Metadata.TITLE));
+                metadata.get(TikaCoreProperties.TITLE));
 
         String content = handler.toString();
         assertTrue(content.contains("Outlook 2003"));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PowerPointParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PowerPointParserTest.java
index 0e565ebcd..27617dde8 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PowerPointParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PowerPointParserTest.java
@@ -21,6 +21,7 @@ import java.util.Locale;
 
 import org.apache.tika.TikaTest;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.sax.BodyContentHandler;
 import org.xml.sax.ContentHandler;
@@ -38,7 +39,7 @@ public class PowerPointParserTest extends TikaTest {
             assertEquals(
                     "application/vnd.ms-powerpoint",
                     metadata.get(Metadata.CONTENT_TYPE));
-            assertEquals("Sample Powerpoint Slide", metadata.get(Metadata.TITLE));
+            assertEquals("Sample Powerpoint Slide", metadata.get(TikaCoreProperties.TITLE));
             assertEquals("Keith Bennett", metadata.get(Metadata.AUTHOR));
             String content = handler.toString();
             assertTrue(content.contains("Sample Powerpoint Slide"));
@@ -104,7 +105,7 @@ public class PowerPointParserTest extends TikaTest {
 
         assertContains("Subject is here", content);
         assertEquals("Subject is here",
-                     metadata.get(Metadata.SUBJECT));
+                     metadata.get(TikaCoreProperties.SUBJECT));
 
         assertContains("Suddenly some Japanese text:", content);
         // Special version of (GHQ)
@@ -203,7 +204,7 @@ public class PowerPointParserTest extends TikaTest {
        assertEquals("2011-08-22T13:30:53Z", metadata.get(Metadata.CREATION_DATE));
        assertEquals("1",                    metadata.get(Metadata.SLIDE_COUNT));
        assertEquals("3",                    metadata.get(Metadata.WORD_COUNT));
-       assertEquals("Test extraction properties pptx", metadata.get(Metadata.TITLE));
+       assertEquals("Test extraction properties pptx", metadata.get(TikaCoreProperties.TITLE));
        assertEquals("true",                 metadata.get("custom:myCustomBoolean"));
        assertEquals("3",                    metadata.get("custom:myCustomNumber"));
        assertEquals("MyStringValue",        metadata.get("custom:MyCustomString"));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ProjectParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ProjectParserTest.java
index b8a13aeeb..696f2f057 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ProjectParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ProjectParserTest.java
@@ -19,6 +19,7 @@ package org.apache.tika.parser.microsoft;
 import java.io.InputStream;
 
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.sax.BodyContentHandler;
 import org.xml.sax.ContentHandler;
@@ -61,8 +62,8 @@ public class ProjectParserTest extends TestCase {
                "application/vnd.ms-project",
                metadata.get(Metadata.CONTENT_TYPE));
        
-       assertEquals("The quick brown fox jumps over the lazy dog", metadata.get(Metadata.TITLE));
-       assertEquals("Gym class featuring a brown fox and lazy dog", metadata.get(Metadata.SUBJECT));
+       assertEquals("The quick brown fox jumps over the lazy dog", metadata.get(TikaCoreProperties.TITLE));
+       assertEquals("Gym class featuring a brown fox and lazy dog", metadata.get(TikaCoreProperties.SUBJECT));
        assertEquals("Nevin Nollop", metadata.get(Metadata.AUTHOR));
        assertEquals("", metadata.get(Metadata.LAST_AUTHOR));
        assertEquals("Pangram, fox, dog", metadata.get(Metadata.KEYWORDS));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PublisherParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PublisherParserTest.java
index c30689123..b31d8eb8b 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PublisherParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PublisherParserTest.java
@@ -19,6 +19,7 @@ package org.apache.tika.parser.microsoft;
 import java.io.InputStream;
 
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.sax.BodyContentHandler;
 import org.xml.sax.ContentHandler;
@@ -38,7 +39,7 @@ public class PublisherParserTest extends TestCase {
             assertEquals(
                     "application/x-mspublisher",
                     metadata.get(Metadata.CONTENT_TYPE));
-            assertEquals(null, metadata.get(Metadata.TITLE));
+            assertEquals(null, metadata.get(TikaCoreProperties.TITLE));
             assertEquals("Nick Burch", metadata.get(Metadata.AUTHOR));
             String content = handler.toString();
             assertTrue(content.contains("0123456789"));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/TNEFParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/TNEFParserTest.java
index 417f8c6e4..a155259e3 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/TNEFParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/TNEFParserTest.java
@@ -22,6 +22,7 @@ import org.apache.tika.extractor.ContainerExtractor;
 import org.apache.tika.extractor.ParserContainerExtractor;
 import org.apache.tika.io.TikaInputStream;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.sax.BodyContentHandler;
@@ -54,7 +55,7 @@ public class TNEFParserTest extends AbstractPOIContainerExtractionTest {
       TNEFParser tnef = new TNEFParser();
       tnef.parse(stream, handler, metadata, new ParseContext());
       
-      assertEquals("This is a test message", metadata.get(Metadata.SUBJECT));
+      assertEquals("This is a test message", metadata.get(TikaCoreProperties.SUBJECT));
    }
    
     /**
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/VisioParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/VisioParserTest.java
index 747cb01b5..6a026aaaa 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/VisioParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/VisioParserTest.java
@@ -19,6 +19,7 @@ package org.apache.tika.parser.microsoft;
 import java.io.InputStream;
 
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.sax.BodyContentHandler;
 import org.xml.sax.ContentHandler;
@@ -38,7 +39,7 @@ public class VisioParserTest extends TestCase {
             assertEquals(
                     "application/vnd.visio",
                     metadata.get(Metadata.CONTENT_TYPE));
-            assertEquals("", metadata.get(Metadata.TITLE));
+            assertEquals("", metadata.get(TikaCoreProperties.TITLE));
             assertEquals("Hogwarts", metadata.get(Metadata.AUTHOR));
             String content = handler.toString();
             assertTrue(content.contains("Some random text, on a page"));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/WordParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/WordParserTest.java
index 528ff403d..c8e8e5f69 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/WordParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/WordParserTest.java
@@ -27,6 +27,7 @@ import javax.xml.transform.stream.StreamResult;
 
 import org.apache.tika.TikaTest;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.parser.microsoft.ooxml.OOXMLParserTest;
 import org.apache.tika.sax.BodyContentHandler;
@@ -45,7 +46,7 @@ public class WordParserTest extends TikaTest {
             assertEquals(
                     "application/msword",
                     metadata.get(Metadata.CONTENT_TYPE));
-            assertEquals("Sample Word Document", metadata.get(Metadata.TITLE));
+            assertEquals("Sample Word Document", metadata.get(TikaCoreProperties.TITLE));
             assertEquals("Keith Bennett", metadata.get(Metadata.AUTHOR));
             assertTrue(handler.toString().contains("Sample Word Document"));
         } finally {
@@ -114,7 +115,7 @@ public class WordParserTest extends TikaTest {
         assertEquals(
                      "application/msword",
                      metadata.get(Metadata.CONTENT_TYPE));
-        assertEquals("Sample Word Document", metadata.get(Metadata.TITLE));
+        assertEquals("Sample Word Document", metadata.get(TikaCoreProperties.TITLE));
         assertEquals("Keith Bennett", metadata.get(Metadata.AUTHOR));
         assertTrue(xml.contains("Sample Word Document"));
 
@@ -176,8 +177,8 @@ public class WordParserTest extends TikaTest {
             assertEquals(
                     "application/msword",
                     metadata.get(Metadata.CONTENT_TYPE));
-            assertEquals("The quick brown fox jumps over the lazy dog", metadata.get(Metadata.TITLE));
-            assertEquals("Gym class featuring a brown fox and lazy dog", metadata.get(Metadata.SUBJECT));
+            assertEquals("The quick brown fox jumps over the lazy dog", metadata.get(TikaCoreProperties.TITLE));
+            assertEquals("Gym class featuring a brown fox and lazy dog", metadata.get(TikaCoreProperties.SUBJECT));
             assertEquals("Nevin Nollop", metadata.get(Metadata.AUTHOR));
             assertTrue(handler.toString().contains("The quick brown fox jumps over the lazy dog"));
         } finally {
@@ -241,7 +242,7 @@ public class WordParserTest extends TikaTest {
 
         assertContains("Subject is here", content);
         assertEquals("Subject is here",
-                     metadata.get(Metadata.SUBJECT));
+                     metadata.get(TikaCoreProperties.SUBJECT));
 
         assertContains("Suddenly some Japanese text:", content);
         // Special version of (GHQ)
@@ -278,11 +279,11 @@ public class WordParserTest extends TikaTest {
        assertEquals("Microsoft Office Word",metadata.get(Metadata.APPLICATION_NAME));
        assertEquals("1",                    metadata.get(Metadata.PAGE_COUNT));
        assertEquals("2",                    metadata.get(Metadata.WORD_COUNT));
-       assertEquals("My Title",             metadata.get(Metadata.TITLE));
+       assertEquals("My Title",             metadata.get(TikaCoreProperties.TITLE));
        assertEquals("My Keyword",           metadata.get(Metadata.KEYWORDS));
        assertEquals("Normal.dotm",          metadata.get(Metadata.TEMPLATE));
        assertEquals("My Comments",          metadata.get(Metadata.COMMENTS));
-       assertEquals("My subject",           metadata.get(Metadata.SUBJECT));
+       assertEquals("My subject",           metadata.get(TikaCoreProperties.SUBJECT));
        assertEquals("EDF-DIT",              metadata.get(Metadata.COMPANY));
        assertEquals("MyStringValue",        metadata.get("custom:MyCustomString"));
        assertEquals("2010-12-30T23:00:00Z", metadata.get("custom:MyCustomDate"));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
index 09a4365b2..1f90e1bef 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
@@ -28,6 +28,7 @@ import javax.xml.transform.stream.StreamResult;
 import org.apache.tika.TikaTest;
 import org.apache.tika.io.TikaInputStream;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.metadata.TikaMetadataKeys;
 import org.apache.tika.parser.AutoDetectParser;
 import org.apache.tika.parser.ParseContext;
@@ -57,7 +58,7 @@ public class OOXMLParserTest extends TikaTest {
             assertEquals(
                     "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                     metadata.get(Metadata.CONTENT_TYPE));
-            assertEquals("Simple Excel document", metadata.get(Metadata.TITLE));
+            assertEquals("Simple Excel document", metadata.get(TikaCoreProperties.TITLE));
             assertEquals("Keith Bennett", metadata.get(Metadata.AUTHOR));
             String content = handler.toString();
             assertTrue(content.contains("Sample Excel Worksheet"));
@@ -184,7 +185,7 @@ public class OOXMLParserTest extends TikaTest {
                         "Mime-type checking for " + filename,
                         mimeTypes[i],
                         metadata.get(Metadata.CONTENT_TYPE));
-                assertEquals("Attachment Test", metadata.get(Metadata.TITLE));
+                assertEquals("Attachment Test", metadata.get(TikaCoreProperties.TITLE));
                 assertEquals("Rajiv", metadata.get(Metadata.AUTHOR));
                 
                 String content = handler.toString();
@@ -273,7 +274,7 @@ public class OOXMLParserTest extends TikaTest {
             assertEquals(
                     "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                     metadata.get(Metadata.CONTENT_TYPE));
-            assertEquals("Sample Word Document", metadata.get(Metadata.TITLE));
+            assertEquals("Sample Word Document", metadata.get(TikaCoreProperties.TITLE));
             assertEquals("Keith Bennett", metadata.get(Metadata.AUTHOR));
             assertTrue(handler.toString().contains("Sample Word Document"));
         } finally {
@@ -344,7 +345,7 @@ public class OOXMLParserTest extends TikaTest {
       assertEquals(
                    "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                    metadata.get(Metadata.CONTENT_TYPE));
-      assertEquals("Sample Word Document", metadata.get(Metadata.TITLE));
+      assertEquals("Sample Word Document", metadata.get(TikaCoreProperties.TITLE));
       assertEquals("Keith Bennett", metadata.get(Metadata.AUTHOR));
       assertTrue(xml.contains("Sample Word Document"));
             
@@ -557,7 +558,7 @@ public class OOXMLParserTest extends TikaTest {
 
         assertContains("Subject is here", content);
         assertEquals("Subject is here",
-                     metadata.get(Metadata.SUBJECT));
+                     metadata.get(TikaCoreProperties.SUBJECT));
 
         assertContains("Suddenly some Japanese text:", content);
         // Special version of (GHQ)
@@ -625,7 +626,7 @@ public class OOXMLParserTest extends TikaTest {
 
         assertContains("Subject is here", content);
         assertEquals("Subject is here",
-                     metadata.get(Metadata.SUBJECT));
+                     metadata.get(TikaCoreProperties.SUBJECT));
 
         assertContains("Suddenly some Japanese text:", content);
         // Special version of (GHQ)
@@ -729,7 +730,7 @@ public class OOXMLParserTest extends TikaTest {
              metadata.get(Metadata.CONTENT_TYPE));
        assertEquals(null,                   metadata.get(Metadata.AUTHOR));
        assertEquals(null,                   metadata.get(Metadata.LAST_AUTHOR));
-       assertEquals("2006-09-12T15:06:44Z", metadata.get(Metadata.DATE));
+       assertEquals("2006-09-12T15:06:44Z", metadata.get(TikaCoreProperties.DATE));
        assertEquals("2006-09-12T15:06:44Z", metadata.get(Metadata.CREATION_DATE));
        assertEquals("2011-08-22T14:24:38Z", metadata.get(Metadata.LAST_MODIFIED));
        assertEquals("Microsoft Excel",      metadata.get(Metadata.APPLICATION_NAME));
@@ -758,17 +759,17 @@ public class OOXMLParserTest extends TikaTest {
              metadata.get(Metadata.CONTENT_TYPE));
        assertEquals("EJ04325S",             metadata.get(Metadata.AUTHOR));
        assertEquals("Etienne Jouvin",       metadata.get(Metadata.LAST_AUTHOR));
-       assertEquals("2011-07-29T16:52:00Z", metadata.get(Metadata.DATE));
+       assertEquals("2011-07-29T16:52:00Z", metadata.get(TikaCoreProperties.DATE));
        assertEquals("2011-07-29T16:52:00Z", metadata.get(Metadata.CREATION_DATE));
        assertEquals("2012-01-03T22:14:00Z", metadata.get(Metadata.LAST_MODIFIED));
        assertEquals("Microsoft Office Word",metadata.get(Metadata.APPLICATION_NAME));
        assertEquals("1",                    metadata.get(Metadata.PAGE_COUNT));
        assertEquals("2",                    metadata.get(Metadata.WORD_COUNT));
-       assertEquals("My Title",             metadata.get(Metadata.TITLE));
+       assertEquals("My Title",             metadata.get(TikaCoreProperties.TITLE));
        assertEquals("My Keyword",           metadata.get(Metadata.KEYWORDS));
        assertEquals("Normal.dotm",          metadata.get(Metadata.TEMPLATE));
-       assertEquals("My subject",           metadata.get(Metadata.SUBJECT));
-       assertEquals("EDF-DIT",              metadata.get(Metadata.PUBLISHER));
+       assertEquals("My subject",           metadata.get(TikaCoreProperties.SUBJECT));
+       assertEquals("EDF-DIT",              metadata.get(TikaCoreProperties.PUBLISHER));
        assertEquals("true",                 metadata.get("custom:myCustomBoolean"));
        assertEquals("3",                    metadata.get("custom:myCustomNumber"));
        assertEquals("MyStringValue",        metadata.get("custom:MyCustomString"));
@@ -794,12 +795,12 @@ public class OOXMLParserTest extends TikaTest {
              metadata.get(Metadata.CONTENT_TYPE));
        assertEquals("JOUVIN ETIENNE",       metadata.get(Metadata.AUTHOR));
        assertEquals("EJ04325S",             metadata.get(Metadata.LAST_AUTHOR));
-       assertEquals("2011-08-22T13:30:53Z", metadata.get(Metadata.DATE));
+       assertEquals("2011-08-22T13:30:53Z", metadata.get(TikaCoreProperties.DATE));
        assertEquals("2011-08-22T13:30:53Z", metadata.get(Metadata.CREATION_DATE));
        assertEquals("2011-08-22T13:32:49Z", metadata.get(Metadata.LAST_MODIFIED));
        assertEquals("1",                    metadata.get(Metadata.SLIDE_COUNT));
        assertEquals("3",                    metadata.get(Metadata.WORD_COUNT));
-       assertEquals("Test extraction properties pptx", metadata.get(Metadata.TITLE));
+       assertEquals("Test extraction properties pptx", metadata.get(TikaCoreProperties.TITLE));
        assertEquals("true",                 metadata.get("custom:myCustomBoolean"));
        assertEquals("3",                    metadata.get("custom:myCustomNumber"));
        assertEquals("MyStringValue",        metadata.get("custom:MyCustomString"));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/mp3/Mp3ParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/mp3/Mp3ParserTest.java
index 41484f2b8..be528287c 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/mp3/Mp3ParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/mp3/Mp3ParserTest.java
@@ -22,6 +22,7 @@ import java.io.InputStream;
 import junit.framework.TestCase;
 
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.metadata.XMPDM;
 import org.apache.tika.parser.AutoDetectParser;
 import org.apache.tika.parser.ParseContext;
@@ -51,7 +52,7 @@ public class Mp3ParserTest extends TestCase {
         }
 
         assertEquals("audio/mpeg", metadata.get(Metadata.CONTENT_TYPE));
-        assertEquals("Test Title", metadata.get(Metadata.TITLE));
+        assertEquals("Test Title", metadata.get(TikaCoreProperties.TITLE));
         assertEquals("Test Artist", metadata.get(Metadata.AUTHOR));
 
         String content = handler.toString();
@@ -86,7 +87,7 @@ public class Mp3ParserTest extends TestCase {
 
         // Check core properties
         assertEquals("audio/mpeg", metadata.get(Metadata.CONTENT_TYPE));
-        assertEquals("Test Title", metadata.get(Metadata.TITLE));
+        assertEquals("Test Title", metadata.get(TikaCoreProperties.TITLE));
         assertEquals("Test Artist", metadata.get(Metadata.AUTHOR));
 
         // Check the textual contents
@@ -135,7 +136,7 @@ public class Mp3ParserTest extends TestCase {
         }
 
         assertEquals("audio/mpeg", metadata.get(Metadata.CONTENT_TYPE));
-        assertEquals("Test Title", metadata.get(Metadata.TITLE));
+        assertEquals("Test Title", metadata.get(TikaCoreProperties.TITLE));
         assertEquals("Test Artist", metadata.get(Metadata.AUTHOR));
 
         String content = handler.toString();
@@ -169,7 +170,7 @@ public class Mp3ParserTest extends TestCase {
         }
 
         assertEquals("audio/mpeg", metadata.get(Metadata.CONTENT_TYPE));
-        assertEquals("Test Title", metadata.get(Metadata.TITLE));
+        assertEquals("Test Title", metadata.get(TikaCoreProperties.TITLE));
         assertEquals("Test Artist", metadata.get(Metadata.AUTHOR));
 
         String content = handler.toString();
@@ -203,7 +204,7 @@ public class Mp3ParserTest extends TestCase {
        }
 
        assertEquals("audio/mpeg", metadata.get(Metadata.CONTENT_TYPE));
-       assertEquals("Une chason en Fran\u00e7ais", metadata.get(Metadata.TITLE));
+       assertEquals("Une chason en Fran\u00e7ais", metadata.get(TikaCoreProperties.TITLE));
        assertEquals("Test Artist \u2468\u2460", metadata.get(Metadata.AUTHOR));
        assertEquals("Test Artist \u2468\u2460", metadata.get(XMPDM.ARTIST));
        assertEquals("Test Album \u2460\u2468", metadata.get(XMPDM.ALBUM));
@@ -241,7 +242,7 @@ public class Mp3ParserTest extends TestCase {
         }
 
         assertEquals("audio/mpeg", metadata.get(Metadata.CONTENT_TYPE));
-        assertEquals("Test Title", metadata.get(Metadata.TITLE));
+        assertEquals("Test Title", metadata.get(TikaCoreProperties.TITLE));
         assertEquals("Test Artist", metadata.get(Metadata.AUTHOR));
 
         String content = handler.toString();
@@ -306,7 +307,7 @@ public class Mp3ParserTest extends TestCase {
        }
 
        assertEquals("audio/mpeg", metadata.get(Metadata.CONTENT_TYPE));
-       assertEquals("Plus loin vers l'ouest", metadata.get(Metadata.TITLE));
+       assertEquals("Plus loin vers l'ouest", metadata.get(TikaCoreProperties.TITLE));
        assertEquals("Merzhin", metadata.get(Metadata.AUTHOR));
 
        String content = handler.toString();
@@ -341,7 +342,7 @@ public class Mp3ParserTest extends TestCase {
 
        // Check we coud get the headers from the start
        assertEquals("audio/mpeg", metadata.get(Metadata.CONTENT_TYPE));
-       assertEquals("Girl you have no faith in medicine", metadata.get(Metadata.TITLE));
+       assertEquals("Girl you have no faith in medicine", metadata.get(TikaCoreProperties.TITLE));
        assertEquals("The White Stripes", metadata.get(Metadata.AUTHOR));
 
        String content = handler.toString();
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/mp4/MP4ParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/mp4/MP4ParserTest.java
index 8b19abc5d..396db5b02 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/mp4/MP4ParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/mp4/MP4ParserTest.java
@@ -22,6 +22,7 @@ import junit.framework.TestCase;
 
 import org.apache.tika.io.TikaInputStream;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.metadata.XMPDM;
 import org.apache.tika.parser.AutoDetectParser;
 import org.apache.tika.parser.ParseContext;
@@ -52,10 +53,10 @@ public class MP4ParserTest extends TestCase {
 
         // Check core properties
         assertEquals("audio/mp4", metadata.get(Metadata.CONTENT_TYPE));
-        assertEquals("Test Title", metadata.get(Metadata.TITLE));
+        assertEquals("Test Title", metadata.get(TikaCoreProperties.TITLE));
         assertEquals("Test Artist", metadata.get(Metadata.AUTHOR));
         assertEquals("2012-01-28T18:39:18Z", metadata.get(Metadata.CREATION_DATE));
-        assertEquals("2012-01-28T18:40:25Z", metadata.get(Metadata.MODIFIED));
+        assertEquals("2012-01-28T18:40:25Z", metadata.get(TikaCoreProperties.MODIFIED));
 
         // Check the textual contents
         String content = handler.toString();
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/netcdf/NetCDFParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/netcdf/NetCDFParserTest.java
index fc6f3d12c..bbef9862c 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/netcdf/NetCDFParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/netcdf/NetCDFParserTest.java
@@ -21,6 +21,7 @@ import java.io.InputStream;
 
 //TIKA imports
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.parser.Parser;
 import org.apache.tika.sax.BodyContentHandler;
@@ -52,7 +53,7 @@ public class NetCDFParserTest extends TestCase {
             stream.close();
         }
 
-        assertEquals(metadata.get(Metadata.TITLE),
+        assertEquals(metadata.get(TikaCoreProperties.TITLE),
                 "model output prepared for IPCC AR4");
         assertEquals(metadata.get(Metadata.CONTACT), "ccsm@ucar.edu");
         assertEquals(metadata.get(Metadata.PROJECT_ID),
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/odf/ODFParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/odf/ODFParserTest.java
index 45e89db85..9f4c17cbe 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/odf/ODFParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/odf/ODFParserTest.java
@@ -21,6 +21,7 @@ import java.io.InputStream;
 import org.apache.tika.TikaTest;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.Office;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.AutoDetectParser;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.parser.Parser;
@@ -77,14 +78,18 @@ public class ODFParserTest extends TikaTest {
              assertEquals(
                    "application/vnd.oasis.opendocument.text",
                    metadata.get(Metadata.CONTENT_TYPE));
-             assertEquals("2007-09-14T11:07:10", metadata.get(Metadata.DATE));
-             assertEquals("2007-09-14T11:06:08", metadata.get(Metadata.CREATION_DATE));
              assertEquals("en-US", metadata.get(Metadata.LANGUAGE));
              assertEquals("PT1M7S", metadata.get(Metadata.EDIT_TIME));
              assertEquals(
                    "NeoOffice/2.2$Unix OpenOffice.org_project/680m18$Build-9161",
                    metadata.get("generator"));
              
+             // Check date metadata, both old-style and new-style
+             assertEquals("2007-09-14T11:07:10", metadata.get(TikaCoreProperties.DATE));
+             assertEquals("2007-09-14T11:06:08", metadata.get(TikaCoreProperties.CREATION_DATE));
+             assertEquals("2007-09-14T11:07:10", metadata.get(Metadata.DATE));
+             assertEquals("2007-09-14T11:06:08", metadata.get(Metadata.CREATION_DATE));
+             
              // Check the document statistics
              assertEquals("1", metadata.get(Office.PAGE_COUNT));
              assertEquals("1", metadata.get(Office.PARAGRAPH_COUNT));
@@ -143,10 +148,10 @@ public class ODFParserTest extends TikaTest {
            assertEquals(
                    "application/vnd.oasis.opendocument.formula",
                    metadata.get(Metadata.CONTENT_TYPE));
-           assertEquals(null, metadata.get(Metadata.DATE));
+           assertEquals(null, metadata.get(TikaCoreProperties.DATE));
            assertEquals("2006-01-27T11:55:22", metadata.get(Metadata.CREATION_DATE));
-           assertEquals("The quick brown fox jumps over the lazy dog", metadata.get(Metadata.TITLE));
-           assertEquals("Gym class featuring a brown fox and lazy dog", metadata.get(Metadata.SUBJECT));
+           assertEquals("The quick brown fox jumps over the lazy dog", metadata.get(TikaCoreProperties.TITLE));
+           assertEquals("Gym class featuring a brown fox and lazy dog", metadata.get(TikaCoreProperties.SUBJECT));
            assertEquals("PT0S", metadata.get(Metadata.EDIT_TIME));
            assertEquals("1", metadata.get("editing-cycles"));
            assertEquals(
@@ -198,12 +203,12 @@ public class ODFParserTest extends TikaTest {
            assertEquals(
                    "application/vnd.oasis.opendocument.text",
                    metadata.get(Metadata.CONTENT_TYPE));
-           assertEquals("2009-10-05T21:22:38", metadata.get(Metadata.DATE));
+           assertEquals("2009-10-05T21:22:38", metadata.get(TikaCoreProperties.DATE));
            assertEquals("2009-10-05T19:04:01", metadata.get(Metadata.CREATION_DATE));
-           assertEquals("Apache Tika", metadata.get(Metadata.TITLE));
-           assertEquals("Test document", metadata.get(Metadata.SUBJECT));
-           assertEquals("A rather complex document", metadata.get(Metadata.DESCRIPTION));
-           assertEquals("Bart Hanssens", metadata.get(Metadata.CREATOR));
+           assertEquals("Apache Tika", metadata.get(TikaCoreProperties.TITLE));
+           assertEquals("Test document", metadata.get(TikaCoreProperties.SUBJECT));
+           assertEquals("A rather complex document", metadata.get(TikaCoreProperties.DESCRIPTION));
+           assertEquals("Bart Hanssens", metadata.get(TikaCoreProperties.CREATOR));
            assertEquals("Bart Hanssens", metadata.get("initial-creator"));
            assertEquals("2", metadata.get("editing-cycles"));
            assertEquals("PT02H03M24S", metadata.get(Metadata.EDIT_TIME));
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java
index 013b03371..17d8278c4 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java
@@ -26,6 +26,7 @@ import javax.xml.transform.stream.StreamResult;
 
 import org.apache.tika.TikaTest;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.AutoDetectParser;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.parser.Parser;
@@ -53,7 +54,7 @@ public class PDFParserTest extends TikaTest {
 
         assertEquals("application/pdf", metadata.get(Metadata.CONTENT_TYPE));
         assertEquals("Bertrand Delacr\u00e9taz", metadata.get(Metadata.AUTHOR));
-        assertEquals("Apache Tika - Apache Tika", metadata.get(Metadata.TITLE));
+        assertEquals("Apache Tika - Apache Tika", metadata.get(TikaCoreProperties.TITLE));
         
         // Can't reliably test dates yet - see TIKA-451 
 //        assertEquals("Sat Sep 15 10:02:31 BST 2007", metadata.get(Metadata.CREATION_DATE));
@@ -87,7 +88,7 @@ public class PDFParserTest extends TikaTest {
 
         assertEquals("application/pdf", metadata.get(Metadata.CONTENT_TYPE));
         assertEquals("Document author", metadata.get(Metadata.AUTHOR));
-        assertEquals("Document title", metadata.get(Metadata.TITLE));
+        assertEquals("Document title", metadata.get(TikaCoreProperties.TITLE));
         
         assertEquals("Custom Value", metadata.get("Custom Property"));
         assertEquals("Array Entry 1", metadata.get("Custom Array"));
@@ -120,8 +121,8 @@ public class PDFParserTest extends TikaTest {
 
        assertEquals("application/pdf", metadata.get(Metadata.CONTENT_TYPE));
        assertEquals("The Bank of England", metadata.get(Metadata.AUTHOR));
-       assertEquals("Speeches by Andrew G Haldane", metadata.get(Metadata.SUBJECT));
-       assertEquals("Rethinking the Financial Network, Speech by Andrew G Haldane, Executive Director, Financial Stability delivered at the Financial Student Association, Amsterdam on 28 April 2009", metadata.get(Metadata.TITLE));
+       assertEquals("Speeches by Andrew G Haldane", metadata.get(TikaCoreProperties.SUBJECT));
+       assertEquals("Rethinking the Financial Network, Speech by Andrew G Haldane, Executive Director, Financial Stability delivered at the Financial Student Association, Amsterdam on 28 April 2009", metadata.get(TikaCoreProperties.TITLE));
 
        String content = handler.toString();
        assertTrue(content.contains("RETHINKING THE FINANCIAL NETWORK"));
@@ -150,8 +151,8 @@ public class PDFParserTest extends TikaTest {
 
        assertEquals("application/pdf", metadata.get(Metadata.CONTENT_TYPE));
        assertEquals("The Bank of England", metadata.get(Metadata.AUTHOR));
-       assertEquals("Speeches by Andrew G Haldane", metadata.get(Metadata.SUBJECT));
-       assertEquals("Rethinking the Financial Network, Speech by Andrew G Haldane, Executive Director, Financial Stability delivered at the Financial Student Association, Amsterdam on 28 April 2009", metadata.get(Metadata.TITLE));
+       assertEquals("Speeches by Andrew G Haldane", metadata.get(TikaCoreProperties.SUBJECT));
+       assertEquals("Rethinking the Financial Network, Speech by Andrew G Haldane, Executive Director, Financial Stability delivered at the Financial Student Association, Amsterdam on 28 April 2009", metadata.get(TikaCoreProperties.TITLE));
 
        assertTrue(content.contains("RETHINKING THE FINANCIAL NETWORK"));
        assertTrue(content.contains("On 16 November 2002"));
@@ -233,7 +234,7 @@ public class PDFParserTest extends TikaTest {
 
         assertContains("Subject is here", content);
         assertEquals("Subject is here",
-                     metadata.get(Metadata.SUBJECT));
+                     metadata.get(TikaCoreProperties.SUBJECT));
 
         assertContains("Suddenly some Japanese text:", content);
         // Special version of (GHQ)
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/prt/PRTParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/prt/PRTParserTest.java
index 2a2ce2826..b8c4bdba9 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/prt/PRTParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/prt/PRTParserTest.java
@@ -20,6 +20,7 @@ import java.io.InputStream;
 
 import org.apache.tika.TikaTest;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.sax.BodyContentHandler;
 import org.xml.sax.ContentHandler;
 
@@ -38,11 +39,11 @@ public class PRTParserTest extends TikaTest {
 
           // This file has a date
           assertEquals("2011-06-20T16:54:00",
-                metadata.get(Metadata.DATE));
+                metadata.get(TikaCoreProperties.DATE));
           assertEquals("2011-06-20T16:54:00",
                 metadata.get(Metadata.CREATION_DATE));
           // But no description
-          assertEquals(null, metadata.get(Metadata.DESCRIPTION));
+          assertEquals(null, metadata.get(TikaCoreProperties.DESCRIPTION));
 
           String contents = handler.toString();
           
@@ -80,7 +81,7 @@ public class PRTParserTest extends TikaTest {
           assertEquals("1997-04-01T08:59:00",
                 metadata.get(Metadata.CREATION_DATE));
           assertEquals("TIKA TEST PART DESCRIPTION INFORMATION\r\n",
-                metadata.get(Metadata.DESCRIPTION));
+                metadata.get(TikaCoreProperties.DESCRIPTION));
 
           String contents = handler.toString();
           
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/rtf/RTFParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/rtf/RTFParserTest.java
index c1152f0ea..f1f6387e8 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/rtf/RTFParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/rtf/RTFParserTest.java
@@ -30,6 +30,7 @@ import org.apache.tika.Tika;
 import org.apache.tika.TikaTest;
 import org.apache.tika.io.TikaInputStream;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.sax.WriteOutContentHandler;
 
@@ -132,7 +133,7 @@ public class RTFParserTest extends TikaTest {
 
         // Verify title, since it was also encoded with MS932:
         Result r = getResult("testRTF-ms932.rtf");
-        assertEquals("\u30bf\u30a4\u30c8\u30eb", r.metadata.get(Metadata.TITLE));
+        assertEquals("\u30bf\u30a4\u30c8\u30eb", r.metadata.get(TikaCoreProperties.TITLE));
     }
 
     public void testUmlautSpacesExtraction() throws Exception {
@@ -153,7 +154,7 @@ public class RTFParserTest extends TikaTest {
         // Verify title -- this title uses upr escape inside
         // title info field:
         assertEquals("\u30be\u30eb\u30b2\u3068\u5c3e\u5d0e\u3001\u6de1\u3005\u3068\u6700\u671f\u3000",
-                     r.metadata.get(Metadata.TITLE));
+                     r.metadata.get(TikaCoreProperties.TITLE));
         assertEquals("VMazel", r.metadata.get(Metadata.AUTHOR));
         assertEquals("StarWriter", r.metadata.get(Metadata.COMMENT));
         assertContains("1.", content);
@@ -267,7 +268,7 @@ public class RTFParserTest extends TikaTest {
 
         assertContains("Subject is here", content);
         assertEquals("Subject is here",
-                     r.metadata.get(Metadata.SUBJECT));
+                     r.metadata.get(TikaCoreProperties.SUBJECT));
 
         assertContains("Suddenly some Japanese text:", content);
         // Special version of (GHQ)
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/txt/TXTParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/txt/TXTParserTest.java
index 8ab02a64c..b9e41d067 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/txt/TXTParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/txt/TXTParserTest.java
@@ -20,6 +20,7 @@ import java.io.ByteArrayInputStream;
 import java.io.StringWriter;
 
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.parser.Parser;
 import org.apache.tika.sax.BodyContentHandler;
@@ -51,7 +52,7 @@ public class TXTParserTest extends TestCase {
         
         // TIKA-501: Remove language detection from TXTParser
         assertNull(metadata.get(Metadata.CONTENT_LANGUAGE));
-        assertNull(metadata.get(Metadata.LANGUAGE));
+        assertNull(metadata.get(TikaCoreProperties.LANGUAGE));
 
         assertTrue(content.contains("Hello"));
         assertTrue(content.contains("World"));
@@ -169,13 +170,13 @@ public class TXTParserTest extends TestCase {
         final String test = "Simple Content";
 
         Metadata metadata = new Metadata();
-        metadata.set(Metadata.LANGUAGE, "en");
+        metadata.set(TikaCoreProperties.LANGUAGE, "en");
 
         parser.parse(
                 new ByteArrayInputStream(test.getBytes("UTF-8")),
                 new BodyContentHandler(),  metadata, new ParseContext());
 
-        assertEquals("en", metadata.get(Metadata.LANGUAGE));
+        assertEquals("en", metadata.get(TikaCoreProperties.LANGUAGE));
     }
 
     public void testCP866() throws Exception {
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/xml/DcXMLParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/xml/DcXMLParserTest.java
index ccd0c2d61..44160ffd1 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/xml/DcXMLParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/xml/DcXMLParserTest.java
@@ -21,6 +21,7 @@ import java.io.InputStream;
 import junit.framework.TestCase;
 
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.sax.BodyContentHandler;
 import org.xml.sax.ContentHandler;
 import org.xml.sax.helpers.DefaultHandler;
@@ -38,34 +39,34 @@ public class DcXMLParserTest extends TestCase {
             assertEquals(
                     "application/xml",
                     metadata.get(Metadata.CONTENT_TYPE));
-            assertEquals("Tika test document", metadata.get(Metadata.TITLE));
-            assertEquals("Rida Benjelloun", metadata.get(Metadata.CREATOR));
+            assertEquals("Tika test document", metadata.get(TikaCoreProperties.TITLE));
+            assertEquals("Rida Benjelloun", metadata.get(TikaCoreProperties.CREATOR));
             
             // The file contains 5 dc:subject tags, which come through as
             //  a multi-valued Tika Metadata entry in file order
-            assertEquals(true, metadata.isMultiValued(Metadata.SUBJECT));
-            assertEquals(5,      metadata.getValues(Metadata.SUBJECT).length);
-            assertEquals("Java", metadata.getValues(Metadata.SUBJECT)[0]);
-            assertEquals("XML",  metadata.getValues(Metadata.SUBJECT)[1]);
-            assertEquals("XSLT", metadata.getValues(Metadata.SUBJECT)[2]);
-            assertEquals("JDOM", metadata.getValues(Metadata.SUBJECT)[3]);
-            assertEquals("Indexation", metadata.getValues(Metadata.SUBJECT)[4]);
+            assertEquals(true, metadata.isMultiValued(TikaCoreProperties.SUBJECT));
+            assertEquals(5,      metadata.getValues(TikaCoreProperties.SUBJECT).length);
+            assertEquals("Java", metadata.getValues(TikaCoreProperties.SUBJECT)[0]);
+            assertEquals("XML",  metadata.getValues(TikaCoreProperties.SUBJECT)[1]);
+            assertEquals("XSLT", metadata.getValues(TikaCoreProperties.SUBJECT)[2]);
+            assertEquals("JDOM", metadata.getValues(TikaCoreProperties.SUBJECT)[3]);
+            assertEquals("Indexation", metadata.getValues(TikaCoreProperties.SUBJECT)[4]);
 
             assertEquals(
                     "Framework d\'indexation des documents XML, HTML, PDF etc..",
-                    metadata.get(Metadata.DESCRIPTION));
+                    metadata.get(TikaCoreProperties.DESCRIPTION));
             assertEquals(
                     "http://www.apache.org",
-                    metadata.get(Metadata.IDENTIFIER));
-            assertEquals("test", metadata.get(Metadata.TYPE));
-            assertEquals("application/msword", metadata.get(Metadata.FORMAT));
-            assertEquals("Fr", metadata.get(Metadata.LANGUAGE));
-            assertTrue(metadata.get(Metadata.RIGHTS).contains("testing chars"));
+                    metadata.get(TikaCoreProperties.IDENTIFIER));
+            assertEquals("test", metadata.get(TikaCoreProperties.TYPE));
+            assertEquals("application/msword", metadata.get(TikaCoreProperties.FORMAT));
+            assertEquals("Fr", metadata.get(TikaCoreProperties.LANGUAGE));
+            assertTrue(metadata.get(TikaCoreProperties.RIGHTS).contains("testing chars"));
 
             String content = handler.toString();
             assertTrue(content.contains("Tika test document"));
             
-            assertEquals("2000-12-01T00:00:00.000Z", metadata.get(Metadata.DATE));
+            assertEquals("2000-12-01T00:00:00.000Z", metadata.get(TikaCoreProperties.DATE));
         } finally {
             input.close();
         }
@@ -78,7 +79,7 @@ public class DcXMLParserTest extends TestCase {
             new DcXMLParser().parse(input, new DefaultHandler(), metadata);
             
             final String expected = "Archim\u00E8de et Lius \u00E0 Ch\u00E2teauneuf testing chars en \u00E9t\u00E9";
-            assertEquals(expected,metadata.get(Metadata.RIGHTS));
+            assertEquals(expected,metadata.get(TikaCoreProperties.RIGHTS));
         } finally {
             input.close();
         }

Commit:
e269e9cd05f9a111e4d78bedef624939894acb29
Nick Burch
nick@apache.org
2012-05-17 19:49:03 +0000
TIKA-928 Fix up the DWG parser and tests to use the new style properties
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/dwg/DWGParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/dwg/DWGParser.java
index 1cc97b6f8..32fd12d71 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/dwg/DWGParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/dwg/DWGParser.java
@@ -26,6 +26,8 @@ import org.apache.poi.util.StringUtil;
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.io.EndianUtils;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.Property;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.parser.AbstractParser;
 import org.apache.tika.parser.ParseContext;
@@ -51,28 +53,28 @@ public class DWGParser extends AbstractParser {
     }
 
     /** The order of the fields in the header */
-    private static final String[] HEADER_PROPERTIES_ENTRIES = {
-        Metadata.TITLE, 
-        Metadata.SUBJECT,
-        Metadata.AUTHOR,
-        Metadata.KEYWORDS,
-        Metadata.COMMENTS,
-        Metadata.LAST_AUTHOR,
+    private static final Property[] HEADER_PROPERTIES_ENTRIES = {
+        TikaCoreProperties.TITLE, 
+        TikaCoreProperties.SUBJECT,
+        Property.internalText(Metadata.AUTHOR),
+        TikaCoreProperties.KEYWORDS,
+        Property.internalText(Metadata.COMMENTS),
+        TikaCoreProperties.LAST_AUTHOR,
         null, // Unknown?
-        Metadata.RELATION, // Hyperlink
+        TikaCoreProperties.RELATION, // Hyperlink
     };
 
     /** For the 2000 file, they're indexed */
-    private static final String[] HEADER_2000_PROPERTIES_ENTRIES = {
+    private static final Property[] HEADER_2000_PROPERTIES_ENTRIES = {
        null, 
-       Metadata.RELATION, // 0x01
-       Metadata.TITLE,    // 0x02
-       Metadata.SUBJECT,  // 0x03
-       Metadata.AUTHOR,   // 0x04
+       TikaCoreProperties.RELATION, // 0x01
+       TikaCoreProperties.TITLE,    // 0x02
+       TikaCoreProperties.SUBJECT,  // 0x03
+       Property.internalText(Metadata.AUTHOR),  // 0x04
        null,
-       Metadata.COMMENTS, // 0x06 
-       Metadata.KEYWORDS, // 0x07
-       Metadata.LAST_AUTHOR, // 0x08
+       Property.internalText(Metadata.COMMENTS),// 0x06 
+       TikaCoreProperties.KEYWORDS,    // 0x07
+       TikaCoreProperties.LAST_AUTHOR, // 0x08
    };
 
     private static final String HEADER_2000_PROPERTIES_MARKER_STR =
@@ -253,7 +255,7 @@ public class DWGParser extends AbstractParser {
             return;
         }
 
-        String headerProp = HEADER_PROPERTIES_ENTRIES[headerNumber];
+        Property headerProp = HEADER_PROPERTIES_ENTRIES[headerNumber];
         if(headerProp != null) {
             metadata.set(headerProp, value);
         }
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/dwg/DWGParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/dwg/DWGParserTest.java
index 28d3ca65e..ca2735ba0 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/dwg/DWGParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/dwg/DWGParserTest.java
@@ -21,6 +21,7 @@ import java.io.InputStream;
 import junit.framework.TestCase;
 
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.sax.BodyContentHandler;
 import org.xml.sax.ContentHandler;
 
@@ -76,9 +77,9 @@ public class DWGParserTest extends TestCase {
             assertEquals("image/vnd.dwg", metadata.get(Metadata.CONTENT_TYPE));
 
             assertEquals("The quick brown fox jumps over the lazy dog", 
-                    metadata.get(Metadata.TITLE));
+                    metadata.get(TikaCoreProperties.TITLE));
             assertEquals("Gym class featuring a brown fox and lazy dog",
-                    metadata.get(Metadata.SUBJECT));
+                    metadata.get(TikaCoreProperties.SUBJECT));
             assertEquals("Nevin Nollop",
                     metadata.get(Metadata.AUTHOR));
             assertEquals("Pangram, fox, dog",
@@ -86,7 +87,13 @@ public class DWGParserTest extends TestCase {
             assertEquals("Lorem ipsum",
                     metadata.get(Metadata.COMMENTS).substring(0,11));
             assertEquals("http://www.alfresco.com",
-                    metadata.get(Metadata.RELATION));
+                    metadata.get(TikaCoreProperties.RELATION));
+            
+            // Check some of the old style metadata too
+            assertEquals("The quick brown fox jumps over the lazy dog", 
+                  metadata.get(Metadata.TITLE));
+            assertEquals("Gym class featuring a brown fox and lazy dog",
+                  metadata.get(Metadata.SUBJECT));
 
             String content = handler.toString();
             assertTrue(content.contains("The quick brown fox jumps over the lazy dog"));
@@ -105,12 +112,12 @@ public class DWGParserTest extends TestCase {
 
             assertEquals("image/vnd.dwg", metadata.get(Metadata.CONTENT_TYPE));
             
-            assertNull(metadata.get(Metadata.TITLE));
-            assertNull(metadata.get(Metadata.SUBJECT));
+            assertNull(metadata.get(TikaCoreProperties.TITLE));
+            assertNull(metadata.get(TikaCoreProperties.SUBJECT));
             assertNull(metadata.get(Metadata.AUTHOR));
             assertNull(metadata.get(Metadata.KEYWORDS));
             assertNull(metadata.get(Metadata.COMMENTS));
-            assertNull(metadata.get(Metadata.RELATION));
+            assertNull(metadata.get(TikaCoreProperties.RELATION));
 
             String content = handler.toString();
             assertTrue(content.contains(""));
@@ -128,9 +135,9 @@ public class DWGParserTest extends TestCase {
             assertEquals("image/vnd.dwg", metadata.get(Metadata.CONTENT_TYPE));
 
             assertEquals("Test Title", 
-                    metadata.get(Metadata.TITLE));
+                    metadata.get(TikaCoreProperties.TITLE));
             assertEquals("Test Subject",
-                    metadata.get(Metadata.SUBJECT));
+                    metadata.get(TikaCoreProperties.SUBJECT));
             assertEquals("My Author",
                     metadata.get(Metadata.AUTHOR));
             assertEquals("My keyword1, MyKeyword2",
@@ -140,7 +147,7 @@ public class DWGParserTest extends TestCase {
             assertEquals("bejanpol",
                     metadata.get(Metadata.LAST_AUTHOR));
             assertEquals("http://mycompany/drawings",
-                    metadata.get(Metadata.RELATION));
+                    metadata.get(TikaCoreProperties.RELATION));
             assertEquals("MyCustomPropertyValue",
                   metadata.get("MyCustomProperty"));
 

Commit:
70c85b4ab78486b2e2781fe6bd196a053e48149e
Nick Burch
nick@apache.org
2012-05-17 19:36:58 +0000
Fix setter to be by property not name for add(Property)
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java b/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
index d321e62f6..2735fafad 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
@@ -350,7 +350,7 @@ public class Metadata implements CreativeCommons, Geographic, HttpHeaders,
     public void add(final Property property, final String value) {
         String[] values = metadata.get(property.getName());
         if (values == null) {
-            set(property.getName(), value);
+            set(property, value);
         } else {
              if (property.isMultiValuePermitted()) {
                  set(property, appendedValues(values, value));

Commit:
34dff7b56672b54b19de4ea6e28ad3f95db6d034
Nick Burch
nick@apache.org
2012-05-17 19:22:04 +0000
Make the composite test more explicit in what it does, fix up some deprecated warnings, and fix the typed getters for composites
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java b/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
index 17f982789..d321e62f6 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
@@ -242,10 +242,10 @@ public class Metadata implements CreativeCommons, Geographic, HttpHeaders,
      * @return property value as a Integer, or <code>null</code> if the property is not set, or not a valid Integer
      */
     public Integer getInt(Property property) {
-        if(property.getPropertyType() != Property.PropertyType.SIMPLE) {
+        if(property.getPrimaryProperty().getPropertyType() != Property.PropertyType.SIMPLE) {
             return null;
         }
-        if(property.getValueType() != Property.ValueType.INTEGER) {
+        if(property.getPrimaryProperty().getValueType() != Property.ValueType.INTEGER) {
             return null;
         }
         
@@ -268,10 +268,10 @@ public class Metadata implements CreativeCommons, Geographic, HttpHeaders,
      * @return property value as a Date, or <code>null</code> if the property is not set, or not a valid Date
      */
     public Date getDate(Property property) {
-        if(property.getPropertyType() != Property.PropertyType.SIMPLE) {
+        if(property.getPrimaryProperty().getPropertyType() != Property.PropertyType.SIMPLE) {
             return null;
         }
-        if(property.getValueType() != Property.ValueType.DATE) {
+        if(property.getPrimaryProperty().getValueType() != Property.ValueType.DATE) {
             return null;
         }
         
diff --git a/tika-core/src/test/java/org/apache/tika/metadata/TestMetadata.java b/tika-core/src/test/java/org/apache/tika/metadata/TestMetadata.java
index 354576848..253380de6 100644
--- a/tika-core/src/test/java/org/apache/tika/metadata/TestMetadata.java
+++ b/tika-core/src/test/java/org/apache/tika/metadata/TestMetadata.java
@@ -234,7 +234,7 @@ public class TestMetadata extends TestCase {
             fail("Shouldn't be able to set a multi valued property as an int");
         } catch(PropertyTypeException e) {}
         try {
-            meta.set(Metadata.CREATION_DATE, 1);
+            meta.set(TikaCoreProperties.CREATION_DATE, 1);
             fail("Shouldn't be able to set a date property as an int");
         } catch(PropertyTypeException e) {}
         
@@ -252,7 +252,7 @@ public class TestMetadata extends TestCase {
         meta.set(Metadata.IMAGE_WIDTH, 22);
         assertEquals(22, meta.getInt(Metadata.IMAGE_WIDTH).intValue());
         assertEquals(null, meta.getInt(Metadata.BITS_PER_SAMPLE));
-        assertEquals(null, meta.getInt(Metadata.CREATION_DATE));
+        assertEquals(null, meta.getInt(TikaCoreProperties.CREATION_DATE));
     }
     
     /**
@@ -264,8 +264,8 @@ public class TestMetadata extends TestCase {
         long hour = 60 * 60 * 1000; 
         
         // Isn't initially set, will get null back
-        assertEquals(null, meta.get(Metadata.CREATION_DATE));
-        assertEquals(null, meta.getInt(Metadata.CREATION_DATE));
+        assertEquals(null, meta.get(TikaCoreProperties.CREATION_DATE));
+        assertEquals(null, meta.getInt(TikaCoreProperties.CREATION_DATE));
         
         // Can only set as a single valued date
         try {
@@ -278,52 +278,52 @@ public class TestMetadata extends TestCase {
         } catch(PropertyTypeException e) {}
         
         // Can set it and retrieve it
-        meta.set(Metadata.CREATION_DATE, new Date(1000));
-        assertEquals("1970-01-01T00:00:01Z", meta.get(Metadata.CREATION_DATE));
-        assertEquals(1000, meta.getDate(Metadata.CREATION_DATE).getTime());
+        meta.set(TikaCoreProperties.CREATION_DATE, new Date(1000));
+        assertEquals("1970-01-01T00:00:01Z", meta.get(TikaCoreProperties.CREATION_DATE));
+        assertEquals(1000, meta.getDate(TikaCoreProperties.CREATION_DATE).getTime());
         
         // If you save a non date value, you get null
-        meta.set(Metadata.CREATION_DATE, "INVALID");
-        assertEquals("INVALID", meta.get(Metadata.CREATION_DATE));
-        assertEquals(null, meta.getDate(Metadata.CREATION_DATE));
+        meta.set(TikaCoreProperties.CREATION_DATE, "INVALID");
+        assertEquals("INVALID", meta.get(TikaCoreProperties.CREATION_DATE));
+        assertEquals(null, meta.getDate(TikaCoreProperties.CREATION_DATE));
         
         // If you try to retrieve a non simple date value, you get null
-        meta.set(Metadata.CREATION_DATE, new Date(1000));
-        assertEquals(1000, meta.getDate(Metadata.CREATION_DATE).getTime());
+        meta.set(TikaCoreProperties.CREATION_DATE, new Date(1000));
+        assertEquals(1000, meta.getDate(TikaCoreProperties.CREATION_DATE).getTime());
         assertEquals(null, meta.getInt(Metadata.BITS_PER_SAMPLE));
-        assertEquals(null, meta.getInt(Metadata.CREATION_DATE));
+        assertEquals(null, meta.getInt(TikaCoreProperties.CREATION_DATE));
         
         // Our format doesn't include milliseconds
         // This means things get rounded 
-        meta.set(Metadata.CREATION_DATE, new Date(1050));
-        assertEquals("1970-01-01T00:00:01Z", meta.get(Metadata.CREATION_DATE));
-        assertEquals(1000, meta.getDate(Metadata.CREATION_DATE).getTime());
+        meta.set(TikaCoreProperties.CREATION_DATE, new Date(1050));
+        assertEquals("1970-01-01T00:00:01Z", meta.get(TikaCoreProperties.CREATION_DATE));
+        assertEquals(1000, meta.getDate(TikaCoreProperties.CREATION_DATE).getTime());
         
         // We can accept a number of different ISO-8601 variants
-        meta.set(Metadata.CREATION_DATE, "1970-01-01T00:00:01Z");
-        assertEquals(1000, meta.getDate(Metadata.CREATION_DATE).getTime());
+        meta.set(TikaCoreProperties.CREATION_DATE, "1970-01-01T00:00:01Z");
+        assertEquals(1000, meta.getDate(TikaCoreProperties.CREATION_DATE).getTime());
         
-        meta.set(Metadata.CREATION_DATE, "1970-01-01 00:00:01Z");
-        assertEquals(1000, meta.getDate(Metadata.CREATION_DATE).getTime());
+        meta.set(TikaCoreProperties.CREATION_DATE, "1970-01-01 00:00:01Z");
+        assertEquals(1000, meta.getDate(TikaCoreProperties.CREATION_DATE).getTime());
         
-        meta.set(Metadata.CREATION_DATE, "1970-01-01T01:00:01+01:00");
-        assertEquals(1000, meta.getDate(Metadata.CREATION_DATE).getTime());
+        meta.set(TikaCoreProperties.CREATION_DATE, "1970-01-01T01:00:01+01:00");
+        assertEquals(1000, meta.getDate(TikaCoreProperties.CREATION_DATE).getTime());
         
-        meta.set(Metadata.CREATION_DATE, "1970-01-01 01:00:01+01:00");
-        assertEquals(1000, meta.getDate(Metadata.CREATION_DATE).getTime());
+        meta.set(TikaCoreProperties.CREATION_DATE, "1970-01-01 01:00:01+01:00");
+        assertEquals(1000, meta.getDate(TikaCoreProperties.CREATION_DATE).getTime());
         
-        meta.set(Metadata.CREATION_DATE, "1970-01-01T12:00:01+12:00");
-        assertEquals(1000, meta.getDate(Metadata.CREATION_DATE).getTime());
+        meta.set(TikaCoreProperties.CREATION_DATE, "1970-01-01T12:00:01+12:00");
+        assertEquals(1000, meta.getDate(TikaCoreProperties.CREATION_DATE).getTime());
         
-        meta.set(Metadata.CREATION_DATE, "1969-12-31T12:00:01-12:00");
-        assertEquals(1000, meta.getDate(Metadata.CREATION_DATE).getTime());
+        meta.set(TikaCoreProperties.CREATION_DATE, "1969-12-31T12:00:01-12:00");
+        assertEquals(1000, meta.getDate(TikaCoreProperties.CREATION_DATE).getTime());
         
         // Dates without times, come in at midday UTC
-        meta.set(Metadata.CREATION_DATE, "1970-01-01");
-        assertEquals(12*hour, meta.getDate(Metadata.CREATION_DATE).getTime());
+        meta.set(TikaCoreProperties.CREATION_DATE, "1970-01-01");
+        assertEquals(12*hour, meta.getDate(TikaCoreProperties.CREATION_DATE).getTime());
         
-        meta.set(Metadata.CREATION_DATE, "1970:01:01");
-        assertEquals(12*hour, meta.getDate(Metadata.CREATION_DATE).getTime());
+        meta.set(TikaCoreProperties.CREATION_DATE, "1970:01:01");
+        assertEquals(12*hour, meta.getDate(TikaCoreProperties.CREATION_DATE).getTime());
     }
     
     /**
@@ -338,14 +338,27 @@ public class TestMetadata extends TestCase {
         		"1970-01-01T00:00:01", meta.get(TikaCoreProperties.DATE));
     }
     
+    /**
+     * Defines a composite property, then checks that when set as the
+     *  composite the value can be retrieved with the property or the aliases
+     */
+    @SuppressWarnings("deprecation")
     public void testCompositeProperty() {
-    	Metadata meta = new Metadata();
-    	Property compositeProperty = Property.composite(
-            DublinCore.DESCRIPTION, new Property[] { Property.internalText(Metadata.DESCRIPTION)});
-    	String message = "composite description";
-    	meta.set(compositeProperty, message);
-    	assertEquals(message, meta.get(DublinCore.DESCRIPTION));
-    	assertEquals(message, meta.get(Metadata.DESCRIPTION));
-    }
-    
+       Metadata meta = new Metadata();
+       Property compositeProperty = Property.composite(
+             DublinCore.DESCRIPTION, new Property[] { 
+                   Property.internalText(Metadata.DESCRIPTION),
+                   Property.internalText("testDescriptionAlt")
+             });
+       String message = "composite description";
+       meta.set(compositeProperty, message);
+
+       // Fetch as the composite
+       assertEquals(message, meta.get(compositeProperty));
+       // Fetch as the primary property on the composite
+       assertEquals(message, meta.get(DublinCore.DESCRIPTION));
+       // Fetch as the aliases
+       assertEquals(message, meta.get(Metadata.DESCRIPTION));
+       assertEquals(message, meta.get("testDescriptionAlt"));
+    }    
 }

Commit:
9b94789f2e9d759d4f6523b3cccd8370831e2469
Nick Burch
nick@apache.org
2012-05-17 19:09:48 +0000
TIKA-928 Patch from Ray Gauss to improve metadata properties setting/getting
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java b/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
index 0f870f679..17f982789 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
@@ -37,7 +37,7 @@ import org.apache.tika.metadata.Property.PropertyType;
  * A multi-valued metadata container.
  */
 public class Metadata implements CreativeCommons, Geographic, HttpHeaders,
-        IPTC, Message, MSOffice, ClimateForcast, TIFF, TikaMetadataKeys, TikaMimeKeys,
+        Message, MSOffice, ClimateForcast, TIFF, TikaMetadataKeys, TikaMimeKeys,
         Serializable {
 
     /** Serial version UID */
@@ -175,6 +175,17 @@ public class Metadata implements CreativeCommons, Geographic, HttpHeaders,
         metadata = new HashMap<String, String[]>();
     }
 
+    /**
+     * Returns true if named value is multivalued.
+     * 
+     * @param property
+     *          metadata property
+     * @return true is named value is multivalued, false if single value or null
+     */
+    public boolean isMultiValued(final Property property) {
+        return metadata.get(property.getName()) != null && metadata.get(property.getName()).length > 1;
+    }
+    
     /**
      * Returns true if named value is multivalued.
      * 
@@ -271,6 +282,17 @@ public class Metadata implements CreativeCommons, Geographic, HttpHeaders,
             return null;
         }
     }
+    
+    /**
+     * Get the values associated to a metadata name.
+     * 
+     * @param property
+     *          of the metadata.
+     * @return the values associated to a metadata name.
+     */
+    public String[] getValues(final Property property) {
+        return _getValues(property.getName());
+    }
 
     /**
      * Get the values associated to a metadata name.
@@ -422,11 +444,11 @@ public class Metadata implements CreativeCommons, Geographic, HttpHeaders,
      * @param value    property value
      */
     public void set(Property property, int value) {
-        if(property.getPropertyType() != Property.PropertyType.SIMPLE) {
-            throw new PropertyTypeException(Property.PropertyType.SIMPLE, property.getPropertyType());
+        if(property.getPrimaryProperty().getPropertyType() != Property.PropertyType.SIMPLE) {
+            throw new PropertyTypeException(Property.PropertyType.SIMPLE, property.getPrimaryProperty().getPropertyType());
         }
-        if(property.getValueType() != Property.ValueType.INTEGER) {
-            throw new PropertyTypeException(Property.ValueType.INTEGER, property.getValueType());
+        if(property.getPrimaryProperty().getValueType() != Property.ValueType.INTEGER) {
+            throw new PropertyTypeException(Property.ValueType.INTEGER, property.getPrimaryProperty().getValueType());
         }
         set(property, Integer.toString(value));
     }
@@ -439,12 +461,12 @@ public class Metadata implements CreativeCommons, Geographic, HttpHeaders,
      * @param value    property value
      */
     public void set(Property property, double value) {
-        if(property.getPropertyType() != Property.PropertyType.SIMPLE) {
-            throw new PropertyTypeException(Property.PropertyType.SIMPLE, property.getPropertyType());
+        if(property.getPrimaryProperty().getPropertyType() != Property.PropertyType.SIMPLE) {
+            throw new PropertyTypeException(Property.PropertyType.SIMPLE, property.getPrimaryProperty().getPropertyType());
         }
-        if(property.getValueType() != Property.ValueType.REAL &&
-              property.getValueType() != Property.ValueType.RATIONAL) {
-            throw new PropertyTypeException(Property.ValueType.REAL, property.getValueType());
+        if(property.getPrimaryProperty().getValueType() != Property.ValueType.REAL &&
+              property.getPrimaryProperty().getValueType() != Property.ValueType.RATIONAL) {
+            throw new PropertyTypeException(Property.ValueType.REAL, property.getPrimaryProperty().getValueType());
         }
         set(property, Double.toString(value));
     }
@@ -457,11 +479,11 @@ public class Metadata implements CreativeCommons, Geographic, HttpHeaders,
      * @param date     property value
      */
     public void set(Property property, Date date) {
-        if(property.getPropertyType() != Property.PropertyType.SIMPLE) {
-            throw new PropertyTypeException(Property.PropertyType.SIMPLE, property.getPropertyType());
+        if(property.getPrimaryProperty().getPropertyType() != Property.PropertyType.SIMPLE) {
+            throw new PropertyTypeException(Property.PropertyType.SIMPLE, property.getPrimaryProperty().getPropertyType());
         }
-        if(property.getValueType() != Property.ValueType.DATE) {
-            throw new PropertyTypeException(Property.ValueType.DATE, property.getValueType());
+        if(property.getPrimaryProperty().getValueType() != Property.ValueType.DATE) {
+            throw new PropertyTypeException(Property.ValueType.DATE, property.getPrimaryProperty().getValueType());
         }
         set(property, formatDate(date));
     }
diff --git a/tika-core/src/main/java/org/apache/tika/sax/XHTMLContentHandler.java b/tika-core/src/main/java/org/apache/tika/sax/XHTMLContentHandler.java
index fd2b30155..0cac39894 100644
--- a/tika-core/src/main/java/org/apache/tika/sax/XHTMLContentHandler.java
+++ b/tika-core/src/main/java/org/apache/tika/sax/XHTMLContentHandler.java
@@ -22,6 +22,7 @@ import java.util.HashSet;
 import java.util.Set;
 
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.xml.sax.Attributes;
 import org.xml.sax.ContentHandler;
 import org.xml.sax.SAXException;
@@ -173,7 +174,7 @@ public class XHTMLContentHandler extends SafeContentHandler {
             }
             
             super.startElement(XHTML, "title", "title", EMPTY_ATTRIBUTES);
-            String title = metadata.get(Metadata.TITLE);
+            String title = metadata.get(TikaCoreProperties.TITLE);
             if (title != null && title.length() > 0) {
                 char[] titleChars = title.toCharArray();
                 super.characters(titleChars, 0, titleChars.length);
diff --git a/tika-core/src/test/java/org/apache/tika/metadata/TestMetadata.java b/tika-core/src/test/java/org/apache/tika/metadata/TestMetadata.java
index 0acec2726..354576848 100644
--- a/tika-core/src/test/java/org/apache/tika/metadata/TestMetadata.java
+++ b/tika-core/src/test/java/org/apache/tika/metadata/TestMetadata.java
@@ -333,9 +333,9 @@ public class TestMetadata extends TestCase {
     public void testGetSetDateUnspecifiedTimezone() {
         Metadata meta = new Metadata();    
         
-        meta.set(Metadata.DATE, "1970-01-01T00:00:01");
+        meta.set(TikaCoreProperties.DATE, "1970-01-01T00:00:01");
         assertEquals("should return string without time zone specifier because zone is not known",
-        		"1970-01-01T00:00:01", meta.get(Metadata.DATE));
+        		"1970-01-01T00:00:01", meta.get(TikaCoreProperties.DATE));
     }
     
     public void testCompositeProperty() {

Commit:
e2c5e08c3228ce6584467ef272a0f95d8d47a0a5
Nick Burch
nick@apache.org
2012-05-17 17:30:32 +0000
TIKA-929 Use the prefered constant rather than the IPTC imported one
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/Office.java b/tika-core/src/main/java/org/apache/tika/metadata/Office.java
index 4531b8ba2..6fc992fac 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/Office.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/Office.java
@@ -44,75 +44,75 @@ public interface Office {
     * Keywords pertaining to a document. 
     */
    Property KEYWORDS = Property.internalTextBag(
-         PREFIX_DOC_META + Metadata.PREFIX_DELIMITER + "keyword");
+         PREFIX_DOC_META + Metadata.NAMESPACE_PREFIX_DELIMITER + "keyword");
 
    /**
     * Name of the initial creator/author of a document
     */
    Property INITIAL_AUTHOR = Property.internalText(
-         PREFIX_DOC_META + Metadata.PREFIX_DELIMITER + "initial-author");
+         PREFIX_DOC_META + Metadata.NAMESPACE_PREFIX_DELIMITER + "initial-author");
 
    /**
     * Name of the last (most recent) author of a document
     */
    Property LAST_AUTHOR = Property.internalText(
-         PREFIX_DOC_META + Metadata.PREFIX_DELIMITER + "last-author");
+         PREFIX_DOC_META + Metadata.NAMESPACE_PREFIX_DELIMITER + "last-author");
 
    
    /** When was the document created? */
    Property CREATION_DATE = Property.internalDate(
-         PREFIX_DOC_META + Metadata.PREFIX_DELIMITER + "creation-date");
+         PREFIX_DOC_META + Metadata.NAMESPACE_PREFIX_DELIMITER + "creation-date");
 
    /** When was the document last saved? */
    Property SAVE_DATE = Property.internalDate(
-         PREFIX_DOC_META + Metadata.PREFIX_DELIMITER + "save-date");
+         PREFIX_DOC_META + Metadata.NAMESPACE_PREFIX_DELIMITER + "save-date");
    
    /** When was the document last printed? */
    Property PRINT_DATE = Property.internalDate(
-         PREFIX_DOC_META + Metadata.PREFIX_DELIMITER + "print-date");
+         PREFIX_DOC_META + Metadata.NAMESPACE_PREFIX_DELIMITER + "print-date");
 
 
     
     /** The number of Slides are there in the (presentation) document */
     Property SLIDE_COUNT = Property.internalInteger(
-          PREFIX_DOC_META_STATS + Metadata.PREFIX_DELIMITER + "slide-count");
+          PREFIX_DOC_META_STATS + Metadata.NAMESPACE_PREFIX_DELIMITER + "slide-count");
     
     /** The number of Pages are there in the (paged) document */
     Property PAGE_COUNT = Property.internalInteger(
-          PREFIX_DOC_META_STATS + Metadata.PREFIX_DELIMITER + "page-count");
+          PREFIX_DOC_META_STATS + Metadata.NAMESPACE_PREFIX_DELIMITER + "page-count");
 
     /** The number of individual Paragraphs in the document */ 
     Property PARAGRAPH_COUNT = Property.internalInteger(
-          PREFIX_DOC_META_STATS + Metadata.PREFIX_DELIMITER + "paragraph-count");
+          PREFIX_DOC_META_STATS + Metadata.NAMESPACE_PREFIX_DELIMITER + "paragraph-count");
     
     /** The number of lines in the document */
     Property LINE_COUNT = Property.internalInteger(
-          PREFIX_DOC_META_STATS + Metadata.PREFIX_DELIMITER + "line-count");
+          PREFIX_DOC_META_STATS + Metadata.NAMESPACE_PREFIX_DELIMITER + "line-count");
 
     /** The number of Words in the document */
     Property WORD_COUNT = Property.internalInteger(
-          PREFIX_DOC_META_STATS + Metadata.PREFIX_DELIMITER + "word-count");
+          PREFIX_DOC_META_STATS + Metadata.NAMESPACE_PREFIX_DELIMITER + "word-count");
 
     /** The number of Characters in the document */
     Property CHARACTER_COUNT = Property.internalInteger(
-          PREFIX_DOC_META_STATS + Metadata.PREFIX_DELIMITER + "character-count");
+          PREFIX_DOC_META_STATS + Metadata.NAMESPACE_PREFIX_DELIMITER + "character-count");
     
     /** The number of Characters in the document, including spaces */
     Property CHARACTER_COUNT_WITH_SPACES = Property.internalInteger(
-          PREFIX_DOC_META_STATS + Metadata.PREFIX_DELIMITER + "character-count-with-spaces");
+          PREFIX_DOC_META_STATS + Metadata.NAMESPACE_PREFIX_DELIMITER + "character-count-with-spaces");
 
     /** The number of Tables in the document */
     Property TABLE_COUNT = Property.internalInteger(
-          PREFIX_DOC_META_STATS + Metadata.PREFIX_DELIMITER + "table-count");
+          PREFIX_DOC_META_STATS + Metadata.NAMESPACE_PREFIX_DELIMITER + "table-count");
     
     /** The number of Images in the document */
     Property IMAGE_COUNT = Property.internalInteger(
-          PREFIX_DOC_META_STATS + Metadata.PREFIX_DELIMITER + "image-count");
+          PREFIX_DOC_META_STATS + Metadata.NAMESPACE_PREFIX_DELIMITER + "image-count");
     
     /** 
      * The number of Objects in the document. These are typically non-Image resources 
      * embedded in the document, such as other documents or non-Image media. 
      */
     Property OBJECT_COUNT = Property.internalInteger(
-          PREFIX_DOC_META_STATS + Metadata.PREFIX_DELIMITER + "object-count");
+          PREFIX_DOC_META_STATS + Metadata.NAMESPACE_PREFIX_DELIMITER + "object-count");
 }

Commit:
d22c2ea763889d96c831fdeb0fc55b82b2e7adf4
Nick Burch
nick@apache.org
2012-05-17 16:58:57 +0000
TIKA-929 Update the ODF Parser to use the new style Office properties
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/MSOffice.java b/tika-core/src/main/java/org/apache/tika/metadata/MSOffice.java
index 0f5107c4a..caf84fedb 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/MSOffice.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/MSOffice.java
@@ -60,39 +60,39 @@ public interface MSOffice {
 
     
     /** The number of Slides are there in the (presentation) document */
-    Property SLIDE_COUNT = 
+    @Deprecated Property SLIDE_COUNT = 
        Property.internalInteger("Slide-Count");
     
     /** The number of Pages are there in the (paged) document */
-    Property PAGE_COUNT = 
+    @Deprecated Property PAGE_COUNT = 
        Property.internalInteger("Page-Count");
 
     /** The number of individual Paragraphs in the document */ 
-    Property PARAGRAPH_COUNT = 
+    @Deprecated Property PARAGRAPH_COUNT = 
        Property.internalInteger("Paragraph-Count");
     
     /** The number of lines in the document */
-    Property LINE_COUNT = 
+    @Deprecated Property LINE_COUNT = 
        Property.internalInteger("Line-Count");
 
     /** The number of Words in the document */
-    Property WORD_COUNT = 
+    @Deprecated Property WORD_COUNT = 
        Property.internalInteger("Word-Count");
 
     /** The number of Characters in the document */
-    Property CHARACTER_COUNT = 
+    @Deprecated Property CHARACTER_COUNT = 
        Property.internalInteger("Character Count");
     
     /** The number of Characters in the document, including spaces */
-    Property CHARACTER_COUNT_WITH_SPACES = 
+    @Deprecated Property CHARACTER_COUNT_WITH_SPACES = 
        Property.internalInteger("Character-Count-With-Spaces");
 
     /** The number of Tables in the document */
-    Property TABLE_COUNT = 
+    @Deprecated Property TABLE_COUNT = 
        Property.internalInteger("Table-Count");
     
     /** The number of Images in the document */
-    Property IMAGE_COUNT = 
+    @Deprecated Property IMAGE_COUNT = 
        Property.internalInteger("Image-Count");
     
     /** 
@@ -100,7 +100,7 @@ public interface MSOffice {
      * This is typically non-Image resources embedded in the
      *  document, such as other documents or non-Image media. 
      */
-    Property OBJECT_COUNT = 
+    @Deprecated Property OBJECT_COUNT = 
        Property.internalInteger("Object-Count");
 
     
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/odf/OpenDocumentMetaParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/odf/OpenDocumentMetaParser.java
index 8e3de9198..2bada243f 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/odf/OpenDocumentMetaParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/odf/OpenDocumentMetaParser.java
@@ -16,12 +16,16 @@
  */
 package org.apache.tika.parser.odf;
 
+import org.apache.tika.metadata.MSOffice;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.Office;
 import org.apache.tika.metadata.PagedText;
+import org.apache.tika.metadata.Property;
+import org.apache.tika.metadata.TikaCoreProperties;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.parser.xml.AttributeDependantMetadataHandler;
-import org.apache.tika.parser.xml.DcXMLParser;
 import org.apache.tika.parser.xml.AttributeMetadataHandler;
+import org.apache.tika.parser.xml.DcXMLParser;
 import org.apache.tika.parser.xml.MetadataHandler;
 import org.apache.tika.sax.TeeContentHandler;
 import org.apache.tika.sax.xpath.CompositeMatcher;
@@ -43,12 +47,12 @@ public class OpenDocumentMetaParser extends DcXMLParser {
     private static final XPathParser META_XPATH = new XPathParser("meta", META_NS);
 
     private static ContentHandler getMeta(
-            ContentHandler ch, Metadata md, String name, String element) {
+            ContentHandler ch, Metadata md, Property property, String element) {
         Matcher matcher = new CompositeMatcher(
                 META_XPATH.parse("//meta:" + element),
                 META_XPATH.parse("//meta:" + element + "//text()"));
         ContentHandler branch =
-            new MatchingContentHandler(new MetadataHandler(md, name), matcher);
+            new MatchingContentHandler(new MetadataHandler(md, property), matcher);
         return new TeeContentHandler(ch, branch);
     }
 
@@ -64,7 +68,7 @@ public class OpenDocumentMetaParser extends DcXMLParser {
         return new TeeContentHandler(ch, branch);
     }
 
-    private static ContentHandler getStatistic(
+    @Deprecated private static ContentHandler getStatistic(
             ContentHandler ch, Metadata md, String name, String attribute) {
         Matcher matcher =
             META_XPATH.parse("//meta:document-statistic/@meta:"+attribute);
@@ -72,30 +76,50 @@ public class OpenDocumentMetaParser extends DcXMLParser {
               new AttributeMetadataHandler(META_NS, attribute, md, name), matcher);
         return new TeeContentHandler(ch, branch);
     }
+    private static ContentHandler getStatistic(
+          ContentHandler ch, Metadata md, Property property, String attribute) {
+      Matcher matcher =
+          META_XPATH.parse("//meta:document-statistic/@meta:"+attribute);
+      ContentHandler branch = new MatchingContentHandler(
+            new AttributeMetadataHandler(META_NS, attribute, md, property), matcher);
+      return new TeeContentHandler(ch, branch);
+  }
 
     protected ContentHandler getContentHandler(ContentHandler ch, Metadata md, ParseContext context) {
         // Process the Dublin Core Attributes 
         ch = super.getContentHandler(ch, md, context);
+        
         // Process the OO Meta Attributes
-        ch = getMeta(ch, md, Metadata.CREATION_DATE.getName(), "creation-date");
-        ch = getMeta(ch, md, Metadata.KEYWORDS, "keyword");
-        ch = getMeta(ch, md, Metadata.EDIT_TIME, "editing-duration");
-        ch = getMeta(ch, md, "editing-cycles", "editing-cycles");
-        ch = getMeta(ch, md, "initial-creator", "initial-creator");
-        ch = getMeta(ch, md, "generator", "generator");
+        ch = getMeta(ch, md, TikaCoreProperties.CREATION_DATE, "creation-date");
+        ch = getMeta(ch, md, TikaCoreProperties.KEYWORDS, "keyword");
+        
+        ch = getMeta(ch, md, Property.externalText(MSOffice.EDIT_TIME), "editing-duration");        
+        ch = getMeta(ch, md, Property.externalText("editing-cycles"), "editing-cycles");
+        ch = getMeta(ch, md, Property.externalText("initial-creator"), "initial-creator");
+        ch = getMeta(ch, md, Property.externalText("generator"), "generator");
         
         // Process the user defined Meta Attributes
         ch = getUserDefined(ch, md);
         
         // Process the OO Statistics Attributes
-        ch = getStatistic(ch, md, Metadata.OBJECT_COUNT.getName(), "object-count");
-        ch = getStatistic(ch, md, Metadata.IMAGE_COUNT.getName(),  "image-count");
-        ch = getStatistic(ch, md, Metadata.PAGE_COUNT.getName(),   "page-count");
-        ch = getStatistic(ch, md, PagedText.N_PAGES.getName(),     "page-count");
-        ch = getStatistic(ch, md, Metadata.TABLE_COUNT.getName(),  "table-count");
-        ch = getStatistic(ch, md, Metadata.PARAGRAPH_COUNT.getName(), "paragraph-count");
-        ch = getStatistic(ch, md, Metadata.WORD_COUNT.getName(),      "word-count");
-        ch = getStatistic(ch, md, Metadata.CHARACTER_COUNT.getName(), "character-count");
+        ch = getStatistic(ch, md, Office.OBJECT_COUNT,  "object-count");
+        ch = getStatistic(ch, md, Office.IMAGE_COUNT,   "image-count");
+        ch = getStatistic(ch, md, Office.PAGE_COUNT,    "page-count");
+        ch = getStatistic(ch, md, PagedText.N_PAGES,    "page-count");
+        ch = getStatistic(ch, md, Office.TABLE_COUNT,   "table-count");
+        ch = getStatistic(ch, md, Office.PARAGRAPH_COUNT, "paragraph-count");
+        ch = getStatistic(ch, md, Office.WORD_COUNT,      "word-count");
+        ch = getStatistic(ch, md, Office.CHARACTER_COUNT, "character-count");
+        
+        // Legacy, Tika-1.0 style attributes
+        // TODO Remove these in Tika 2.0
+        ch = getStatistic(ch, md, MSOffice.OBJECT_COUNT,  "object-count");
+        ch = getStatistic(ch, md, MSOffice.IMAGE_COUNT,   "image-count");
+        ch = getStatistic(ch, md, MSOffice.PAGE_COUNT,    "page-count");
+        ch = getStatistic(ch, md, MSOffice.TABLE_COUNT,   "table-count");
+        ch = getStatistic(ch, md, MSOffice.PARAGRAPH_COUNT, "paragraph-count");
+        ch = getStatistic(ch, md, MSOffice.WORD_COUNT,      "word-count");
+        ch = getStatistic(ch, md, MSOffice.CHARACTER_COUNT, "character-count");
         
         // Legacy Statistics Attributes, replaced with real keys above
         // TODO Remove these shortly, eg after Tika 1.1 (TIKA-770)
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/xml/AbstractMetadataHandler.java b/tika-parsers/src/main/java/org/apache/tika/parser/xml/AbstractMetadataHandler.java
index 598649094..1e87538ed 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/xml/AbstractMetadataHandler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/xml/AbstractMetadataHandler.java
@@ -20,6 +20,7 @@ import java.util.Arrays;
 import java.util.List;
 
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.Property;
 import org.xml.sax.helpers.DefaultHandler;
 
 /**
@@ -30,13 +31,19 @@ import org.xml.sax.helpers.DefaultHandler;
 class AbstractMetadataHandler extends DefaultHandler {
 
     private final Metadata metadata;
-
+    private final Property property;
     private final String name;
 
     protected AbstractMetadataHandler(Metadata metadata, String name) {
         this.metadata = metadata;
+        this.property = null;
         this.name = name;
     }
+    protected AbstractMetadataHandler(Metadata metadata, Property property) {
+       this.metadata = metadata;
+       this.property = property;
+       this.name = property.getName();
+   }
 
     /**
      * Adds the given metadata value. The value is ignored if it is
@@ -51,20 +58,31 @@ class AbstractMetadataHandler extends DefaultHandler {
                 // Add the value, assuming it's not already there
                 List<String> previous = Arrays.asList(metadata.getValues(name));
                 if (!previous.contains(value)) {
-                    metadata.add(name, value);
+                    if (property != null) {
+                       metadata.add(property, value);
+                    } else {
+                       metadata.add(name, value);
+                    }
                 }
             } else {
                 // Set the value, assuming it's not already there
                 String previous = metadata.get(name);
                 if (previous != null && previous.length() > 0) {
                     if (!previous.equals(value)) {
-                        metadata.add(name, value);
+                       if (property != null) {
+                          metadata.add(property, value);
+                       } else {
+                          metadata.add(name, value);
+                       }
                     }
                 } else {
-                    metadata.set(name, value);
+                   if (property != null) {
+                      metadata.set(property, value);
+                   } else {
+                      metadata.set(name, value);
+                   }
                 }
             }
         }
     }
-
 }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/xml/AttributeMetadataHandler.java b/tika-parsers/src/main/java/org/apache/tika/parser/xml/AttributeMetadataHandler.java
index dddb37748..dba5e4cb6 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/xml/AttributeMetadataHandler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/xml/AttributeMetadataHandler.java
@@ -17,6 +17,7 @@
 package org.apache.tika.parser.xml;
 
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.Property;
 import org.xml.sax.Attributes;
 import org.xml.sax.SAXException;
 
@@ -38,6 +39,12 @@ public class AttributeMetadataHandler extends AbstractMetadataHandler {
         this.uri = uri;
         this.localName = localName;
     }
+    public AttributeMetadataHandler(
+          String uri, String localName, Metadata metadata, Property property) {
+      super(metadata, property);
+      this.uri = uri;
+      this.localName = localName;
+  }
 
     @Override
     public void startElement(
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/xml/MetadataHandler.java b/tika-parsers/src/main/java/org/apache/tika/parser/xml/MetadataHandler.java
index 52a5be0a7..3fee00a34 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/xml/MetadataHandler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/xml/MetadataHandler.java
@@ -17,6 +17,7 @@
 package org.apache.tika.parser.xml;
 
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.Property;
 import org.xml.sax.Attributes;
 import org.xml.sax.helpers.DefaultHandler;
 
@@ -33,14 +34,21 @@ public class MetadataHandler extends DefaultHandler {
 
     private final Metadata metadata;
 
+    private final Property property;
     private final String name;
 
     private final StringBuilder buffer = new StringBuilder();
 
     public MetadataHandler(Metadata metadata, String name) {
         this.metadata = metadata;
+        this.property = null;
         this.name = name;
     }
+    public MetadataHandler(Metadata metadata, Property property) {
+       this.metadata = metadata;
+       this.property = property;
+       this.name = property.getName();
+   }
 
     public void addMetadata(String value) {
         if (value.length() > 0) {
@@ -48,7 +56,12 @@ public class MetadataHandler extends DefaultHandler {
             if (previous != null && previous.length() > 0) {
                 value = previous + ", " + value;
             }
-            metadata.set(name, value);
+            
+            if (this.property != null) {
+               metadata.set(property, value);
+            } else {
+               metadata.set(name, value);
+            }
         }
     }
 
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/odf/ODFParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/odf/ODFParserTest.java
index 673807fbd..45e89db85 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/odf/ODFParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/odf/ODFParserTest.java
@@ -20,6 +20,7 @@ import java.io.InputStream;
 
 import org.apache.tika.TikaTest;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.Office;
 import org.apache.tika.parser.AutoDetectParser;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.parser.Parser;
@@ -85,6 +86,15 @@ public class ODFParserTest extends TikaTest {
                    metadata.get("generator"));
              
              // Check the document statistics
+             assertEquals("1", metadata.get(Office.PAGE_COUNT));
+             assertEquals("1", metadata.get(Office.PARAGRAPH_COUNT));
+             assertEquals("14", metadata.get(Office.WORD_COUNT));
+             assertEquals("78", metadata.get(Office.CHARACTER_COUNT));
+             assertEquals("0", metadata.get(Office.TABLE_COUNT));
+             assertEquals("0", metadata.get(Office.OBJECT_COUNT));
+             assertEquals("0", metadata.get(Office.IMAGE_COUNT));
+             
+             // Check the Tika-1.0 style document statistics
              assertEquals("1", metadata.get(Metadata.PAGE_COUNT));
              assertEquals("1", metadata.get(Metadata.PARAGRAPH_COUNT));
              assertEquals("14", metadata.get(Metadata.WORD_COUNT));
@@ -93,7 +103,7 @@ public class ODFParserTest extends TikaTest {
              assertEquals("0", metadata.get(Metadata.OBJECT_COUNT));
              assertEquals("0", metadata.get(Metadata.IMAGE_COUNT));
              
-             // Check the old style statistics (these will be removed shortly)
+             // Check the very old style statistics (these will be removed shortly)
              assertEquals("0", metadata.get("nbTab"));
              assertEquals("0", metadata.get("nbObject"));
              assertEquals("0", metadata.get("nbImg"));
@@ -209,6 +219,15 @@ public class ODFParserTest extends TikaTest {
            assertEquals(null, metadata.get("custom:Info 4"));
            
            // Check the document statistics
+           assertEquals("2", metadata.get(Office.PAGE_COUNT));
+           assertEquals("13", metadata.get(Office.PARAGRAPH_COUNT));
+           assertEquals("54", metadata.get(Office.WORD_COUNT));
+           assertEquals("351", metadata.get(Office.CHARACTER_COUNT));
+           assertEquals("0", metadata.get(Office.TABLE_COUNT));
+           assertEquals("2", metadata.get(Office.OBJECT_COUNT));
+           assertEquals("0", metadata.get(Office.IMAGE_COUNT));
+           
+           // Check the Tika-1.0 style document statistics
            assertEquals("2", metadata.get(Metadata.PAGE_COUNT));
            assertEquals("13", metadata.get(Metadata.PARAGRAPH_COUNT));
            assertEquals("54", metadata.get(Metadata.WORD_COUNT));

Commit:
a8755b0c33d216be5b64cfd039d0f9dac1f1406e
Nick Burch
nick@apache.org
2012-05-17 16:33:44 +0000
TIKA-929 Bring some of the key parts of the Office metadata into TikaCoreProperties, with composites to support the previous (now deprecated) ones in MSOffice
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/MSOffice.java b/tika-core/src/main/java/org/apache/tika/metadata/MSOffice.java
index c6f1942d1..0f5107c4a 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/MSOffice.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/MSOffice.java
@@ -24,11 +24,11 @@ package org.apache.tika.metadata;
  */
 public interface MSOffice {
 
-    String KEYWORDS = "Keywords";
+    @Deprecated String KEYWORDS = "Keywords";
 
     String COMMENTS = "Comments";
 
-    String LAST_AUTHOR = "Last-Author";
+    @Deprecated String LAST_AUTHOR = "Last-Author";
 
     String APPLICATION_NAME = "Application-Name";
 
@@ -108,15 +108,15 @@ public interface MSOffice {
     String EDIT_TIME = "Edit-Time"; 
 
     /** When was the document created? */
-    Property CREATION_DATE = 
+    @Deprecated Property CREATION_DATE = 
         Property.internalDate("Creation-Date");
 
     /** When was the document last saved? */
-    Property LAST_SAVED = 
+    @Deprecated Property LAST_SAVED = 
        Property.internalDate("Last-Save-Date");
     
     /** When was the document last printed? */
-    Property LAST_PRINTED = 
+    @Deprecated Property LAST_PRINTED = 
        Property.internalDate("Last-Printed");
     
     /** 
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/Office.java b/tika-core/src/main/java/org/apache/tika/metadata/Office.java
index 8529c6297..4531b8ba2 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/Office.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/Office.java
@@ -58,6 +58,7 @@ public interface Office {
    Property LAST_AUTHOR = Property.internalText(
          PREFIX_DOC_META + Metadata.PREFIX_DELIMITER + "last-author");
 
+   
    /** When was the document created? */
    Property CREATION_DATE = Property.internalDate(
          PREFIX_DOC_META + Metadata.PREFIX_DELIMITER + "creation-date");
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/TikaCoreProperties.java b/tika-core/src/main/java/org/apache/tika/metadata/TikaCoreProperties.java
index 6d8785673..b1d11cb4c 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/TikaCoreProperties.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/TikaCoreProperties.java
@@ -64,6 +64,17 @@ public interface TikaCoreProperties {
     public static final Property CREATOR = Property.composite(DublinCore.CREATOR, 
             new Property[] { Property.internalText(Metadata.CREATOR) });
     
+    /**
+     * @see Office#INITIAL_AUTHOR
+     */
+    public static final Property INITIAL_AUTHOR = Office.INITIAL_AUTHOR;
+
+    /**
+     * @see Office#LAST_AUTHOR
+     */
+    public static final Property LAST_AUTHOR = Property.composite(Office.LAST_AUTHOR,
+            new Property[] { Property.internalText(MSOffice.LAST_AUTHOR) });
+    
    /**
     * @see DublinCore#LANGUAGE
     */
@@ -121,6 +132,12 @@ public interface TikaCoreProperties {
     public static final Property SUBJECT = Property.composite(DublinCore.SUBJECT, 
             new Property[] { Property.internalText(Metadata.SUBJECT) });
       
+    /**
+     * @see Office#KEYWORDS
+     */
+    public static final Property KEYWORDS = Property.composite(Office.KEYWORDS,
+            new Property[] { Property.internalTextBag(MSOffice.KEYWORDS) });
+
     
     // Date related properties
     
@@ -136,7 +153,17 @@ public interface TikaCoreProperties {
      public static final Property MODIFIED = Property.composite(DublinCore.MODIFIED, 
              new Property[] { Property.internalText(Metadata.MODIFIED) });
      
-     // TODO Bring across additional date properties from MSOffice, once they're namespaced
+     /** @see Office#CREATION_DATE */
+     public static final Property CREATION_DATE = Property.composite(Office.CREATION_DATE,
+             new Property[] { MSOffice.CREATION_DATE });
+
+     /** @see Office#SAVE_DATE */
+     public static final Property SAVE_DATE = Property.composite(Office.SAVE_DATE,
+             new Property[] { MSOffice.LAST_SAVED });
+     
+     /** @see Office#PRINT_DATE */
+     public static final Property PRINT_DATE = Property.composite(Office.PRINT_DATE, 
+             new Property[] { MSOffice.LAST_PRINTED });
     
      
     // Geographic related properties

Commit:
ce9ffb3ff03d8a6eb1a0bf16e04d35372a3ba626
Nick Burch
nick@apache.org
2012-05-17 16:20:10 +0000
TIKA-929 Start to replace the old non-prefixed, largely non-property MSOffice metadata definitions with new style ones
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/MSOffice.java b/tika-core/src/main/java/org/apache/tika/metadata/MSOffice.java
index c4010038b..c6f1942d1 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/MSOffice.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/MSOffice.java
@@ -17,7 +17,10 @@
 package org.apache.tika.metadata;
 
 /**
- * A collection of Microsoft Office documents property names.
+ * A collection of Microsoft Office and Open Document property names.
+ * 
+ * This is being replaced with cleaner, better defined properties in
+ *  {@link Office}.
  */
 public interface MSOffice {
 
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/Office.java b/tika-core/src/main/java/org/apache/tika/metadata/Office.java
new file mode 100644
index 000000000..8529c6297
--- /dev/null
+++ b/tika-core/src/main/java/org/apache/tika/metadata/Office.java
@@ -0,0 +1,117 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.metadata;
+
+/**
+ * Office Document properties collection. These properties apply to 
+ *  Office / Productivity Documents of all forms, including (but not limited 
+ *  to) MS Office and OpenDocument formats.
+ * This is a logical collection of properties, which may be drawn from a
+ *  few different external definitions.
+ * 
+ * Note that some of the legacy properties from the {@link MSOffice}
+ *  collection still need to be migrated over
+ */
+public interface Office {
+   // These are taken from the OpenDocumentFormat specification
+   public static final String NAMESPACE_URI_DOC_META = "urn:oasis:names:tc:opendocument:xmlns:meta:1.0";
+   public static final String PREFIX_DOC_META = "doc-meta";
+   public static final String PREFIX_DOC_META_STATS = "doc-meta-stats";
+
+   /** 
+    * For user defined metadata entries in the document,
+    *  what prefix should be attached to the key names.
+    * eg <meta:user-defined meta:name="Info1">Text1</meta:user-defined> becomes custom:Info1=Text1
+    */
+   public static final String USER_DEFINED_METADATA_NAME_PREFIX = "custom:";
+
+   
+   /**
+    * Keywords pertaining to a document. 
+    */
+   Property KEYWORDS = Property.internalTextBag(
+         PREFIX_DOC_META + Metadata.PREFIX_DELIMITER + "keyword");
+
+   /**
+    * Name of the initial creator/author of a document
+    */
+   Property INITIAL_AUTHOR = Property.internalText(
+         PREFIX_DOC_META + Metadata.PREFIX_DELIMITER + "initial-author");
+
+   /**
+    * Name of the last (most recent) author of a document
+    */
+   Property LAST_AUTHOR = Property.internalText(
+         PREFIX_DOC_META + Metadata.PREFIX_DELIMITER + "last-author");
+
+   /** When was the document created? */
+   Property CREATION_DATE = Property.internalDate(
+         PREFIX_DOC_META + Metadata.PREFIX_DELIMITER + "creation-date");
+
+   /** When was the document last saved? */
+   Property SAVE_DATE = Property.internalDate(
+         PREFIX_DOC_META + Metadata.PREFIX_DELIMITER + "save-date");
+   
+   /** When was the document last printed? */
+   Property PRINT_DATE = Property.internalDate(
+         PREFIX_DOC_META + Metadata.PREFIX_DELIMITER + "print-date");
+
+
+    
+    /** The number of Slides are there in the (presentation) document */
+    Property SLIDE_COUNT = Property.internalInteger(
+          PREFIX_DOC_META_STATS + Metadata.PREFIX_DELIMITER + "slide-count");
+    
+    /** The number of Pages are there in the (paged) document */
+    Property PAGE_COUNT = Property.internalInteger(
+          PREFIX_DOC_META_STATS + Metadata.PREFIX_DELIMITER + "page-count");
+
+    /** The number of individual Paragraphs in the document */ 
+    Property PARAGRAPH_COUNT = Property.internalInteger(
+          PREFIX_DOC_META_STATS + Metadata.PREFIX_DELIMITER + "paragraph-count");
+    
+    /** The number of lines in the document */
+    Property LINE_COUNT = Property.internalInteger(
+          PREFIX_DOC_META_STATS + Metadata.PREFIX_DELIMITER + "line-count");
+
+    /** The number of Words in the document */
+    Property WORD_COUNT = Property.internalInteger(
+          PREFIX_DOC_META_STATS + Metadata.PREFIX_DELIMITER + "word-count");
+
+    /** The number of Characters in the document */
+    Property CHARACTER_COUNT = Property.internalInteger(
+          PREFIX_DOC_META_STATS + Metadata.PREFIX_DELIMITER + "character-count");
+    
+    /** The number of Characters in the document, including spaces */
+    Property CHARACTER_COUNT_WITH_SPACES = Property.internalInteger(
+          PREFIX_DOC_META_STATS + Metadata.PREFIX_DELIMITER + "character-count-with-spaces");
+
+    /** The number of Tables in the document */
+    Property TABLE_COUNT = Property.internalInteger(
+          PREFIX_DOC_META_STATS + Metadata.PREFIX_DELIMITER + "table-count");
+    
+    /** The number of Images in the document */
+    Property IMAGE_COUNT = Property.internalInteger(
+          PREFIX_DOC_META_STATS + Metadata.PREFIX_DELIMITER + "image-count");
+    
+    /** 
+     * The number of Objects in the document. These are typically non-Image resources 
+     * embedded in the document, such as other documents or non-Image media. 
+     */
+    Property OBJECT_COUNT = Property.internalInteger(
+          PREFIX_DOC_META_STATS + Metadata.PREFIX_DELIMITER + "object-count");
+}

Commit:
362aa5e1b89de3bb67b9ff212ed69b8fdd16b796
Nick Burch
nick@apache.org
2012-05-17 16:19:06 +0000
TIKA-876 Another pkcs7 magic pattern
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index c9f4e546a..8302e9c31 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -397,6 +397,8 @@
       <match value="-----BEGIN PKCS7" type="string" offset="0"/>
       <match value="0x3082FFFF06092a864886f70d0107FFa0" type="string"
               mask="0xFFFF0000FFFFFFFFFFFFFFFFFFFF00FF" offset="0"/>
+      <match value="0x308006092a864886f70d0107FFa0" type="string"
+              mask="0xFFFFFFFFFFFFFFFFFFFFFFFF00FF" offset="0"/>
     </magic>
   </mime-type>
   <mime-type type="application/pkix-cert">

Commit:
ffe9d51a4c966599f2215c6f000030a017b1d35d
Nick Burch
nick@apache.org
2012-05-16 23:15:09 +0000
TIKA-926 Patch from Ray Gauss to allow set(Property,String[]) and add(Property,String), to mirror the string key based methods but with type safety
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java b/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
index 7b161969a..0f870f679 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
@@ -290,6 +290,13 @@ public class Metadata implements CreativeCommons, Geographic, HttpHeaders,
         }
         return values;
     }
+    
+    private String[] appendedValues(String[] values, final String value) {
+        String[] newValues = new String[values.length + 1];
+        System.arraycopy(values, 0, newValues, 0, values.length);
+        newValues[newValues.length - 1] = value;
+        return newValues;
+    }
 
     /**
      * Add a metadata name/value mapping. Add the specified value to the list of
@@ -305,10 +312,29 @@ public class Metadata implements CreativeCommons, Geographic, HttpHeaders,
         if (values == null) {
             set(name, value);
         } else {
-            String[] newValues = new String[values.length + 1];
-            System.arraycopy(values, 0, newValues, 0, values.length);
-            newValues[newValues.length - 1] = value;
-            metadata.put(name, newValues);
+            metadata.put(name, appendedValues(values, value));
+        }
+    }
+    
+    /**
+     * Add a metadata property/value mapping. Add the specified value to the list of
+     * values associated to the specified metadata property.
+     * 
+     * @param property
+     *          the metadata property.
+     * @param value
+     *          the metadata value.
+     */
+    public void add(final Property property, final String value) {
+        String[] values = metadata.get(property.getName());
+        if (values == null) {
+            set(property.getName(), value);
+        } else {
+             if (property.isMultiValuePermitted()) {
+                 set(property, appendedValues(values, value));
+             } else {
+                 throw new PropertyTypeException(property.getPropertyType());
+             }
         }
     }
 
@@ -364,6 +390,29 @@ public class Metadata implements CreativeCommons, Geographic, HttpHeaders,
             set(property.getName(), value);
         }
     }
+    
+    /**
+     * Sets the values of the identified metadata property.
+     *
+     * @since Apache Tika 1.2
+     * @param property property definition
+     * @param values    property values
+     */
+    public void set(Property property, String[] values) {
+        if (property == null) {
+            throw new NullPointerException("property must not be null");
+        }
+        if (property.getPropertyType() == PropertyType.COMPOSITE) {
+            set(property.getPrimaryProperty(), values);
+            if (property.getSecondaryExtractProperties() != null) {
+                for (Property secondaryExtractProperty : property.getSecondaryExtractProperties()) {
+                    set(secondaryExtractProperty, values);
+                }
+            }
+        } else {
+            metadata.put(property.getName(), values);
+        }
+    }
 
     /**
      * Sets the integer value of the identified metadata property.
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/Property.java b/tika-core/src/main/java/org/apache/tika/metadata/Property.java
index 9c56a54c8..36ca6492d 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/Property.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/Property.java
@@ -136,6 +136,20 @@ public final class Property implements Comparable<Property> {
     public boolean isExternal() {
         return !internal;
     }
+    
+    /**
+     * Is the PropertyType one which accepts multiple values?
+     */
+    public boolean isMultiValuePermitted() {
+        if (propertyType == PropertyType.BAG || propertyType == PropertyType.SEQ ||
+            propertyType == PropertyType.ALT) {
+           return true;
+        } else if (propertyType == PropertyType.COMPOSITE) {
+           // Base it on the primary property's behaviour
+           return primaryProperty.isMultiValuePermitted();
+        }
+        return false;
+    }
 
     public PropertyType getPropertyType() {
         return propertyType;
diff --git a/tika-core/src/test/java/org/apache/tika/metadata/TestMetadata.java b/tika-core/src/test/java/org/apache/tika/metadata/TestMetadata.java
index eb7f8480d..0acec2726 100644
--- a/tika-core/src/test/java/org/apache/tika/metadata/TestMetadata.java
+++ b/tika-core/src/test/java/org/apache/tika/metadata/TestMetadata.java
@@ -72,6 +72,14 @@ public class TestMetadata extends TestCase {
         assertEquals("value1", values[0]);
         assertEquals("value2", values[1]);
         assertEquals("value1", values[2]);
+        
+        Property nonMultiValued = Property.internalText("nonMultiValued");
+        meta.add(nonMultiValued, "value1");
+        try {
+            meta.add(nonMultiValued, "value2");
+            fail("add should fail on the second call of a non-multi valued item");
+        } catch (PropertyTypeException e) {
+        }
     }
 
     /** Test for the <code>set(String, String)</code> method. */

Commit:
7488dcce89571d9aa81b3ea0fd95bd6f67290c60
Nick Burch
nick@apache.org
2012-05-16 23:04:29 +0000
Add some simple JavaDoc descriptions of the property types, to help people who don't natively speak xmp! (TIKA-926 related)
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/Property.java b/tika-core/src/main/java/org/apache/tika/metadata/Property.java
index d45a0563a..9c56a54c8 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/Property.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/Property.java
@@ -37,7 +37,17 @@ import java.util.TreeSet;
 public final class Property implements Comparable<Property> {
 
     public static enum PropertyType {
-        SIMPLE, STRUCTURE, BAG, SEQ, ALT, COMPOSITE
+        /** A single value */
+        SIMPLE, 
+        STRUCTURE, 
+        /** An un-ordered array */
+        BAG, 
+        /** An ordered array */
+        SEQ, 
+        /** An ordered array with some sort of criteria */
+        ALT, 
+        /** Multiple child properties */
+        COMPOSITE
     }
 
     public static enum ValueType {

Commit:
08ef9c198b06fd1c1f4722c53a09945e6377c532
Nick Burch
nick@apache.org
2012-05-16 22:52:51 +0000
TIKA-928 Include the Geographic details to the common set of properties, and group slightly
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/TikaCoreProperties.java b/tika-core/src/main/java/org/apache/tika/metadata/TikaCoreProperties.java
index eb0f0890f..6d8785673 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/TikaCoreProperties.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/TikaCoreProperties.java
@@ -46,12 +46,6 @@ public interface TikaCoreProperties {
    public static final Property IDENTIFIER = Property.composite(DublinCore.IDENTIFIER, 
             new Property[] { Property.internalText(Metadata.IDENTIFIER) });
     
-   /**
-    * @see DublinCore#MODIFIED
-    */
-    public static final Property MODIFIED = Property.composite(DublinCore.MODIFIED, 
-            new Property[] { Property.internalText(Metadata.MODIFIED) });
-    
    /**
     * @see DublinCore#CONTRIBUTOR
     */
@@ -70,18 +64,6 @@ public interface TikaCoreProperties {
     public static final Property CREATOR = Property.composite(DublinCore.CREATOR, 
             new Property[] { Property.internalText(Metadata.CREATOR) });
     
-   /**
-    * @see DublinCore#DATE
-    */
-    public static final Property DATE = Property.composite(DublinCore.DATE, 
-            new Property[] { Metadata.DATE });
-    
-   /**
-    * @see DublinCore#DESCRIPTION
-    */
-    public static final Property DESCRIPTION = Property.composite(DublinCore.DESCRIPTION, 
-            new Property[] { Property.internalText(Metadata.DESCRIPTION) });
-    
    /**
     * @see DublinCore#LANGUAGE
     */
@@ -113,20 +95,64 @@ public interface TikaCoreProperties {
             new Property[] { Property.internalText(Metadata.SOURCE) });
     
    /**
-    * @see DublinCore#SUBJECT
+    * @see DublinCore#TYPE
     */
-    public static final Property SUBJECT = Property.composite(DublinCore.SUBJECT, 
-            new Property[] { Property.internalText(Metadata.SUBJECT) });
+    public static final Property TYPE = Property.composite(DublinCore.TYPE, 
+            new Property[] { Property.internalText(Metadata.TYPE) });
+
     
-   /**
-    * @see DublinCore#TITLE
-    */
+    // Descriptive properties
+    
+    /**
+     * @see DublinCore#TITLE
+     */
     public static final Property TITLE = Property.composite(DublinCore.TITLE, 
             new Property[] { Property.internalText(Metadata.TITLE) });
+     
+    /**
+     * @see DublinCore#DESCRIPTION
+     */
+    public static final Property DESCRIPTION = Property.composite(DublinCore.DESCRIPTION, 
+            new Property[] { Property.internalText(Metadata.DESCRIPTION) });
+     
+    /**
+     * @see DublinCore#SUBJECT
+     */
+    public static final Property SUBJECT = Property.composite(DublinCore.SUBJECT, 
+            new Property[] { Property.internalText(Metadata.SUBJECT) });
+      
     
-   /**
-    * @see DublinCore#TYPE
-    */
-    public static final Property TYPE = Property.composite(DublinCore.TYPE, 
-            new Property[] { Property.internalText(Metadata.TYPE) });
+    // Date related properties
+    
+    /**
+     * @see DublinCore#DATE
+     */
+     public static final Property DATE = Property.composite(DublinCore.DATE, 
+             new Property[] { Metadata.DATE });
+     
+    /**
+     * @see DublinCore#MODIFIED
+     */
+     public static final Property MODIFIED = Property.composite(DublinCore.MODIFIED, 
+             new Property[] { Property.internalText(Metadata.MODIFIED) });
+     
+     // TODO Bring across additional date properties from MSOffice, once they're namespaced
+    
+     
+    // Geographic related properties
+     
+    /**
+     * @see Geographic#LATITUDE
+     */
+    public static final Property LATITUDE = Geographic.LATITUDE;
+    
+    /**
+     * @see Geographic#LONGITUDE
+     */
+    public static final Property LONGITUDE = Geographic.LONGITUDE;
+    
+    /**
+     * @see Geographic#ALTITUDE
+     */
+    public static final Property ALTITUDE = Geographic.ALTITUDE;
 }

Commit:
5796aa68af70085f82216721b529c0bd850f1932
Nick Burch
nick@apache.org
2012-05-16 22:37:19 +0000
TIKA-928 Patch from Ray Gauss (plus extra JavaDocs) - start to define the set of common consistent metadata that all parsers will try to provide, no matter what their individual file format may term things
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/TikaCoreProperties.java b/tika-core/src/main/java/org/apache/tika/metadata/TikaCoreProperties.java
new file mode 100644
index 000000000..eb0f0890f
--- /dev/null
+++ b/tika-core/src/main/java/org/apache/tika/metadata/TikaCoreProperties.java
@@ -0,0 +1,132 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.metadata;
+
+/**
+ * Contains a core set of basic Tika metadata properties, which all parsers
+ *  will attempt to supply (where the file format permits). These are all
+ *  defined in terms of other standard namespaces.
+ *  
+ * Users of Tika who wish to have consistent metadata across file formats
+ *  can make use of these Properties, knowing that where present they will
+ *  have consistent semantic meaning between different file formats. (No 
+ *  matter if one file format calls it Title, another Long-Title and another
+ *  Long-Name, if they all mean the same thing as defined by 
+ *  {@link DublinCore#TITLE} then they will all be present as such)
+ *
+ * For now, most of these properties are composite ones including the deprecated
+ *  non-prefixed String properties from the Metadata class. In Tika 2.0, most
+ *  of these will revert back to simple assignments.
+ */
+@SuppressWarnings("deprecation")
+public interface TikaCoreProperties {
+    /**
+     * @see DublinCore#FORMAT
+     */
+    public static final Property FORMAT = Property.composite(DublinCore.FORMAT, 
+            new Property[] { Property.internalText(Metadata.FORMAT) });
+    
+   /**
+    * @see DublinCore#IDENTIFIER
+    */
+   public static final Property IDENTIFIER = Property.composite(DublinCore.IDENTIFIER, 
+            new Property[] { Property.internalText(Metadata.IDENTIFIER) });
+    
+   /**
+    * @see DublinCore#MODIFIED
+    */
+    public static final Property MODIFIED = Property.composite(DublinCore.MODIFIED, 
+            new Property[] { Property.internalText(Metadata.MODIFIED) });
+    
+   /**
+    * @see DublinCore#CONTRIBUTOR
+    */
+    public static final Property CONTRIBUTOR = Property.composite(DublinCore.CONTRIBUTOR, 
+            new Property[] { Property.internalText(Metadata.CONTRIBUTOR) });
+    
+   /**
+    * @see DublinCore#COVERAGE
+    */
+    public static final Property COVERAGE = Property.composite(DublinCore.COVERAGE, 
+            new Property[] { Property.internalText(Metadata.COVERAGE) });
+    
+   /**
+    * @see DublinCore#CREATOR
+    */
+    public static final Property CREATOR = Property.composite(DublinCore.CREATOR, 
+            new Property[] { Property.internalText(Metadata.CREATOR) });
+    
+   /**
+    * @see DublinCore#DATE
+    */
+    public static final Property DATE = Property.composite(DublinCore.DATE, 
+            new Property[] { Metadata.DATE });
+    
+   /**
+    * @see DublinCore#DESCRIPTION
+    */
+    public static final Property DESCRIPTION = Property.composite(DublinCore.DESCRIPTION, 
+            new Property[] { Property.internalText(Metadata.DESCRIPTION) });
+    
+   /**
+    * @see DublinCore#LANGUAGE
+    */
+    public static final Property LANGUAGE = Property.composite(DublinCore.LANGUAGE, 
+            new Property[] { Property.internalText(Metadata.LANGUAGE) });
+    
+   /**
+    * @see DublinCore#PUBLISHER
+    */
+    public static final Property PUBLISHER = Property.composite(DublinCore.PUBLISHER, 
+            new Property[] { Property.internalText(Metadata.PUBLISHER) });
+    
+   /**
+    * @see DublinCore#RELATION
+    */
+    public static final Property RELATION = Property.composite(DublinCore.RELATION, 
+            new Property[] { Property.internalText(Metadata.RELATION) });
+    
+   /**
+    * @see DublinCore#RIGHTS
+    */
+    public static final Property RIGHTS = Property.composite(DublinCore.RIGHTS, 
+            new Property[] { Property.internalText(Metadata.RIGHTS) });
+    
+   /**
+    * @see DublinCore#SOURCE
+    */
+    public static final Property SOURCE = Property.composite(DublinCore.SOURCE, 
+            new Property[] { Property.internalText(Metadata.SOURCE) });
+    
+   /**
+    * @see DublinCore#SUBJECT
+    */
+    public static final Property SUBJECT = Property.composite(DublinCore.SUBJECT, 
+            new Property[] { Property.internalText(Metadata.SUBJECT) });
+    
+   /**
+    * @see DublinCore#TITLE
+    */
+    public static final Property TITLE = Property.composite(DublinCore.TITLE, 
+            new Property[] { Property.internalText(Metadata.TITLE) });
+    
+   /**
+    * @see DublinCore#TYPE
+    */
+    public static final Property TYPE = Property.composite(DublinCore.TYPE, 
+            new Property[] { Property.internalText(Metadata.TYPE) });
+}

Commit:
00a14bb29de9d26224720194d596604f90570480
Nick Burch
nick@apache.org
2012-05-16 22:05:14 +0000
TIKA-916 Correctly bail out early for .xps and .thmx files, which are an unsupported variant of PPTX, plus tests
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/OOXMLExtractorFactory.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/OOXMLExtractorFactory.java
index e6809a767..6be6bee9d 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/OOXMLExtractorFactory.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/OOXMLExtractorFactory.java
@@ -76,7 +76,7 @@ public class OOXMLExtractorFactory {
             
             // Get the type, and ensure it's one we handle
             MediaType type = ZipContainerDetector.detectOfficeOpenXML(pkg);
-            if (type != null && OOXMLParser.UNSUPPORTED_OOXML_TYPES.contains(type)) {
+            if (type == null || OOXMLParser.UNSUPPORTED_OOXML_TYPES.contains(type)) {
                // Not a supported type, delegate to Empty Parser 
                EmptyParser.INSTANCE.parse(stream, baseHandler, metadata, context);
                return;
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
index 6fd3b4d2f..09a4365b2 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
@@ -151,11 +151,11 @@ public class OOXMLParserTest extends TikaTest {
      *  such as presentation, macro-enabled etc
      */
     public void testPowerPoint() throws Exception {
-	String[] extensions = new String[] {
-		"pptx", "pptm", "ppsm", "ppsx", "potm"
-		//"thmx", // TIKA-418: Will be supported in POI 3.7 beta 2 
-		//"xps" // TIKA-418: Not yet supported by POI
-	};
+       String[] extensions = new String[] {
+             "pptx", "pptm", "ppsm", "ppsx", "potm"
+             //"thmx", // TIKA-418: Will be supported in POI 3.7 beta 2 
+             //"xps" // TIKA-418: Not yet supported by POI
+       };
 
         String[] mimeTypes = new String[] {
                 "application/vnd.openxmlformats-officedocument.presentationml.presentation",
@@ -216,7 +216,46 @@ public class OOXMLParserTest extends TikaTest {
             } finally {
                 input.close();
             }
-	}
+        }
+    }
+    
+    /**
+     * For the PowerPoint formats we don't currently support, ensure that
+     *  we don't break either
+     */
+    public void testUnsupportedPowerPoint() throws Exception {
+       String[] extensions = new String[] { "xps", "thmx" };
+       String[] mimeTypes = new String[] {
+             "application/vnd.ms-xpsdocument",
+             "application/vnd.openxmlformats-officedocument" // Is this right?
+       };
+       
+       for (int i=0; i<extensions.length; i++) {
+          String extension = extensions[i];
+          String filename = "testPPT." + extension;
+          String mimetype = mimeTypes[i];
+
+          Parser parser = new AutoDetectParser();
+          Metadata metadata = new Metadata();
+          metadata.set(Metadata.RESOURCE_NAME_KEY, filename);
+          ContentHandler handler = new BodyContentHandler();
+          ParseContext context = new ParseContext();
+  
+          InputStream input = getTestDocument(filename);
+          try {
+              parser.parse(input, handler, metadata, context);
+
+              // Should get the metadata
+              assertEquals(
+                    "Mime-type checking for " + filename,
+                    mimeTypes[i],
+                    metadata.get(Metadata.CONTENT_TYPE));
+
+              // But that's about it
+          } finally {
+             input.close();
+         }
+       }
     }
     
     /**

Commit:
912357deafb6584c22724a01575d6de43bbadb82
Nick Burch
nick@apache.org
2012-05-16 22:04:20 +0000
TIKA-917 Get the elf OS, if that bit of the header is set (but it often gets left as null....)
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/executable/ExecutableParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/executable/ExecutableParser.java
index d585cc029..9ba3cc822 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/executable/ExecutableParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/executable/ExecutableParser.java
@@ -250,61 +250,63 @@ public class ExecutableParser extends AbstractParser implements MachineMetadata
        // Byte 7 is the elf version
        int elfVer = stream.read();
        
-       // Byte 8 is the OS
+       // Byte 8 is the OS, if set (lots of compilers don't)
        // Byte 9 is the OS (specific) ABI version
        int os = stream.read();
        int osVer = stream.read();
-       // TODO Fix up, doesn't seem to be working
-//       switch (os) {
-//         case 0:
-//            metadata.set(PLATFORM, PLATFORM_SYSV);
-//            break;
-//            
-//         case 1:
-//            metadata.set(PLATFORM, PLATFORM_HPUX);
-//            break;
-//            
-//         case 2:
-//            metadata.set(PLATFORM, PLATFORM_NETBSD);
-//            break;
-//            
-//         case 3:
-//            metadata.set(PLATFORM, PLATFORM_LINUX);
-//            break;
-//            
-//         case 6:
-//            metadata.set(PLATFORM, PLATFORM_SOLARIS);
-//            break;
-//            
-//         case 7:
-//            metadata.set(PLATFORM, PLATFORM_AIX);
-//            break;
-//            
-//         case 8:
-//            metadata.set(PLATFORM, PLATFORM_IRIX);
-//            break;
-//            
-//         case 9:
-//            metadata.set(PLATFORM, PLATFORM_FREEBSD);
-//            break;
-//            
-//         case 10:
-//            metadata.set(PLATFORM, PLATFORM_TRU64);
-//            break;
-//            
-//         case 12:
-//            metadata.set(PLATFORM, PLATFORM_FREEBSD);
-//            break;
-//            
-//         case 64:
-//         case 97:
-//            metadata.set(PLATFORM, PLATFORM_ARM);
-//            break;
-//            
-//         case 255:
-//            metadata.set(PLATFORM, PLATFORM_EMBEDDED);
-//            break;
-//       }
+       if (os > 0 || osVer > 0)
+       {
+          switch (os) {
+          case 0:
+             metadata.set(PLATFORM, PLATFORM_SYSV);
+             break;
+
+          case 1:
+             metadata.set(PLATFORM, PLATFORM_HPUX);
+             break;
+
+          case 2:
+             metadata.set(PLATFORM, PLATFORM_NETBSD);
+             break;
+
+          case 3:
+             metadata.set(PLATFORM, PLATFORM_LINUX);
+             break;
+
+          case 6:
+             metadata.set(PLATFORM, PLATFORM_SOLARIS);
+             break;
+
+          case 7:
+             metadata.set(PLATFORM, PLATFORM_AIX);
+             break;
+
+          case 8:
+             metadata.set(PLATFORM, PLATFORM_IRIX);
+             break;
+
+          case 9:
+             metadata.set(PLATFORM, PLATFORM_FREEBSD);
+             break;
+
+          case 10:
+             metadata.set(PLATFORM, PLATFORM_TRU64);
+             break;
+
+          case 12:
+             metadata.set(PLATFORM, PLATFORM_FREEBSD);
+             break;
+
+          case 64:
+          case 97:
+             metadata.set(PLATFORM, PLATFORM_ARM);
+             break;
+
+          case 255:
+             metadata.set(PLATFORM, PLATFORM_EMBEDDED);
+             break;
+          }
+       }
        
        // Bytes 10-16 are padding and lengths
        byte[] padLength = new byte[7];
@@ -396,6 +398,8 @@ public class ExecutableParser extends AbstractParser implements MachineMetadata
             break;
        }
        
+       
+       
        // Bytes 20-23 are the version
        // TODO
     }

Commit:
49229f793f29af5736e8d8ea964066b0abfc07dc
Nick Burch
nick@apache.org
2012-05-16 21:42:49 +0000
TIKA-927 - Patch from Ray Gauss to support Composite Properties (useful for backwards compatibility, and mapping between application and core properties)
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java b/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
index 5d1096e51..7b161969a 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
@@ -31,6 +31,8 @@ import java.util.Map;
 import java.util.Properties;
 import java.util.TimeZone;
 
+import org.apache.tika.metadata.Property.PropertyType;
+
 /**
  * A multi-valued metadata container.
  */
@@ -348,7 +350,19 @@ public class Metadata implements CreativeCommons, Geographic, HttpHeaders,
      * @param value    property value
      */
     public void set(Property property, String value) {
-        set(property.getName(), value);
+        if (property == null) {
+            throw new NullPointerException("property must not be null");
+        }
+        if (property.getPropertyType() == PropertyType.COMPOSITE) {
+            set(property.getPrimaryProperty(), value);
+            if (property.getSecondaryExtractProperties() != null) {
+                for (Property secondaryExtractProperty : property.getSecondaryExtractProperties()) {
+                    set(secondaryExtractProperty, value);
+                }
+            }
+        } else {
+            set(property.getName(), value);
+        }
     }
 
     /**
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/Property.java b/tika-core/src/main/java/org/apache/tika/metadata/Property.java
index 6023c4681..d45a0563a 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/Property.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/Property.java
@@ -37,12 +37,12 @@ import java.util.TreeSet;
 public final class Property implements Comparable<Property> {
 
     public static enum PropertyType {
-        SIMPLE, STRUCTURE, BAG, SEQ, ALT
+        SIMPLE, STRUCTURE, BAG, SEQ, ALT, COMPOSITE
     }
 
     public static enum ValueType {
         BOOLEAN, OPEN_CHOICE, CLOSED_CHOICE, DATE, INTEGER, LOCALE,
-        MIME_TYPE, PROPER_NAME, RATIONAL, REAL, TEXT, URI, URL, XPATH
+        MIME_TYPE, PROPER_NAME, RATIONAL, REAL, TEXT, URI, URL, XPATH, PROPERTY
     }
 
     private static final Map<String, Property> properties =
@@ -55,6 +55,10 @@ public final class Property implements Comparable<Property> {
     private final PropertyType propertyType;
 
     private final ValueType valueType;
+    
+    private final Property primaryProperty;
+    
+    private final Property[] secondaryExtractProperties;
 
     /**
      * The available choices for the open and closed choice value types.
@@ -63,7 +67,7 @@ public final class Property implements Comparable<Property> {
 
     private Property(
             String name, boolean internal, PropertyType propertyType,
-            ValueType valueType, String[] choices) {
+            ValueType valueType, String[] choices, Property primaryProperty, Property[] secondaryExtractProperties) {
         this.name = name;
         this.internal = internal;
         this.propertyType = propertyType;
@@ -74,11 +78,26 @@ public final class Property implements Comparable<Property> {
         } else {
             this.choices = null;
         }
-
-        synchronized (properties) {
-            properties.put(name, this);
+        
+        if (primaryProperty != null) {
+            this.primaryProperty = primaryProperty;
+            this.secondaryExtractProperties = secondaryExtractProperties;
+        } else {
+            this.primaryProperty = this;
+            this.secondaryExtractProperties = null;
+            
+            // Only store primary properties for lookup, not composites
+            synchronized (properties) {
+               properties.put(name, this);
+           }
         }
     }
+    
+    private Property(
+            String name, boolean internal, PropertyType propertyType,
+            ValueType valueType, String[] choices) {
+    	this(name, internal, propertyType, valueType, choices, null, null);
+    }
 
     private Property(
             String name, boolean internal,
@@ -95,7 +114,7 @@ public final class Property implements Comparable<Property> {
             PropertyType propertyType, ValueType valueType) {
         this(name, internal, propertyType, valueType, null);
     }
-
+    
     public String getName() {
         return name;
     }
@@ -126,7 +145,25 @@ public final class Property implements Comparable<Property> {
     public Set<String> getChoices() {
         return choices;
     }
+    
+    /**
+     * Gets the primary property for a composite property
+     * 
+     * @return the primary property
+     */
+    public Property getPrimaryProperty() {
+        return primaryProperty;
+    }
 
+    /**
+     * Gets the secondary properties for a composite property
+     * 
+     * @return the secondary properties
+     */
+    public Property[] getSecondaryExtractProperties() {
+		return secondaryExtractProperties;
+	}
+    
     public static SortedSet<Property> getProperties(String prefix) {
         SortedSet<Property> set = new TreeSet<Property>();
         String p = prefix + ":";
@@ -209,6 +246,41 @@ public final class Property implements Comparable<Property> {
     public static Property externalText(String name) {
         return new Property(name, false, ValueType.TEXT);
     }
+    
+    /**
+     * Constructs a new composite property from the given primary and array of secondary properties.
+     * <p>
+     * Note that name of the composite property is taken from its primary property, 
+     * and primary and secondary properties must not be composite properties themselves.
+     * 
+     * @param primaryProperty
+     * @param secondaryExtractProperties
+     * @return the composite property
+     */
+    public static Property composite(Property primaryProperty, Property[] secondaryExtractProperties) {
+        if (primaryProperty == null) {
+            throw new NullPointerException("primaryProperty must not be null");
+        }
+        if (primaryProperty.getPropertyType() == PropertyType.COMPOSITE) {
+            throw new PropertyTypeException(primaryProperty.getPropertyType());
+        }
+        if (secondaryExtractProperties != null) {
+            for (Property secondaryExtractProperty : secondaryExtractProperties) {
+                if (secondaryExtractProperty.getPropertyType() == PropertyType.COMPOSITE) {
+                    throw new PropertyTypeException(secondaryExtractProperty.getPropertyType());
+                }
+            }
+        }
+        String[] choices = null;
+        if (primaryProperty.getChoices() != null) {
+            choices = primaryProperty.getChoices().toArray(
+                    new String[primaryProperty.getChoices().size()]);
+        }
+        return new Property(primaryProperty.getName(),
+                primaryProperty.isInternal(), PropertyType.COMPOSITE,
+                ValueType.PROPERTY, choices, primaryProperty,
+                secondaryExtractProperties);
+    }
 
     //----------------------------------------------------------< Comparable >
 
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/PropertyTypeException.java b/tika-core/src/main/java/org/apache/tika/metadata/PropertyTypeException.java
index ca70a77a6..cf9b662f4 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/PropertyTypeException.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/PropertyTypeException.java
@@ -34,4 +34,9 @@ public final class PropertyTypeException extends IllegalArgumentException {
     public PropertyTypeException(ValueType expected, ValueType found) {
         super("Expected a property with a " + expected + " value, but received a " + found);
     }
+    public PropertyTypeException(PropertyType unsupportedPropertyType) {
+    	super((unsupportedPropertyType != PropertyType.COMPOSITE) ? 
+    			(unsupportedPropertyType + " is not supported") : 
+    			("Composite Properties must not include other Composite Properties as either Primary or Secondary"));
+    }
 }
diff --git a/tika-core/src/test/java/org/apache/tika/metadata/TestMetadata.java b/tika-core/src/test/java/org/apache/tika/metadata/TestMetadata.java
index 1a4941450..eb7f8480d 100644
--- a/tika-core/src/test/java/org/apache/tika/metadata/TestMetadata.java
+++ b/tika-core/src/test/java/org/apache/tika/metadata/TestMetadata.java
@@ -330,4 +330,14 @@ public class TestMetadata extends TestCase {
         		"1970-01-01T00:00:01", meta.get(Metadata.DATE));
     }
     
+    public void testCompositeProperty() {
+    	Metadata meta = new Metadata();
+    	Property compositeProperty = Property.composite(
+            DublinCore.DESCRIPTION, new Property[] { Property.internalText(Metadata.DESCRIPTION)});
+    	String message = "composite description";
+    	meta.set(compositeProperty, message);
+    	assertEquals(message, meta.get(DublinCore.DESCRIPTION));
+    	assertEquals(message, meta.get(Metadata.DESCRIPTION));
+    }
+    
 }

Commit:
9e79399d2129cc9ccffaf4cc1834fac742238f05
Nick Burch
nick@apache.org
2012-05-16 21:17:10 +0000
Update JavaDoc following TIKA-864 change
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java b/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
index a9bf84f6f..5d1096e51 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
@@ -146,9 +146,8 @@ public class Metadata implements CreativeCommons, Geographic, HttpHeaders,
     }
 
     /**
-     * Returns a ISO 8601 representation of the given date. This method is
-     * synchronized to prevent concurrent access to the thread-unsafe date
-     * formats.
+     * Returns a ISO 8601 representation of the given date. This method 
+     * is thread safe and non-blocking.
      *
      * @see <a href="https://issues.apache.org/jira/browse/TIKA-495">TIKA-495</a>
      * @param date given date

Commit:
c0d60f016e6dcc03cd1a2b2f460e4c2f61375df8
Nick Burch
nick@apache.org
2012-05-16 20:42:37 +0000
TIKA-926 Patch from Ray Gauss - Data Typed Metadata.set(...) Value Methods Should Call Metadata.set(Property...)
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java b/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
index 5354d6cb2..a9bf84f6f 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
@@ -366,7 +366,7 @@ public class Metadata implements CreativeCommons, Geographic, HttpHeaders,
         if(property.getValueType() != Property.ValueType.INTEGER) {
             throw new PropertyTypeException(Property.ValueType.INTEGER, property.getValueType());
         }
-        set(property.getName(), Integer.toString(value));
+        set(property, Integer.toString(value));
     }
 
     /**
@@ -384,7 +384,7 @@ public class Metadata implements CreativeCommons, Geographic, HttpHeaders,
               property.getValueType() != Property.ValueType.RATIONAL) {
             throw new PropertyTypeException(Property.ValueType.REAL, property.getValueType());
         }
-        set(property.getName(), Double.toString(value));
+        set(property, Double.toString(value));
     }
 
     /**
@@ -401,7 +401,7 @@ public class Metadata implements CreativeCommons, Geographic, HttpHeaders,
         if(property.getValueType() != Property.ValueType.DATE) {
             throw new PropertyTypeException(Property.ValueType.DATE, property.getValueType());
         }
-        set(property.getName(), formatDate(date));
+        set(property, formatDate(date));
     }
 
     /**

Commit:
5c32a6764a05ec8fb8c51ac2f432ad1047d5ca4e
Nick Burch
nick@apache.org
2012-05-16 20:03:27 +0000
TIKA-917 Some more sample elf files
diff --git a/tika-parsers/src/test/resources/test-documents/testFreeBSD-x86-64 b/tika-parsers/src/test/resources/test-documents/testFreeBSD-x86-64
new file mode 100755
index 000000000..04fc0c37e
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testFreeBSD-x86-64 differ
diff --git a/tika-parsers/src/test/resources/test-documents/testSolaris-x86-32 b/tika-parsers/src/test/resources/test-documents/testSolaris-x86-32
new file mode 100755
index 000000000..8644f9280
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testSolaris-x86-32 differ

Commit:
385c9930d65b4263c1bf26781e38a80195c9a1df
Nick Burch
nick@apache.org
2012-05-16 17:33:15 +0000
TIKA-925 - Patch from Ray Gauss to start on improving how the common metadata is stored/fetched
diff --git a/tika-core/pom.xml b/tika-core/pom.xml
index 64db96eb7..85dea3fa4 100644
--- a/tika-core/pom.xml
+++ b/tika-core/pom.xml
@@ -102,6 +102,8 @@
                 <exlude>org/apache/tika/config/TikaActivator</exlude>
                 <exlude>org/apache/tika/metadata/Property$PropertyType</exlude>
                 <exlude>org/apache/tika/metadata/Property$ValueType</exlude>
+                <exlude>org/apache/tika/metadata/DublinCore</exlude>
+                <exlude>org/apache/tika/metadata/Metadata</exlude>
                 <exlude>org/apache/tika/metadata/MSOffice</exlude>
                 <exlude>org/apache/tika/parser/EmptyParser</exlude>
               </excludes>
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/DublinCore.java b/tika-core/src/main/java/org/apache/tika/metadata/DublinCore.java
index bb8fd9683..1a3ae1096 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/DublinCore.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/DublinCore.java
@@ -18,13 +18,14 @@ package org.apache.tika.metadata;
 
 /**
  * A collection of Dublin Core metadata names.
- * 
- * TODO Prefix these keys with the dc: prefix
- * 
+ *
  * @see <a href="http://dublincore.org">dublincore.org</a>
  */
 public interface DublinCore {
 
+	public static final String NAMESPACE_URI_DC = "http://purl.org/dc/elements/1.1/";
+	public static final String PREFIX_DC = "dc";
+
     /**
      * Typically, Format may include the media-type or dimensions of the
      * resource. Format may be used to determine the software, hardware or
@@ -33,7 +34,8 @@ public interface DublinCore {
      * to select a value from a controlled vocabulary (for example, the list
      * of Internet Media Types [MIME] defining computer media formats).
      */
-    String FORMAT = "format";
+	Property FORMAT = Property.internalText(
+    		PREFIX_DC + Metadata.NAMESPACE_PREFIX_DELIMITER + "format");
 
     /**
      * Recommended best practice is to identify the resource by means of
@@ -43,13 +45,14 @@ public interface DublinCore {
      * the Digital Object Identifier (DOI) and the International Standard
      * Book Number (ISBN).
      */
-    String IDENTIFIER = "identifier";
+	Property IDENTIFIER = Property.internalText(
+    		PREFIX_DC + Metadata.NAMESPACE_PREFIX_DELIMITER + "identifier");
 
     /**
      * Date on which the resource was changed.
-     * TODO Make me a Date Property
      */
-    String MODIFIED = "modified";
+	Property MODIFIED = Property.internalDate(
+			PREFIX_DC + Metadata.NAMESPACE_PREFIX_DELIMITER + "modified");
 
     /**
      * An entity responsible for making contributions to the content of the
@@ -57,7 +60,8 @@ public interface DublinCore {
      * or a service. Typically, the name of a Contributor should be used to
      * indicate the entity.
      */
-    String CONTRIBUTOR = "contributor";
+	Property CONTRIBUTOR = Property.internalText(
+    		PREFIX_DC + Metadata.NAMESPACE_PREFIX_DELIMITER + "contributor");
 
     /**
      * The extent or scope of the content of the resource. Coverage will
@@ -69,14 +73,16 @@ public interface DublinCore {
      * appropriate, named places or time periods be used in preference to
      * numeric identifiers such as sets of coordinates or date ranges.
      */
-    String COVERAGE = "coverage";
+	Property COVERAGE = Property.internalText(
+    		PREFIX_DC + Metadata.NAMESPACE_PREFIX_DELIMITER + "coverage");
 
     /**
      * An entity primarily responsible for making the content of the resource.
      * Examples of a Creator include a person, an organisation, or a service.
      * Typically, the name of a Creator should be used to indicate the entity.
      */
-    String CREATOR = "creator";
+	Property CREATOR = Property.internalText(
+    		PREFIX_DC + Metadata.NAMESPACE_PREFIX_DELIMITER + "creator");
 
     /**
      * A date associated with an event in the life cycle of the resource.
@@ -85,7 +91,8 @@ public interface DublinCore {
      * defined in a profile of ISO 8601 [W3CDTF] and follows the YYYY-MM-DD
      * format.
      */
-    Property DATE = Property.internalDate("date");
+	Property DATE = Property.internalDate(
+    		PREFIX_DC + Metadata.NAMESPACE_PREFIX_DELIMITER + "date");
 
     /**
      * An account of the content of the resource. Description may include
@@ -93,7 +100,8 @@ public interface DublinCore {
      * a graphical representation of content or a free-text account of
      * the content.
      */
-    String DESCRIPTION = "description";
+	Property DESCRIPTION = Property.internalText(
+    		PREFIX_DC + Metadata.NAMESPACE_PREFIX_DELIMITER + "description");
 
     /**
      * A language of the intellectual content of the resource. Recommended
@@ -102,21 +110,24 @@ public interface DublinCore {
      * tags with optional subtags. Examples include "en" or "eng" for English,
      * "akk" for Akkadian, and "en-GB" for English used in the United Kingdom.
      */
-    String LANGUAGE = "language";
+	Property LANGUAGE = Property.internalText(
+    		PREFIX_DC + Metadata.NAMESPACE_PREFIX_DELIMITER + "language");
 
     /**
      * An entity responsible for making the resource available. Examples of
      * a Publisher include a person, an organisation, or a service. Typically,
      * the name of a Publisher should be used to indicate the entity.
      */
-    String PUBLISHER = "publisher";
+	Property PUBLISHER = Property.internalText(
+    		PREFIX_DC + Metadata.NAMESPACE_PREFIX_DELIMITER + "publisher");
 
     /**
      * A reference to a related resource. Recommended best practice is to
      * reference the resource by means of a string or number conforming to
      * a formal identification system.
      */
-    String RELATION = "relation";
+	Property RELATION = Property.internalText(
+    		PREFIX_DC + Metadata.NAMESPACE_PREFIX_DELIMITER + "relation");
 
     /**
      * Information about rights held in and over the resource. Typically,
@@ -127,7 +138,8 @@ public interface DublinCore {
      * is absent, no assumptions can be made about the status of these and
      * other rights with respect to the resource.
      */
-    String RIGHTS = "rights";
+	Property RIGHTS = Property.internalText(
+    		PREFIX_DC + Metadata.NAMESPACE_PREFIX_DELIMITER + "rights");
 
     /**
      * A reference to a resource from which the present resource is derived.
@@ -136,7 +148,8 @@ public interface DublinCore {
      * means of a string or number conforming to a formal identification
      * system.
      */
-    String SOURCE = "source";
+	Property SOURCE = Property.internalText(
+    		PREFIX_DC + Metadata.NAMESPACE_PREFIX_DELIMITER + "source");
 
     /**
      * The topic of the content of the resource. Typically, a Subject will
@@ -145,13 +158,15 @@ public interface DublinCore {
      * select a value from a controlled vocabulary or formal classification
      * scheme.
      */
-    String SUBJECT = "subject";
+	Property SUBJECT = Property.internalTextBag(
+    		PREFIX_DC + Metadata.NAMESPACE_PREFIX_DELIMITER + "subject");
 
     /**
      * A name given to the resource. Typically, a Title will be a name by
      * which the resource is formally known.
      */
-    String TITLE = "title";
+	Property TITLE = Property.internalText(
+    		PREFIX_DC + Metadata.NAMESPACE_PREFIX_DELIMITER + "title");
 
     /**
      * The nature or genre of the content of the resource. Type includes terms
@@ -161,6 +176,7 @@ public interface DublinCore {
      * [DCMITYPE]). To describe the physical or digital manifestation of
      * the resource, use the Format element.
      */
-    String TYPE = "type";
+	Property TYPE = Property.internalText(
+    		PREFIX_DC + Metadata.NAMESPACE_PREFIX_DELIMITER + "type");
 
 }
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java b/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
index 99c25f45a..5354d6cb2 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
@@ -34,7 +34,7 @@ import java.util.TimeZone;
 /**
  * A multi-valued metadata container.
  */
-public class Metadata implements CreativeCommons, DublinCore, Geographic, HttpHeaders,
+public class Metadata implements CreativeCommons, Geographic, HttpHeaders,
         IPTC, Message, MSOffice, ClimateForcast, TIFF, TikaMetadataKeys, TikaMimeKeys,
         Serializable {
 
@@ -46,6 +46,29 @@ public class Metadata implements CreativeCommons, DublinCore, Geographic, HttpHe
      */
     private Map<String, String[]> metadata = null;
 
+    /**
+     * The common delimiter used between the namespace abbreviation and the property name
+     */
+    public static final String NAMESPACE_PREFIX_DELIMITER = ":";
+
+    // These properties are being moved to a new Tika core properties definition, javadocs will be added once it's available
+    @Deprecated public static final String FORMAT = "format";
+    @Deprecated public static final String IDENTIFIER = "identifier";
+    @Deprecated public static final String MODIFIED = "modified";
+    @Deprecated public static final String CONTRIBUTOR = "contributor";
+    @Deprecated public static final String COVERAGE = "coverage";
+    @Deprecated public static final String CREATOR = "creator";
+    @Deprecated public static final Property DATE = Property.internalDate("date");
+    @Deprecated public static final String DESCRIPTION = "description";
+    @Deprecated public static final String LANGUAGE = "language";
+    @Deprecated public static final String PUBLISHER = "publisher";
+    @Deprecated public static final String RELATION = "relation";
+    @Deprecated public static final String RIGHTS = "rights";
+    @Deprecated public static final String SOURCE = "source";
+    @Deprecated public static final String SUBJECT = "subject";
+    @Deprecated public static final String TITLE = "title";
+    @Deprecated public static final String TYPE = "type";
+
     /**
      * The UTC time zone. Not sure if {@link TimeZone#getTimeZone(String)}
      * understands "UTC" in all environments, but it'll fall back to GMT
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/font/TrueTypeParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/font/TrueTypeParser.java
index 859ab86c0..fa1f7089f 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/font/TrueTypeParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/font/TrueTypeParser.java
@@ -67,9 +67,9 @@ public class TrueTypeParser extends AbstractParser {
         }
 
         metadata.set(Metadata.CONTENT_TYPE, TYPE.toString());
-        metadata.set(DublinCore.DATE, font.getHeader().getCreated().getTime());
+        metadata.set(Metadata.DATE, font.getHeader().getCreated().getTime());
         metadata.set(
-                Property.internalDate(DublinCore.MODIFIED),
+                Property.internalDate(Metadata.MODIFIED),
                 font.getHeader().getModified().getTime());
 
         XHTMLContentHandler xhtml = new XHTMLContentHandler(handler, metadata);
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/image/xmp/JempboxExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/image/xmp/JempboxExtractor.java
index f6dd5e394..b537fe81a 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/image/xmp/JempboxExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/image/xmp/JempboxExtractor.java
@@ -59,18 +59,18 @@ public class JempboxExtractor {
             XMPSchemaDublinCore dc = xmp.getDublinCoreSchema();
             if (dc != null) {
                 if (dc.getTitle() != null) {
-                    metadata.set(DublinCore.TITLE, dc.getTitle());
+                    metadata.set(Metadata.TITLE, dc.getTitle());
                 }
                 if (dc.getDescription() != null) {
-                    metadata.set(DublinCore.DESCRIPTION, dc.getDescription());
+                    metadata.set(Metadata.DESCRIPTION, dc.getDescription());
                 }
                 if (dc.getCreators() != null && dc.getCreators().size() > 0) {
-                    metadata.set(DublinCore.CREATOR, joinCreators(dc.getCreators()));
+                    metadata.set(Metadata.CREATOR, joinCreators(dc.getCreators()));
                 }
                 if (dc.getSubjects() != null && dc.getSubjects().size() > 0) {
                     Iterator<String> keywords = dc.getSubjects().iterator();
                     while (keywords.hasNext()) {
-                        metadata.add(DublinCore.SUBJECT, keywords.next());
+                        metadata.add(Metadata.SUBJECT, keywords.next());
                     }
                     // TODO should we set KEYWORDS too?
                     // All tested photo managers set the same in Iptc.Application2.Keywords and Xmp.dc.subject
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/iptc/IptcAnpaParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/iptc/IptcAnpaParser.java
index fc946d5fd..da5e8f1c8 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/iptc/IptcAnpaParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/iptc/IptcAnpaParser.java
@@ -777,14 +777,14 @@ public class IptcAnpaParser implements Parser {
       metadata.set(Metadata.AUTHOR,        clean(properties.get("author")));
       metadata.set(Metadata.CREATION_DATE, clean(properties.get("created")));
       metadata.set(Metadata.MODIFIED,      clean(properties.get("modified")));
-      metadata.set(DublinCore.SOURCE,      clean(properties.get("source")));
+      metadata.set(Metadata.SOURCE,      clean(properties.get("source")));
 //      metadata.set(Metadata.PUBLISHER,     clean(properties.get("publisher")));
       metadata.set(Metadata.PUBLISHER,     clean(this.getFormatName()));
 
 /*
-        metadata.set(DublinCore.DATE, font.getHeader().getCreated().getTime());
+        metadata.set(Metadata.DATE, font.getHeader().getCreated().getTime());
         metadata.set(
-                Property.internalDate(DublinCore.MODIFIED),
+                Property.internalDate(Metadata.MODIFIED),
                 font.getHeader().getModified().getTime());
 */
    }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/xml/DcXMLParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/xml/DcXMLParser.java
index d78546ac6..d2cff4b8e 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/xml/DcXMLParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/xml/DcXMLParser.java
@@ -41,18 +41,18 @@ public class DcXMLParser extends XMLParser {
             ContentHandler handler, Metadata metadata, ParseContext context) {
         return new TeeContentHandler(
                 super.getContentHandler(handler, metadata, context),
-                getDublinCoreHandler(metadata, DublinCore.TITLE, "title"),
-                getDublinCoreHandler(metadata, DublinCore.SUBJECT, "subject"),
-                getDublinCoreHandler(metadata, DublinCore.CREATOR, "creator"),
-                getDublinCoreHandler(metadata, DublinCore.DESCRIPTION, "description"),
-                getDublinCoreHandler(metadata, DublinCore.PUBLISHER, "publisher"),
-                getDublinCoreHandler(metadata, DublinCore.CONTRIBUTOR, "contributor"),
-                getDublinCoreHandler(metadata, DublinCore.DATE.getName(), "date"),
-                getDublinCoreHandler(metadata, DublinCore.TYPE, "type"),
-                getDublinCoreHandler(metadata, DublinCore.FORMAT, "format"),
-                getDublinCoreHandler(metadata, DublinCore.IDENTIFIER, "identifier"),
-                getDublinCoreHandler(metadata, DublinCore.LANGUAGE, "language"),
-                getDublinCoreHandler(metadata, DublinCore.RIGHTS, "rights"));
+                getDublinCoreHandler(metadata, Metadata.TITLE, "title"),
+                getDublinCoreHandler(metadata, Metadata.SUBJECT, "subject"),
+                getDublinCoreHandler(metadata, Metadata.CREATOR, "creator"),
+                getDublinCoreHandler(metadata, Metadata.DESCRIPTION, "description"),
+                getDublinCoreHandler(metadata, Metadata.PUBLISHER, "publisher"),
+                getDublinCoreHandler(metadata, Metadata.CONTRIBUTOR, "contributor"),
+                getDublinCoreHandler(metadata, Metadata.DATE.getName(), "date"),
+                getDublinCoreHandler(metadata, Metadata.TYPE, "type"),
+                getDublinCoreHandler(metadata, Metadata.FORMAT, "format"),
+                getDublinCoreHandler(metadata, Metadata.IDENTIFIER, "identifier"),
+                getDublinCoreHandler(metadata, Metadata.LANGUAGE, "language"),
+                getDublinCoreHandler(metadata, Metadata.RIGHTS, "rights"));
     }
 
 }
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/image/ImageMetadataExtractorTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/image/ImageMetadataExtractorTest.java
index cce599539..3773d348d 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/image/ImageMetadataExtractorTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/image/ImageMetadataExtractorTest.java
@@ -66,7 +66,7 @@ public class ImageMetadataExtractorTest extends TestCase {
         Metadata metadata = new Metadata();
         
         new ImageMetadataExtractor.ExifHandler().handle(exif, metadata);
-        assertEquals("Should be ISO date without time zone", "2000-01-01T00:00:00", metadata.get(DublinCore.DATE));
+        assertEquals("Should be ISO date without time zone", "2000-01-01T00:00:00", metadata.get(Metadata.DATE));
     }
 
     public void testExifHandlerParseDateFallback() throws MetadataException {
@@ -77,7 +77,7 @@ public class ImageMetadataExtractorTest extends TestCase {
         Metadata metadata = new Metadata();
         
         new ImageMetadataExtractor.ExifHandler().handle(exif, metadata);
-        assertEquals("Should try EXIF Date/Time if Original is not set", "1999-01-01T00:00:00", metadata.get(DublinCore.DATE));
+        assertEquals("Should try EXIF Date/Time if Original is not set", "1999-01-01T00:00:00", metadata.get(Metadata.DATE));
     }
     
     public void testExifHandlerParseDateError() throws MetadataException {
@@ -88,7 +88,7 @@ public class ImageMetadataExtractorTest extends TestCase {
         Metadata metadata = new Metadata();
         
         new ImageMetadataExtractor.ExifHandler().handle(exif, metadata);
-        assertEquals("Parsing should proceed without date", null, metadata.get(DublinCore.DATE));
+        assertEquals("Parsing should proceed without date", null, metadata.get(Metadata.DATE));
     }
     
     public void testCopyUnknownFieldsHandler() throws MetadataException {
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/image/MetadataFieldsTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/image/MetadataFieldsTest.java
index 3b145bd7c..c16e865bf 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/image/MetadataFieldsTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/image/MetadataFieldsTest.java
@@ -16,7 +16,7 @@
  */
 package org.apache.tika.parser.image;
 
-import org.apache.tika.metadata.DublinCore;
+import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.TIFF;
 
 import junit.framework.TestCase;
@@ -26,7 +26,7 @@ public class MetadataFieldsTest extends TestCase {
     public void testIsMetadataField() {
         assertFalse(MetadataFields.isMetadataField("random string that is not a field"));
         assertFalse(MetadataFields.isMetadataField("xyz"));
-        assertTrue(MetadataFields.isMetadataField(DublinCore.SUBJECT));
+        assertTrue(MetadataFields.isMetadataField(Metadata.SUBJECT));
         assertTrue(MetadataFields.isMetadataField(TIFF.F_NUMBER.getName()));
     }
 

Commit:
291e16752deafa76864dcbc6bfdf0032c79dbf7b
Nick Burch
nick@apache.org
2012-05-16 17:27:38 +0000
TIKA-917 Expand platform and architecture parsing
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/executable/ExecutableParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/executable/ExecutableParser.java
index 55d4e5dc6..d585cc029 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/executable/ExecutableParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/executable/ExecutableParser.java
@@ -88,6 +88,7 @@ public class ExecutableParser extends AbstractParser implements MachineMetadata
     public void parsePE(XHTMLContentHandler xhtml, Metadata metadata,
           InputStream stream, byte[] first4) throws TikaException, IOException {
        metadata.add(Metadata.CONTENT_TYPE, PE_EXE.toString());
+       metadata.set(PLATFORM, PLATFORM_WINDOWS);
        
        // Skip over the MS-DOS bit
        byte[] msdosSection = new byte[0x3c-4];
@@ -134,19 +135,91 @@ public class ExecutableParser extends AbstractParser implements MachineMetadata
             metadata.set(ENDIAN, Endian.LITTLE.getName());
             metadata.set(ARCHITECTURE_BITS, "32");
             break;
-
          case 0x8664:
             metadata.set(MACHINE_TYPE, MACHINE_x86_32);
             metadata.set(ENDIAN, Endian.LITTLE.getName());
             metadata.set(ARCHITECTURE_BITS, "64");
             break;
-
          case 0x200:
             metadata.set(MACHINE_TYPE, MACHINE_IA_64);
             metadata.set(ENDIAN, Endian.LITTLE.getName());
             metadata.set(ARCHITECTURE_BITS, "64");
             break;
             
+         case 0x184:
+            metadata.set(MACHINE_TYPE, MACHINE_ALPHA);
+            metadata.set(ENDIAN, Endian.LITTLE.getName());
+            metadata.set(ARCHITECTURE_BITS, "32");
+            break;
+         case 0x284:
+            metadata.set(MACHINE_TYPE, MACHINE_ALPHA);
+            metadata.set(ENDIAN, Endian.LITTLE.getName());
+            metadata.set(ARCHITECTURE_BITS, "64");
+            break;
+            
+         case 0x1c0:
+         case 0x1c4:
+            metadata.set(MACHINE_TYPE, MACHINE_ARM);
+            metadata.set(ENDIAN, Endian.LITTLE.getName());
+            metadata.set(ARCHITECTURE_BITS, "32");
+            break;
+
+         case 0x268:
+            metadata.set(MACHINE_TYPE, MACHINE_M68K);
+            metadata.set(ENDIAN, Endian.BIG.getName());
+            metadata.set(ARCHITECTURE_BITS, "32");
+            break;
+
+         case 0x266:
+         case 0x366:
+         case 0x466:
+            metadata.set(MACHINE_TYPE, MACHINE_MIPS);
+            metadata.set(ENDIAN, Endian.BIG.getName());
+            metadata.set(ARCHITECTURE_BITS, "16");
+            break;
+         case 0x162:
+         case 0x166:
+         case 0x168:
+         case 0x169:
+            metadata.set(MACHINE_TYPE, MACHINE_MIPS);
+            metadata.set(ENDIAN, Endian.LITTLE.getName());
+            metadata.set(ARCHITECTURE_BITS, "16");
+            break;
+            
+         case 0x1f0:
+         case 0x1f1:
+            metadata.set(MACHINE_TYPE, MACHINE_PPC);
+            metadata.set(ENDIAN, Endian.LITTLE.getName());
+            metadata.set(ARCHITECTURE_BITS, "32");
+            break;
+            
+         case 0x1a2:
+         case 0x1a3:
+            metadata.set(MACHINE_TYPE, MACHINE_SH3);
+            metadata.set(ENDIAN, Endian.BIG.getName());
+            metadata.set(ARCHITECTURE_BITS, "32");
+            break;
+         case 0x1a6:
+            metadata.set(MACHINE_TYPE, MACHINE_SH4);
+            metadata.set(ENDIAN, Endian.BIG.getName());
+            metadata.set(ARCHITECTURE_BITS, "32");
+            break;
+         case 0x1a8:
+            metadata.set(MACHINE_TYPE, MACHINE_SH3);
+            metadata.set(ENDIAN, Endian.BIG.getName());
+            metadata.set(ARCHITECTURE_BITS, "32");
+            break;
+
+         case 0x9041:
+            metadata.set(MACHINE_TYPE, MACHINE_M32R);
+            metadata.set(ENDIAN, Endian.BIG.getName());
+            metadata.set(ARCHITECTURE_BITS, "32");
+            break;
+
+         case 0xebc:
+            metadata.set(MACHINE_TYPE, MACHINE_EFI);
+            break;
+
          default:
             metadata.set(MACHINE_TYPE, MACHINE_UNKNOWN);
             break;
@@ -181,6 +254,57 @@ public class ExecutableParser extends AbstractParser implements MachineMetadata
        // Byte 9 is the OS (specific) ABI version
        int os = stream.read();
        int osVer = stream.read();
+       // TODO Fix up, doesn't seem to be working
+//       switch (os) {
+//         case 0:
+//            metadata.set(PLATFORM, PLATFORM_SYSV);
+//            break;
+//            
+//         case 1:
+//            metadata.set(PLATFORM, PLATFORM_HPUX);
+//            break;
+//            
+//         case 2:
+//            metadata.set(PLATFORM, PLATFORM_NETBSD);
+//            break;
+//            
+//         case 3:
+//            metadata.set(PLATFORM, PLATFORM_LINUX);
+//            break;
+//            
+//         case 6:
+//            metadata.set(PLATFORM, PLATFORM_SOLARIS);
+//            break;
+//            
+//         case 7:
+//            metadata.set(PLATFORM, PLATFORM_AIX);
+//            break;
+//            
+//         case 8:
+//            metadata.set(PLATFORM, PLATFORM_IRIX);
+//            break;
+//            
+//         case 9:
+//            metadata.set(PLATFORM, PLATFORM_FREEBSD);
+//            break;
+//            
+//         case 10:
+//            metadata.set(PLATFORM, PLATFORM_TRU64);
+//            break;
+//            
+//         case 12:
+//            metadata.set(PLATFORM, PLATFORM_FREEBSD);
+//            break;
+//            
+//         case 64:
+//         case 97:
+//            metadata.set(PLATFORM, PLATFORM_ARM);
+//            break;
+//            
+//         case 255:
+//            metadata.set(PLATFORM, PLATFORM_EMBEDDED);
+//            break;
+//       }
        
        // Bytes 10-16 are padding and lengths
        byte[] padLength = new byte[7];
@@ -223,15 +347,53 @@ public class ExecutableParser extends AbstractParser implements MachineMetadata
           machine = EndianUtils.readUShortBE(stream);
        }
        switch(machine) {
+         case 2:
+         case 18:
+         case 43:
+            metadata.set(MACHINE_TYPE, MACHINE_SPARC);
+            break;
          case 3:
             metadata.set(MACHINE_TYPE, MACHINE_x86_32);
             break;
+         case 4:
+            metadata.set(MACHINE_TYPE, MACHINE_M68K);
+            break;
+         case 5:
+            metadata.set(MACHINE_TYPE, MACHINE_M88K);
+            break;
+         case 8:
+         case 10:
+            metadata.set(MACHINE_TYPE, MACHINE_MIPS);
+            break;
+         case 7:
+            metadata.set(MACHINE_TYPE, MACHINE_S370);
+            break;
+         case 20:
+         case 21:
+            metadata.set(MACHINE_TYPE, MACHINE_PPC);
+            break;
+         case 22:
+            metadata.set(MACHINE_TYPE, MACHINE_S390);
+            break;
+         case 40:
+            metadata.set(MACHINE_TYPE, MACHINE_ARM);
+            break;
+         case 41:
+         case 0x9026:
+            metadata.set(MACHINE_TYPE, MACHINE_ALPHA);
+            break;
          case 50:
             metadata.set(MACHINE_TYPE, MACHINE_IA_64);
             break;
          case 62:
             metadata.set(MACHINE_TYPE, MACHINE_x86_64);
             break;
+         case 75:
+            metadata.set(MACHINE_TYPE, MACHINE_VAX);
+            break;
+         case 88:
+            metadata.set(MACHINE_TYPE, MACHINE_M32R);
+            break;
        }
        
        // Bytes 20-23 are the version
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/executable/MachineMetadata.java b/tika-parsers/src/main/java/org/apache/tika/parser/executable/MachineMetadata.java
index 569c86b51..f860dfdd9 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/executable/MachineMetadata.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/executable/MachineMetadata.java
@@ -33,6 +33,7 @@ public interface MachineMetadata {
     public static final String PLATFORM_NETBSD  = "NetBSD";
     public static final String PLATFORM_LINUX   = "Linux";
     public static final String PLATFORM_SOLARIS = "Solaris";
+    public static final String PLATFORM_AIX     = "AIX";
     public static final String PLATFORM_IRIX    = "IRIX";
     public static final String PLATFORM_FREEBSD = "FreeBSD";
     public static final String PLATFORM_TRU64   = "Tru64";
@@ -42,26 +43,35 @@ public interface MachineMetadata {
     
     public static Property PLATFORM = Property.internalClosedChoise(PREFIX+"platform", 
           new String[] { PLATFORM_SYSV, PLATFORM_HPUX, PLATFORM_NETBSD, PLATFORM_LINUX,
-                         PLATFORM_SOLARIS, PLATFORM_IRIX, PLATFORM_FREEBSD, PLATFORM_TRU64,
+                         PLATFORM_SOLARIS, PLATFORM_AIX, PLATFORM_IRIX, PLATFORM_FREEBSD, PLATFORM_TRU64,
                          PLATFORM_ARM, PLATFORM_EMBEDDED, PLATFORM_WINDOWS });
     
     public static final String MACHINE_x86_32 = "x86-32";
     public static final String MACHINE_x86_64 = "x86-64";
-    public static final String MACHINE_IA_64 = "IA-64";
-    public static final String MACHINE_SPARC = "SPARC";
-    public static final String MACHINE_M68K = "Motorola-68000";
-    public static final String MACHINE_M88K = "Motorola-88000";
-    public static final String MACHINE_MIPS = "MIPS";
-    public static final String MACHINE_PPC = "PPC";
-    public static final String MACHINE_S390 = "S390";
-    public static final String MACHINE_ARM = "ARM"; // TODO Multiple?
-    public static final String MACHINE_VAX = "Vax";
+    public static final String MACHINE_IA_64  = "IA-64";
+    public static final String MACHINE_SPARC  = "SPARC";
+    public static final String MACHINE_M68K   = "Motorola-68000";
+    public static final String MACHINE_M88K   = "Motorola-88000";
+    public static final String MACHINE_MIPS   = "MIPS";
+    public static final String MACHINE_PPC    = "PPC";
+    public static final String MACHINE_S370   = "S370";
+    public static final String MACHINE_S390   = "S390";
+    public static final String MACHINE_ARM    = "ARM";
+    public static final String MACHINE_VAX    = "Vax";
+    public static final String MACHINE_ALPHA  = "Alpha";
+    public static final String MACHINE_EFI    = "EFI"; // EFI ByteCode
+    public static final String MACHINE_M32R   = "M32R";
+    public static final String MACHINE_SH3    = "SH3";
+    public static final String MACHINE_SH4    = "SH4";
+    public static final String MACHINE_SH5    = "SH5";
     public static final String MACHINE_UNKNOWN = "Unknown";
     
     public static Property MACHINE_TYPE = Property.internalClosedChoise(PREFIX+"machineType", 
           new String[] { MACHINE_x86_32, MACHINE_x86_64, MACHINE_IA_64, MACHINE_SPARC,
-                         MACHINE_M68K, MACHINE_M88K, MACHINE_MIPS, MACHINE_PPC, MACHINE_S390,
-                         MACHINE_ARM, MACHINE_VAX, MACHINE_UNKNOWN });
+                         MACHINE_M68K, MACHINE_M88K, MACHINE_MIPS, MACHINE_PPC, 
+                         MACHINE_S370, MACHINE_S390,
+                         MACHINE_ARM, MACHINE_VAX, MACHINE_ALPHA, MACHINE_EFI, MACHINE_M32R,
+                         MACHINE_SH3, MACHINE_SH4, MACHINE_SH5, MACHINE_UNKNOWN });
     
     public static final class Endian {
        private String name;
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/executable/ExecutableParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/executable/ExecutableParserTest.java
index bbbc2296d..74b96f1ba 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/executable/ExecutableParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/executable/ExecutableParserTest.java
@@ -46,6 +46,8 @@ public class ExecutableParserTest extends TestCase {
                   metadata.get(ExecutableParser.ENDIAN));
             assertEquals("32", 
                   metadata.get(ExecutableParser.ARCHITECTURE_BITS));
+            assertEquals("Windows", 
+                  metadata.get(ExecutableParser.PLATFORM));
 
             String content = handler.toString();
             assertEquals("", content); // No text yet
@@ -71,6 +73,8 @@ public class ExecutableParserTest extends TestCase {
                metadata.get(ExecutableParser.ENDIAN));
          assertEquals("32", 
                metadata.get(ExecutableParser.ARCHITECTURE_BITS));
+//         assertEquals("Linux", 
+//               metadata.get(ExecutableParser.PLATFORM));
 
          String content = handler.toString();
          assertEquals("", content); // No text yet

Commit:
22e9376b611fd8b5089737288452e8745a5214c4
Nick Burch
nick@apache.org
2012-05-16 16:32:41 +0000
TIKA-917 Pull the property definitions out to their own class, add more machine types, and define the platform
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/executable/ExecutableParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/executable/ExecutableParser.java
index 5f59deb88..55d4e5dc6 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/executable/ExecutableParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/executable/ExecutableParser.java
@@ -29,7 +29,6 @@ import org.apache.poi.util.LittleEndian;
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.io.EndianUtils;
 import org.apache.tika.metadata.Metadata;
-import org.apache.tika.metadata.Property;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.parser.AbstractParser;
 import org.apache.tika.parser.ParseContext;
@@ -40,37 +39,10 @@ import org.xml.sax.SAXException;
 /**
  * Parser for executable files. Currently supports ELF and PE
  */
-public class ExecutableParser extends AbstractParser {
-
+public class ExecutableParser extends AbstractParser implements MachineMetadata {
     /** Serial version UID */
     private static final long serialVersionUID = 32128791892482l;
 
-    // TODO Put these somewhere more general
-    public static final String MACHINE_x86_32 = "x86-32";
-    public static final String MACHINE_x86_64 = "x86-64";
-    public static final String MACHINE_IA_64 = "IA-64";
-    public static final String MACHINE_UNKNOWN = "Unknown";
-    // TODO The rest
-    public static Property MACHINE_TYPE = Property.internalClosedChoise("machine", 
-          new String[] { MACHINE_x86_32, MACHINE_x86_64, MACHINE_UNKNOWN });
-    
-    public static Property ARCHITECTURE = Property.internalClosedChoise("architecture", 
-          new String[] { "32", "64" });
-    
-    public static final class Endian {
-       private String name;
-       private boolean msb;
-       public String getName() { return name; }
-       public boolean isMSB() { return msb; }
-       public String getMSB() { if(msb) { return "MSB"; } else { return "LSB"; } }
-       private Endian(String name, boolean msb) { this.name = name; this.msb = msb; }
-       
-       public static final Endian LITTLE_ENDIAN = new Endian("Little", false);
-       public static final Endian BIG_ENDIAN = new Endian("Big", true);
-    }
-    public static Property ENDIAN = Property.internalClosedChoise("endian", 
-          new String[] { Endian.LITTLE_ENDIAN.name, Endian.BIG_ENDIAN.name });
-    
     private static final MediaType PE_EXE = MediaType.application("x-msdownload");
     private static final MediaType ELF_GENERAL = MediaType.application("x-elf");
     private static final MediaType ELF_OBJECT = MediaType.application("x-object");
@@ -159,20 +131,20 @@ public class ExecutableParser extends AbstractParser {
        switch(machine) {
          case 0x14c:
             metadata.set(MACHINE_TYPE, MACHINE_x86_32);
-            metadata.set(ENDIAN, Endian.LITTLE_ENDIAN.name);
-            metadata.set(ARCHITECTURE, "32");
+            metadata.set(ENDIAN, Endian.LITTLE.getName());
+            metadata.set(ARCHITECTURE_BITS, "32");
             break;
 
          case 0x8664:
             metadata.set(MACHINE_TYPE, MACHINE_x86_32);
-            metadata.set(ENDIAN, Endian.LITTLE_ENDIAN.name);
-            metadata.set(ARCHITECTURE, "64");
+            metadata.set(ENDIAN, Endian.LITTLE.getName());
+            metadata.set(ARCHITECTURE_BITS, "64");
             break;
 
          case 0x200:
             metadata.set(MACHINE_TYPE, MACHINE_IA_64);
-            metadata.set(ENDIAN, Endian.LITTLE_ENDIAN.name);
-            metadata.set(ARCHITECTURE, "64");
+            metadata.set(ENDIAN, Endian.LITTLE.getName());
+            metadata.set(ARCHITECTURE_BITS, "64");
             break;
             
          default:
@@ -189,17 +161,17 @@ public class ExecutableParser extends AbstractParser {
        // Byte 5 is the architecture
        int architecture = stream.read();
        if (architecture == 1) {
-          metadata.set(ARCHITECTURE, "32");
+          metadata.set(ARCHITECTURE_BITS, "32");
        } else if (architecture == 2) {
-          metadata.set(ARCHITECTURE, "64");          
+          metadata.set(ARCHITECTURE_BITS, "64");          
        }
        
        // Byte 6 is the endian-ness
        int endian = stream.read();
        if (endian == 1) {
-          metadata.set(ENDIAN, Endian.LITTLE_ENDIAN.name);
+          metadata.set(ENDIAN, Endian.LITTLE.getName());
        } else if (endian == 2) {
-          metadata.set(ENDIAN, Endian.BIG_ENDIAN.name);
+          metadata.set(ENDIAN, Endian.BIG.getName());
        }
        
        // Byte 7 is the elf version
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/executable/MachineMetadata.java b/tika-parsers/src/main/java/org/apache/tika/parser/executable/MachineMetadata.java
new file mode 100644
index 000000000..569c86b51
--- /dev/null
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/executable/MachineMetadata.java
@@ -0,0 +1,79 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.parser.executable;
+
+import org.apache.tika.metadata.Property;
+
+/**
+ * Metadata for describing machines, such as their
+ *  architecture, type and endian-ness
+ */
+public interface MachineMetadata {
+    public static final String PREFIX = "machine:";
+   
+    public static Property ARCHITECTURE_BITS = Property.internalClosedChoise(PREFIX+"architectureBits", 
+         new String[] { "8", "16", "32", "64" });
+
+    public static final String PLATFORM_SYSV    = "System V";
+    public static final String PLATFORM_HPUX    = "HP-UX";
+    public static final String PLATFORM_NETBSD  = "NetBSD";
+    public static final String PLATFORM_LINUX   = "Linux";
+    public static final String PLATFORM_SOLARIS = "Solaris";
+    public static final String PLATFORM_IRIX    = "IRIX";
+    public static final String PLATFORM_FREEBSD = "FreeBSD";
+    public static final String PLATFORM_TRU64   = "Tru64";
+    public static final String PLATFORM_ARM     = "ARM"; // ARM architecture ABI
+    public static final String PLATFORM_EMBEDDED = "Embedded"; // Stand-alone (embedded) ABI
+    public static final String PLATFORM_WINDOWS = "Windows";
+    
+    public static Property PLATFORM = Property.internalClosedChoise(PREFIX+"platform", 
+          new String[] { PLATFORM_SYSV, PLATFORM_HPUX, PLATFORM_NETBSD, PLATFORM_LINUX,
+                         PLATFORM_SOLARIS, PLATFORM_IRIX, PLATFORM_FREEBSD, PLATFORM_TRU64,
+                         PLATFORM_ARM, PLATFORM_EMBEDDED, PLATFORM_WINDOWS });
+    
+    public static final String MACHINE_x86_32 = "x86-32";
+    public static final String MACHINE_x86_64 = "x86-64";
+    public static final String MACHINE_IA_64 = "IA-64";
+    public static final String MACHINE_SPARC = "SPARC";
+    public static final String MACHINE_M68K = "Motorola-68000";
+    public static final String MACHINE_M88K = "Motorola-88000";
+    public static final String MACHINE_MIPS = "MIPS";
+    public static final String MACHINE_PPC = "PPC";
+    public static final String MACHINE_S390 = "S390";
+    public static final String MACHINE_ARM = "ARM"; // TODO Multiple?
+    public static final String MACHINE_VAX = "Vax";
+    public static final String MACHINE_UNKNOWN = "Unknown";
+    
+    public static Property MACHINE_TYPE = Property.internalClosedChoise(PREFIX+"machineType", 
+          new String[] { MACHINE_x86_32, MACHINE_x86_64, MACHINE_IA_64, MACHINE_SPARC,
+                         MACHINE_M68K, MACHINE_M88K, MACHINE_MIPS, MACHINE_PPC, MACHINE_S390,
+                         MACHINE_ARM, MACHINE_VAX, MACHINE_UNKNOWN });
+    
+    public static final class Endian {
+       private String name;
+       private boolean msb;
+       public String getName() { return name; }
+       public boolean isMSB() { return msb; }
+       public String getMSB() { if(msb) { return "MSB"; } else { return "LSB"; } }
+       private Endian(String name, boolean msb) { this.name = name; this.msb = msb; }
+       
+       public static final Endian LITTLE = new Endian("Little", false);
+       public static final Endian BIG = new Endian("Big", true);
+    }
+    public static Property ENDIAN = Property.internalClosedChoise(PREFIX+"endian", 
+          new String[] { Endian.LITTLE.name, Endian.BIG.name });
+}
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/executable/ExecutableParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/executable/ExecutableParserTest.java
index 9acba5c6d..bbbc2296d 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/executable/ExecutableParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/executable/ExecutableParserTest.java
@@ -45,7 +45,7 @@ public class ExecutableParserTest extends TestCase {
             assertEquals("Little", 
                   metadata.get(ExecutableParser.ENDIAN));
             assertEquals("32", 
-                  metadata.get(ExecutableParser.ARCHITECTURE));
+                  metadata.get(ExecutableParser.ARCHITECTURE_BITS));
 
             String content = handler.toString();
             assertEquals("", content); // No text yet
@@ -70,7 +70,7 @@ public class ExecutableParserTest extends TestCase {
          assertEquals("Little", 
                metadata.get(ExecutableParser.ENDIAN));
          assertEquals("32", 
-               metadata.get(ExecutableParser.ARCHITECTURE));
+               metadata.get(ExecutableParser.ARCHITECTURE_BITS));
 
          String content = handler.toString();
          assertEquals("", content); // No text yet

Commit:
4a0641765bdd155c4a7acafb474becb47fee617e
Michael McCandless
mikemccand@apache.org
2012-05-15 22:41:36 +0000
remove leftover sop
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
index b556a6f4e..1bb180512 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
@@ -152,7 +152,6 @@ public class IWorkParserTest extends TestCase {
         for(int row=1;row<=3;row++) {
           assertTrue(content.contains("row" + row));
         }
-        System.out.println("MKM done");
     }
 
     /**

Commit:
a42f88a863eaebcdb020c55923d1c2d94b18fe27
Michael McCandless
mikemccand@apache.org
2012-05-15 21:42:50 +0000
add iWork test case
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
index 24cb7d012..b556a6f4e 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
@@ -139,6 +139,22 @@ public class IWorkParserTest extends TestCase {
         assertTrue(content.contains("Try adding your own account transactions to this table."));
     }
 
+    public void testParseNumbersTableHeaders() throws Exception {
+        InputStream input = IWorkParserTest.class.getResourceAsStream("/test-documents/tableHeaders.numbers");
+        Metadata metadata = new Metadata();
+        ContentHandler handler = new BodyContentHandler();
+        iWorkParser.parse(input, handler, metadata, parseContext);
+
+        String content = handler.toString();
+        for(int header=1;header<=5;header++) {
+          assertTrue(content.contains("header" + header));
+        }
+        for(int row=1;row<=3;row++) {
+          assertTrue(content.contains("row" + row));
+        }
+        System.out.println("MKM done");
+    }
+
     /**
      * We don't currently support password protected Pages files, as
      *  we don't know how the encryption works (it's not regular Zip
diff --git a/tika-parsers/src/test/resources/test-documents/tableHeaders.numbers b/tika-parsers/src/test/resources/test-documents/tableHeaders.numbers
new file mode 100644
index 000000000..8ed0b9f1b
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/tableHeaders.numbers differ

Commit:
cd6533b19a855d3aeef6243dfae2adece659277f
Nick Burch
nick@apache.org
2012-05-13 18:47:19 +0000
TIKA-917 Start on a parser for PE and ELF executables, to output metadata
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 88c53d4f4..c9f4e546a 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -2450,7 +2450,8 @@
     <sub-class-of type="application/x-elf"/>
     <magic priority="50">
       <match value="\177ELF" type="string" offset="0">
-        <match value="0x01" type="string" offset="16"/>
+        <match value="0x0100" type="string" offset="16"/>
+        <match value="0x0001" type="string" offset="16"/>
       </match>
     </magic>
   </mime-type>
@@ -2458,7 +2459,8 @@
     <sub-class-of type="application/x-elf"/>
     <magic priority="50">
       <match value="\177ELF" type="string" offset="0">
-        <match value="0x02" type="string" offset="16"/>
+        <match value="0x0200" type="string" offset="16"/>
+        <match value="0x0002" type="string" offset="16"/>
       </match>
     </magic>
   </mime-type>
@@ -2466,7 +2468,8 @@
     <sub-class-of type="application/x-elf"/>
     <magic priority="50">
       <match value="\177ELF" type="string" offset="0">
-        <match value="0x03" type="string" offset="16"/>
+        <match value="0x0300" type="string" offset="16"/>
+        <match value="0x0003" type="string" offset="16"/>
       </match>
     </magic>
   </mime-type>
@@ -2474,7 +2477,8 @@
     <sub-class-of type="application/x-elf"/>
     <magic priority="50">
       <match value="\177ELF" type="string" offset="0">
-        <match value="0x04" type="string" offset="16"/>
+        <match value="0x0400" type="string" offset="16"/>
+        <match value="0x0004" type="string" offset="16"/>
       </match>
     </magic>
   </mime-type>
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/executable/ExecutableParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/executable/ExecutableParser.java
new file mode 100644
index 000000000..5f59deb88
--- /dev/null
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/executable/ExecutableParser.java
@@ -0,0 +1,268 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.parser.executable;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.sql.Date;
+import java.util.Arrays;
+import java.util.Collections;
+import java.util.HashSet;
+import java.util.Set;
+
+import org.apache.poi.util.IOUtils;
+import org.apache.poi.util.LittleEndian;
+import org.apache.tika.exception.TikaException;
+import org.apache.tika.io.EndianUtils;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.Property;
+import org.apache.tika.mime.MediaType;
+import org.apache.tika.parser.AbstractParser;
+import org.apache.tika.parser.ParseContext;
+import org.apache.tika.sax.XHTMLContentHandler;
+import org.xml.sax.ContentHandler;
+import org.xml.sax.SAXException;
+
+/**
+ * Parser for executable files. Currently supports ELF and PE
+ */
+public class ExecutableParser extends AbstractParser {
+
+    /** Serial version UID */
+    private static final long serialVersionUID = 32128791892482l;
+
+    // TODO Put these somewhere more general
+    public static final String MACHINE_x86_32 = "x86-32";
+    public static final String MACHINE_x86_64 = "x86-64";
+    public static final String MACHINE_IA_64 = "IA-64";
+    public static final String MACHINE_UNKNOWN = "Unknown";
+    // TODO The rest
+    public static Property MACHINE_TYPE = Property.internalClosedChoise("machine", 
+          new String[] { MACHINE_x86_32, MACHINE_x86_64, MACHINE_UNKNOWN });
+    
+    public static Property ARCHITECTURE = Property.internalClosedChoise("architecture", 
+          new String[] { "32", "64" });
+    
+    public static final class Endian {
+       private String name;
+       private boolean msb;
+       public String getName() { return name; }
+       public boolean isMSB() { return msb; }
+       public String getMSB() { if(msb) { return "MSB"; } else { return "LSB"; } }
+       private Endian(String name, boolean msb) { this.name = name; this.msb = msb; }
+       
+       public static final Endian LITTLE_ENDIAN = new Endian("Little", false);
+       public static final Endian BIG_ENDIAN = new Endian("Big", true);
+    }
+    public static Property ENDIAN = Property.internalClosedChoise("endian", 
+          new String[] { Endian.LITTLE_ENDIAN.name, Endian.BIG_ENDIAN.name });
+    
+    private static final MediaType PE_EXE = MediaType.application("x-msdownload");
+    private static final MediaType ELF_GENERAL = MediaType.application("x-elf");
+    private static final MediaType ELF_OBJECT = MediaType.application("x-object");
+    private static final MediaType ELF_EXECUTABLE = MediaType.application("x-executable");
+    private static final MediaType ELF_SHAREDLIB = MediaType.application("x-sharedlib");
+    private static final MediaType ELF_COREDUMP = MediaType.application("x-coredump");
+    private static final Set<MediaType> SUPPORTED_TYPES =
+            Collections.unmodifiableSet(new HashSet<MediaType>(Arrays.asList(
+            		PE_EXE,
+                  ELF_GENERAL,
+                  ELF_OBJECT, ELF_EXECUTABLE, ELF_SHAREDLIB, ELF_COREDUMP
+            )));
+    public Set<MediaType> getSupportedTypes(ParseContext context) {
+        return SUPPORTED_TYPES;
+    }
+
+    public void parse(
+            InputStream stream, ContentHandler handler,
+            Metadata metadata, ParseContext context)
+            throws IOException, SAXException, TikaException {
+        // We only do metadata, for now
+        XHTMLContentHandler xhtml = new XHTMLContentHandler(handler, metadata);
+
+        // What kind is it?
+        byte[] first4 = new byte[4];
+        IOUtils.readFully(stream, first4);
+        
+        if (first4[0] == (byte)'M' && first4[1] == (byte)'Z') {
+           parsePE(xhtml, metadata, stream, first4);
+        } else if (first4[0] == (byte)0x7f && first4[1] == (byte)'E' &&
+                   first4[2] == (byte)'L' && first4[3] == (byte)'F') {
+           parseELF(xhtml, metadata, stream, first4);
+        }
+        
+        
+        // Finish everything
+        xhtml.endDocument();
+    }
+
+    /**
+     * Parses a DOS or Windows PE file
+     */
+    public void parsePE(XHTMLContentHandler xhtml, Metadata metadata,
+          InputStream stream, byte[] first4) throws TikaException, IOException {
+       metadata.add(Metadata.CONTENT_TYPE, PE_EXE.toString());
+       
+       // Skip over the MS-DOS bit
+       byte[] msdosSection = new byte[0x3c-4];
+       IOUtils.readFully(stream, msdosSection);
+       
+       // Grab the PE header offset
+       int peOffset = LittleEndian.readInt(stream);
+       
+       // Sanity check - while it may go anywhere, it's normally in the first few kb
+       if (peOffset > 4096 || peOffset < 0x3f) return;
+       
+       // Skip the rest of the MS-DOS stub (if PE), until we reach what should
+       //  be the PE header (if this is a PE executable)
+       stream.skip(peOffset - 0x40);
+       
+       // Read the PE header
+       byte[] pe = new byte[24];
+       IOUtils.readFully(stream, pe);
+       
+       // Check it really is a PE header
+       if (pe[0] == (byte)'P' && pe[1] == (byte)'E' && pe[2]==0 && pe[3]==0) {
+          // Good, has a valid PE signature
+       } else {
+          // Old style MS-DOS
+          return;
+       }
+       
+       // Read the header values
+       int machine    = LittleEndian.getUShort(pe, 4);
+       int numSectors = LittleEndian.getUShort(pe, 6);
+       long createdAt = LittleEndian.getInt(pe, 8);
+       long symbolTableOffset = LittleEndian.getInt(pe, 12);
+       long numSymbols = LittleEndian.getInt(pe, 16);
+       int sizeOptHdrs = LittleEndian.getUShort(pe, 20);
+       int characteristcs = LittleEndian.getUShort(pe, 22);
+       
+       // Turn this into helpful metadata
+       Date createdAtD = new Date(createdAt*1000l);
+       metadata.set(Metadata.CREATION_DATE, createdAtD);
+       
+       switch(machine) {
+         case 0x14c:
+            metadata.set(MACHINE_TYPE, MACHINE_x86_32);
+            metadata.set(ENDIAN, Endian.LITTLE_ENDIAN.name);
+            metadata.set(ARCHITECTURE, "32");
+            break;
+
+         case 0x8664:
+            metadata.set(MACHINE_TYPE, MACHINE_x86_32);
+            metadata.set(ENDIAN, Endian.LITTLE_ENDIAN.name);
+            metadata.set(ARCHITECTURE, "64");
+            break;
+
+         case 0x200:
+            metadata.set(MACHINE_TYPE, MACHINE_IA_64);
+            metadata.set(ENDIAN, Endian.LITTLE_ENDIAN.name);
+            metadata.set(ARCHITECTURE, "64");
+            break;
+            
+         default:
+            metadata.set(MACHINE_TYPE, MACHINE_UNKNOWN);
+            break;
+       }
+    }
+
+    /**
+     * Parses a Unix ELF file
+     */
+    public void parseELF(XHTMLContentHandler xhtml, Metadata metadata,
+          InputStream stream, byte[] first4) throws TikaException, IOException {
+       // Byte 5 is the architecture
+       int architecture = stream.read();
+       if (architecture == 1) {
+          metadata.set(ARCHITECTURE, "32");
+       } else if (architecture == 2) {
+          metadata.set(ARCHITECTURE, "64");          
+       }
+       
+       // Byte 6 is the endian-ness
+       int endian = stream.read();
+       if (endian == 1) {
+          metadata.set(ENDIAN, Endian.LITTLE_ENDIAN.name);
+       } else if (endian == 2) {
+          metadata.set(ENDIAN, Endian.BIG_ENDIAN.name);
+       }
+       
+       // Byte 7 is the elf version
+       int elfVer = stream.read();
+       
+       // Byte 8 is the OS
+       // Byte 9 is the OS (specific) ABI version
+       int os = stream.read();
+       int osVer = stream.read();
+       
+       // Bytes 10-16 are padding and lengths
+       byte[] padLength = new byte[7];
+       IOUtils.readFully(stream, padLength);
+       
+       // Bytes 16-17 are the object type (LE/BE)
+       int type;
+       if (endian == 1) {
+          type = EndianUtils.readUShortLE(stream);
+       } else {
+          type = EndianUtils.readUShortBE(stream);
+       }
+       switch(type) {
+         case 1:
+            metadata.add(Metadata.CONTENT_TYPE, ELF_OBJECT.toString());
+            break;
+            
+         case 2:
+            metadata.add(Metadata.CONTENT_TYPE, ELF_EXECUTABLE.toString());
+            break;
+            
+         case 3:
+            metadata.add(Metadata.CONTENT_TYPE, ELF_SHAREDLIB.toString());
+            break;
+            
+         case 4:
+            metadata.add(Metadata.CONTENT_TYPE, ELF_COREDUMP.toString());
+            break;
+            
+         default:
+            metadata.add(Metadata.CONTENT_TYPE, ELF_GENERAL.toString());
+            break;
+       }
+                 
+       // Bytes 18-19 are the machine (EM_*)
+       int machine;
+       if (endian == 1) {
+          machine = EndianUtils.readUShortLE(stream);
+       } else {
+          machine = EndianUtils.readUShortBE(stream);
+       }
+       switch(machine) {
+         case 3:
+            metadata.set(MACHINE_TYPE, MACHINE_x86_32);
+            break;
+         case 50:
+            metadata.set(MACHINE_TYPE, MACHINE_IA_64);
+            break;
+         case 62:
+            metadata.set(MACHINE_TYPE, MACHINE_x86_64);
+            break;
+       }
+       
+       // Bytes 20-23 are the version
+       // TODO
+    }
+}
diff --git a/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.parser.Parser b/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.parser.Parser
index b3f6dc1dc..284751525 100644
--- a/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.parser.Parser
+++ b/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.parser.Parser
@@ -18,6 +18,7 @@ org.apache.tika.parser.audio.AudioParser
 org.apache.tika.parser.audio.MidiParser
 org.apache.tika.parser.dwg.DWGParser
 org.apache.tika.parser.epub.EpubParser
+org.apache.tika.parser.executable.ExecutableParser
 org.apache.tika.parser.feed.FeedParser
 org.apache.tika.parser.font.AdobeFontMetricParser
 org.apache.tika.parser.font.TrueTypeParser
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/executable/ExecutableParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/executable/ExecutableParserTest.java
new file mode 100644
index 000000000..9acba5c6d
--- /dev/null
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/executable/ExecutableParserTest.java
@@ -0,0 +1,82 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.parser.executable;
+
+import java.io.InputStream;
+
+import junit.framework.TestCase;
+
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.parser.ParseContext;
+import org.apache.tika.sax.BodyContentHandler;
+import org.xml.sax.ContentHandler;
+
+public class ExecutableParserTest extends TestCase {
+
+    public void testWin32Parser() throws Exception {
+        InputStream input = ExecutableParserTest.class.getResourceAsStream(
+                "/test-documents/testWindows-x86-32.exe");
+        try {
+            Metadata metadata = new Metadata();
+            ContentHandler handler = new BodyContentHandler();
+            new ExecutableParser().parse(input, handler, metadata, new ParseContext());
+
+            assertEquals("application/x-msdownload",
+                    metadata.get(Metadata.CONTENT_TYPE));
+            assertEquals("2012-05-13T13:40:11Z",
+                    metadata.get(Metadata.CREATION_DATE));
+            
+            assertEquals(ExecutableParser.MACHINE_x86_32, 
+                    metadata.get(ExecutableParser.MACHINE_TYPE));
+            assertEquals("Little", 
+                  metadata.get(ExecutableParser.ENDIAN));
+            assertEquals("32", 
+                  metadata.get(ExecutableParser.ARCHITECTURE));
+
+            String content = handler.toString();
+            assertEquals("", content); // No text yet
+        } finally {
+            input.close();
+        }
+    }
+    
+    public void testElfParser_x86_32() throws Exception {
+       InputStream input = ExecutableParserTest.class.getResourceAsStream(
+             "/test-documents/testLinux-x86-32");
+     try {
+         Metadata metadata = new Metadata();
+         ContentHandler handler = new BodyContentHandler();
+         new ExecutableParser().parse(input, handler, metadata, new ParseContext());
+
+         assertEquals("application/x-executable",
+                 metadata.get(Metadata.CONTENT_TYPE));
+         
+         assertEquals(ExecutableParser.MACHINE_x86_32, 
+                 metadata.get(ExecutableParser.MACHINE_TYPE));
+         assertEquals("Little", 
+               metadata.get(ExecutableParser.ENDIAN));
+         assertEquals("32", 
+               metadata.get(ExecutableParser.ARCHITECTURE));
+
+         String content = handler.toString();
+         assertEquals("", content); // No text yet
+     } finally {
+         input.close();
+     }       
+    }
+
+}

Commit:
47a66ff77bb93e9087f71d4e666b300a6726ccfe
Nick Burch
nick@apache.org
2012-05-13 13:47:04 +0000
TIKA-917 A few sample files for Linux-ELF, and a PE32 one, plus the C file
diff --git a/tika-parsers/src/test/resources/test-documents/testC.c b/tika-parsers/src/test/resources/test-documents/testC.c
new file mode 100644
index 000000000..ebc72c824
--- /dev/null
+++ b/tika-parsers/src/test/resources/test-documents/testC.c
@@ -0,0 +1,6 @@
+#include <stdio.h>
+
+int main ()
+{
+  printf ("Apache Tika!\n");
+}
diff --git a/tika-parsers/src/test/resources/test-documents/testLinux-arm-32le b/tika-parsers/src/test/resources/test-documents/testLinux-arm-32le
new file mode 100755
index 000000000..22a362f61
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testLinux-arm-32le differ
diff --git a/tika-parsers/src/test/resources/test-documents/testLinux-mips-32be b/tika-parsers/src/test/resources/test-documents/testLinux-mips-32be
new file mode 100755
index 000000000..3c67dcef3
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testLinux-mips-32be differ
diff --git a/tika-parsers/src/test/resources/test-documents/testLinux-mips-32le b/tika-parsers/src/test/resources/test-documents/testLinux-mips-32le
new file mode 100755
index 000000000..445e6a7e8
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testLinux-mips-32le differ
diff --git a/tika-parsers/src/test/resources/test-documents/testLinux-ppc-32be b/tika-parsers/src/test/resources/test-documents/testLinux-ppc-32be
new file mode 100755
index 000000000..2b4e6fe74
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testLinux-ppc-32be differ
diff --git a/tika-parsers/src/test/resources/test-documents/testLinux-x86-32 b/tika-parsers/src/test/resources/test-documents/testLinux-x86-32
new file mode 100755
index 000000000..784e4bed3
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testLinux-x86-32 differ
diff --git a/tika-parsers/src/test/resources/test-documents/testLinux-x86-64 b/tika-parsers/src/test/resources/test-documents/testLinux-x86-64
new file mode 100755
index 000000000..941128295
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testLinux-x86-64 differ
diff --git a/tika-parsers/src/test/resources/test-documents/testWindows-x86-32.exe b/tika-parsers/src/test/resources/test-documents/testWindows-x86-32.exe
new file mode 100755
index 000000000..b1a38b1cc
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testWindows-x86-32.exe differ

Commit:
e59e664a5cc17b5a0cc5be27986a5424719efcf5
Nick Burch
nick@apache.org
2012-05-10 11:52:05 +0000
TIKA-915 related - add mime magic for the elf format too, based on the mimetypes in the httpd magic file
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 208be3230..88c53d4f4 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -2441,6 +2441,44 @@
     <glob pattern="*.elc"/>
   </mime-type>
 
+  <mime-type type="application/x-elf">
+    <magic priority="50">
+      <match value="\177ELF" type="string" offset="0" />
+    </magic>
+  </mime-type>
+  <mime-type type="application/x-object">
+    <sub-class-of type="application/x-elf"/>
+    <magic priority="50">
+      <match value="\177ELF" type="string" offset="0">
+        <match value="0x01" type="string" offset="16"/>
+      </match>
+    </magic>
+  </mime-type>
+  <mime-type type="application/x-executable">
+    <sub-class-of type="application/x-elf"/>
+    <magic priority="50">
+      <match value="\177ELF" type="string" offset="0">
+        <match value="0x02" type="string" offset="16"/>
+      </match>
+    </magic>
+  </mime-type>
+  <mime-type type="application/x-sharedlib">
+    <sub-class-of type="application/x-elf"/>
+    <magic priority="50">
+      <match value="\177ELF" type="string" offset="0">
+        <match value="0x03" type="string" offset="16"/>
+      </match>
+    </magic>
+  </mime-type>
+  <mime-type type="application/x-coredump">
+    <sub-class-of type="application/x-elf"/>
+    <magic priority="50">
+      <match value="\177ELF" type="string" offset="0">
+        <match value="0x04" type="string" offset="16"/>
+      </match>
+    </magic>
+  </mime-type>
+
   <mime-type type="application/x-emf">
     <acronym>EMF</acronym>
     <_comment>Extended Metafile</_comment>

Commit:
28ae6120609d6303044588f6882bcfd72e607843
Nick Burch
nick@apache.org
2012-05-10 11:37:13 +0000
TIKA-913 Mime Magic for PE, PE32 and PE64 executables
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 93844e40d..208be3230 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -2677,13 +2677,83 @@
   <mime-type type="application/x-msclip">
     <glob pattern="*.clp"/>
   </mime-type>
+
   <mime-type type="application/x-msdownload">
     <glob pattern="*.exe"/>
     <glob pattern="*.dll"/>
     <glob pattern="*.com"/>
     <glob pattern="*.bat"/>
     <glob pattern="*.msi"/>
+    <magic priority="50">
+      <match value="MZ" type="string" offset="0"/>
+    </magic>
+  </mime-type>
+  <mime-type type="application/x-msdownload;format=pe">
+    <sub-class-of type="application/x-msdownload"/>
+    <magic priority="55">
+      <!-- Technically the header offset is stored at 0x3c, and isn't a -->
+      <!-- constant, but it's almost always set to start at 0x80 or 0xf0 -->
+      <match value="PE\000\000" type="string" offset="128"/>
+      <match value="PE\000\000" type="string" offset="240"/>
+    </magic>
+  </mime-type>
+  <!-- the PE header should be PEx00x00 then a two byte machine type -->
+  <mime-type type="application/x-msdownload;format=pe32">
+    <sub-class-of type="application/x-msdownload;format=pe"/>
+    <magic priority="60">
+      <match value="PE\000\000" type="string" offset="128">
+         <match value="0x014c" type="little16" offset="132"/>
+      </match>
+      <match value="PE\000\000" type="string" offset="240">
+         <match value="0x014c" type="little16" offset="244"/>
+      </match>
+    </magic>
+  </mime-type>
+  <mime-type type="application/x-msdownload;format=pe64">
+    <sub-class-of type="application/x-msdownload;format=pe"/>
+    <magic priority="60">
+      <match value="PE\000\000" type="string" offset="128">
+         <match value="0x8664" type="little16" offset="132"/>
+      </match>
+      <match value="PE\000\000" type="string" offset="240">
+         <match value="0x8664" type="little16" offset="244"/>
+      </match>
+    </magic>
   </mime-type>
+  <mime-type type="application/x-msdownload;format=pe-itanium">
+    <sub-class-of type="application/x-msdownload;format=pe"/>
+    <magic priority="60">
+      <match value="PE\000\000" type="string" offset="128">
+         <match value="0x0200" type="little16" offset="132"/>
+      </match>
+      <match value="PE\000\000" type="string" offset="240">
+         <match value="0x0200" type="little16" offset="244"/>
+      </match>
+    </magic>
+  </mime-type>
+  <mime-type type="application/x-msdownload;format=pe-armLE">
+    <sub-class-of type="application/x-msdownload;format=pe"/>
+    <magic priority="60">
+      <match value="pe\000\000" type="string" offset="128">
+         <match value="0x01c0" type="little16" offset="132"/>
+      </match>
+      <match value="pe\000\000" type="string" offset="240">
+         <match value="0x01c0" type="little16" offset="244"/>
+      </match>
+    </magic>
+  </mime-type>
+  <mime-type type="application/x-msdownload;format=pe-arm7">
+    <sub-class-of type="application/x-msdownload;format=pe"/>
+    <magic priority="60">
+      <match value="pe\000\000" type="string" offset="128">
+         <match value="0x01c4" type="little16" offset="132"/>
+      </match>
+      <match value="pe\000\000" type="string" offset="240">
+         <match value="0x01c4" type="little16" offset="244"/>
+      </match>
+    </magic>
+  </mime-type>
+
   <mime-type type="application/x-msmediaview">
     <glob pattern="*.mvb"/>
     <glob pattern="*.m13"/>

Commit:
e2f1ef5cef672bf52400f35fc33ff4a123c2db16
Nick Burch
nick@apache.org
2012-05-09 14:36:42 +0000
Whoops, properly disable the test for TIKA-915 this time...
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/jpeg/JpegParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/jpeg/JpegParserTest.java
index 1feea276d..cccbe35a2 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/jpeg/JpegParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/jpeg/JpegParserTest.java
@@ -121,7 +121,7 @@ public class JpegParserTest extends TestCase {
      *  different way, see TIKA-915 for details
      * Disabled for now, pending a fix to the underlying library
      */
-    public void testJPEGGeo2() throws Exception {
+    public void DISABLEDtestJPEGGeo2() throws Exception {
        Metadata metadata = new Metadata();
        metadata.set(Metadata.CONTENT_TYPE, "image/jpeg");
        InputStream stream =

Commit:
b90d72d36534d5b175b86b8584afd4f236f47696
Nick Burch
nick@apache.org
2012-05-09 14:33:52 +0000
Patch from Ray Gauss II from TIKA-915 - add a disabled unit and a small sample file for the geo rounding problem
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/jpeg/JpegParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/jpeg/JpegParserTest.java
index 6f06b2b17..1feea276d 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/jpeg/JpegParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/jpeg/JpegParserTest.java
@@ -73,6 +73,9 @@ public class JpegParserTest extends TestCase {
         assertFalse(keywords.contains("canon-55-250 moscow-birds serbor"));
     }
 
+    /**
+     * Test for a file with Geographic information (lat, long etc) in it
+     */
     public void testJPEGGeo() throws Exception {
         Metadata metadata = new Metadata();
         metadata.set(Metadata.CONTENT_TYPE, "image/jpeg");
@@ -112,6 +115,23 @@ public class JpegParserTest extends TestCase {
                 "2009-08-11T09:09:45", metadata.get(TIFF.ORIGINAL_DATE));
         assertEquals("canon-55-250", metadata.getValues(Metadata.KEYWORDS)[0]);
     }
+
+    /**
+     * Test for an image with the geographic information stored in a slightly
+     *  different way, see TIKA-915 for details
+     * Disabled for now, pending a fix to the underlying library
+     */
+    public void testJPEGGeo2() throws Exception {
+       Metadata metadata = new Metadata();
+       metadata.set(Metadata.CONTENT_TYPE, "image/jpeg");
+       InputStream stream =
+          getClass().getResourceAsStream("/test-documents/testJPEG_GEO_2.jpg");
+       parser.parse(stream, new DefaultHandler(), metadata, new ParseContext());
+
+       // Geo tags should be there with 5dp, and not rounded
+       assertEquals("51.57576", metadata.get(Metadata.LATITUDE));
+       assertEquals("-1.56788", metadata.get(Metadata.LONGITUDE));
+    }
     
     public void testJPEGTitleAndDescription() throws Exception {
         Metadata metadata = new Metadata();
diff --git a/tika-parsers/src/test/resources/test-documents/testJPEG_GEO_2.jpg b/tika-parsers/src/test/resources/test-documents/testJPEG_GEO_2.jpg
new file mode 100644
index 000000000..a9397c3f3
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testJPEG_GEO_2.jpg differ

Commit:
fdec3f36c00edd7e8c466661626330efb8272b75
Michael McCandless
mikemccand@apache.org
2012-05-04 20:32:08 +0000
remove stale nocommit
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OutlookExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OutlookExtractor.java
index 18819264d..491d528f7 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OutlookExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OutlookExtractor.java
@@ -191,7 +191,6 @@ public class OutlookExtractor extends AbstractPOIFSExtractor {
                  data = ((StringChunk)htmlChunk).getRawValue();
               }
               if(data != null) {
-                  // nocommit same problem here?
                  HtmlParser htmlParser = new HtmlParser();
                  htmlParser.parse(
                        new ByteArrayInputStream(data),

Commit:
9b1fcfd577232315ffe5c1d39ec40aac4e4879a8
Nick Burch
nick@apache.org
2012-05-04 14:38:34 +0000
Add Adobe AfterEffects mimetypes, fix up the Adobe Premier detection, and give .AEP to AfterEffects as it seems much more common now than AudioGraph
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 3910ff441..93844e40d 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -593,6 +593,12 @@
   <mime-type type="application/vnd.adobe.air-application-installer-package+zip">
     <glob pattern="*.air"/>
   </mime-type>
+  <mime-type type="application/vnd.adobe.aftereffects.project">
+    <glob pattern="*.aep"/>
+  </mime-type>
+  <mime-type type="application/vnd.adobe.aftereffects.template">
+    <glob pattern="*.aet"/>
+  </mime-type>
   <mime-type type="application/vnd.adobe.xdp+xml">
     <glob pattern="*.xdp"/>
   </mime-type>
@@ -654,9 +660,7 @@
   <mime-type type="application/vnd.arastra.swi">
     <glob pattern="*.swi"/>
   </mime-type>
-  <mime-type type="application/vnd.audiograph">
-    <glob pattern="*.aep"/>
-  </mime-type>
+  <mime-type type="application/vnd.audiograph"/>
   <mime-type type="application/vnd.autopackage"/>
   <mime-type type="application/vnd.avistar+xml"/>
   <mime-type type="application/vnd.blueice.multipass">
@@ -3497,6 +3501,8 @@
 
   <mime-type type="image/vnd.adobe.premiere">
     <glob pattern="*.ppj"/>
+    <root-XML localName="PremiereData"/>
+    <sub-class-of type="application/xml"/>
   </mime-type>
 
   <mime-type type="image/vnd.cns.inf2"/>
diff --git a/tika-core/src/test/java/org/apache/tika/TikaDetectionTest.java b/tika-core/src/test/java/org/apache/tika/TikaDetectionTest.java
index a95947cfa..dd319081a 100644
--- a/tika-core/src/test/java/org/apache/tika/TikaDetectionTest.java
+++ b/tika-core/src/test/java/org/apache/tika/TikaDetectionTest.java
@@ -158,7 +158,8 @@ public class TikaDetectionTest extends TestCase {
         assertEquals("application/vnd.antix.game-component", tika.detect("x.atx"));
         assertEquals("application/vnd.apple.installer+xml", tika.detect("x.mpkg"));
         assertEquals("application/vnd.arastra.swi", tika.detect("x.swi"));
-        assertEquals("application/vnd.audiograph", tika.detect("x.aep"));
+        // Differ from httpd - Adobe After Effects is a much more common user of .AEP these days
+        //assertEquals("application/vnd.audiograph", tika.detect("x.aep"));
         assertEquals("application/vnd.blueice.multipass", tika.detect("x.mpm"));
         assertEquals("application/vnd.bmi", tika.detect("x.bmi"));
         assertEquals("application/vnd.businessobjects", tika.detect("x.rep"));

Commit:
824a2b4a35e49052b86fed3e7deb5dada53994be
Jukka Zitting
jukka@apache.org
2012-04-30 08:24:13 +0000
Add a .gitignore file for people using the git mirrors
diff --git a/.gitignore b/.gitignore
new file mode 100644
index 000000000..260bf1351
--- /dev/null
+++ b/.gitignore
@@ -0,0 +1,8 @@
+target
+.idea
+.classpath
+.project
+.settings
+*.iml
+*.ipr
+*.iws

Commit:
0204adc0f4d3ff6e10f94a82bad442625e81a7fb
Nick Burch
nick@apache.org
2012-04-29 16:43:16 +0000
TIKA-858 Fix Java 1.6isms
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/iptc/IptcAnpaParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/iptc/IptcAnpaParser.java
index aea9fc699..fc946d5fd 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/iptc/IptcAnpaParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/iptc/IptcAnpaParser.java
@@ -794,11 +794,6 @@ public class IptcAnpaParser implements Parser {
          value = "";
       }
 
-      try {
-         String tmpvalue = new String(value.getBytes(Charset.forName("UTF-8")),"UTF-8");
-         value = tmpvalue;
-      }
-      catch (UnsupportedEncodingException eue) {}
       value = value.replaceAll("``", "`");
       value = value.replaceAll("''", "'");
       value = value.replaceAll(new String(new char[] {SL}), "'");

Commit:
9543dfafc94be216a24897a08ea002396927971a
Nick Burch
nick@apache.org
2012-04-29 16:42:10 +0000
TIKA-858 Fix Java 1.6isms
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/iptc/IptcAnpaParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/iptc/IptcAnpaParser.java
index f7befad6f..aea9fc699 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/iptc/IptcAnpaParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/iptc/IptcAnpaParser.java
@@ -468,7 +468,7 @@ public class IptcAnpaParser implements Parser {
                   // hit the delimiter, carry on
                   val_next =  (read < value.length) ? value[read++] : 0x00;
                }
-               while (!bdy_heading.isEmpty() && ((val_next == CR) || (val_next == LF))) {
+               while (bdy_heading.length() > 0 && ((val_next == CR) || (val_next == LF))) {
                   val_next =  (read < value.length) ? value[read++] : 0x00;  // skip the new lines
                   if ((val_next != CR) && (val_next != LF)) {
                      --read;
@@ -519,7 +519,7 @@ public class IptcAnpaParser implements Parser {
                   val_next =  (read < value.length) ? value[read++] : 0x00;
                }
 
-               while (!bdy_title.isEmpty() && ((val_next == CR) || (val_next == LF))) {
+               while (bdy_title.length() > 0 && ((val_next == CR) || (val_next == LF))) {
                   val_next =  (read < value.length) ? value[read++] : 0x00;  // skip the new lines
                   if ((val_next != CR) && (val_next != LF)) {
                      --read;
@@ -687,9 +687,9 @@ public class IptcAnpaParser implements Parser {
       properties.put("author", bdy_author);
       properties.put("source", bdy_source);
 
-      added = (!bdy_body.isEmpty() || !bdy_title.isEmpty() || !bdy_heading.isEmpty() || !bdy_author.isEmpty() || !bdy_source.isEmpty());
-
-      return (added);
+      added = (bdy_body.length() + bdy_title.length() + bdy_heading.length() + bdy_author.length() +
+               bdy_source.length()) > 0;
+      return added;
    }
 
 
@@ -726,7 +726,7 @@ public class IptcAnpaParser implements Parser {
             val_next =  (read < value.length) ? value[read++] : 0x00;
          }
 
-         if (!ftr_datetime.isEmpty()) {
+         if (ftr_datetime.length() > 0) {
             // we want to pass this back in a more friendly format
             String format_out = "yyyy-MM-dd'T'HH:mm:ss'Z'";
             Date dateunix = new Date();
@@ -762,9 +762,8 @@ public class IptcAnpaParser implements Parser {
       properties.put("created", ftr_datetime);
       properties.put("modified", ftr_datetime);
 
-      added = (!ftr_source.isEmpty() || !ftr_datetime.isEmpty());
-
-      return (added);
+      added = (ftr_source.length() + ftr_datetime.length()) > 0; 
+      return added;
    }
 
 
@@ -782,19 +781,15 @@ public class IptcAnpaParser implements Parser {
 //      metadata.set(Metadata.PUBLISHER,     clean(properties.get("publisher")));
       metadata.set(Metadata.PUBLISHER,     clean(this.getFormatName()));
 
-
 /*
         metadata.set(DublinCore.DATE, font.getHeader().getCreated().getTime());
         metadata.set(
                 Property.internalDate(DublinCore.MODIFIED),
                 font.getHeader().getModified().getTime());
 */
-
    }
 
-
    private String clean(String value) {
-
       if (value == null) {
          value = "";
       }
@@ -814,5 +809,4 @@ public class IptcAnpaParser implements Parser {
 
       return (value);
    }
-   
 }

Commit:
f0107444a5f038ba6f087e517a8d87530122a0a9
Nick Burch
nick@apache.org
2012-04-28 18:17:58 +0000
TIKA-858 Fix Java 1.6isms
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/iptc/IptcAnpaParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/iptc/IptcAnpaParser.java
index 7c15f490a..f7befad6f 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/iptc/IptcAnpaParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/iptc/IptcAnpaParser.java
@@ -18,23 +18,19 @@ package org.apache.tika.parser.iptc;
 
 import java.io.IOException;
 import java.io.InputStream;
+import java.io.UnsupportedEncodingException;
+import java.nio.charset.Charset;
+import java.text.ParseException;
+import java.text.SimpleDateFormat;
 import java.util.Collections;
-import java.util.Set;
-import java.util.HashMap;
-
 import java.util.Date;
+import java.util.HashMap;
+import java.util.Set;
 import java.util.TimeZone;
-import java.text.DateFormat;
-import java.text.SimpleDateFormat;
-import java.text.ParseException;
-import java.nio.charset.Charset;
-import java.io.UnsupportedEncodingException;
 
 import org.apache.tika.exception.TikaException;
-import org.apache.tika.io.TikaInputStream;
 import org.apache.tika.metadata.DublinCore;
 import org.apache.tika.metadata.Metadata;
-import org.apache.tika.metadata.Property;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.parser.Parser;
@@ -46,6 +42,8 @@ import org.xml.sax.SAXException;
  * Parser for IPTC ANPA New Wire Feeds
  */
 public class IptcAnpaParser implements Parser {
+    /** Serial version UID */
+    private static final long serialVersionUID = -6062820170212879115L;
 
     private static final MediaType TYPE =
         MediaType.text("vnd.iptc.anpa");
@@ -410,7 +408,7 @@ public class IptcAnpaParser implements Parser {
          // pull apart the envelope, getting the date and time
          while (read < value.length) {
             byte val_next = value[read++];
-            if (hdr_date.isEmpty()) {
+            if (hdr_date.length() == 0) {
                while (((val_next >= (byte)0x30) && (val_next <= (byte)0x39))  // consume all numerics and hyphens
                   ||   (val_next == HY)) {
                   hdr_date += (char)(val_next & 0xff);  // convert the byte to an unsigned int
@@ -436,12 +434,11 @@ public class IptcAnpaParser implements Parser {
 
       // if we were saving any of these values, we would set the properties map here
 
-      added = (!env_serviceid.isEmpty() || !env_category.isEmpty() || !hdr_subject.isEmpty() || !hdr_date.isEmpty() || !hdr_time.isEmpty());
-
-      return (added);
+      added = (env_serviceid.length() + env_category.length() + hdr_subject.length() + 
+               hdr_date.length() + hdr_time.length()) > 0; 
+      return added;
    }
 
-
    private boolean parseBody(byte[] value, HashMap<String,String> properties) {
       boolean added = false;
 

Commit:
de7092125649cd61840e27b1f70d68cfab910d89
Nick Burch
nick@apache.org
2012-04-28 16:53:35 +0000
TIKA-858 Patch from Craig Stires to add support for parsing IPTC ANPA News Wire Feeds
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 02be578ea..3910ff441 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -4137,6 +4137,14 @@
   <mime-type type="text/vnd.in3d.spot">
     <glob pattern="*.spot"/>
   </mime-type>
+  <mime-type type="text/vnd.iptc.anpa">
+    <acronym>ANPA</acronym>
+    <_comment>American Newspaper Publishers Association Wire Feeds</_comment>
+    <glob pattern="*.anpa"/>
+    <magic priority="50">
+      <match value="\x16\x16\x01" type="string" offset="0"/>
+    </magic>
+  </mime-type>
   <mime-type type="text/vnd.iptc.newsml"/>
   <mime-type type="text/vnd.iptc.nitf"/>
   <mime-type type="text/vnd.latex-z"/>
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/iptc/IptcAnpaParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/iptc/IptcAnpaParser.java
new file mode 100644
index 000000000..7c15f490a
--- /dev/null
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/iptc/IptcAnpaParser.java
@@ -0,0 +1,821 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.parser.iptc;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.util.Collections;
+import java.util.Set;
+import java.util.HashMap;
+
+import java.util.Date;
+import java.util.TimeZone;
+import java.text.DateFormat;
+import java.text.SimpleDateFormat;
+import java.text.ParseException;
+import java.nio.charset.Charset;
+import java.io.UnsupportedEncodingException;
+
+import org.apache.tika.exception.TikaException;
+import org.apache.tika.io.TikaInputStream;
+import org.apache.tika.metadata.DublinCore;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.Property;
+import org.apache.tika.mime.MediaType;
+import org.apache.tika.parser.ParseContext;
+import org.apache.tika.parser.Parser;
+import org.apache.tika.sax.XHTMLContentHandler;
+import org.xml.sax.ContentHandler;
+import org.xml.sax.SAXException;
+
+/**
+ * Parser for IPTC ANPA New Wire Feeds
+ */
+public class IptcAnpaParser implements Parser {
+
+    private static final MediaType TYPE =
+        MediaType.text("vnd.iptc.anpa");
+
+    private static final Set<MediaType> SUPPORTED_TYPES =
+        Collections.singleton(TYPE);
+
+    public Set<MediaType> getSupportedTypes(ParseContext context) {
+        return SUPPORTED_TYPES;
+    }
+
+    public void parse(
+           InputStream stream, ContentHandler handler,
+           Metadata metadata, ParseContext context)
+           throws IOException, SAXException, TikaException {
+
+        HashMap<String,String> properties = this.loadProperties(stream);
+        this.setMetadata(metadata, properties);
+
+        XHTMLContentHandler xhtml = new XHTMLContentHandler(handler, metadata);
+        xhtml.startDocument();
+        // TODO: put body content here
+        xhtml.startElement("p");
+        String body = clean(properties.get("body"));
+        if (body != null)
+           xhtml.characters(body);
+        xhtml.endElement("p");
+        xhtml.endDocument();
+    }
+
+    /**
+     * @deprecated This method will be removed in Apache Tika 1.0.
+     */
+    public void parse(
+            InputStream stream, ContentHandler handler, Metadata metadata)
+            throws IOException, SAXException, TikaException {
+        parse(stream, handler, metadata, new ParseContext());
+    }
+
+
+   private int FMT_ANPA_1312    = 0x00;   // "NAA 89-3 (ANPA 1312)"
+   private int FMT_ANPA_UPI     = 0x01;   // "United Press International ANPA 1312 variant"
+   private int FMT_ANPA_UPI_DL  = 0x02;   // "United Press International Down-Load Message"
+   private int FMT_IPTC_7901    = 0x03;   // "IPTC7901 Recommended Message Format"
+   private int FMT_IPTC_PHOTO   = 0x04;   // "IPTC-NAA Digital Newsphoto Parameter Record"
+   private int FMT_IPTC_CHAR    = 0x05;   // "IPTC Unstructured Character Oriented File Format (UCOFF)"
+   private int FMT_NITF         = 0x06;   // "News Industry Text Format (NITF)"
+   private int FMT_NITF_TT      = 0x07;   // "Tidningarnas Telegrambyra NITF version (TTNITF DTD)"
+   private int FMT_NITF_RB      = 0x08;   // "Ritzaus Bureau NITF version (RBNITF DTD)"
+   private int FMT_IPTC_AP      = 0x09;   // "Associated Press news wire format"
+   private int FMT_IPTC_BLM     = 0x0A;   // "Bloomberg News news wire format"
+   private int FMT_IPTC_NYT     = 0x0B;   // "New York Times news wire format"
+   private int FMT_IPTC_RTR     = 0x0C;   // "Reuters news wire format"
+
+   private int FORMAT = FMT_ANPA_1312;    // assume the default format to be ANPA-1312
+
+   private final static char SOH = 0x01;    // start of header (ctrl-a)
+   private final static char STX = 0x02;    // start of text (ctrl-b)
+   private final static char ETX = 0x03;    // end of text (ctrl-c)
+   private final static char EOT = 0x04;    // the tab character (ctrl-d)
+   private final static char SYN = 0x16;    // synchronous idle (ctrl-v)
+
+   private final static char BS = 0x08;    // the backspace character (used for diacriticals)
+   private final static char TB = 0x09;    // the tab character
+   private final static char LF = 0x0A;    // line feed
+   private final static char FF = 0x0C;    // form feed
+   private final static char CR = 0x0D;    // carriage return
+   private final static char XQ = 0x11;    // device control (ctrl-q)
+   private final static char XS = 0x13;    // device control (ctrl-s)
+   private final static char FS = 0x1F;    // a field delimiter
+
+   private final static char HY = 0x2D;    // hyphen
+   private final static char SP = 0x20;    // the blank space
+   private final static char LT = 0x3C;    // less than
+   private final static char EQ = 0x3D;    // less than
+   private final static char CT = 0x5E;    // carat
+
+   private final static char SL = 0x91;    // single-quote left
+   private final static char SR = 0x92;    // single-quote right
+   private final static char DL = 0x93;    // double-quote left
+   private final static char DR = 0x94;    // double-quote right
+
+
+   /**
+    * scan the news messsage and store the metadata and data into a map
+    */
+   private HashMap<String,String> loadProperties(InputStream is) {
+      
+      HashMap<String,String> properties = new HashMap<String,String>();
+
+      FORMAT = this.scanFormat(is);
+
+      byte[] residual = this.getSection(is,"residual");
+
+      byte[] header = this.getSection(is,"header");
+      parseHeader(header, properties);
+
+      byte[] body = this.getSection(is,"body");
+      parseBody(body, properties);
+
+      byte[] footer = this.getSection(is,"footer");
+      parseFooter(footer, properties);
+       
+      return (properties);
+   }
+
+
+   private int scanFormat(InputStream is) {
+      int format    = this.FORMAT;
+      int  maxsize  = 524288;     //  512K
+
+      byte[] buf = new byte[maxsize];
+      try {
+         if (is.markSupported()) {
+            is.mark(maxsize);
+         }
+         int msgsize = is.read(buf);                // read in at least the full data
+
+         String message = (new String(buf)).toLowerCase();
+         // these are not if-then-else, because we want to go from most common
+         // and fall through to least.  this is imperfect, as these tags could
+         // show up in other agency stories, but i can't find a spec or any
+         // explicit codes to identify the wire source in the message itself
+
+         if (message.contains("ap-wf")) {
+            format = this.FMT_IPTC_AP;
+         }
+         if (message.contains("reuters")) {
+            format = this.FMT_IPTC_RTR;
+         }
+         if (message.contains("new york times")) {
+            format = this.FMT_IPTC_NYT;
+         }
+         if (message.contains("bloomberg news")) {
+            format = this.FMT_IPTC_BLM;
+         }
+      }
+      catch (IOException eio) {
+         // we are in an unstable state
+      }
+
+      try {
+         if (is.markSupported()) {
+            is.reset();
+         }
+      }
+      catch (IOException eio) {
+         // we are in an unstable state
+      }
+      return (format);
+   }
+
+
+   private void setFormat(int format) {
+      this.FORMAT = format;
+   }
+
+
+   private String getFormatName() {
+      
+      String name = "";
+      
+      if (FORMAT == this.FMT_IPTC_AP) {
+         name = "Associated Press";
+      }
+      
+      else if(FORMAT == this.FMT_IPTC_BLM) {
+         name = "Bloomberg";
+      }
+
+      else if(FORMAT == this.FMT_IPTC_NYT) {
+         name = "New York Times";
+      }
+
+      else if(FORMAT == this.FMT_IPTC_RTR) {
+         name = "Reuters";
+      }
+
+      return (name);
+   }
+
+
+   private byte[] getSection(InputStream is, String name) {
+
+      byte[] value = new byte[0];
+
+      if (name.equals("residual")) {
+         // the header shouldn't be more than 1k, but just being generous here
+         int  maxsize  = 8192;     //  8K
+         byte bstart   = SYN;     // check for SYN [0x16 : ctrl-v] (may have leftover residue from preceding message)
+         byte bfinish  = SOH;     // check for SOH [0x01 : ctrl-a] (typically follows a pair of SYN [0x16 : ctrl-v])
+         value = getSection(is, maxsize, bstart, bfinish, true);
+      }
+
+      else if(name.equals("header")) {
+         // the header shouldn't be more than 1k, but just being generous here
+         int  maxsize  = 8192;     //  8K
+         byte bstart   = SOH;     // check for SOH [0x01 : ctrl-a] (typically follows a pair of SYN [0x16 : ctrl-v])
+         byte bfinish  = STX;     // check for STX [0x02 : ctrl-b] (marks end of header, beginning of message)
+         value = getSection(is, maxsize, bstart, bfinish, true);
+      }
+
+      else if (name.equals("body")) {
+         // the message shouldn't be more than 16k (?), leaving plenty of space
+         int  maxsize  = 524288;     //  512K
+         byte bstart   = STX;     // check for STX [0x02 : ctrl-b] (marks end of header, beginning of message)
+         byte bfinish  = ETX;     // check for ETX [0x03 : ctrl-c] (marks end of message, beginning of footer)
+         value = getSection(is, maxsize, bstart, bfinish, true);
+      }
+
+      else if (name.equals("footer")) {
+         // the footer shouldn't be more than 1k , leaving plenty of space
+         int maxsize   = 8192;     //  8K
+         byte bstart   = ETX;     // check for ETX [0x03 : ctrl-c] (marks end of message, beginning of footer)
+         byte bfinish  = EOT;     // check for EOT [0x04 : ctrl-d] (marks end of transmission)
+         value = getSection(is, maxsize, bstart, bfinish, true);
+      }
+
+      return (value);
+   }
+
+
+   private byte[] getSection(InputStream is, int maxsize, byte bstart, byte bfinish, boolean ifincomplete) {
+      byte[] value  = new byte[0];
+
+      try {
+         boolean started = false;                   // check if we have found the start flag
+         boolean finished = false;                  // check if we have found the finish flag
+         int read = 0;                              // the number of bytes we read
+         int start = 0;                             // the position after the start flag
+
+         // TODO: this only pulls back 8K of data on a read, regardless of buffer size
+         //       more nefariously, it caps at a total 8K, through all sections
+         int streammax = is.available();
+         maxsize = Math.min(maxsize, streammax);
+
+         is.mark(maxsize);
+         byte[] buf = new byte[maxsize];
+         int totsize = 0;
+         int remainder = maxsize - totsize;
+         while (remainder > 0) {
+            int msgsize = is.read(buf, maxsize-remainder, maxsize);    // read in at least the full data
+            if (msgsize == -1) {
+               remainder = msgsize = 0;
+            }
+            remainder -= msgsize;
+            totsize   += msgsize;
+         }
+
+         // scan through the provided input stream
+         for (read=0; read < totsize; read++) {
+            byte b = buf[read];
+
+            if (!started) {
+               started = (b == bstart);
+               start = read + 1;
+               continue;
+            }
+
+            if (finished = (b == bfinish)) {
+/*
+               is.reset();
+               long skipped = is.skip((long)read);
+               if (skipped != read) {
+                  // we are in an unstable state
+               }
+               is.mark(1);
+ */
+               break;
+            }
+
+            // load from the stream until we run out of characters, or hit the termination byte
+            continue;
+         }
+
+         // move the input stream back to where it was initially
+         is.reset();
+
+         if (finished) {
+            // now, we want to reset the stream to be sitting right on top of the finish marker
+            is.skip(read);
+            value = new byte[read-start];
+            System.arraycopy(buf, start, value, 0, read-start);
+         }
+         else {
+            if (ifincomplete && started) {
+               // the caller wants anything that was read, and we finished the stream or buffer
+               value = new byte[read-start];
+               System.arraycopy(buf, start, value, 0, read-start);
+            }
+         }
+      }
+      catch (IOException eio) {
+         // something invalid occurred, return an empty string
+      }
+
+      return (value);
+   }
+
+
+   private boolean parseHeader(byte[] value, HashMap<String,String> properties) {
+      boolean added = false;
+
+      String env_serviceid = "";
+      String env_category = "";
+      String env_urgency = "";
+      String hdr_edcode = "";
+      String hdr_subject = "";
+      String hdr_date = "";
+      String hdr_time = "";
+
+      int read = 0;
+
+      while (read < value.length) {
+
+         // pull apart the envelope, getting the service id  (....\x1f)
+         while (read < value.length) {
+            byte val_next = value[read++];
+            if (val_next != FS) {
+               env_serviceid += (char)(val_next & 0xff);  // convert the byte to an unsigned int
+            }
+            else {
+               break;
+            }
+         }
+
+         // pull apart the envelope, getting the category  (....\x13\x11)
+         while (read < value.length) {
+            byte val_next = value[read++];
+            if (val_next != XS) {   // the end of the envelope is marked (\x13)
+               env_category += (char)(val_next & 0xff);  // convert the byte to an unsigned int
+            }
+            else {
+               val_next = value[read];  // get the remaining byte (\x11)
+               if (val_next == XQ) {
+                  read++;
+               }
+               break;
+            }
+         }
+
+         // pull apart the envelope, getting the subject heading
+         while (read < value.length) {
+            boolean subject = true;
+            byte val_next = value[read++];
+            while ((subject) && (val_next != SP) && (val_next != 0x00)) {  // ignore the envelope subject
+               hdr_subject += (char)(val_next & 0xff);  // convert the byte to an unsigned int
+               val_next =  (read < value.length) ? value[read++] : 0x00;
+               while (val_next == SP) {  // consume all the spaces
+                  subject = false;
+                  val_next =  (read < value.length) ? value[read++] : 0x00;
+                  if (val_next != SP) {
+                     --read;  // otherwise we eat into the next section
+                  }
+               }
+            }
+            if (!subject) {
+               break;
+            }
+         }
+
+         // pull apart the envelope, getting the date and time
+         while (read < value.length) {
+            byte val_next = value[read++];
+            if (hdr_date.isEmpty()) {
+               while (((val_next >= (byte)0x30) && (val_next <= (byte)0x39))  // consume all numerics and hyphens
+                  ||   (val_next == HY)) {
+                  hdr_date += (char)(val_next & 0xff);  // convert the byte to an unsigned int
+                  val_next =  (read < value.length) ? value[read++] : 0x00;
+               }
+            }
+            else if (val_next == SP) {
+               while (val_next == SP) {  // consume all the spaces
+                  val_next =  (read < value.length) ? value[read++] : 0x00;
+               }
+               continue;
+            }
+            else {
+               while (((val_next >= (byte)0x30) && (val_next <= (byte)0x39))  // consume all numerics and hyphens
+                  ||   (val_next == HY)) {
+                  hdr_time += (char)(val_next & 0xff);  // convert the byte to an unsigned int
+                  val_next =  (read < value.length) ? value[read++] : 0x00;
+               }
+            }
+         }
+         break; // don't let this run back through and start thrashing metadata
+      }
+
+      // if we were saving any of these values, we would set the properties map here
+
+      added = (!env_serviceid.isEmpty() || !env_category.isEmpty() || !hdr_subject.isEmpty() || !hdr_date.isEmpty() || !hdr_time.isEmpty());
+
+      return (added);
+   }
+
+
+   private boolean parseBody(byte[] value, HashMap<String,String> properties) {
+      boolean added = false;
+
+      String bdy_heading = "";
+      String bdy_title = "";
+      String bdy_source = "";
+      String bdy_author = "";
+      String bdy_body = "";
+
+      int read = 0;
+      boolean done = false;
+
+      while (!done && (read < value.length)) {
+
+         // pull apart the body, getting the heading (^....\x0d\x0a)
+         while (read < value.length) {
+            byte val_next = value[read++];
+            if (val_next == CT) {      //  start of a new section , first is the heading
+               val_next =  (read < value.length) ? value[read++] : 0x00;
+               // AP, NYT, and Bloomberg end with < , Reuters with EOL
+               while ((val_next != LT) && (val_next != CR) && (val_next != LF)) {   // less than delimiter (\x3c) and not EOL
+                  bdy_heading += (char)(val_next & 0xff);  // convert the byte to an unsigned int
+                  val_next =  (read < value.length) ? value[read++] : 0x00;
+                  if (read > value.length) { break; }  // shouldn't ever hit this, but save a NPE
+               }
+               if (val_next == LT) {
+                  // hit the delimiter, carry on
+                  val_next =  (read < value.length) ? value[read++] : 0x00;
+               }
+               while (!bdy_heading.isEmpty() && ((val_next == CR) || (val_next == LF))) {
+                  val_next =  (read < value.length) ? value[read++] : 0x00;  // skip the new lines
+                  if ((val_next != CR) && (val_next != LF)) {
+                     --read;
+                  }
+               }
+            }
+            else {
+               // this will only be hit on poorly-formed files
+
+               // for reuters, the heading does not start with the ^, so we push one back into the stream
+               if (FORMAT == this.FMT_IPTC_RTR) {
+                  if (val_next != CT) {
+                     // for any non-whitespace, we need to go back an additional step to non destroy the data
+                     if ((val_next != SP) && (val_next != TB) && (val_next != CR) && (val_next != LF)) {
+                        // if the very first byte is data, we have to shift the whole array, and stuff in a carat
+                        if (read == 1) {
+                           byte[] resize = new byte[value.length + 1];
+                           System.arraycopy(value, 0, resize, 1, value.length);
+                           value = resize;
+                        }
+                     }
+                     value[--read] = CT;
+                     continue;
+                  }
+               }
+            }
+            break;
+         }
+
+         // pull apart the body, getting the title (^....\x0d\x0a)
+         while (read < value.length) {
+            byte val_next = value[read++];
+            if (val_next == CT) {      //  start of a new section , first is the heading
+               val_next =  (read < value.length) ? value[read++] : 0x00;
+               // AP, NYT, and Bloomberg end with < , Reuters with EOL
+               while ((val_next != LT) && (val_next != CT) && (val_next != CR) && (val_next != LF)) {   // less than delimiter (\x3c), or carat (\x5e) and not EOL
+                  bdy_title += (char)(val_next & 0xff);  // convert the byte to an unsigned int
+                  val_next =  (read < value.length) ? value[read++] : 0x00;
+                  if (read > value.length) { break; }  // shouldn't ever hit this, but save a NPE
+               }
+
+               if (val_next == CT) {      //  start of a new section , when first didn't finish cleanly
+                   --read;
+               }
+
+               if (val_next == LT) {
+                  // hit the delimiter, carry on
+                  val_next =  (read < value.length) ? value[read++] : 0x00;
+               }
+
+               while (!bdy_title.isEmpty() && ((val_next == CR) || (val_next == LF))) {
+                  val_next =  (read < value.length) ? value[read++] : 0x00;  // skip the new lines
+                  if ((val_next != CR) && (val_next != LF)) {
+                     --read;
+                  }
+               }
+            }
+            else {
+               // this will only be hit on poorly-formed files
+
+               // for bloomberg, the title does not start with the ^, so we push one back into the stream
+               if (FORMAT == this.FMT_IPTC_BLM) {
+                  if (val_next == TB) {
+                     value[--read] = CT;
+                     continue;
+                  }
+               }
+
+               // for reuters, the title does not start with the ^, so we push one back into the stream
+               if (FORMAT == this.FMT_IPTC_RTR) {
+                  if (val_next != CT) {
+                     // for any non-whitespace, we need to go back an additional step to non destroy the data
+                     if ((val_next != SP) && (val_next != TB) && (val_next != CR) && (val_next != LF)) {
+                        --read;
+                     }
+                     value[--read] = CT;
+                     continue;
+                  }
+               }
+            }
+            break;
+         }
+
+
+         // at this point, we have a variable number of metadata lines, with various orders
+         // we scan the start of each line for the special character, and run to the end character
+         // pull apart the body, getting the title (^....\x0d\x0a)
+         boolean metastarted = false;
+         String longline = "";
+         String longkey = "";
+         while (read < value.length) {
+            byte val_next = value[read++];
+
+            // eat up whitespace before committing to the next section
+            if ((val_next == SP) || (val_next == TB) || (val_next == CR) || (val_next == LF)) {
+               continue;
+            }
+
+            if (val_next == CT) {      //  start of a new section , could be authors, sources, etc
+               val_next =  (read < value.length) ? value[read++] : 0x00;
+               String tmp_line = "";
+               while ((val_next != LT) && (val_next != CT) && (val_next != CR) && (val_next != LF) && (val_next != 0))  {
+                  // less than delimiter (\x3c), maybe also badly formed with just new line
+                  tmp_line += (char)(val_next & 0xff);  // convert the byte to an unsigned int
+                  val_next =  (read < value.length) ? value[read++] : 0x00;
+                  if (read > value.length) { break; }  // shouldn't ever hit this, but save a NPE
+               }
+
+               if (val_next == CT) {      //  start of a new section , when first didn't finish cleanly
+                   --read;
+               }
+
+               if (val_next == LT) {
+                  // hit the delimiter, carry on
+                  val_next =  (read < value.length) ? value[read++] : 0x00;
+               }
+
+               while ((val_next == CR) || (val_next == LF)) {
+                  val_next =  (read < value.length) ? value[read++] : 0x00;  // skip the new lines
+                  if ((val_next != CR) && (val_next != LF)) {
+                     --read;
+                  }
+               }
+               if (tmp_line.toLowerCase().startsWith("by") || longline.equals("bdy_author")) {
+                  longkey = "bdy_author";
+
+                  // prepend a space to subsequent line, so it gets parsed consistent with the lead line
+                  tmp_line = (longline.equals(longkey) ? " " : "") + tmp_line;
+
+                  // we have an author candidate
+                  int term = tmp_line.length();
+                  term = Math.min(term, (tmp_line.indexOf("<")  > -1 ? tmp_line.indexOf("<")  : term));
+                  term = Math.min(term, (tmp_line.indexOf("=")  > -1 ? tmp_line.indexOf("=")  : term));
+                  term = Math.min(term, (tmp_line.indexOf("\n") > -1 ? tmp_line.indexOf("\n") : term));
+                  term = (term > 0 ) ? term : tmp_line.length();
+                  bdy_author += tmp_line.substring(tmp_line.indexOf(" "), term);
+                  metastarted = true;
+                  longline = ((tmp_line.indexOf("=")  > -1) && (!longline.equals(longkey)) ? longkey : "");
+               }
+               else if (FORMAT == this.FMT_IPTC_BLM) {
+                  String byline = "   by ";
+                  if (tmp_line.toLowerCase().contains(byline)) {
+                     longkey = "bdy_author";
+
+                     int term = tmp_line.length();
+                     term = Math.min(term, (tmp_line.indexOf("<")  > -1 ? tmp_line.indexOf("<")  : term));
+                     term = Math.min(term, (tmp_line.indexOf("=")  > -1 ? tmp_line.indexOf("=")  : term));
+                     term = Math.min(term, (tmp_line.indexOf("\n") > -1 ? tmp_line.indexOf("\n") : term));
+                     term = (term > 0 ) ? term : tmp_line.length();
+                     // for bloomberg, the author line sits below their copyright statement
+                     bdy_author += tmp_line.substring(tmp_line.toLowerCase().indexOf(byline) + byline.length(), term) + " ";
+                     metastarted = true;
+                     longline = ((tmp_line.indexOf("=")  > -1) && (!longline.equals(longkey)) ? longkey : "");
+                  }
+                  else if(tmp_line.toLowerCase().startsWith("c.")) {
+                     // the author line for bloomberg is a multiline starting with c.2011 Bloomberg News
+                     // then containing the author info on the next line
+                     if (val_next == TB) {
+                        value[--read] = CT;
+                        continue;
+                     }
+                  }
+                  else if(tmp_line.toLowerCase().trim().startsWith("(") && tmp_line.toLowerCase().trim().endsWith(")")) {
+                     // the author line may have one or more comment lines between the copyright
+                     // statement, and the By AUTHORNAME line
+                     if (val_next == TB) {
+                        value[--read] = CT;
+                        continue;
+                     }
+                  }
+               }
+
+               else if (tmp_line.toLowerCase().startsWith("eds") || longline.equals("bdy_source")) {
+                  longkey = "bdy_source";
+                  // prepend a space to subsequent line, so it gets parsed consistent with the lead line
+                  tmp_line = (longline.equals(longkey) ? " " : "") + tmp_line;
+
+                  // we have a source candidate
+                  int term = tmp_line.length();
+                  term = Math.min(term, (tmp_line.indexOf("<")  > -1 ? tmp_line.indexOf("<")  : term));
+                  term = Math.min(term, (tmp_line.indexOf("=")  > -1 ? tmp_line.indexOf("=")  : term));
+//                  term = Math.min(term, (tmp_line.indexOf("\n") > -1 ? tmp_line.indexOf("\n") : term));
+                  term = (term > 0 ) ? term : tmp_line.length();
+                  bdy_source += tmp_line.substring(tmp_line.indexOf(" ") + 1, term) + " ";
+                  metastarted = true;
+                  longline = (!longline.equals(longkey) ? longkey  : "");
+               }
+               else {
+                  // this has fallen all the way through.  trap it as part of the subject,
+                  // rather than just losing it
+                  if (!metastarted) {
+                     bdy_title += " , " + tmp_line;     //  not sure where else to put this but in the title
+                  }
+                  else {
+                     // what to do with stuff that is metadata, which falls after metadata lines started?
+                     bdy_body += " " + tmp_line + " , ";     //  not sure where else to put this but in the title
+                  }
+               }
+            }
+            else {  // we're on to the main body
+               while ((read < value.length) && (val_next != 0))  {
+                  // read until the train runs out of tracks
+                  bdy_body += (char)(val_next & 0xff);  // convert the byte to an unsigned int
+                  val_next =  (read < value.length) ? value[read++] : 0x00;
+                  if (read > value.length) { break; }  // shouldn't ever hit this, but save a NPE
+               }
+
+            }
+            // we would normally break here, but just let this read out to the end
+         }
+         done = true; // don't let this run back through and start thrashing metadata
+      }
+      properties.put("body", bdy_body);
+      properties.put("title", bdy_title);
+      properties.put("subject", bdy_heading);
+      properties.put("author", bdy_author);
+      properties.put("source", bdy_source);
+
+      added = (!bdy_body.isEmpty() || !bdy_title.isEmpty() || !bdy_heading.isEmpty() || !bdy_author.isEmpty() || !bdy_source.isEmpty());
+
+      return (added);
+   }
+
+
+   private boolean parseFooter(byte[] value, HashMap<String,String> properties) {
+      boolean added = false;
+
+      String ftr_source = "";
+      String ftr_datetime = "";
+
+      int read = 0;
+      boolean done = false;
+
+      while (!done && (read < value.length)) {
+
+         // pull apart the footer, getting the news feed source (^....\x0d\x0a)
+         byte val_next = value[read++];
+         byte val_peek =  (read < value.length) ? value[read+1] : 0x00;  // skip the new lines
+
+         while (((val_next < (byte)0x30) || (val_next > (byte)0x39)) && (val_next != 0)) {  // consume all non-numerics first
+            ftr_source += (char)(val_next & 0xff);  // convert the byte to an unsigned int
+            val_next =  (read < value.length) ? value[read] : 0x00;  // attempt to read until end of stream
+            read++;
+            if (read > value.length) { break; }  // shouldn't ever hit this, but save a NPE
+         }
+
+         while ((val_next != LT) && (val_next != CR) && (val_next != LF) && (val_next != 0))  {  // get as much timedate as possible
+            // this is an american format, so arrives as mm-dd-yy HHiizzz
+            ftr_datetime += (char)(val_next & 0xff);  // convert the byte to an unsigned int
+            val_next =  (read < value.length) ? value[read++] : 0x00;  // skip the new lines
+            if (read > value.length) { break; }  // shouldn't ever hit this, but save a NPE
+         }
+         if (val_next == LT) {
+            // hit the delimiter, carry on
+            val_next =  (read < value.length) ? value[read++] : 0x00;
+         }
+
+         if (!ftr_datetime.isEmpty()) {
+            // we want to pass this back in a more friendly format
+            String format_out = "yyyy-MM-dd'T'HH:mm:ss'Z'";
+            Date dateunix = new Date();
+            try {
+               // standard ap format
+               String format_in = "MM-dd-yy HHmmzzz";
+
+               if (FORMAT == this.FMT_IPTC_RTR) {
+                  // standard reuters format
+                  format_in = "HH:mm MM-dd-yy";
+               }
+               SimpleDateFormat dfi =   new SimpleDateFormat(format_in);
+               dfi.setTimeZone(TimeZone.getTimeZone("UTC"));
+               dateunix = dfi.parse(ftr_datetime);
+            }
+            catch (ParseException ep) {
+               // failed, but this will just fall through to setting the date to now
+            }
+            SimpleDateFormat dfo =   new SimpleDateFormat(format_out);
+            dfo.setTimeZone(TimeZone.getTimeZone("UTC"));
+            ftr_datetime = dfo.format(dateunix);
+         }
+         while ((val_next == CR) || (val_next == LF)) {
+            val_next =  (read < value.length) ? value[read++] : 0x00;  // skip the new lines
+            if ((val_next != CR) && (val_next != LF)) {
+               --read;
+            }
+         }
+         done = true; // don't let this run back through and start thrashing metadata
+      }
+
+      properties.put("publisher", ftr_source);
+      properties.put("created", ftr_datetime);
+      properties.put("modified", ftr_datetime);
+
+      added = (!ftr_source.isEmpty() || !ftr_datetime.isEmpty());
+
+      return (added);
+   }
+
+
+   private void setMetadata(Metadata metadata, HashMap<String,String> properties) {
+
+      // every property that gets set must be non-null, or it will cause NPE
+      // in other consuming applications, like Lucene
+      metadata.set(Metadata.CONTENT_TYPE,  clean("text/anpa-1312"));
+      metadata.set(Metadata.TITLE,         clean(properties.get("title")));
+      metadata.set(Metadata.SUBJECT,       clean(properties.get("subject")));
+      metadata.set(Metadata.AUTHOR,        clean(properties.get("author")));
+      metadata.set(Metadata.CREATION_DATE, clean(properties.get("created")));
+      metadata.set(Metadata.MODIFIED,      clean(properties.get("modified")));
+      metadata.set(DublinCore.SOURCE,      clean(properties.get("source")));
+//      metadata.set(Metadata.PUBLISHER,     clean(properties.get("publisher")));
+      metadata.set(Metadata.PUBLISHER,     clean(this.getFormatName()));
+
+
+/*
+        metadata.set(DublinCore.DATE, font.getHeader().getCreated().getTime());
+        metadata.set(
+                Property.internalDate(DublinCore.MODIFIED),
+                font.getHeader().getModified().getTime());
+*/
+
+   }
+
+
+   private String clean(String value) {
+
+      if (value == null) {
+         value = "";
+      }
+
+      try {
+         String tmpvalue = new String(value.getBytes(Charset.forName("UTF-8")),"UTF-8");
+         value = tmpvalue;
+      }
+      catch (UnsupportedEncodingException eue) {}
+      value = value.replaceAll("``", "`");
+      value = value.replaceAll("''", "'");
+      value = value.replaceAll(new String(new char[] {SL}), "'");
+      value = value.replaceAll(new String(new char[] {SR}), "'");
+      value = value.replaceAll(new String(new char[] {DL}), "\"");
+      value = value.replaceAll(new String(new char[] {DR}), "\"");
+      value = value.trim();
+
+      return (value);
+   }
+   
+}
diff --git a/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.parser.Parser b/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.parser.Parser
index 60e4358ff..b3f6dc1dc 100644
--- a/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.parser.Parser
+++ b/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.parser.Parser
@@ -25,6 +25,7 @@ org.apache.tika.parser.html.HtmlParser
 org.apache.tika.parser.image.ImageParser
 org.apache.tika.parser.image.PSDParser
 org.apache.tika.parser.image.TiffParser
+org.apache.tika.parser.iptc.IptcAnpaParser
 org.apache.tika.parser.iwork.IWorkPackageParser
 org.apache.tika.parser.jpeg.JpegParser
 org.apache.tika.parser.mail.RFC822Parser

Commit:
7ef354893172ac0a49f929e950e72154d4793b44
Nick Burch
nick@apache.org
2012-04-28 16:08:21 +0000
TIKA-852 Upgrade the MP4 parser to 1.0 RC1, which allows us to enable the MP4 unit test (patch from Sebastian Annies)
diff --git a/tika-bundle/pom.xml b/tika-bundle/pom.xml
index 601460901..ed8e038ff 100644
--- a/tika-bundle/pom.xml
+++ b/tika-bundle/pom.xml
@@ -114,14 +114,14 @@
             </Bundle-Activator>
             <Embed-Dependency>
               tika-parsers;inline=true,
-              commons-compress, commons-codec,
+              commons-compress, commons-codec, commons-io,
               pdfbox,fontbox,jempbox,bcmail-jdk15,bcprov-jdk15,
               poi,poi-scratchpad,poi-ooxml,poi-ooxml-schemas,
               xmlbeans, dom4j,
               tagsoup,
               asm, 
               vorbis-java-core, vorbis-java-tika,
-              isoparser, scannotation, javassist,
+              isoparser, aspectjrt,
               metadata-extractor,
               boilerpipe, rome,
               apache-mime4j-core, apache-mime4j-dom
diff --git a/tika-parsers/pom.xml b/tika-parsers/pom.xml
index 2159b6105..3975588db 100644
--- a/tika-parsers/pom.xml
+++ b/tika-parsers/pom.xml
@@ -158,7 +158,7 @@
     <dependency>
       <groupId>com.googlecode.mp4parser</groupId> 
       <artifactId>isoparser</artifactId> 
-      <version>1.0-beta-5</version> 
+      <version>1.0-RC-1</version>
     </dependency> 
     <dependency>
        <groupId>com.drewnoakes</groupId>
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java b/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java
index 654ee96c9..4f1169f25 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java
@@ -38,8 +38,6 @@ import org.apache.tika.sax.XHTMLContentHandler;
 import org.xml.sax.ContentHandler;
 import org.xml.sax.SAXException;
 
-import com.coremedia.iso.IsoBufferWrapper;
-import com.coremedia.iso.IsoBufferWrapperImpl;
 import com.coremedia.iso.IsoFile;
 import com.coremedia.iso.boxes.Box;
 import com.coremedia.iso.boxes.ContainerBox;
@@ -115,10 +113,7 @@ public class MP4Parser extends AbstractParser {
         //  avoid OOMs that may occur with in-memory buffering
         TikaInputStream tstream = TikaInputStream.get(stream);
         try {
-           IsoBufferWrapper isoBufferWrapper = 
-              new IsoBufferWrapperImpl(tstream.getFile());
-           isoFile = new IsoFile(isoBufferWrapper);
-           isoFile.parse();
+           isoFile = new IsoFile(tstream.getFileChannel());
         } finally {
            tstream.close();
         }
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/mp4/MP4ParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/mp4/MP4ParserTest.java
index a0f733fe8..8b19abc5d 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/mp4/MP4ParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/mp4/MP4ParserTest.java
@@ -31,10 +31,8 @@ import org.xml.sax.ContentHandler;
 
 /**
  * Test case for parsing mp4 files.
- * 
- * TODO Work out why this test passes in Eclipse, but fails from Maven
  */
-public abstract class MP4ParserTest extends TestCase {
+public class MP4ParserTest extends TestCase {
     /**
      * Test that we can extract information from
      *  a M4A MP4 Audio file

Commit:
c98a42173ca64ec77b7e19eac9ad9cf5cf71c776
Nick Burch
nick@apache.org
2012-04-27 23:55:09 +0000
TIKA-907 Comments in iWorks Pages files
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/PagesContentHandler.java b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/PagesContentHandler.java
index ddd09f88d..26cdd512c 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/PagesContentHandler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/PagesContentHandler.java
@@ -38,7 +38,7 @@ class PagesContentHandler extends DefaultHandler {
        METADATA, PARSABLE_TEXT, 
        HEADERS, HEADER_ODD, HEADER_EVEN, HEADER_FIRST,
        FOOTERS, FOOTER_ODD, FOOTER_EVEN, FOOTER_FIRST,
-       FOOTNOTES;
+       FOOTNOTES, ANNOTATIONS;
     }
     private DocumentPart inPart = null;
     
@@ -48,6 +48,7 @@ class PagesContentHandler extends DefaultHandler {
     private HeaderFooter headers = null;
     private HeaderFooter footers = null;
     private Footnotes footnotes = null; 
+    private Annotations annotations = null; 
     
     private Map<String, List<List<String>>> tableData =
         new HashMap<String, List<List<String>>>();
@@ -139,6 +140,20 @@ class PagesContentHandler extends DefaultHandler {
                  xhtml.endElement("div");
               }
            }
+        } else if ("sf:annotations".equals(qName)) {
+           annotations = new Annotations();
+           inPart = DocumentPart.ANNOTATIONS;
+        } else if ("sf:annotation".equals(qName) && inPart == DocumentPart.ANNOTATIONS) {
+           annotations.start(attributes.getValue("sf:target"));
+        } else if ("sf:annotation-field".equals(qName) && inPart == DocumentPart.PARSABLE_TEXT) {
+           xhtml.startElement("div", "style", "annotated");
+           
+           String annotationText = annotations.annotations.get(attributes.getValue("sfa:ID"));
+           if (annotationText != null) {
+              xhtml.startElement("div", "style", "annotation");
+              xhtml.characters(annotationText);
+              xhtml.endElement("div");
+           }
         }
 
         if (activeTableId != null) {
@@ -169,6 +184,10 @@ class PagesContentHandler extends DefaultHandler {
             xhtml.endElement("p");
         } else if ("sf:attachment".equals(qName)) {
             activeTableId = null;
+        } else if ("sf:annotation".equals(qName) && inPart == DocumentPart.ANNOTATIONS) {
+           annotations.end();
+        } else if ("sf:annotation-field".equals(qName) && inPart == DocumentPart.PARSABLE_TEXT) {
+           xhtml.endElement("div");
         }
     }
 
@@ -186,6 +205,7 @@ class PagesContentHandler extends DefaultHandler {
               if (inPart == DocumentPart.FOOTER_EVEN)  footers.defaultEven = str;
               if (inPart == DocumentPart.FOOTER_ODD)   footers.defaultOdd = str;
               if (inPart == DocumentPart.FOOTNOTES)    footnotes.text(str);
+              if (inPart == DocumentPart.ANNOTATIONS)  annotations.text(str);
           }
         }
     }
@@ -329,7 +349,8 @@ class PagesContentHandler extends DefaultHandler {
        }
     }
     /**
-     * Represents Footnotes in a document
+     * Represents Footnotes in a document. The way these work
+     *  in the file format isn't very clean...
      */
     private static class Footnotes {
        /** Mark -> Text */
@@ -351,4 +372,31 @@ class PagesContentHandler extends DefaultHandler {
           }
        }
     }
+    /**
+     * Represents Annotations in a document. We currently
+     *  just grab all the sf:p text in each one 
+     */
+    private class Annotations {
+       /** ID -> Text */
+       Map<String,String> annotations = new HashMap<String, String>();
+       String currentID = null;
+       StringBuffer currentText = null;
+       
+       private void start(String id) {
+          currentID = id;
+          currentText = new StringBuffer();
+       }
+       private void text(String text) {
+          if (text != null && text.length() > 0 && currentText != null) {
+             currentText.append(text);
+          }
+       }
+       private void end() {
+          if (currentText.length() > 0) {
+             annotations.put(currentID, currentText.toString());
+             currentID = null;
+             currentText = null;
+          }
+       }
+    }
 }
\ No newline at end of file
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
index 33319afbd..24cb7d012 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
@@ -161,7 +161,7 @@ public class IWorkParserTest extends TestCase {
     }
     
     /**
-     * Check we get headers, footers and footnotes from keynote
+     * Check we get headers, footers and footnotes from Pages
      */
     public void testParsePagesHeadersFootersFootnotes() throws Exception {
        String footnote = "Footnote: Do a lot of people really use iWork?!?!";
@@ -186,6 +186,31 @@ public class IWorkParserTest extends TestCase {
        assertContains(contents, footnote);
     }
     
+    /**
+     * Check we get annotations (eg comments) from Pages
+     */
+    public void testParsePagesAnnotations() throws Exception {
+       String commentA = "comment about the APXL file";
+       String commentB = "comment about UIMA";
+       
+       
+       InputStream input = IWorkParserTest.class.getResourceAsStream("/test-documents/testPagesComments.pages");
+       Metadata metadata = new Metadata();
+       ContentHandler handler = new BodyContentHandler();
+
+       iWorkParser.parse(input, handler, metadata, parseContext);
+       String contents = handler.toString();
+
+       // Check regular text
+       assertContains(contents, "Both Pages 1.x"); // P1
+       assertContains(contents, "understanding the Pages document"); // P1
+       assertContains(contents, "should be page 2"); // P2
+       
+       // Check for comments
+       assertContains(contents, commentA);
+       assertContains(contents, commentB);
+    }
+    
     public void assertContains(String haystack, String needle) {
        assertTrue(needle + " not found in:\n" + haystack, haystack.contains(needle));
     }
diff --git a/tika-parsers/src/test/resources/test-documents/testPagesComments.pages b/tika-parsers/src/test/resources/test-documents/testPagesComments.pages
new file mode 100644
index 000000000..d7ff81c41
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testPagesComments.pages differ

Commit:
c66a8baa8dba820a7150b48201a5ee97449b872b
Nick Burch
nick@apache.org
2012-04-27 23:31:21 +0000
TIKA-876 Slight PKCS7 der magic tweak
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 73fd2696c..02be578ea 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -395,8 +395,8 @@
     <glob pattern="*.p7s"/>
     <magic priority="50">
       <match value="-----BEGIN PKCS7" type="string" offset="0"/>
-      <match value="0x308202FF06092a864886f70d010703a0" type="string"
-              mask="0xFFFFFF00FFFFFFFFFFFFFFFFFFFFFFFF" offset="0"/>
+      <match value="0x3082FFFF06092a864886f70d0107FFa0" type="string"
+              mask="0xFFFF0000FFFFFFFFFFFFFFFFFFFF00FF" offset="0"/>
     </magic>
   </mime-type>
   <mime-type type="application/pkix-cert">

Commit:
7d8b3ea972f917c6b2a7deb930bc57a6ece60e96
Nick Burch
nick@apache.org
2012-04-27 23:26:44 +0000
Magic for PCKS7 in PEM format, and DER format (probably...)
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index ef653af3b..73fd2696c 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -393,6 +393,11 @@
   </mime-type>
   <mime-type type="application/pkcs7-signature">
     <glob pattern="*.p7s"/>
+    <magic priority="50">
+      <match value="-----BEGIN PKCS7" type="string" offset="0"/>
+      <match value="0x308202FF06092a864886f70d010703a0" type="string"
+              mask="0xFFFFFF00FFFFFFFFFFFFFFFFFFFFFFFF" offset="0"/>
+    </magic>
   </mime-type>
   <mime-type type="application/pkix-cert">
     <glob pattern="*.cer"/>

Commit:
aa901df66c086303085ab5fbc5f1febf75ce031c
Nick Burch
nick@apache.org
2012-04-27 22:48:32 +0000
TIKA-906 Support extracting Headers, Footers and Footnotes in iWorks Pages files. As part of this, make the parser a little more aware of where in the file it is, and start tracking some of the earlier parts of the file ready for when we hit the main text
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/PagesContentHandler.java b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/PagesContentHandler.java
index 9d53fb738..ddd09f88d 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/PagesContentHandler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/PagesContentHandler.java
@@ -33,11 +33,22 @@ class PagesContentHandler extends DefaultHandler {
     private final XHTMLContentHandler xhtml;
     private final Metadata metadata;
 
-    private boolean inMetaDataPart = false;
+    /** The (interesting) part of the document we're in. Should be more structured... */
+    private enum DocumentPart {
+       METADATA, PARSABLE_TEXT, 
+       HEADERS, HEADER_ODD, HEADER_EVEN, HEADER_FIRST,
+       FOOTERS, FOOTER_ODD, FOOTER_EVEN, FOOTER_FIRST,
+       FOOTNOTES;
+    }
+    private DocumentPart inPart = null;
+    
     private boolean parseProperty = false;
-    private boolean inParsableText = false;
     private int pageCount = 0;
 
+    private HeaderFooter headers = null;
+    private HeaderFooter footers = null;
+    private Footnotes footnotes = null; 
+    
     private Map<String, List<List<String>>> tableData =
         new HashMap<String, List<List<String>>>();
     private String activeTableId;
@@ -56,6 +67,7 @@ class PagesContentHandler extends DefaultHandler {
     public void endDocument() throws SAXException {
         metadata.set(Metadata.PAGE_COUNT, String.valueOf(pageCount));
         if (pageCount > 0) {
+            doFooter();
             xhtml.endElement("div");
         }
     }
@@ -77,17 +89,19 @@ class PagesContentHandler extends DefaultHandler {
         }
 
         if ("sl:publication-info".equals(qName)) {
-            inMetaDataPart = true;
+            inPart = DocumentPart.METADATA;
         } else if ("sf:metadata".equals(qName)) {
-            inMetaDataPart = true;
+           inPart = DocumentPart.METADATA;
         } else if ("sf:page-start".equals(qName)) {
             if (pageCount > 0) {
+                doFooter();
                 xhtml.endElement("div");
             }
             xhtml.startElement("div");
             pageCount++;
+            doHeader();
         } else if ("sf:p".equals(qName) && pageCount > 0) {
-            inParsableText = true;
+            inPart = DocumentPart.PARSABLE_TEXT;
             xhtml.startElement("p");
         } else if ("sf:attachment".equals(qName)) {
             String kind = attributes.getValue("sf:kind");
@@ -98,13 +112,40 @@ class PagesContentHandler extends DefaultHandler {
         } else if ("sf:attachment-ref".equals(qName)) {
             String idRef = attributes.getValue("sfa:IDREF");
             outputTable(idRef);
+        } else if ("sf:headers".equals(qName)) {
+            headers = new HeaderFooter(qName);
+            inPart = DocumentPart.HEADERS;
+        } else if ("sf:footers".equals(qName)) {
+           footers = new HeaderFooter(qName);
+           inPart = DocumentPart.FOOTERS;
+        } else if ("sf:header".equals(qName)) {
+            inPart = headers.identifyPart(attributes.getValue("sf:name"));
+        } else if ("sf:footer".equals(qName)) {
+           inPart = footers.identifyPart(attributes.getValue("sf:name"));
+        } else if ("sf:footnotes".equals(qName)) {
+           footnotes = new Footnotes();
+           inPart = DocumentPart.FOOTNOTES;
+        } else if ("sf:footnote-mark".equals(qName)) {
+           footnotes.recordMark(attributes.getValue("sf:mark"));
+        } else if ("sf:footnote".equals(qName) && inPart == DocumentPart.PARSABLE_TEXT) {
+           // What about non auto-numbered?
+           String footnoteMark = attributes.getValue("sf:autonumber");
+           if (footnotes != null) {
+              String footnoteText = footnotes.footnotes.get(footnoteMark);
+              if (footnoteText != null) {
+                 xhtml.startElement("div", "style", "footnote");
+                 xhtml.characters("Footnote:" ); // As shown in Pages
+                 xhtml.characters(footnoteText);
+                 xhtml.endElement("div");
+              }
+           }
         }
 
         if (activeTableId != null) {
             parseTableData(qName, attributes);
         }
 
-        if (inMetaDataPart) {
+        if (inPart == DocumentPart.METADATA) {
             metaDataLocalName = localName;
             metaDataQName = qName;
             parseProperty = true;
@@ -120,11 +161,11 @@ class PagesContentHandler extends DefaultHandler {
         }
 
         if ("sl:publication-info".equals(qName)) {
-            inMetaDataPart = false;
+            inPart = null;
         } else if ("sf:metadata".equals(qName)) {
-            inMetaDataPart = false;
+            inPart = null;
         } else if ("sf:p".equals(qName) && pageCount > 0) {
-            inParsableText = false;
+            inPart = null;
             xhtml.endElement("p");
         } else if ("sf:attachment".equals(qName)) {
             activeTableId = null;
@@ -133,8 +174,19 @@ class PagesContentHandler extends DefaultHandler {
 
     @Override
     public void characters(char[] ch, int start, int length) throws SAXException {
-        if (inParsableText && length > 0) {
-            xhtml.characters(ch, start, length);
+        if (length > 0) {
+           if (inPart == DocumentPart.PARSABLE_TEXT) {
+              xhtml.characters(ch, start, length);
+          } else if(inPart != null) {
+              String str = new String(ch, start, length);
+              if (inPart == DocumentPart.HEADER_FIRST) headers.defaultFirst = str;
+              if (inPart == DocumentPart.HEADER_EVEN)  headers.defaultEven = str;
+              if (inPart == DocumentPart.HEADER_ODD)   headers.defaultOdd = str;
+              if (inPart == DocumentPart.FOOTER_FIRST) footers.defaultFirst = str;
+              if (inPart == DocumentPart.FOOTER_EVEN)  footers.defaultEven = str;
+              if (inPart == DocumentPart.FOOTER_ODD)   footers.defaultOdd = str;
+              if (inPart == DocumentPart.FOOTNOTES)    footnotes.text(str);
+          }
         }
     }
 
@@ -217,5 +269,86 @@ class PagesContentHandler extends DefaultHandler {
 
         return null;
     }
+    
+    private void doHeader() throws SAXException {
+       if (headers != null) {
+          headers.output("header");
+       }
+    }
+    private void doFooter() throws SAXException {
+       if (footers != null) {
+          footers.output("footer");
+       }
+    }
 
+    /**
+     * Represents the Headers or Footers in a document
+     */
+    private class HeaderFooter {
+       private String type; // sf:headers or sf:footers
+       private String defaultOdd;
+       private String defaultEven;
+       private String defaultFirst;
+       // TODO Can there be custom ones?
+       
+       private HeaderFooter(String type) {
+          this.type = type; 
+       }
+       private DocumentPart identifyPart(String name) {
+          if("SFWPDefaultOddHeaderIdentifier".equals(name))
+             return DocumentPart.HEADER_ODD;
+          if("SFWPDefaultEvenHeaderIdentifier".equals(name))
+             return DocumentPart.HEADER_EVEN;
+          if("SFWPDefaultFirstHeaderIdentifier".equals(name))
+             return DocumentPart.HEADER_FIRST;
+          
+          if("SFWPDefaultOddFooterIdentifier".equals(name))
+             return DocumentPart.FOOTER_ODD;
+          if("SFWPDefaultEvenFooterIdentifier".equals(name))
+             return DocumentPart.FOOTER_EVEN;
+          if("SFWPDefaultFirstFooterIdentifier".equals(name))
+             return DocumentPart.FOOTER_FIRST;
+          
+          return null;
+       }
+       private void output(String what) throws SAXException {
+          String text = null;
+          if (pageCount == 1 && defaultFirst != null) {
+             text = defaultFirst;
+          } else if (pageCount % 2 == 0 && defaultEven != null) {
+             text = defaultEven;
+          } else {
+             text = defaultOdd;
+          }
+          
+          if (text != null) {
+             xhtml.startElement("div", "class", "header");
+             xhtml.characters(text);
+             xhtml.endElement("div");
+          }
+       }
+    }
+    /**
+     * Represents Footnotes in a document
+     */
+    private static class Footnotes {
+       /** Mark -> Text */
+       Map<String,String> footnotes = new HashMap<String, String>();
+       String lastSeenMark = null;
+       
+       /**
+        * Normally happens before the text of the mark
+        */
+       private void recordMark(String mark) {
+          lastSeenMark = mark;
+       }
+       private void text(String text) {
+          if (lastSeenMark != null) {
+             if (footnotes.containsKey(lastSeenMark)) {
+                text = footnotes.get(lastSeenMark) + text;
+             }
+             footnotes.put(lastSeenMark, text);
+          }
+       }
+    }
 }
\ No newline at end of file
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
index 402c49597..33319afbd 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
@@ -159,4 +159,34 @@ public class IWorkParserTest extends TestCase {
        // Will have been identified as encrypted
        assertEquals("application/x-tika-iworks-protected", metadata.get(Metadata.CONTENT_TYPE));
     }
+    
+    /**
+     * Check we get headers, footers and footnotes from keynote
+     */
+    public void testParsePagesHeadersFootersFootnotes() throws Exception {
+       String footnote = "Footnote: Do a lot of people really use iWork?!?!";
+       String header = "THIS IS SOME HEADER TEXT";
+       String footer = "THIS IS SOME FOOTER TEXT";
+       
+       InputStream input = IWorkParserTest.class.getResourceAsStream("/test-documents/testPagesHeadersFootersFootnotes.pages");
+       Metadata metadata = new Metadata();
+       ContentHandler handler = new BodyContentHandler();
+
+       iWorkParser.parse(input, handler, metadata, parseContext);
+       String contents = handler.toString();
+
+       // Check regular text
+       assertContains(contents, "Both Pages 1.x"); // P1
+       assertContains(contents, "understanding the Pages document"); // P1
+       assertContains(contents, "should be page 2"); // P2
+       
+       // Check for headers, footers and footnotes
+       assertContains(contents, header);
+       assertContains(contents, footer);
+       assertContains(contents, footnote);
+    }
+    
+    public void assertContains(String haystack, String needle) {
+       assertTrue(needle + " not found in:\n" + haystack, haystack.contains(needle));
+    }
 }
diff --git a/tika-parsers/src/test/resources/test-documents/testPagesHeadersFootersFootnotes.pages b/tika-parsers/src/test/resources/test-documents/testPagesHeadersFootersFootnotes.pages
new file mode 100644
index 000000000..cfecc8c0c
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testPagesHeadersFootersFootnotes.pages differ

Commit:
27fbb0a2303433efb077ec449a591114c264e3c1
Nick Burch
nick@apache.org
2012-04-27 17:03:23 +0000
TIKA-903 Avoid breaking on Password Protected iWorks files. We can't parse them yet though, as we don't know how the encryption works
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index cc99740ab..ef653af3b 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -641,6 +641,10 @@
     <sub-class-of type="application/vnd.apple.iwork" />
     <glob pattern="*.numbers"/>
   </mime-type>
+  <mime-type type="application/x-tika-iworks-protected">
+    <sub-class-of type="application/vnd.apple.iwork" />
+    <_comment>Password Protected iWorks File</_comment>
+  </mime-type>
 
   <mime-type type="application/vnd.arastra.swi">
     <glob pattern="*.swi"/>
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/IWorkPackageParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/IWorkPackageParser.java
index 95183c5c9..2df1b900a 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/iwork/IWorkPackageParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/iwork/IWorkPackageParser.java
@@ -26,6 +26,7 @@ import java.util.Set;
 
 import javax.xml.namespace.QName;
 
+import org.apache.commons.compress.archivers.zip.UnsupportedZipFeatureException;
 import org.apache.commons.compress.archivers.zip.ZipArchiveEntry;
 import org.apache.commons.compress.archivers.zip.ZipArchiveInputStream;
 import org.apache.commons.compress.archivers.zip.ZipFile;
@@ -71,7 +72,8 @@ public class IWorkPackageParser extends AbstractParser {
     public enum IWORKDocumentType {
        KEYNOTE("http://developer.apple.com/namespaces/keynote2", "presentation", MediaType.application("vnd.apple.keynote")),
        NUMBERS("http://developer.apple.com/namespaces/ls", "document", MediaType.application("vnd.apple.numbers")),
-       PAGES("http://developer.apple.com/namespaces/sl", "document", MediaType.application("vnd.apple.pages"));
+       PAGES("http://developer.apple.com/namespaces/sl", "document", MediaType.application("vnd.apple.pages")),
+       ENCRYPTED(null, null, MediaType.application("x-tika-iworks-protected"));
        
        private final String namespace;
        private final String part;
@@ -122,13 +124,26 @@ public class IWorkPackageParser extends AbstractParser {
        
        private static IWORKDocumentType detectType(InputStream stream) {
           QName qname = new XmlRootExtractor().extractRootElement(stream);
-          String uri = qname.getNamespaceURI();
-          String local = qname.getLocalPart();
-         
-          for (IWORKDocumentType type : values()) {
-             if(type.getNamespace().equals(uri) && 
-                type.getPart().equals(local)) {
-                return type;
+          if (qname != null) {
+             String uri = qname.getNamespaceURI();
+             String local = qname.getLocalPart();
+            
+             for (IWORKDocumentType type : values()) {
+                if(type.getNamespace().equals(uri) && 
+                   type.getPart().equals(local)) {
+                   return type;
+                }
+             }
+          } else {
+             // There was a problem with extracting the root type
+             // Password Protected iWorks files are funny, but we can usually
+             //  spot them because they encrypt part of the zip stream 
+             try {
+                stream.read();
+             } catch(UnsupportedZipFeatureException e) {
+                // Compression field was likely encrypted
+                return ENCRYPTED;
+             } catch(Exception ignored) {
              }
           }
           return null;
@@ -180,16 +195,22 @@ public class IWorkPackageParser extends AbstractParser {
                case PAGES:
                   contentHandler = new PagesContentHandler(xhtml, metadata);
                   break;
+               case ENCRYPTED:
+                   // We can't do anything for the file right now
+                   contentHandler = null;
+                   break;
                default:
                   throw new TikaException("Unhandled iWorks file " + type);
                }
 
                metadata.add(Metadata.CONTENT_TYPE, type.getType().toString());
                xhtml.startDocument();
-               context.getSAXParser().parse(
-                       new CloseShieldInputStream(entryStream),
-                       new OfflineContentHandler(contentHandler)
-               );
+               if (contentHandler != null) {
+                  context.getSAXParser().parse(
+                          new CloseShieldInputStream(entryStream),
+                          new OfflineContentHandler(contentHandler)
+                  );
+               }
                xhtml.endDocument();
             }
             
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
index f076138ea..402c49597 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/iwork/IWorkParserTest.java
@@ -139,4 +139,24 @@ public class IWorkParserTest extends TestCase {
         assertTrue(content.contains("Try adding your own account transactions to this table."));
     }
 
+    /**
+     * We don't currently support password protected Pages files, as
+     *  we don't know how the encryption works (it's not regular Zip
+     *  Encryption). See TIKA-903 for details
+     */
+    public void testParsePagesPasswordProtected() throws Exception {
+       // Document password is "tika", but we can't use that yet...
+       InputStream input = IWorkParserTest.class.getResourceAsStream("/test-documents/testPagesPwdProtected.pages");
+       Metadata metadata = new Metadata();
+       ContentHandler handler = new BodyContentHandler();
+
+       iWorkParser.parse(input, handler, metadata, parseContext);
+
+       // Content will be empty
+       String content = handler.toString();
+       assertEquals("", content);
+       
+       // Will have been identified as encrypted
+       assertEquals("application/x-tika-iworks-protected", metadata.get(Metadata.CONTENT_TYPE));
+    }
 }
diff --git a/tika-parsers/src/test/resources/test-documents/testPagesPwdProtected.pages b/tika-parsers/src/test/resources/test-documents/testPagesPwdProtected.pages
new file mode 100644
index 000000000..788b51678
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testPagesPwdProtected.pages differ

Commit:
0f729e61d69e68d231006ff717e2b1cb726851e0
Chris Mattmann
mattmann@apache.org
2012-04-27 15:03:48 +0000
- disable until shade plugin is fixed.
diff --git a/pom.xml b/pom.xml
index 5ed9e9251..4423da54d 100644
--- a/pom.xml
+++ b/pom.xml
@@ -50,7 +50,7 @@
     <module>tika-parsers</module>
     <module>tika-app</module>
     <module>tika-bundle</module>
-    <module>tika-server</module>
+    <!-- <module>tika-server</module>-->
   </modules>
 
   <build>

Commit:
35539abaad27119d6a5a51728b2a93a6e981d38b
Nick Burch
nick@apache.org
2012-04-27 13:59:49 +0000
TIKA-861 Patch from Ryan Quam to enable extracting PDF Links. (Links are extracted for now at the end of the page, further work will be needed to match them to the text they apply to)
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDF2XHTML.java b/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDF2XHTML.java
index ca1c54377..e2eb65d2a 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDF2XHTML.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDF2XHTML.java
@@ -22,7 +22,10 @@ import java.io.Writer;
 import org.apache.pdfbox.pdmodel.PDDocument;
 import org.apache.pdfbox.pdmodel.PDPage;
 import org.apache.pdfbox.util.PDFTextStripper;
+import org.apache.pdfbox.pdmodel.interactive.action.type.PDAction;
+import org.apache.pdfbox.pdmodel.interactive.action.type.PDActionURI;
 import org.apache.pdfbox.pdmodel.interactive.annotation.PDAnnotation;
+import org.apache.pdfbox.pdmodel.interactive.annotation.PDAnnotationLink;
 import org.apache.pdfbox.pdmodel.interactive.annotation.PDAnnotationMarkup;
 import org.apache.pdfbox.util.TextPosition;
 import org.apache.tika.exception.TikaException;
@@ -140,6 +143,23 @@ class PDF2XHTML extends PDFTextStripper {
             // TODO: remove once PDFBOX-1143 is fixed:
             if (extractAnnotationText) {
                 for(Object o : page.getAnnotations()) {
+                    if( o instanceof PDAnnotationLink ) {
+                        PDAnnotationLink annotationlink = (PDAnnotationLink) o;
+                        if (annotationlink.getAction()  != null) {
+                            PDAction action = annotationlink.getAction();
+                            if( action instanceof PDActionURI ) {
+                                PDActionURI uri = (PDActionURI) action;
+                                String link = uri.getURI();
+                                if (link != null) {
+                                    handler.startElement("div", "class", "annotation");
+                                    handler.startElement("a", "href", link);
+                                    handler.endElement("a");
+                                    handler.endElement("div");
+                                }
+                             }
+                        }
+                    }
+                
                     if ((o instanceof PDAnnotation) && PDAnnotationMarkup.SUB_TYPE_FREETEXT.equals(((PDAnnotation) o).getSubtype())) {
                         // It's a text annotation:
                         PDAnnotationMarkup annot = (PDAnnotationMarkup) o;
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java
index 7e7901739..013b03371 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java
@@ -308,6 +308,19 @@ public class PDFParserTest extends TikaTest {
         assertContains("<p>1</p>", content);
     }
 
+    /**
+     * Test to ensure that Links are extracted from the text
+     * 
+     * Note - the PDF contains the text "This is a hyperlink" which
+     *  a hyperlink annotation, linking to the tika site, on it. This
+     *  test will need updating when we're able to apply the annotation
+     *  to the text itself, rather than following on afterwards as now 
+     */
+    public void testLinks() throws Exception {
+        final XMLResult result = getXML("testPDFVarious.pdf");
+        assertContains("<div class=\"annotation\"><a href=\"http://tika.apache.org/\"/></div>", result.xml);
+    }
+
     public void testDisableAutoSpace() throws Exception {
         PDFParser parser = new PDFParser();
         parser.setEnableAutoSpace(false);

Commit:
d53f02f4c76495e26f0ce77cd2007fec1385ada5
Chris Mattmann
mattmann@apache.org
2012-04-26 23:17:41 +0000
- apply patch from TIKA-901: Provide version number in tika-server contributed by Ingo Renner
diff --git a/CHANGES.txt b/CHANGES.txt
index f046f7682..c9944515e 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -4,7 +4,7 @@ Release 1.2 - Current Development
   * Tika's JAX-RS based Network server now is based on Apache CXF,
     which is available in Maven Central and now allows the server
     module to be packaged and included in our release
-    (TIKA-593).
+    (TIKA-593, TIKA-901).
 
   * Tika: parseToString now lets you specify the max string length
     per-call, in addition to per-Tika-instance. (TIKA-870)
diff --git a/tika-server/src/main/java/org/apache/tika/server/TikaServerCli.java b/tika-server/src/main/java/org/apache/tika/server/TikaServerCli.java
index 2139b02e9..75169af25 100644
--- a/tika-server/src/main/java/org/apache/tika/server/TikaServerCli.java
+++ b/tika-server/src/main/java/org/apache/tika/server/TikaServerCli.java
@@ -17,20 +17,24 @@
 
 package org.apache.tika.server;
 
-import org.apache.commons.cli.*;
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.Properties;
+
+import org.apache.commons.cli.CommandLine;
+import org.apache.commons.cli.CommandLineParser;
+import org.apache.commons.cli.GnuParser;
+import org.apache.commons.cli.HelpFormatter;
+import org.apache.commons.cli.Options;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.cxf.binding.BindingFactoryManager;
 import org.apache.cxf.endpoint.Server;
 import org.apache.cxf.jaxrs.JAXRSBindingFactory;
 import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;
-import org.apache.cxf.jaxrs.lifecycle.ResourceProvider;
 import org.apache.cxf.jaxrs.lifecycle.SingletonResourceProvider;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.List;
-import java.util.Properties;
+import org.apache.tika.Tika;
 
 public class TikaServerCli {
   private static final Log logger = LogFactory.getLog(TikaServerCli.class);
@@ -53,6 +57,7 @@ public class TikaServerCli {
     }
 
     logger.info("Starting Tikaserver "+properties.getProperty("tikaserver.version"));
+    logger.info("Starting Tika Server " + new Tika().toString());
 
     try {
       Options options = getOptions();
@@ -70,9 +75,9 @@ public class TikaServerCli {
         helpFormatter.printHelp("tikaserver", options);
         System.exit(-1);
       }
-      
+
       JAXRSServerFactoryBean sf = new JAXRSServerFactoryBean();
-      sf.setResourceClasses(MetadataResource.class, TikaResource.class, UnpackerResource.class);
+      sf.setResourceClasses(MetadataResource.class, TikaResource.class, UnpackerResource.class, TikaVersion.class);
 
       List providers = new ArrayList();
       providers.add(new TarWriter());
@@ -81,6 +86,7 @@ public class TikaServerCli {
       providers.add(new SingletonResourceProvider(new MetadataResource()));
       providers.add(new SingletonResourceProvider(new TikaResource()));
       providers.add(new SingletonResourceProvider(new UnpackerResource()));
+      providers.add(new SingletonResourceProvider(new TikaVersion()));
       sf.setProviders(providers);
       sf.setAddress("http://localhost:" + TikaServerCli.DEFAULT_PORT + "/");
       BindingFactoryManager manager = sf.getBus().getExtension(
diff --git a/tika-server/src/main/java/org/apache/tika/server/TikaVersion.java b/tika-server/src/main/java/org/apache/tika/server/TikaVersion.java
new file mode 100644
index 000000000..8881ae4f1
--- /dev/null
+++ b/tika-server/src/main/java/org/apache/tika/server/TikaVersion.java
@@ -0,0 +1,34 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.server;
+
+import javax.ws.rs.GET;
+import javax.ws.rs.Path;
+import javax.ws.rs.Produces;
+
+import org.apache.tika.Tika;
+
+@Path("/version")
+public class TikaVersion {
+
+    @GET
+    @Produces("text/plain")
+    public String getVersion() {
+      return new Tika().toString();
+    }
+
+}
diff --git a/tika-server/src/test/java/org/apache/tika/server/TikaVersionTest.java b/tika-server/src/test/java/org/apache/tika/server/TikaVersionTest.java
new file mode 100644
index 000000000..3199e2392
--- /dev/null
+++ b/tika-server/src/test/java/org/apache/tika/server/TikaVersionTest.java
@@ -0,0 +1,93 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.server;
+
+import java.io.InputStream;
+
+import javax.ws.rs.core.Response;
+
+import org.apache.cxf.binding.BindingFactoryManager;
+import org.apache.cxf.endpoint.Server;
+import org.apache.cxf.jaxrs.JAXRSBindingFactory;
+import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;
+import org.apache.cxf.jaxrs.client.WebClient;
+import org.apache.cxf.jaxrs.lifecycle.SingletonResourceProvider;
+import org.apache.tika.Tika;
+import org.junit.Test;
+
+public class TikaVersionTest extends CXFTestBase {
+
+  private static final String VERSION_PATH = "/version";
+  private static final String endPoint = "http://localhost:"
+      + TikaServerCli.DEFAULT_PORT;
+  private Server server;
+
+  /*
+   * (non-Javadoc)
+   *
+   * @see junit.framework.TestCase#setUp()
+   */
+  @Override
+  protected void setUp() throws Exception {
+    JAXRSServerFactoryBean sf = new JAXRSServerFactoryBean();
+    sf.setResourceClasses(TikaVersion.class);
+    sf.setResourceProvider(
+        TikaVersion.class,
+        new SingletonResourceProvider(new TikaVersion())
+    );
+    sf.setAddress(endPoint + "/");
+
+    BindingFactoryManager manager = sf.getBus().getExtension(
+        BindingFactoryManager.class
+    );
+
+    JAXRSBindingFactory factory = new JAXRSBindingFactory();
+    factory.setBus(sf.getBus());
+
+    manager.registerBindingFactory(
+        JAXRSBindingFactory.JAXRS_BINDING_ID,
+        factory
+    );
+
+    server = sf.create();
+  }
+
+  /*
+   * (non-Javadoc)
+   *
+   * @see junit.framework.TestCase#tearDown()
+   */
+  @Override
+  protected void tearDown() throws Exception {
+    server.stop();
+    server.destroy();
+  }
+
+  @Test
+  public void testGetVersion() throws Exception {
+    Response response = WebClient
+        .create(endPoint + VERSION_PATH)
+        .type("text/plain")
+        .accept("text/plain")
+        .get();
+
+    assertEquals(new Tika().toString(),
+        getStringFromInputStream((InputStream) response.getEntity()));
+  }
+
+}

Commit:
aeeb366b987b20902c531f5ecac38f334a377d72
Nick Burch
nick@apache.org
2012-04-20 13:32:55 +0000
TIKA-897 Detect XML files that start with the UTF-8 BOM, plus test
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 52a99c414..cc99740ab 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -2940,6 +2940,9 @@
       <match value="&lt;?xml" type="string" offset="0"/>
       <match value="&lt;?XML" type="string" offset="0"/>
       <match value="&lt;!--" type="string" offset="0"/>
+      <!-- UTF-8 BOM -->
+      <match value="0xEFBBBF3C3F786D6C" type="string" offset="0"/>
+      <!-- UTF-16 LE/BE -->
       <match value="0xFFFE3C003F0078006D006C00" type="string" offset="0"/>
       <match value="0xFEFF003C003F0078006D006C" type="string" offset="0"/>
       <!-- TODO: Add matches for the other possible XML encoding schemes -->
diff --git a/tika-core/src/test/java/org/apache/tika/mime/MimeDetectionTest.java b/tika-core/src/test/java/org/apache/tika/mime/MimeDetectionTest.java
index bd7194604..996b8a995 100644
--- a/tika-core/src/test/java/org/apache/tika/mime/MimeDetectionTest.java
+++ b/tika-core/src/test/java/org/apache/tika/mime/MimeDetectionTest.java
@@ -46,6 +46,7 @@ public class MimeDetectionTest extends TestCase {
         testFile("text/html", "test.html");
         testFile("application/xml", "test-iso-8859-1.xml");
         testFile("application/xml", "test-utf8.xml");
+        testFile("application/xml", "test-utf8-bom.xml");
         testFile("application/xml", "test-utf16le.xml");
         testFile("application/xml", "test-utf16be.xml");
         testFile("application/xml", "test-long-comment.xml");
diff --git a/tika-core/src/test/resources/org/apache/tika/mime/test-utf8-bom.xml b/tika-core/src/test/resources/org/apache/tika/mime/test-utf8-bom.xml
new file mode 100644
index 000000000..4cd4db38c
--- /dev/null
+++ b/tika-core/src/test/resources/org/apache/tika/mime/test-utf8-bom.xml
@@ -0,0 +1,2 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<test hello="world"/>
\ No newline at end of file

Commit:
1f5a278f83e6793441bab1be53bc0327069e9354
Jukka Zitting
jukka@apache.org
2012-04-19 21:40:29 +0000
tika-server/pom.xml: add svn:eol-style, remove duplicate license header
diff --git a/tika-server/pom.xml b/tika-server/pom.xml
index e96e326f9..f636f2216 100644
--- a/tika-server/pom.xml
+++ b/tika-server/pom.xml
@@ -1,40 +1,20 @@
 <!--
-  ~ Licensed to the Apache Software Foundation (ASF) under one or more
-  ~ contributor license agreements.  See the NOTICE file distributed with
-  ~ this work for additional information regarding copyright ownership.
-  ~ The ASF licenses this file to You under the Apache License, Version 2.0
-  ~ (the "License"); you may not use this file except in compliance with
-  ~ the License.  You may obtain a copy of the License at
-  ~
-  ~     http://www.apache.org/licenses/LICENSE-2.0
-  ~
-  ~ Unless required by applicable law or agreed to in writing, software
-  ~ distributed under the License is distributed on an "AS IS" BASIS,
-  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  ~ See the License for the specific language governing permissions and
-  ~ limitations under the License.
-  -->
+  Licensed to the Apache Software Foundation (ASF) under one or more
+  contributor license agreements.  See the NOTICE file distributed with
+  this work for additional information regarding copyright ownership.
+  The ASF licenses this file to You under the Apache License, Version 2.0
+  (the "License"); you may not use this file except in compliance with
+  the License.  You may obtain a copy of the License at
 
-<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
-
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one
-  or more contributor license agreements.  See the NOTICE file
-  distributed with this work for additional information
-  regarding copyright ownership.  The ASF licenses this file
-  to you under the Apache License, Version 2.0 (the
-  "License"); you may not use this file except in compliance
-  with the License.  You may obtain a copy of the License at
+      http://www.apache.org/licenses/LICENSE-2.0
 
-    http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing,
-  software distributed under the License is distributed on an
-  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-  KIND, either express or implied.  See the License for the
-  specific language governing permissions and limitations
-  under the License.
+  Unless required by applicable law or agreed to in writing, software
+  distributed under the License is distributed on an "AS IS" BASIS,
+  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  See the License for the specific language governing permissions and
+  limitations under the License.
 -->
+<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
   <modelVersion>4.0.0</modelVersion>
 
   <parent>

Commit:
67f1be59059ce85fb0128da45c5067beb06eafb5
Jukka Zitting
jukka@apache.org
2012-04-19 15:41:53 +0000
Ignore Eclipse project settings and other hidden files.
Commit:
0eaf0f573103908599bdb976e6782991fc7b0178
Jukka Zitting
jukka@apache.org
2012-04-19 15:40:36 +0000
TIKA-896: OSGi deployment without declarative services
diff --git a/tika-bundle/pom.xml b/tika-bundle/pom.xml
index 2fe0f84f1..601460901 100644
--- a/tika-bundle/pom.xml
+++ b/tika-bundle/pom.xml
@@ -110,7 +110,7 @@
         <configuration>
           <instructions>
             <Bundle-Activator>
-              org.apache.tika.parser.internal.TikaActivator
+              org.apache.tika.parser.internal.Activator
             </Bundle-Activator>
             <Embed-Dependency>
               tika-parsers;inline=true,

Commit:
07e105b4a6dec3ac528b729a3b7dd458d49f73ab
Jukka Zitting
jukka@apache.org
2012-04-19 13:04:19 +0000
TIKA-896: OSGi deployment without declarative services
diff --git a/tika-parsers/pom.xml b/tika-parsers/pom.xml
index 0a66564f6..2159b6105 100644
--- a/tika-parsers/pom.xml
+++ b/tika-parsers/pom.xml
@@ -211,7 +211,7 @@
           <instructions>
             <Bundle-DocURL>${project.url}</Bundle-DocURL>
             <Bundle-Activator>
-              org.apache.tika.parser.internal.TikaActivator
+              org.apache.tika.parser.internal.Activator
             </Bundle-Activator>
             <Import-Package>
                 org.w3c.dom,
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/internal/Activator.java b/tika-parsers/src/main/java/org/apache/tika/parser/internal/Activator.java
new file mode 100644
index 000000000..48d909ff9
--- /dev/null
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/internal/Activator.java
@@ -0,0 +1,51 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.parser.internal;
+
+import java.util.Properties;
+
+import org.apache.tika.detect.DefaultDetector;
+import org.apache.tika.detect.Detector;
+import org.apache.tika.parser.DefaultParser;
+import org.apache.tika.parser.Parser;
+import org.osgi.framework.BundleActivator;
+import org.osgi.framework.BundleContext;
+import org.osgi.framework.ServiceRegistration;
+
+public class Activator implements BundleActivator {
+
+    private ServiceRegistration detectorService;
+
+    private ServiceRegistration parserService;
+
+    public void start(BundleContext context) throws Exception {
+        detectorService = context.registerService(
+                Detector.class.getName(),
+                new DefaultDetector(Activator.class.getClassLoader()),
+                new Properties());
+        parserService = context.registerService(
+                Parser.class.getName(),
+                new DefaultParser(Activator.class.getClassLoader()),
+                new Properties());
+    }
+
+    public void stop(BundleContext context) throws Exception {
+        parserService.unregister();
+        detectorService.unregister();
+    }
+
+}
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/internal/OSGiDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/internal/OSGiDetector.java
deleted file mode 100644
index 1b2e3a823..000000000
--- a/tika-parsers/src/main/java/org/apache/tika/parser/internal/OSGiDetector.java
+++ /dev/null
@@ -1,30 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.tika.parser.internal;
-
-import org.apache.tika.detect.DefaultDetector;
-
-public class OSGiDetector extends DefaultDetector {
-
-    /** Serial version UID */
-    private static final long serialVersionUID = -4397900223116731483L;
-
-    public OSGiDetector() {
-        super(OSGiDetector.class.getClassLoader());
-    }
-
-}
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/internal/OSGiParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/internal/OSGiParser.java
deleted file mode 100644
index d146d068d..000000000
--- a/tika-parsers/src/main/java/org/apache/tika/parser/internal/OSGiParser.java
+++ /dev/null
@@ -1,30 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.tika.parser.internal;
-
-import org.apache.tika.parser.DefaultParser;
-
-public class OSGiParser extends DefaultParser {
-
-    /** Serial version UID */
-    private static final long serialVersionUID = -2496251420681985759L;
-
-    public OSGiParser() {
-        super(OSGiParser.class.getClassLoader());
-    }
-
-}

Commit:
f4332420e55c093463bf0b84a8256c412f4cc03b
Jukka Zitting
jukka@apache.org
2012-04-19 12:43:24 +0000
TIKA-896: OSGi deployment without declarative services
diff --git a/tika-bundle/pom.xml b/tika-bundle/pom.xml
index 1210469b6..2fe0f84f1 100644
--- a/tika-bundle/pom.xml
+++ b/tika-bundle/pom.xml
@@ -109,6 +109,9 @@
         <extensions>true</extensions>
         <configuration>
           <instructions>
+            <Bundle-Activator>
+              org.apache.tika.parser.internal.TikaActivator
+            </Bundle-Activator>
             <Embed-Dependency>
               tika-parsers;inline=true,
               commons-compress, commons-codec,
@@ -135,9 +138,6 @@
               !org.apache.tika.parser.external,
               org.apache.tika.parser.*
             </Export-Package>
-            <Service-Component>
-              OSGI-INF/serviceComponents.xml
-            </Service-Component>
           </instructions>
         </configuration>
       </plugin>
diff --git a/tika-bundle/src/test/java/org/apache/tika/bundle/BundleIT.java b/tika-bundle/src/test/java/org/apache/tika/bundle/BundleIT.java
index 8dc9469ed..6fcaa947c 100644
--- a/tika-bundle/src/test/java/org/apache/tika/bundle/BundleIT.java
+++ b/tika-bundle/src/test/java/org/apache/tika/bundle/BundleIT.java
@@ -20,7 +20,6 @@ import static junit.framework.Assert.assertEquals;
 import static junit.framework.Assert.assertTrue;
 import static org.ops4j.pax.exam.CoreOptions.bundle;
 import static org.ops4j.pax.exam.CoreOptions.junitBundles;
-import static org.ops4j.pax.exam.CoreOptions.mavenBundle;
 
 import java.io.File;
 import java.io.FileInputStream;
@@ -52,7 +51,6 @@ public class BundleIT {
         File base = new File(TARGET, "test-bundles");
         return CoreOptions.options(
                 junitBundles(),
-                mavenBundle("org.apache.felix", "org.apache.felix.scr", "1.6.0"),
                 bundle(new File(base, "tika-core.jar").toURL().toURI().toString()),
                 bundle(new File(base, "tika-bundle.jar").toURL().toURI().toString()));
     }
diff --git a/tika-core/pom.xml b/tika-core/pom.xml
index 3fc46ad92..64db96eb7 100644
--- a/tika-core/pom.xml
+++ b/tika-core/pom.xml
@@ -43,6 +43,13 @@
       <scope>provided</scope>
       <optional>true</optional>
     </dependency>
+    <dependency>
+      <groupId>org.osgi</groupId>
+      <artifactId>org.osgi.compendium</artifactId>
+      <version>4.0.0</version>
+      <scope>provided</scope>
+      <optional>true</optional>
+    </dependency>
     <dependency>
       <groupId>biz.aQute</groupId>
       <artifactId>bndlib</artifactId>
@@ -92,6 +99,7 @@
             </goals>
             <configuration>
               <excludes>
+                <exlude>org/apache/tika/config/TikaActivator</exlude>
                 <exlude>org/apache/tika/metadata/Property$PropertyType</exlude>
                 <exlude>org/apache/tika/metadata/Property$ValueType</exlude>
                 <exlude>org/apache/tika/metadata/MSOffice</exlude>
diff --git a/tika-core/src/main/java/org/apache/tika/config/TikaActivator.java b/tika-core/src/main/java/org/apache/tika/config/TikaActivator.java
index 6126a9a56..0d68dfc96 100644
--- a/tika-core/src/main/java/org/apache/tika/config/TikaActivator.java
+++ b/tika-core/src/main/java/org/apache/tika/config/TikaActivator.java
@@ -16,11 +16,13 @@
  */
 package org.apache.tika.config;
 
+import org.apache.tika.detect.Detector;
+import org.apache.tika.parser.Parser;
 import org.osgi.framework.BundleActivator;
 import org.osgi.framework.BundleContext;
-import org.osgi.framework.ServiceEvent;
-import org.osgi.framework.ServiceListener;
 import org.osgi.framework.ServiceReference;
+import org.osgi.util.tracker.ServiceTracker;
+import org.osgi.util.tracker.ServiceTrackerCustomizer;
 
 /**
  * Bundle activator that adjust the class loading mechanism of the
@@ -33,36 +35,42 @@ import org.osgi.framework.ServiceReference;
  *
  * @since Apache Tika 0.9
  */
-public class TikaActivator
-        implements BundleActivator, ServiceListener {
+public class TikaActivator implements BundleActivator, ServiceTrackerCustomizer {
 
-    private BundleContext bundleContext;
+	private ServiceTracker detectorTracker;
 
+	private ServiceTracker parserTracker;
+
+	private BundleContext bundleContext;
     //-----------------------------------------------------< BundleActivator >
 
-    public void start(BundleContext context) throws Exception {
-        bundleContext = context;
-        bundleContext.addServiceListener(this,
-                "(|(objectClass=org.apache.tika.detect.Detector)"
-                + "(objectClass=org.apache.tika.parser.Parser))");
+    public void start(final BundleContext context) throws Exception {
+    	bundleContext = context;
+
+    	detectorTracker = new ServiceTracker(context, Detector.class.getName(), this);
+        parserTracker = new ServiceTracker(context, Parser.class.getName(), this);
+
+        detectorTracker.open();
+        parserTracker.open();
     }
 
     public void stop(BundleContext context) throws Exception {
-        bundleContext.removeServiceListener(this);
+    	parserTracker.close();
+    	detectorTracker.close();
     }
 
-    //-----------------------------------------------------< ServiceListener >
+	public Object addingService(ServiceReference reference) {
+        Object service = bundleContext.getService(reference);
+        ServiceLoader.addService(reference, service);
+		return service;
+	}
 
-    public synchronized void serviceChanged(ServiceEvent event) {
-        if (event.getType() == ServiceEvent.REGISTERED) {
-            ServiceReference reference = event.getServiceReference();
-            Object service = bundleContext.getService(reference);
-            ServiceLoader.addService(reference, service);
-        } else if (event.getType() == ServiceEvent.UNREGISTERING) {
-            ServiceReference reference = event.getServiceReference();
-            ServiceLoader.removeService(reference);
-            bundleContext.ungetService(reference);
-        }
-    }
+	public void modifiedService(ServiceReference reference, Object service) {
+	}
+
+	public void removedService(ServiceReference reference, Object service) {
+        ServiceLoader.removeService(reference);
+        bundleContext.ungetService(reference);
+	}
 
 }
diff --git a/tika-parsers/pom.xml b/tika-parsers/pom.xml
index d35bd22be..0a66564f6 100644
--- a/tika-parsers/pom.xml
+++ b/tika-parsers/pom.xml
@@ -42,6 +42,15 @@
   </properties>
 
   <dependencies>
+    <!-- Optional OSGi dependency, used only when running within OSGi -->
+    <dependency>
+      <groupId>org.osgi</groupId>
+      <artifactId>org.osgi.core</artifactId>
+      <version>4.0.0</version>
+      <scope>provided</scope>
+      <optional>true</optional>
+    </dependency>
+
     <dependency>
       <groupId>${project.groupId}</groupId>
       <artifactId>tika-core</artifactId>
@@ -201,6 +210,9 @@
         <configuration>
           <instructions>
             <Bundle-DocURL>${project.url}</Bundle-DocURL>
+            <Bundle-Activator>
+              org.apache.tika.parser.internal.TikaActivator
+            </Bundle-Activator>
             <Import-Package>
                 org.w3c.dom,
                 org.apache.tika.*,
@@ -219,19 +231,6 @@
           </excludes>
         </configuration>
       </plugin>
-      <plugin>
-        <groupId>org.apache.felix</groupId>
-        <artifactId>maven-scr-plugin</artifactId>
-        <version>1.7.2</version>
-        <executions>
-          <execution>
-            <id>generate-scr-scrdescriptor</id>
-            <goals>
-              <goal>scr</goal>
-            </goals>
-          </execution>
-        </executions>
-      </plugin>
     </plugins>
 
     <pluginManagement>
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/internal/OSGiDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/internal/OSGiDetector.java
index 1b0c951d7..1b2e3a823 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/internal/OSGiDetector.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/internal/OSGiDetector.java
@@ -16,12 +16,8 @@
  */
 package org.apache.tika.parser.internal;
 
-import org.apache.felix.scr.annotations.Component;
-import org.apache.felix.scr.annotations.Service;
 import org.apache.tika.detect.DefaultDetector;
-import org.apache.tika.detect.Detector;
 
-@Component @Service(Detector.class)
 public class OSGiDetector extends DefaultDetector {
 
     /** Serial version UID */
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/internal/OSGiParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/internal/OSGiParser.java
index d1a708f7f..d146d068d 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/internal/OSGiParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/internal/OSGiParser.java
@@ -16,12 +16,8 @@
  */
 package org.apache.tika.parser.internal;
 
-import org.apache.felix.scr.annotations.Component;
-import org.apache.felix.scr.annotations.Service;
 import org.apache.tika.parser.DefaultParser;
-import org.apache.tika.parser.Parser;
 
-@Component @Service(Parser.class)
 public class OSGiParser extends DefaultParser {
 
     /** Serial version UID */

Commit:
d8e91b6beb45376a351305c53698ccca98177462
Nick Burch
nick@apache.org
2012-04-05 13:39:25 +0000
TIKA-890 Container Aware detection of JAR derived types such as WAR, EAR and APK, with tests
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/pkg/ZipContainerDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/pkg/ZipContainerDetector.java
index edad4a7ef..8d8190c2b 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/pkg/ZipContainerDetector.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/pkg/ZipContainerDetector.java
@@ -77,10 +77,11 @@ public class ZipContainerDetector implements Detector {
                     if (type == null) {
                         type = detectIWork(zip);
                     }
+                    if (type == null) {
+                        type = detectJar(zip); 
+                    }
                     if (type != null) {
                         return type;
-                    } else if (zip.getEntry("META-INF/MANIFEST.MF") != null) {
-                        return MediaType.application("java-archive");
                     }
                 } finally {
                     // TODO: shouldn't we record the open
@@ -191,4 +192,33 @@ public class ZipContainerDetector implements Detector {
             return null;
         }
     }
+    
+    private static MediaType detectJar(ZipFile zip) {
+       if (zip.getEntry("META-INF/MANIFEST.MF") != null) {
+          // It's a Jar file, or something based on Jar
+          
+          // Is it an Android APK?
+          if (zip.getEntry("AndroidManifest.xml") != null) {
+             return MediaType.application("vnd.android.package-archive");
+          }
+          
+          // Check for WAR and EAR
+          if (zip.getEntry("WEB-INF/") != null) {
+             return MediaType.application("x-tika-java-web-archive");
+          }
+          if (zip.getEntry("META-INF/application.xml") != null) {
+             return MediaType.application("x-tika-java-enterprise-archive");
+          }
+          
+          // Looks like a regular Jar Archive
+          return MediaType.application("java-archive");
+       } else {
+          // Some Android APKs miss the default Manifest
+          if (zip.getEntry("AndroidManifest.xml") != null) {
+             return MediaType.application("vnd.android.package-archive");
+          }
+          
+          return null;
+       }
+    }
 }
\ No newline at end of file
diff --git a/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java b/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
index e4a748b5b..c9bc97f04 100644
--- a/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
+++ b/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
@@ -281,7 +281,12 @@ public class TestContainerAwareDetector extends TestCase {
     public void testDetectZip() throws Exception {
         assertTypeByData("test-documents.zip", "application/zip");
         assertTypeByData("test-zip-of-zip.zip", "application/zip");
+        
+        // JAR based formats
         assertTypeByData("testJAR.jar", "application/java-archive");
+        assertTypeByData("testWAR.war", "application/x-tika-java-web-archive");
+        assertTypeByData("testEAR.ear", "application/x-tika-java-enterprise-archive");
+        assertTypeByData("testAPK.apk", "application/vnd.android.package-archive");
     }
 
     private TikaInputStream getTruncatedFile(String name, int n)

Commit:
83cee2a7b04adc9de1a3aaa068b8be3843d88aec
Nick Burch
nick@apache.org
2012-04-05 13:39:01 +0000
TIKA-890 Update the APK mimetype entry to mark it as JAR derived, and add entries for WAR and EAR (also JAR derived)
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 7b007aa0e..52a99c414 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -176,6 +176,18 @@
     <sub-class-of type="application/zip"/>
     <glob pattern="*.jar"/>
   </mime-type>
+  <mime-type type="application/vnd.android.package-archive">
+    <sub-class-of type="application/java-archive"/>
+    <glob pattern="*.apk"/>
+  </mime-type>
+  <mime-type type="application/x-tika-java-enterprise-archive">
+    <sub-class-of type="application/java-archive"/>
+    <glob pattern="*.ear"/>
+  </mime-type>
+  <mime-type type="application/x-tika-java-web-archive">
+    <sub-class-of type="application/java-archive"/>
+    <glob pattern="*.war"/>
+  </mime-type>
 
   <mime-type type="application/java-serialized-object">
     <glob pattern="*.ser"/>
@@ -598,9 +610,6 @@
   <mime-type type="application/vnd.amiga.ami">
     <glob pattern="*.ami"/>
   </mime-type>
-  <mime-type type="application/vnd.android.package-archive">
-    <glob pattern="*.apk"/>
-  </mime-type>
   <mime-type type="application/vnd.anser-web-certificate-issue-initiation">
     <glob pattern="*.cii"/>
   </mime-type>

Commit:
1c777daab92e190b31f4c1b5fefb22e73f95b11e
Nick Burch
nick@apache.org
2012-04-05 13:37:27 +0000
TIKA-890 Sample APK file, along with sample EAR and WAR files (related)
diff --git a/tika-parsers/src/test/resources/test-documents/testAPK.apk b/tika-parsers/src/test/resources/test-documents/testAPK.apk
new file mode 100644
index 000000000..1dce996de
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testAPK.apk differ
diff --git a/tika-parsers/src/test/resources/test-documents/testEAR.ear b/tika-parsers/src/test/resources/test-documents/testEAR.ear
new file mode 100644
index 000000000..1682e63d7
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testEAR.ear differ
diff --git a/tika-parsers/src/test/resources/test-documents/testWAR.war b/tika-parsers/src/test/resources/test-documents/testWAR.war
new file mode 100644
index 000000000..3cdcf5b6c
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testWAR.war differ

Commit:
b63d7e6d58ab88a6b39377892c634eae37e1c335
Maxim Valyanskiy
maxcom@apache.org
2012-04-04 11:43:36 +0000
TIKA-593: fix java5 compatibility
diff --git a/tika-server/pom.xml b/tika-server/pom.xml
index 3e5a9c431..e96e326f9 100644
--- a/tika-server/pom.xml
+++ b/tika-server/pom.xml
@@ -117,7 +117,7 @@
         <groupId>org.apache.felix</groupId>
         <artifactId>maven-bundle-plugin</artifactId>
         <extensions>true</extensions>
-        <version>2.3.5</version>
+        <version>2.3.6</version>
         <configuration>
           <instructions>
             <Export-Package>org.apache.tika.*</Export-Package>

Commit:
5caebac4027b5856bb8374d71c35bd4a45cce1cc
Maxim Valyanskiy
maxcom@apache.org
2012-04-04 09:59:12 +0000
TIKA-593: share/bundle plugin configuration
diff --git a/tika-server/pom.xml b/tika-server/pom.xml
index 0df7cc195..3e5a9c431 100644
--- a/tika-server/pom.xml
+++ b/tika-server/pom.xml
@@ -121,10 +121,6 @@
         <configuration>
           <instructions>
             <Export-Package>org.apache.tika.*</Export-Package>
-            <Embed-Dependency>
-                *;scope=compile;inline=META-INF/services/**|au/**|javax/**|org/**|com/**|Resources/**|font_metrics.properties|repackage/**|schema*/**|META-INF/cxf/**|schemas/**
-            </Embed-Dependency>
-            <Embed-Transitive>true</Embed-Transitive>
             <Bundle-DocURL>${project.url}</Bundle-DocURL>
                     <Main-Class>org.apache.tika.server.TikaServerCli</Main-Class>
           </instructions>
@@ -145,6 +141,66 @@
                     </systemProperties>
                 </configuration>
             </plugin>
+
+          <plugin>
+            <groupId>org.apache.maven.plugins</groupId>
+            <artifactId>maven-shade-plugin</artifactId>
+            <executions>
+              <execution>
+                <phase>package</phase>
+                <goals>
+                  <goal>shade</goal>
+                </goals>
+                <configuration>
+                  <filters>
+                    <filter>
+                      <artifact>*:*</artifact>
+                      <excludes>
+                        <exclude>META-INF/*.SF</exclude>
+                        <exclude>META-INF/*.DSA</exclude>
+                        <exclude>META-INF/*.RSA</exclude>
+                      </excludes>
+                    </filter>
+                  </filters>
+                  <transformers>
+                    <transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer">
+                      <resource>META-INF/spring.handlers</resource>
+                    </transformer>
+                    <transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer">
+                      <resource>META-INF/services/com.sun.tools.xjc.Plugin</resource>
+                    </transformer>
+                    <transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer">
+                      <resource>META-INF/spring.schemas</resource>
+                    </transformer>
+                    <transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer">
+                      <resource>META-INF/cxf/cxf.extension</resource>
+                    </transformer>
+                    <transformer implementation="org.apache.maven.plugins.shade.resource.XmlAppendingTransformer">
+                      <resource>META-INF/extensions.xml</resource>
+                    </transformer>
+                    <transformer implementation="org.apache.maven.plugins.shade.resource.XmlAppendingTransformer">
+                      <resource>META-INF/cxf/extensions.xml</resource>
+                    </transformer>
+                    <transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer">
+                      <resource>META-INF/cxf/bus-extensions.txt</resource>
+                    </transformer>
+                    <transformer implementation="org.apache.maven.plugins.shade.resource.XmlAppendingTransformer">
+                      <resource>META-INF/cxf/bus-extensions.xml</resource>
+                    </transformer>
+                    <transformer implementation="org.apache.maven.plugins.shade.resource.XmlAppendingTransformer">
+                      <resource>META-INF/wsdl.plugin.xml</resource>
+                    </transformer>
+                    <transformer implementation="org.apache.maven.plugins.shade.resource.XmlAppendingTransformer">
+                      <resource>META-INF/tools.service.validator.xml</resource>
+                    </transformer>
+                    <transformer implementation="org.apache.maven.plugins.shade.resource.XmlAppendingTransformer">
+                      <resource>META-INF/cxf/java2wsbeans.xml</resource>
+                    </transformer>
+                  </transformers>
+                </configuration>
+              </execution>
+            </executions>
+          </plugin>
         </plugins>
     </build>
 </project>

Commit:
a9e1304be5f928d99ff8d10f11eed43d78793812
Nick Burch
nick@apache.org
2012-04-03 16:01:51 +0000
TIKA-700 Upgrade to POI 3.8 Final
diff --git a/tika-parsers/pom.xml b/tika-parsers/pom.xml
index 823b8bf68..d35bd22be 100644
--- a/tika-parsers/pom.xml
+++ b/tika-parsers/pom.xml
@@ -35,7 +35,7 @@
   <url>http://tika.apache.org/</url>
 
   <properties>
-    <poi.version>3.8-beta5</poi.version>
+    <poi.version>3.8</poi.version>
     <codec.version>1.5</codec.version> <!-- NOTE: sync with POI -->
     <mime4j.version>0.7.2</mime4j.version>
     <vorbis.version>0.1</vorbis.version>

Commit:
4f5c6b54b98468d0d20d8e407eee4e79b564e00f
Chris Mattmann
mattmann@apache.org
2012-03-29 14:40:09 +0000
- TIKA-593 note.
diff --git a/CHANGES.txt b/CHANGES.txt
index 04e8ead8f..f046f7682 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -1,6 +1,11 @@
 Release 1.2 - Current Development
 ---------------------------------
 
+  * Tika's JAX-RS based Network server now is based on Apache CXF,
+    which is available in Maven Central and now allows the server
+    module to be packaged and included in our release
+    (TIKA-593).
+
   * Tika: parseToString now lets you specify the max string length
     per-call, in addition to per-Tika-instance. (TIKA-870)
 

Commit:
7b42120d9f8f7b009f6ece479d67c934076b7f47
Chris Mattmann
mattmann@apache.org
2012-03-29 14:38:19 +0000
- TIKA-593: remove FIXME and uncomment @Test, per max's comments.
diff --git a/tika-server/src/test/java/org/apache/tika/server/UnpackerResourceTest.java b/tika-server/src/test/java/org/apache/tika/server/UnpackerResourceTest.java
index 4cdc67de7..56329ba40 100644
--- a/tika-server/src/test/java/org/apache/tika/server/UnpackerResourceTest.java
+++ b/tika-server/src/test/java/org/apache/tika/server/UnpackerResourceTest.java
@@ -174,7 +174,7 @@ public class UnpackerResourceTest extends CXFTestBase {
 		assertEquals(DOCX_IMAGE2_MD5, data.get(DOCX_IMAGE2_NAME));
 	}
 
-	//FIXME: Disabled for now until TIKA-593 is done @Test
+	@Test
 	public void test415() throws Exception {
 		Response response = WebClient.create(endPoint + UNPACKER_PATH)
 				.type("xxx/xxx")

Commit:
46f295f7d38a6e6b1bcbc17af1ceabe67e69aeeb
Maxim Valyanskiy
maxcom@apache.org
2012-03-29 14:15:21 +0000
TIKA-593 - trying to fix .jar build
diff --git a/tika-server/pom.xml b/tika-server/pom.xml
index 224f8e0a3..0df7cc195 100644
--- a/tika-server/pom.xml
+++ b/tika-server/pom.xml
@@ -117,12 +117,12 @@
         <groupId>org.apache.felix</groupId>
         <artifactId>maven-bundle-plugin</artifactId>
         <extensions>true</extensions>
+        <version>2.3.5</version>
         <configuration>
           <instructions>
             <Export-Package>org.apache.tika.*</Export-Package>
             <Embed-Dependency>
-                inline=META-INF/services/**|au/**|javax/**|org/**|com/**|Resources/**|font_metrics.properties|repackage/**|schema*/**,
-                inline=com/** |META-INF/services/com.sun*|META-INF/services/javax.ws.rs.ext.RuntimeDelegate
+                *;scope=compile;inline=META-INF/services/**|au/**|javax/**|org/**|com/**|Resources/**|font_metrics.properties|repackage/**|schema*/**|META-INF/cxf/**|schemas/**
             </Embed-Dependency>
             <Embed-Transitive>true</Embed-Transitive>
             <Bundle-DocURL>${project.url}</Bundle-DocURL>

Commit:
0b8f59f622f248bbd039012a91b68b6f82048771
Maxim Valyanskiy
maxcom@apache.org
2012-03-29 13:41:40 +0000
TIKA-593: add ExceptionMapper for TikaException for prodivers list (this fixes test415)
diff --git a/tika-server/src/main/java/org/apache/tika/server/TikaServerCli.java b/tika-server/src/main/java/org/apache/tika/server/TikaServerCli.java
index aacaa2dab..2139b02e9 100644
--- a/tika-server/src/main/java/org/apache/tika/server/TikaServerCli.java
+++ b/tika-server/src/main/java/org/apache/tika/server/TikaServerCli.java
@@ -76,7 +76,8 @@ public class TikaServerCli {
 
       List providers = new ArrayList();
       providers.add(new TarWriter());
-	  providers.add(new ZipWriter());      
+      providers.add(new ZipWriter());
+      providers.add(new TikaExceptionMapper());
       providers.add(new SingletonResourceProvider(new MetadataResource()));
       providers.add(new SingletonResourceProvider(new TikaResource()));
       providers.add(new SingletonResourceProvider(new UnpackerResource()));
diff --git a/tika-server/src/test/java/org/apache/tika/server/UnpackerResourceTest.java b/tika-server/src/test/java/org/apache/tika/server/UnpackerResourceTest.java
index de7978dde..4cdc67de7 100644
--- a/tika-server/src/test/java/org/apache/tika/server/UnpackerResourceTest.java
+++ b/tika-server/src/test/java/org/apache/tika/server/UnpackerResourceTest.java
@@ -78,7 +78,8 @@ public class UnpackerResourceTest extends CXFTestBase {
 		List providers = new ArrayList();
 		providers.add(new TarWriter());
 		providers.add(new ZipWriter());
-		sf.setProviders(providers);
+                providers.add(new TikaExceptionMapper());
+    		sf.setProviders(providers);
 		sf.setResourceClasses(UnpackerResource.class);
 		sf.setResourceProvider(UnpackerResource.class,
 				new SingletonResourceProvider(new UnpackerResource()));
@@ -174,7 +175,7 @@ public class UnpackerResourceTest extends CXFTestBase {
 	}
 
 	//FIXME: Disabled for now until TIKA-593 is done @Test
-	public void Xtest415() throws Exception {
+	public void test415() throws Exception {
 		Response response = WebClient.create(endPoint + UNPACKER_PATH)
 				.type("xxx/xxx")
 				.accept("*/*")

Commit:
d442f3680c9db0db9944786cd63820ebae177f91
Nick Burch
nick@apache.org
2012-03-29 10:51:10 +0000
Bump the Apache James Mime4J version from 0.7 to 0.7.2, for recent bugfixes
diff --git a/tika-parsers/pom.xml b/tika-parsers/pom.xml
index 586177d24..823b8bf68 100644
--- a/tika-parsers/pom.xml
+++ b/tika-parsers/pom.xml
@@ -37,7 +37,7 @@
   <properties>
     <poi.version>3.8-beta5</poi.version>
     <codec.version>1.5</codec.version> <!-- NOTE: sync with POI -->
-    <mime4j.version>0.7</mime4j.version>
+    <mime4j.version>0.7.2</mime4j.version>
     <vorbis.version>0.1</vorbis.version>
   </properties>
 

Commit:
232cc5ddc7a1adb357959102accd52a3ee11d755
Nick Burch
nick@apache.org
2012-03-28 15:26:10 +0000
TIKA-886 If we open the OPCPackage from a File on a TikaInputStream, have it tracked (+closed) by the TikaInputStream the same way that ZipContainerDetector opened ones are
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/OOXMLExtractorFactory.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/OOXMLExtractorFactory.java
index 87a14ff53..e6809a767 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/OOXMLExtractorFactory.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/OOXMLExtractorFactory.java
@@ -26,6 +26,7 @@ import org.apache.poi.extractor.ExtractorFactory;
 import org.apache.poi.openxml4j.exceptions.InvalidFormatException;
 import org.apache.poi.openxml4j.exceptions.OpenXML4JException;
 import org.apache.poi.openxml4j.opc.OPCPackage;
+import org.apache.poi.openxml4j.opc.PackageAccess;
 import org.apache.poi.xslf.extractor.XSLFPowerPointExtractor;
 import org.apache.poi.xslf.usermodel.XMLSlideShow;
 import org.apache.poi.xssf.extractor.XSSFEventBasedExcelExtractor;
@@ -61,12 +62,13 @@ public class OOXMLExtractorFactory {
             OOXMLExtractor extractor;
             OPCPackage pkg;
 
-            // Open the OPCPackage for the file
+            // Locate or Open the OPCPackage for the file
             TikaInputStream tis = TikaInputStream.cast(stream);
             if (tis != null && tis.getOpenContainer() instanceof OPCPackage) {
                 pkg = (OPCPackage) tis.getOpenContainer();
             } else if (tis != null && tis.hasFile()) {
-                pkg = OPCPackage.open( tis.getFile().getPath() );
+                pkg = OPCPackage.open( tis.getFile().getPath(), PackageAccess.READ );
+                tis.setOpenContainer(pkg);
             } else {
                 InputStream shield = new CloseShieldInputStream(stream);
                 pkg = OPCPackage.open(shield); 

Commit:
a1e4fed9b35fb377991758f4cb25f340f4b081b4
Chris Mattmann
mattmann@apache.org
2012-03-28 04:39:12 +0000
- TIKA-593: forgot X method
diff --git a/tika-server/src/test/java/org/apache/tika/server/UnpackerResourceTest.java b/tika-server/src/test/java/org/apache/tika/server/UnpackerResourceTest.java
index 631629086..de7978dde 100644
--- a/tika-server/src/test/java/org/apache/tika/server/UnpackerResourceTest.java
+++ b/tika-server/src/test/java/org/apache/tika/server/UnpackerResourceTest.java
@@ -174,7 +174,7 @@ public class UnpackerResourceTest extends CXFTestBase {
 	}
 
 	//FIXME: Disabled for now until TIKA-593 is done @Test
-	public void test415() throws Exception {
+	public void Xtest415() throws Exception {
 		Response response = WebClient.create(endPoint + UNPACKER_PATH)
 				.type("xxx/xxx")
 				.accept("*/*")

Commit:
f906d346e235a2317c583975339d8dd3fea74591
Chris Mattmann
mattmann@apache.org
2012-03-28 04:38:52 +0000
- accept should be */* since by default CXF client sets to an XML accept (yikes), thanks to pramirez for identification, TIKA-593, see: http://cxf.547215.n5.nabble.com/Why-is-the-default-accept-for-WebClient-text-xml-td5013707.html
diff --git a/tika-server/src/test/java/org/apache/tika/server/UnpackerResourceTest.java b/tika-server/src/test/java/org/apache/tika/server/UnpackerResourceTest.java
index 489cbe033..631629086 100644
--- a/tika-server/src/test/java/org/apache/tika/server/UnpackerResourceTest.java
+++ b/tika-server/src/test/java/org/apache/tika/server/UnpackerResourceTest.java
@@ -173,10 +173,11 @@ public class UnpackerResourceTest extends CXFTestBase {
 		assertEquals(DOCX_IMAGE2_MD5, data.get(DOCX_IMAGE2_NAME));
 	}
 
-	//FIXME: Disabled until TIKA-593 is done @Test
-	public void Xtest415() throws Exception {
+	//FIXME: Disabled for now until TIKA-593 is done @Test
+	public void test415() throws Exception {
 		Response response = WebClient.create(endPoint + UNPACKER_PATH)
-				.type("xxx/xxx").accept("application/zip")
+				.type("xxx/xxx")
+				.accept("*/*")
 				.put(ClassLoader.getSystemResourceAsStream(TEST_DOC_WAV));
 
 		assertEquals(415, response.getStatus());

Commit:
71772d2fd1227a0fe6c020eba65530c2c0afcfe0
Chris Mattmann
mattmann@apache.org
2012-03-28 04:32:34 +0000
- update and configure logging.properties
diff --git a/tika-server/pom.xml b/tika-server/pom.xml
index 708369218..224f8e0a3 100644
--- a/tika-server/pom.xml
+++ b/tika-server/pom.xml
@@ -137,6 +137,12 @@
                 <configuration>
                     <redirectTestOutputToFile>true</redirectTestOutputToFile>
                     <argLine>-da -XX:+HeapDumpOnOutOfMemoryError -Xmx512m</argLine>
+                    <systemProperties>
+		             <property>
+		               <name>java.util.logging.config.file</name>
+		               <value>${basedir}/src/main/resources/commons-logging.properties</value>
+		             </property>
+                    </systemProperties>
                 </configuration>
             </plugin>
         </plugins>
diff --git a/tika-server/src/main/resources/commons-logging.properties b/tika-server/src/main/resources/commons-logging.properties
index 0a4f7a4dc..07d7dc0e1 100644
--- a/tika-server/src/main/resources/commons-logging.properties
+++ b/tika-server/src/main/resources/commons-logging.properties
@@ -14,4 +14,17 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
-org.apache.commons.logging.Log=org.apache.commons.logging.impl.Jdk14Logger
+
+handlers = java.util.logging.ConsoleHandler
+
+# Set the default logging level for the root logger
+.level = ALL
+    
+# Set the default logging level for new ConsoleHandler instances
+java.util.logging.ConsoleHandler.level = ALL
+        
+# Set the default formatter for new ConsoleHandler instances
+java.util.logging.ConsoleHandler.formatter = java.util.logging.SimpleFormatter
+#org.apache.commons.logging.Log=org.apache.commons.logging.impl.Jdk14Logger
+
+org.apache.cxf.level = INFO

Commit:
abb7e351a23a9855a76066af8a014402c844b103
Chris Mattmann
mattmann@apache.org
2012-03-28 04:05:10 +0000
- TIKA-593: improvement: use CXF client for test harnesses, remove all extraneous pom.xml dependencies and remove dep on commons-httpclient
diff --git a/tika-server/pom.xml b/tika-server/pom.xml
index 502f509f0..708369218 100644
--- a/tika-server/pom.xml
+++ b/tika-server/pom.xml
@@ -69,32 +69,6 @@
 		   <artifactId>cxf-rt-transports-http-jetty</artifactId>
 		   <version>2.5.2</version>
 		</dependency>   	
-        <dependency>
-            <groupId>org.slf4j</groupId>
-            <artifactId>slf4j-jdk14</artifactId>
-            <version>1.6.1</version>
-        </dependency>
-        <dependency>
-            <groupId>commons-httpclient</groupId>
-            <artifactId>commons-httpclient</artifactId>
-            <version>3.1</version>
-            <scope>test</scope>
-        </dependency>
-        <dependency>
-            <groupId>commons-logging</groupId>
-            <artifactId>commons-logging</artifactId>
-            <version>1.1.1</version>
-        </dependency>
-        <dependency>
-            <groupId>commons-codec</groupId>
-            <artifactId>commons-codec</artifactId>
-            <version>1.3</version>
-        </dependency>
-        <dependency>
-            <groupId>commons-collections</groupId>
-            <artifactId>commons-collections</artifactId>
-            <version>3.2.1</version>
-        </dependency>
         <dependency>
             <groupId>commons-cli</groupId>
             <artifactId>commons-cli</artifactId>
@@ -105,12 +79,6 @@
             <artifactId>commons-lang</artifactId>
             <version>2.5</version>
         </dependency>
-	    <dependency>
-	       <groupId>javax.servlet</groupId>
-	       <artifactId>servlet-api</artifactId>
-	       <version>2.4</version>
-	       <scope>provided</scope>
-	    </dependency>        
         <dependency>
             <groupId>junit</groupId>
             <artifactId>junit</artifactId>
diff --git a/tika-server/src/test/java/org/apache/tika/server/CXFTestBase.java b/tika-server/src/test/java/org/apache/tika/server/CXFTestBase.java
index 0255610ab..6cb7524dc 100644
--- a/tika-server/src/test/java/org/apache/tika/server/CXFTestBase.java
+++ b/tika-server/src/test/java/org/apache/tika/server/CXFTestBase.java
@@ -17,176 +17,21 @@
 
 package org.apache.tika.server;
 
-import java.io.ByteArrayInputStream;
 import java.io.ByteArrayOutputStream;
 import java.io.IOException;
 import java.io.InputStream;
-import java.io.InputStreamReader;
 import java.util.HashMap;
 import java.util.Map;
 
-import javax.ws.rs.core.HttpHeaders;
-
 import org.apache.commons.codec.digest.DigestUtils;
 import org.apache.commons.compress.archivers.ArchiveEntry;
 import org.apache.commons.compress.archivers.ArchiveInputStream;
-import org.apache.commons.compress.archivers.tar.TarArchiveInputStream;
-import org.apache.commons.compress.archivers.zip.ZipArchiveInputStream;
 import org.apache.commons.compress.utils.IOUtils;
-import org.apache.commons.httpclient.Header;
-import org.apache.commons.httpclient.HttpClient;
-import org.apache.commons.httpclient.HttpException;
-import org.apache.commons.httpclient.methods.GetMethod;
-import org.apache.commons.httpclient.methods.PutMethod;
 import org.apache.cxf.io.CachedOutputStream;
-import org.apache.tika.io.CloseShieldInputStream;
-
-import au.com.bytecode.opencsv.CSVReader;
 import junit.framework.TestCase;
 
 public class CXFTestBase extends TestCase {
 
-	protected Map<String, String> putAndGetMet(String address,
-			InputStream content) throws Exception {
-		Map<String, String> met = new HashMap<String, String>();
-		PutMethod put = new PutMethod(address);
-		put.setRequestBody(content);
-		HttpClient httpClient = new HttpClient();
-		InputStreamReader reader = null;
-
-		try {
-			httpClient.executeMethod(put);
-			CSVReader csvReader = new CSVReader(new InputStreamReader(
-					put.getResponseBodyAsStream()));
-
-			String[] nextLine;
-			while ((nextLine = csvReader.readNext()) != null) {
-				met.put(nextLine[0], nextLine[1]);
-			}
-
-		} finally {
-			put.releaseConnection();
-		}
-
-		return met;
-	}
-
-	protected String getAndReturnResp(String address) throws HttpException,
-			IOException {
-		String resp = null;
-		GetMethod get = new GetMethod(address);
-		HttpClient httpClient = new HttpClient();
-		InputStreamReader reader = null;
-
-		try {
-			httpClient.executeMethod(get);
-			resp = get.getResponseBodyAsString();
-		} finally {
-			get.releaseConnection();
-		}
-
-		return resp;
-	}
-
-	protected void putAndCheckStatus(String address, InputStream content,
-			int expectedStatus) throws Exception {
-		putAndCheckStatus(address, null, content, expectedStatus);
-	}
-	
-	protected void putAndCheckStatus(String address, String contentType, InputStream content,
-			int expectedStatus) throws Exception {
-		PutMethod put = new PutMethod(address);
-		put.setRequestBody(content);
-		if(contentType != null) 
-			put.setRequestHeader(HttpHeaders.CONTENT_TYPE, contentType);
-		HttpClient httpClient = new HttpClient();
-		try {
-			int result = httpClient.executeMethod(put);
-			assertEquals(expectedStatus, result);
-		} finally {
-			put.releaseConnection();
-		}
-	}
-
-	protected String putAndGetString(String address, InputStream content)
-			throws Exception {
-		String resp = null;
-		PutMethod put = new PutMethod(address);
-		put.setRequestBody(content);
-		HttpClient httpClient = new HttpClient();
-		InputStreamReader reader = null;
-
-		try {
-			httpClient.executeMethod(put);
-			resp = put.getResponseBodyAsString();
-		} finally {
-			put.releaseConnection();
-		}
-
-		return resp;
-	}
-
-	protected Map<String,String> putAndGetMapData(String address,
-			InputStream content, boolean zip) throws Exception {
-		PutMethod put = new PutMethod(address);
-		put.setRequestBody(content);
-		HttpClient httpClient = new HttpClient();
-        Map<String,String> data = new HashMap<String, String>();
-		
-		try {
-			httpClient.executeMethod(put);
-			data = readArchive(zip ? 
-					new ZipArchiveInputStream(put.getResponseBodyAsStream()):
-						new TarArchiveInputStream(put.getResponseBodyAsStream()));
-		} finally {
-			put.releaseConnection();
-		}
-
-		return data;
-	}
-	
-	protected String putAndGetArchiveText(String address,
-			InputStream content, boolean zip) throws Exception {
-		PutMethod put = new PutMethod(address);
-		put.setRequestBody(content);
-		HttpClient httpClient = new HttpClient();
-        String archiveText = null;
-		
-		try {
-			httpClient.executeMethod(put);
-			archiveText = readArchiveText(zip ? 
-					new ZipArchiveInputStream(put.getResponseBodyAsStream()):
-						new TarArchiveInputStream(put.getResponseBodyAsStream()));
-		} finally {
-			//put.releaseConnection();
-		}
-
-		return archiveText;
-	}	
-
-	protected void getAndCompare(String address, String expectedValue,
-			String acceptType, String expectedContentType, int expectedStatus)
-			throws Exception {
-		GetMethod get = new GetMethod(address);
-		get.setRequestHeader("Accept", acceptType);
-		get.setRequestHeader("Accept-Language", "da;q=0.8,en");
-		HttpClient httpClient = new HttpClient();
-		try {
-			int result = httpClient.executeMethod(get);
-			assertEquals(expectedStatus, result);
-			String content = getStringFromInputStream(get
-					.getResponseBodyAsStream());
-			assertEquals("Expected value is wrong", expectedValue, content);
-			if (expectedContentType != null) {
-				Header ct = get.getResponseHeader("Content-Type");
-				assertEquals("Wrong type of response", expectedContentType,
-						ct.getValue());
-			}
-		} finally {
-			get.releaseConnection();
-		}
-	}
-
 	protected String getStringFromInputStream(InputStream in) throws Exception {
 		CachedOutputStream bos = new CachedOutputStream();
 		IOUtils.copy(in, bos);
@@ -195,48 +40,27 @@ public class CXFTestBase extends TestCase {
 		return bos.getOut().toString();
 	}
 
-	protected InputStream cloneInputStream(InputStream is) throws IOException {
-		ByteArrayOutputStream baos = new ByteArrayOutputStream();
-		// Fake code simulating the copy
-		// You can generally do better with nio if you need...
-		// And please, unlike me, do something about the Exceptions :D
-		byte[] buffer = new byte[1024];
-		int len;
-		while ((len = is.read(buffer)) > -1) {
-			baos.write(buffer, 0, len);
-		}
-		baos.flush();
-		return new ByteArrayInputStream(baos.toByteArray());
-
-	}
-	
-
 	protected Map<String, String> readArchive(ArchiveInputStream zip)
 			throws IOException {
 		Map<String, String> data = new HashMap<String, String>();
 
 		while (true) {
 			ArchiveEntry entry = zip.getNextEntry();
-
 			if (entry == null) {
 				break;
 			}
-
+			
 			ByteArrayOutputStream bos = new ByteArrayOutputStream();
-
 			IOUtils.copy(zip, bos);
-
 			data.put(entry.getName(), DigestUtils.md5Hex(bos.toByteArray()));
 		}
 
 		return data;
 	}
 
-	protected String readArchiveText(ArchiveInputStream zip)
-			throws IOException {
+	protected String readArchiveText(ArchiveInputStream zip) throws IOException {
 		while (true) {
 			ArchiveEntry entry = zip.getNextEntry();
-
 			if (entry == null) {
 				break;
 			}
@@ -246,13 +70,10 @@ public class CXFTestBase extends TestCase {
 			}
 
 			ByteArrayOutputStream bos = new ByteArrayOutputStream();
-
 			IOUtils.copy(zip, bos);
-
 			return bos.toString("UTF-8");
 		}
 
 		return null;
-	}	
-
+	}
 }
diff --git a/tika-server/src/test/java/org/apache/tika/server/MetadataResourceTest.java b/tika-server/src/test/java/org/apache/tika/server/MetadataResourceTest.java
index 8fb1816eb..15ecee3b5 100644
--- a/tika-server/src/test/java/org/apache/tika/server/MetadataResourceTest.java
+++ b/tika-server/src/test/java/org/apache/tika/server/MetadataResourceTest.java
@@ -17,18 +17,30 @@
 
 package org.apache.tika.server;
 
+import java.io.InputStream;
+import java.io.InputStreamReader;
+import java.io.Reader;
+import java.util.HashMap;
 import java.util.Map;
 
+import javax.ws.rs.core.Response;
+
 import org.apache.cxf.binding.BindingFactoryManager;
 import org.apache.cxf.endpoint.Server;
 import org.apache.cxf.jaxrs.JAXRSBindingFactory;
 import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;
+import org.apache.cxf.jaxrs.client.WebClient;
 import org.apache.cxf.jaxrs.lifecycle.SingletonResourceProvider;
 import org.junit.Test;
 
+import au.com.bytecode.opencsv.CSVReader;
+
 public class MetadataResourceTest extends CXFTestBase {
 	private static final String META_PATH = "/meta";
 
+	private static final String endPoint = "http://localhost:"
+			+ TikaServerCli.DEFAULT_PORT;
+
 	private Server server;
 
 	/*
@@ -42,7 +54,7 @@ public class MetadataResourceTest extends CXFTestBase {
 		sf.setResourceClasses(MetadataResource.class);
 		sf.setResourceProvider(MetadataResource.class,
 				new SingletonResourceProvider(new MetadataResource()));
-		sf.setAddress("http://localhost:" + TikaServerCli.DEFAULT_PORT + "/");
+		sf.setAddress(endPoint + "/");
 		BindingFactoryManager manager = sf.getBus().getExtension(
 				BindingFactoryManager.class);
 		JAXRSBindingFactory factory = new JAXRSBindingFactory();
@@ -51,7 +63,6 @@ public class MetadataResourceTest extends CXFTestBase {
 				factory);
 		server = sf.create();
 	}
-	
 
 	/*
 	 * (non-Javadoc)
@@ -63,19 +74,30 @@ public class MetadataResourceTest extends CXFTestBase {
 		server.stop();
 		server.destroy();
 	}
-	
 
 	@Test
 	public void testSimpleWord() throws Exception {
-		Map<String, String> metadata = putAndGetMet("http://localhost:"
-				+ TikaServerCli.DEFAULT_PORT + META_PATH+ "/" + TikaResourceTest.TEST_DOC,
-				ClassLoader
+		Response response = WebClient
+				.create(endPoint + META_PATH)
+				.type("application/msword")
+				.accept("text/csv")
+				.put(ClassLoader
 						.getSystemResourceAsStream(TikaResourceTest.TEST_DOC));
-		System.out.println(metadata);
+
+		Reader reader = new InputStreamReader(
+				(InputStream) response.getEntity());
+
+		CSVReader csvReader = new CSVReader(reader);
+
+		Map<String, String> metadata = new HashMap<String, String>();
+
+		String[] nextLine;
+		while ((nextLine = csvReader.readNext()) != null) {
+			metadata.put(nextLine[0], nextLine[1]);
+		}
 
 		assertNotNull(metadata.get("Author"));
 		assertEquals("Maxim Valyanskiy", metadata.get("Author"));
 	}
 
-
 }
diff --git a/tika-server/src/test/java/org/apache/tika/server/TikaResourceTest.java b/tika-server/src/test/java/org/apache/tika/server/TikaResourceTest.java
index e6983ef30..9c63fa565 100644
--- a/tika-server/src/test/java/org/apache/tika/server/TikaResourceTest.java
+++ b/tika-server/src/test/java/org/apache/tika/server/TikaResourceTest.java
@@ -17,24 +17,25 @@
 
 package org.apache.tika.server;
 
-import java.io.IOException;
-import org.apache.commons.httpclient.HttpException;
+import java.io.InputStream;
+
+import javax.ws.rs.core.Response;
 import org.apache.cxf.binding.BindingFactoryManager;
 import org.apache.cxf.endpoint.Server;
 import org.apache.cxf.jaxrs.JAXRSBindingFactory;
 import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;
+import org.apache.cxf.jaxrs.client.WebClient;
 import org.apache.cxf.jaxrs.lifecycle.SingletonResourceProvider;
 import org.junit.Test;
 
 public class TikaResourceTest extends CXFTestBase {
-	private static final String TIKA_PATH = "tika";
+	private static final String TIKA_PATH = "/tika";
 	public static final String TEST_DOC = "test.doc";
 	public static final String TEST_XLSX = "16637.xlsx";
 	private static final int UNPROCESSEABLE = 422;
-	private static final String service = "http://localhost:"
-			+ TikaServerCli.DEFAULT_PORT + "/";
 	private static final String endPoint = "http://localhost:"
-			+ TikaServerCli.DEFAULT_PORT + "/" + TIKA_PATH;
+			+ TikaServerCli.DEFAULT_PORT;
+	private static final String WADL_MEDIA_TYPE = "application/vnd.sun.wadl+xml";
 
 	private Server server;
 
@@ -49,7 +50,7 @@ public class TikaResourceTest extends CXFTestBase {
 		sf.setResourceClasses(TikaResource.class);
 		sf.setResourceProvider(TikaResource.class,
 				new SingletonResourceProvider(new TikaResource()));
-		sf.setAddress(service);
+		sf.setAddress(endPoint + "/");
 		BindingFactoryManager manager = sf.getBus().getExtension(
 				BindingFactoryManager.class);
 		JAXRSBindingFactory factory = new JAXRSBindingFactory();
@@ -58,7 +59,6 @@ public class TikaResourceTest extends CXFTestBase {
 				factory);
 		server = sf.create();
 	}
-	
 
 	/*
 	 * (non-Javadoc)
@@ -70,34 +70,43 @@ public class TikaResourceTest extends CXFTestBase {
 		server.stop();
 		server.destroy();
 	}
-	
 
 	@Test
 	public void testHelloWorld() throws Exception {
-		getAndCompare(endPoint, TikaResource.GREETING, "text/plain",
-				"text/plain", 200);
+		Response response = WebClient.create(endPoint + TIKA_PATH)
+				.type("text/plain").accept("text/plain").get();
+		assertEquals(TikaResource.GREETING,
+				getStringFromInputStream((InputStream) response.getEntity()));
 	}
 
 	@Test
 	public void testSimpleWord() throws Exception {
-		String responseMsg = putAndGetString(endPoint,
-				ClassLoader
-						.getSystemResourceAsStream(TikaResourceTest.TEST_DOC));
-
+		Response response = WebClient.create(endPoint + TIKA_PATH)
+				.type("application/msword")
+				.accept("text/plain")
+				.put(ClassLoader.getSystemResourceAsStream(TEST_DOC));
+		String responseMsg = getStringFromInputStream((InputStream) response
+				.getEntity());
 		assertTrue(responseMsg.contains("test"));
 	}
 
 	@Test
-	public void testApplicationWadl() throws HttpException, IOException {
-		String serviceWadl = endPoint + "/application.wadl";
-		String resp = getAndReturnResp(serviceWadl);
+	public void testApplicationWadl() throws Exception {
+		Response response = WebClient
+				.create(endPoint + TIKA_PATH + "/application.wadl")
+				.accept("text/plain").get();
+		String resp = getStringFromInputStream((InputStream) response
+				.getEntity());
 		assertTrue(resp.length() > 0);
 	}
 
 	@Test
 	public void testPasswordXLS() throws Exception {
-		putAndCheckStatus(endPoint,
-				ClassLoader.getSystemResourceAsStream("password.xls"),
-				UNPROCESSEABLE);
+		Response response = WebClient.create(endPoint + TIKA_PATH)
+				.type("application/vnd.ms-excel")
+				.accept("text/plain")
+				.put(ClassLoader.getSystemResourceAsStream("password.xls"));
+
+		assertEquals(UNPROCESSEABLE, response.getStatus());
 	}
 }
diff --git a/tika-server/src/test/java/org/apache/tika/server/UnpackerResourceTest.java b/tika-server/src/test/java/org/apache/tika/server/UnpackerResourceTest.java
index 7955e0e76..489cbe033 100644
--- a/tika-server/src/test/java/org/apache/tika/server/UnpackerResourceTest.java
+++ b/tika-server/src/test/java/org/apache/tika/server/UnpackerResourceTest.java
@@ -17,16 +17,22 @@
 
 package org.apache.tika.server;
 
+import org.apache.commons.compress.archivers.ArchiveInputStream;
+import org.apache.commons.compress.archivers.tar.TarArchiveInputStream;
+import org.apache.commons.compress.archivers.zip.ZipArchiveInputStream;
 import org.apache.cxf.binding.BindingFactoryManager;
 import org.apache.cxf.endpoint.Server;
 import org.apache.cxf.jaxrs.JAXRSBindingFactory;
 import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;
+import org.apache.cxf.jaxrs.client.WebClient;
 import org.apache.cxf.jaxrs.lifecycle.SingletonResourceProvider;
 import org.junit.Test;
 
+import java.io.InputStream;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
+import javax.ws.rs.core.Response;
 
 public class UnpackerResourceTest extends CXFTestBase {
 	private static final String UNPACKER_PATH = "/unpacker";
@@ -55,7 +61,9 @@ public class UnpackerResourceTest extends CXFTestBase {
 	private static final String DOCX_EXE2_MD5 = "2485435c7c22d35f2de9b4c98c0c2e1a";
 	private static final String DOCX_EXE2_NAME = "Setup.exe";
 	private static final String XSL_IMAGE2_MD5 = "8969288f4245120e7c3870287cce0ff3";
-
+	private static final String APPLICATION_MSWORD = "application/msword";
+	private static final String APPLICATION_XML = "application/xml";
+	private static final String CONTENT_TYPE = "Content-type";
 
 	private Server server;
 
@@ -74,7 +82,7 @@ public class UnpackerResourceTest extends CXFTestBase {
 		sf.setResourceClasses(UnpackerResource.class);
 		sf.setResourceProvider(UnpackerResource.class,
 				new SingletonResourceProvider(new UnpackerResource()));
-		sf.setAddress(endPoint+"/");
+		sf.setAddress(endPoint + "/");
 		BindingFactoryManager manager = sf.getBus().getExtension(
 				BindingFactoryManager.class);
 		JAXRSBindingFactory factory = new JAXRSBindingFactory();
@@ -97,9 +105,14 @@ public class UnpackerResourceTest extends CXFTestBase {
 
 	@Test
 	public void testDocWAV() throws Exception {
-		Map<String, String> data = putAndGetMapData(endPoint + UNPACKER_PATH + 
-				"/" + TEST_DOC_WAV,
-				ClassLoader.getSystemResourceAsStream(TEST_DOC_WAV), true);
+		Response response = WebClient.create(endPoint + UNPACKER_PATH)
+				.type(APPLICATION_MSWORD).accept("application/zip")
+				.put(ClassLoader.getSystemResourceAsStream(TEST_DOC_WAV));
+
+		ArchiveInputStream zip = new ZipArchiveInputStream(
+				(InputStream) response.getEntity());
+
+		Map<String, String> data = readArchive(zip);
 		assertEquals(WAV1_MD5, data.get(WAV1_NAME));
 		assertEquals(WAV2_MD5, data.get(WAV2_NAME));
 		assertFalse(data.containsKey(UnpackerResource.TEXT_FILENAME));
@@ -107,9 +120,14 @@ public class UnpackerResourceTest extends CXFTestBase {
 
 	@Test
 	public void testDocWAVText() throws Exception {
-		Map<String, String> data = putAndGetMapData(endPoint + ALL_PATH + 
-				"/" + TEST_DOC_WAV,
-				ClassLoader.getSystemResourceAsStream(TEST_DOC_WAV), true);
+		Response response = WebClient.create(endPoint + ALL_PATH)
+				.type(APPLICATION_MSWORD).accept("application/zip")
+				.put(ClassLoader.getSystemResourceAsStream(TEST_DOC_WAV));
+
+		ArchiveInputStream zip = new ZipArchiveInputStream(
+				(InputStream) response.getEntity());
+
+		Map<String, String> data = readArchive(zip);
 		assertEquals(WAV1_MD5, data.get(WAV1_NAME));
 		assertEquals(WAV2_MD5, data.get(WAV2_NAME));
 		assertTrue(data.containsKey(UnpackerResource.TEXT_FILENAME));
@@ -117,70 +135,106 @@ public class UnpackerResourceTest extends CXFTestBase {
 
 	@Test
 	public void testDocPicture() throws Exception {
-		Map<String, String> data = putAndGetMapData(endPoint + UNPACKER_PATH + 
-				"/" + TEST_DOC_WAV,
-				ClassLoader.getSystemResourceAsStream(TEST_DOC_WAV), true);
+		Response response = WebClient.create(endPoint + UNPACKER_PATH)
+				.type(APPLICATION_MSWORD).accept("application/zip")
+				.put(ClassLoader.getSystemResourceAsStream(TEST_DOC_WAV));
+
+		ZipArchiveInputStream zip = new ZipArchiveInputStream(
+				(InputStream) response.getEntity());
+		Map<String, String> data = readArchive(zip);
+
 		assertEquals(JPG_MD5, data.get(JPG_NAME));
 	}
 
 	@Test
 	public void testDocPictureNoOle() throws Exception {
-		Map<String, String> data = putAndGetMapData(endPoint + UNPACKER_PATH + 
-				"/2pic.doc",
-				ClassLoader.getSystemResourceAsStream("2pic.doc"), true);
+		Response response = WebClient.create(endPoint + UNPACKER_PATH)
+				.type(APPLICATION_MSWORD).accept("application/zip")
+				.put(ClassLoader.getSystemResourceAsStream("2pic.doc"));
+
+		ZipArchiveInputStream zip = new ZipArchiveInputStream(
+				(InputStream) response.getEntity());
+
+		Map<String, String> data = readArchive(zip);
 		assertEquals(JPG2_MD5, data.get(JPG2_NAME));
 	}
 
 	@Test
 	public void testImageDOCX() throws Exception {
-		Map<String, String> data = putAndGetMapData(endPoint + UNPACKER_PATH + 
-				"/" + TEST_DOCX_IMAGE,
-				ClassLoader.getSystemResourceAsStream(TEST_DOCX_IMAGE), true);
+		Response response = WebClient.create(endPoint + UNPACKER_PATH)
+		.accept("application/zip").put(
+				ClassLoader.getSystemResourceAsStream(TEST_DOCX_IMAGE));
+
+		ZipArchiveInputStream zip = new ZipArchiveInputStream(
+				(InputStream) response.getEntity());
+
+		Map<String, String> data = readArchive(zip);
 		assertEquals(DOCX_IMAGE1_MD5, data.get(DOCX_IMAGE1_NAME));
 		assertEquals(DOCX_IMAGE2_MD5, data.get(DOCX_IMAGE2_NAME));
 	}
 
-	//FIXME: Disabled for now, pending TIKA-593 @Test
+	//FIXME: Disabled until TIKA-593 is done @Test
 	public void Xtest415() throws Exception {
-		putAndCheckStatus(endPoint + UNPACKER_PATH + "/" + TEST_DOC_WAV,
-				"xxx/xxx", ClassLoader.getSystemResourceAsStream(TEST_DOC_WAV), 415);
+		Response response = WebClient.create(endPoint + UNPACKER_PATH)
+				.type("xxx/xxx").accept("application/zip")
+				.put(ClassLoader.getSystemResourceAsStream(TEST_DOC_WAV));
+
+		assertEquals(415, response.getStatus());
 	}
 
 	@Test
 	public void testExeDOCX() throws Exception {
 		String TEST_DOCX_EXE = "2exe.docx";
-		Map<String, String> data = putAndGetMapData(endPoint + UNPACKER_PATH 
-				+ "/" + TEST_DOCX_EXE,
-				ClassLoader.getSystemResourceAsStream(TEST_DOCX_EXE), true);
+		Response response = WebClient.create(endPoint + UNPACKER_PATH)
+				.accept("application/zip")
+				.put(ClassLoader.getSystemResourceAsStream(TEST_DOCX_EXE));
+
+		ZipArchiveInputStream zip = new ZipArchiveInputStream(
+				(InputStream) response.getEntity());
+
+		Map<String, String> data = readArchive(zip);
+
 		assertEquals(DOCX_EXE1_MD5, data.get(DOCX_EXE1_NAME));
 		assertEquals(DOCX_EXE2_MD5, data.get(DOCX_EXE2_NAME));
 	}
 
 	@Test
 	public void testImageXSL() throws Exception {
-		Map<String, String> data = putAndGetMapData(endPoint + UNPACKER_PATH + "/" 
-				+ "pic.xls",
-				ClassLoader.getSystemResourceAsStream("pic.xls"), true);
+		Response response = WebClient.create(endPoint + UNPACKER_PATH)
+				.accept("application/zip")
+				.put(ClassLoader.getSystemResourceAsStream("pic.xls"));
+
+		ZipArchiveInputStream zip = new ZipArchiveInputStream(
+				(InputStream) response.getEntity());
+
+		Map<String, String> data = readArchive(zip);
 		assertEquals(XSL_IMAGE1_MD5, data.get("0.jpg"));
 		assertEquals(XSL_IMAGE2_MD5, data.get("1.jpg"));
 	}
 
-	//FIXME: Disabled for now @Test
-	public void XtestTarDocPicture() throws Exception {
-		Map<String, String> data = putAndGetMapData(endPoint + UNPACKER_PATH + "/" + 
-				TEST_DOC_WAV,
-				ClassLoader.getSystemResourceAsStream(TEST_DOC_WAV), false);
+	@Test
+	public void testTarDocPicture() throws Exception {
+		Response response = WebClient.create(endPoint + UNPACKER_PATH)
+				.type(APPLICATION_MSWORD).accept("application/x-tar")
+				.put(ClassLoader.getSystemResourceAsStream(TEST_DOC_WAV));
+
+		Map<String, String> data = readArchive(new TarArchiveInputStream(
+				(InputStream) response.getEntity()));
+
 		assertEquals(JPG_MD5, data.get(JPG_NAME));
 	}
 
-	//FIXME: Disabled for now @Test
-	public void XtestText() throws Exception {
-		String responseMsg = putAndGetArchiveText(endPoint + UNPACKER_PATH + "/" + 
-				"test.doc",
-				ClassLoader.getSystemResourceAsStream("test.doc"), true);
+	@Test
+	public void testText() throws Exception {
+		Response response = WebClient.create(endPoint + ALL_PATH)
+				.header(CONTENT_TYPE, APPLICATION_XML)
+				.accept("application/zip")
+				.put(ClassLoader.getSystemResourceAsStream("test.doc"));
+
+		String responseMsg = readArchiveText(new ZipArchiveInputStream(
+				(InputStream) response.getEntity()));
 		assertNotNull(responseMsg);
 		assertTrue(responseMsg.contains("test"));
 	}
 
-
 }

Commit:
892f9f9052ee592551dd0e196582d2a57fd6fe70
Chris Mattmann
mattmann@apache.org
2012-03-27 22:24:54 +0000
- TIKA-593: try with 1.5
diff --git a/tika-server/pom.xml b/tika-server/pom.xml
index f36238997..502f509f0 100644
--- a/tika-server/pom.xml
+++ b/tika-server/pom.xml
@@ -141,8 +141,8 @@
                 <artifactId>maven-compiler-plugin</artifactId>
                 <inherited>true</inherited>
                 <configuration>
-                    <source>1.6</source>
-                    <target>1.6</target>
+                    <source>1.5</source>
+                    <target>1.5</target>
                 </configuration>
             </plugin>
       <plugin>

Commit:
27163d3bc04713e194e115b2e3610bfb5d116d6e
Chris Mattmann
mattmann@apache.org
2012-03-27 22:24:15 +0000
- set Content-Type field: that's what the test is actually doing. TIKA-593
diff --git a/tika-server/src/test/java/org/apache/tika/server/CXFTestBase.java b/tika-server/src/test/java/org/apache/tika/server/CXFTestBase.java
index 81470a228..0255610ab 100644
--- a/tika-server/src/test/java/org/apache/tika/server/CXFTestBase.java
+++ b/tika-server/src/test/java/org/apache/tika/server/CXFTestBase.java
@@ -25,6 +25,8 @@ import java.io.InputStreamReader;
 import java.util.HashMap;
 import java.util.Map;
 
+import javax.ws.rs.core.HttpHeaders;
+
 import org.apache.commons.codec.digest.DigestUtils;
 import org.apache.commons.compress.archivers.ArchiveEntry;
 import org.apache.commons.compress.archivers.ArchiveInputStream;
@@ -91,11 +93,12 @@ public class CXFTestBase extends TestCase {
 		putAndCheckStatus(address, null, content, expectedStatus);
 	}
 	
-	protected void putAndCheckStatus(String address, String accept, InputStream content,
+	protected void putAndCheckStatus(String address, String contentType, InputStream content,
 			int expectedStatus) throws Exception {
 		PutMethod put = new PutMethod(address);
 		put.setRequestBody(content);
-		if(accept != null) put.setRequestHeader("Accept", accept);
+		if(contentType != null) 
+			put.setRequestHeader(HttpHeaders.CONTENT_TYPE, contentType);
 		HttpClient httpClient = new HttpClient();
 		try {
 			int result = httpClient.executeMethod(put);
@@ -139,7 +142,6 @@ public class CXFTestBase extends TestCase {
 			put.releaseConnection();
 		}
 
-		System.out.println("DATA: "+data);
 		return data;
 	}
 	

Commit:
6d7753e5733523b3947577f04d1f246da1f524c6
Chris Mattmann
mattmann@apache.org
2012-03-27 18:25:51 +0000
- ignore
Commit:
93ab990cd392631cb51e89711c4850d449df0491
Chris Mattmann
mattmann@apache.org
2012-03-27 18:24:52 +0000
- progress towards TIKA-593: replace Jersey with CXF. Checking in to reduce the need to review patches. Disabled 3 tests for now that aren't passing. Will work with Max to make them pass.
diff --git a/tika-server/pom.xml b/tika-server/pom.xml
index 94aa76bf7..f36238997 100644
--- a/tika-server/pom.xml
+++ b/tika-server/pom.xml
@@ -54,43 +54,32 @@
             <artifactId>tika-parsers</artifactId>
             <version>${project.version}</version>
         </dependency>
-
-        <dependency>
-            <groupId>com.sun.jersey</groupId>
-            <artifactId>jersey-server</artifactId>
-            <version>1.7</version>
-        </dependency>
-        <dependency>
-            <groupId>com.sun.jersey</groupId>
-            <artifactId>jersey-core</artifactId>
-            <version>1.7</version>
-        </dependency>
-        <dependency>
-            <groupId>javax.ws.rs</groupId>
-            <artifactId>jsr311-api</artifactId>
-            <version>1.1</version>
-        </dependency>
-        <dependency>
-            <groupId>com.sun.jersey.jersey-test-framework</groupId>
-            <artifactId>jersey-test-framework-grizzly</artifactId>
-            <version>1.7</version>
-            <scope>test</scope>
-        </dependency>
-        <dependency>
-            <groupId>org.eclipse.jetty</groupId>
-            <artifactId>jetty-server</artifactId>
-            <version>8.0.0.M3</version>
-        </dependency>
-        <dependency>
-            <groupId>org.eclipse.jetty</groupId>
-            <artifactId>jetty-servlet</artifactId>
-            <version>8.0.0.M3</version>
-        </dependency>
+		<dependency>
+			<groupId>net.sf.opencsv</groupId>
+			<artifactId>opencsv</artifactId>
+			<version>2.0</version>
+		</dependency>      
+		<dependency>
+	      <groupId>org.apache.cxf</groupId>
+	      <artifactId>cxf-rt-frontend-jaxrs</artifactId>
+	      <version>2.5.2</version>
+		</dependency>  
+		<dependency>
+		   <groupId>org.apache.cxf</groupId>
+		   <artifactId>cxf-rt-transports-http-jetty</artifactId>
+		   <version>2.5.2</version>
+		</dependency>   	
         <dependency>
             <groupId>org.slf4j</groupId>
             <artifactId>slf4j-jdk14</artifactId>
             <version>1.6.1</version>
         </dependency>
+        <dependency>
+            <groupId>commons-httpclient</groupId>
+            <artifactId>commons-httpclient</artifactId>
+            <version>3.1</version>
+            <scope>test</scope>
+        </dependency>
         <dependency>
             <groupId>commons-logging</groupId>
             <artifactId>commons-logging</artifactId>
@@ -116,11 +105,12 @@
             <artifactId>commons-lang</artifactId>
             <version>2.5</version>
         </dependency>
-        <dependency>
-            <groupId>net.sf.opencsv</groupId>
-            <artifactId>opencsv</artifactId>
-            <version>2.0</version>
-        </dependency>
+	    <dependency>
+	       <groupId>javax.servlet</groupId>
+	       <artifactId>servlet-api</artifactId>
+	       <version>2.4</version>
+	       <scope>provided</scope>
+	    </dependency>        
         <dependency>
             <groupId>junit</groupId>
             <artifactId>junit</artifactId>
@@ -163,8 +153,8 @@
           <instructions>
             <Export-Package>org.apache.tika.*</Export-Package>
             <Embed-Dependency>
-                !jersey-server;scope=compile;inline=META-INF/services/**|au/**|javax/**|org/**|com/**|Resources/**|font_metrics.properties|repackage/**|schema*/**,
-                jersey-server;scope=compile;inline=com/** |META-INF/services/com.sun*|META-INF/services/javax.ws.rs.ext.RuntimeDelegate
+                inline=META-INF/services/**|au/**|javax/**|org/**|com/**|Resources/**|font_metrics.properties|repackage/**|schema*/**,
+                inline=com/** |META-INF/services/com.sun*|META-INF/services/javax.ws.rs.ext.RuntimeDelegate
             </Embed-Dependency>
             <Embed-Transitive>true</Embed-Transitive>
             <Bundle-DocURL>${project.url}</Bundle-DocURL>
diff --git a/tika-server/src/main/java/org/apache/tika/server/TikaServerCli.java b/tika-server/src/main/java/org/apache/tika/server/TikaServerCli.java
index f4c4653a5..aacaa2dab 100644
--- a/tika-server/src/main/java/org/apache/tika/server/TikaServerCli.java
+++ b/tika-server/src/main/java/org/apache/tika/server/TikaServerCli.java
@@ -17,16 +17,19 @@
 
 package org.apache.tika.server;
 
-import com.sun.jersey.api.core.PackagesResourceConfig;
-import com.sun.jersey.spi.container.servlet.ServletContainer;
 import org.apache.commons.cli.*;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
-import org.eclipse.jetty.server.Server;
-import org.eclipse.jetty.servlet.ServletContextHandler;
-import org.eclipse.jetty.servlet.ServletHolder;
+import org.apache.cxf.binding.BindingFactoryManager;
+import org.apache.cxf.endpoint.Server;
+import org.apache.cxf.jaxrs.JAXRSBindingFactory;
+import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;
+import org.apache.cxf.jaxrs.lifecycle.ResourceProvider;
+import org.apache.cxf.jaxrs.lifecycle.SingletonResourceProvider;
 
 import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
 import java.util.Properties;
 
 public class TikaServerCli {
@@ -67,19 +70,26 @@ public class TikaServerCli {
         helpFormatter.printHelp("tikaserver", options);
         System.exit(-1);
       }
-
-      Server server = new Server(port);
-      ServletContextHandler context = new ServletContextHandler(ServletContextHandler.NO_SESSIONS);
-      context.setContextPath("/");
-      server.setHandler(context);
-
-      context.addServlet(new ServletHolder(new ServletContainer(new PackagesResourceConfig("org.apache.tika.server"))), "/*");
-
-      server.start();
-
+      
+      JAXRSServerFactoryBean sf = new JAXRSServerFactoryBean();
+      sf.setResourceClasses(MetadataResource.class, TikaResource.class, UnpackerResource.class);
+
+      List providers = new ArrayList();
+      providers.add(new TarWriter());
+	  providers.add(new ZipWriter());      
+      providers.add(new SingletonResourceProvider(new MetadataResource()));
+      providers.add(new SingletonResourceProvider(new TikaResource()));
+      providers.add(new SingletonResourceProvider(new UnpackerResource()));
+      sf.setProviders(providers);
+      sf.setAddress("http://localhost:" + TikaServerCli.DEFAULT_PORT + "/");
+      BindingFactoryManager manager = sf.getBus().getExtension(
+				BindingFactoryManager.class);
+      JAXRSBindingFactory factory = new JAXRSBindingFactory();
+      factory.setBus(sf.getBus());
+      manager.registerBindingFactory(JAXRSBindingFactory.JAXRS_BINDING_ID,
+				factory);
+      Server server = sf.create();
       logger.info("Started");
-
-      server.join();
     } catch (Exception ex) {
       logger.fatal("Can't start", ex);
       System.exit(-1);
diff --git a/tika-server/src/test/java/org/apache/tika/server/CXFTestBase.java b/tika-server/src/test/java/org/apache/tika/server/CXFTestBase.java
new file mode 100644
index 000000000..81470a228
--- /dev/null
+++ b/tika-server/src/test/java/org/apache/tika/server/CXFTestBase.java
@@ -0,0 +1,256 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.server;
+
+import java.io.ByteArrayInputStream;
+import java.io.ByteArrayOutputStream;
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.InputStreamReader;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.commons.codec.digest.DigestUtils;
+import org.apache.commons.compress.archivers.ArchiveEntry;
+import org.apache.commons.compress.archivers.ArchiveInputStream;
+import org.apache.commons.compress.archivers.tar.TarArchiveInputStream;
+import org.apache.commons.compress.archivers.zip.ZipArchiveInputStream;
+import org.apache.commons.compress.utils.IOUtils;
+import org.apache.commons.httpclient.Header;
+import org.apache.commons.httpclient.HttpClient;
+import org.apache.commons.httpclient.HttpException;
+import org.apache.commons.httpclient.methods.GetMethod;
+import org.apache.commons.httpclient.methods.PutMethod;
+import org.apache.cxf.io.CachedOutputStream;
+import org.apache.tika.io.CloseShieldInputStream;
+
+import au.com.bytecode.opencsv.CSVReader;
+import junit.framework.TestCase;
+
+public class CXFTestBase extends TestCase {
+
+	protected Map<String, String> putAndGetMet(String address,
+			InputStream content) throws Exception {
+		Map<String, String> met = new HashMap<String, String>();
+		PutMethod put = new PutMethod(address);
+		put.setRequestBody(content);
+		HttpClient httpClient = new HttpClient();
+		InputStreamReader reader = null;
+
+		try {
+			httpClient.executeMethod(put);
+			CSVReader csvReader = new CSVReader(new InputStreamReader(
+					put.getResponseBodyAsStream()));
+
+			String[] nextLine;
+			while ((nextLine = csvReader.readNext()) != null) {
+				met.put(nextLine[0], nextLine[1]);
+			}
+
+		} finally {
+			put.releaseConnection();
+		}
+
+		return met;
+	}
+
+	protected String getAndReturnResp(String address) throws HttpException,
+			IOException {
+		String resp = null;
+		GetMethod get = new GetMethod(address);
+		HttpClient httpClient = new HttpClient();
+		InputStreamReader reader = null;
+
+		try {
+			httpClient.executeMethod(get);
+			resp = get.getResponseBodyAsString();
+		} finally {
+			get.releaseConnection();
+		}
+
+		return resp;
+	}
+
+	protected void putAndCheckStatus(String address, InputStream content,
+			int expectedStatus) throws Exception {
+		putAndCheckStatus(address, null, content, expectedStatus);
+	}
+	
+	protected void putAndCheckStatus(String address, String accept, InputStream content,
+			int expectedStatus) throws Exception {
+		PutMethod put = new PutMethod(address);
+		put.setRequestBody(content);
+		if(accept != null) put.setRequestHeader("Accept", accept);
+		HttpClient httpClient = new HttpClient();
+		try {
+			int result = httpClient.executeMethod(put);
+			assertEquals(expectedStatus, result);
+		} finally {
+			put.releaseConnection();
+		}
+	}
+
+	protected String putAndGetString(String address, InputStream content)
+			throws Exception {
+		String resp = null;
+		PutMethod put = new PutMethod(address);
+		put.setRequestBody(content);
+		HttpClient httpClient = new HttpClient();
+		InputStreamReader reader = null;
+
+		try {
+			httpClient.executeMethod(put);
+			resp = put.getResponseBodyAsString();
+		} finally {
+			put.releaseConnection();
+		}
+
+		return resp;
+	}
+
+	protected Map<String,String> putAndGetMapData(String address,
+			InputStream content, boolean zip) throws Exception {
+		PutMethod put = new PutMethod(address);
+		put.setRequestBody(content);
+		HttpClient httpClient = new HttpClient();
+        Map<String,String> data = new HashMap<String, String>();
+		
+		try {
+			httpClient.executeMethod(put);
+			data = readArchive(zip ? 
+					new ZipArchiveInputStream(put.getResponseBodyAsStream()):
+						new TarArchiveInputStream(put.getResponseBodyAsStream()));
+		} finally {
+			put.releaseConnection();
+		}
+
+		System.out.println("DATA: "+data);
+		return data;
+	}
+	
+	protected String putAndGetArchiveText(String address,
+			InputStream content, boolean zip) throws Exception {
+		PutMethod put = new PutMethod(address);
+		put.setRequestBody(content);
+		HttpClient httpClient = new HttpClient();
+        String archiveText = null;
+		
+		try {
+			httpClient.executeMethod(put);
+			archiveText = readArchiveText(zip ? 
+					new ZipArchiveInputStream(put.getResponseBodyAsStream()):
+						new TarArchiveInputStream(put.getResponseBodyAsStream()));
+		} finally {
+			//put.releaseConnection();
+		}
+
+		return archiveText;
+	}	
+
+	protected void getAndCompare(String address, String expectedValue,
+			String acceptType, String expectedContentType, int expectedStatus)
+			throws Exception {
+		GetMethod get = new GetMethod(address);
+		get.setRequestHeader("Accept", acceptType);
+		get.setRequestHeader("Accept-Language", "da;q=0.8,en");
+		HttpClient httpClient = new HttpClient();
+		try {
+			int result = httpClient.executeMethod(get);
+			assertEquals(expectedStatus, result);
+			String content = getStringFromInputStream(get
+					.getResponseBodyAsStream());
+			assertEquals("Expected value is wrong", expectedValue, content);
+			if (expectedContentType != null) {
+				Header ct = get.getResponseHeader("Content-Type");
+				assertEquals("Wrong type of response", expectedContentType,
+						ct.getValue());
+			}
+		} finally {
+			get.releaseConnection();
+		}
+	}
+
+	protected String getStringFromInputStream(InputStream in) throws Exception {
+		CachedOutputStream bos = new CachedOutputStream();
+		IOUtils.copy(in, bos);
+		in.close();
+		bos.close();
+		return bos.getOut().toString();
+	}
+
+	protected InputStream cloneInputStream(InputStream is) throws IOException {
+		ByteArrayOutputStream baos = new ByteArrayOutputStream();
+		// Fake code simulating the copy
+		// You can generally do better with nio if you need...
+		// And please, unlike me, do something about the Exceptions :D
+		byte[] buffer = new byte[1024];
+		int len;
+		while ((len = is.read(buffer)) > -1) {
+			baos.write(buffer, 0, len);
+		}
+		baos.flush();
+		return new ByteArrayInputStream(baos.toByteArray());
+
+	}
+	
+
+	protected Map<String, String> readArchive(ArchiveInputStream zip)
+			throws IOException {
+		Map<String, String> data = new HashMap<String, String>();
+
+		while (true) {
+			ArchiveEntry entry = zip.getNextEntry();
+
+			if (entry == null) {
+				break;
+			}
+
+			ByteArrayOutputStream bos = new ByteArrayOutputStream();
+
+			IOUtils.copy(zip, bos);
+
+			data.put(entry.getName(), DigestUtils.md5Hex(bos.toByteArray()));
+		}
+
+		return data;
+	}
+
+	protected String readArchiveText(ArchiveInputStream zip)
+			throws IOException {
+		while (true) {
+			ArchiveEntry entry = zip.getNextEntry();
+
+			if (entry == null) {
+				break;
+			}
+
+			if (!entry.getName().equals(UnpackerResource.TEXT_FILENAME)) {
+				continue;
+			}
+
+			ByteArrayOutputStream bos = new ByteArrayOutputStream();
+
+			IOUtils.copy(zip, bos);
+
+			return bos.toString("UTF-8");
+		}
+
+		return null;
+	}	
+
+}
diff --git a/tika-server/src/test/java/org/apache/tika/server/MetadataResourceTest.java b/tika-server/src/test/java/org/apache/tika/server/MetadataResourceTest.java
index f98c04690..8fb1816eb 100644
--- a/tika-server/src/test/java/org/apache/tika/server/MetadataResourceTest.java
+++ b/tika-server/src/test/java/org/apache/tika/server/MetadataResourceTest.java
@@ -17,73 +17,65 @@
 
 package org.apache.tika.server;
 
-import au.com.bytecode.opencsv.CSVReader;
-import com.sun.jersey.test.framework.JerseyTest;
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertNotNull;
-import org.junit.Test;
-
-import java.io.Reader;
-import java.util.HashMap;
 import java.util.Map;
 
-public class MetadataResourceTest extends JerseyTest {
-  private static final String META_PATH = "/meta";
-
-  public MetadataResourceTest() throws Exception {
-    super("org.apache.tika.server");
-  }
+import org.apache.cxf.binding.BindingFactoryManager;
+import org.apache.cxf.endpoint.Server;
+import org.apache.cxf.jaxrs.JAXRSBindingFactory;
+import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;
+import org.apache.cxf.jaxrs.lifecycle.SingletonResourceProvider;
+import org.junit.Test;
 
-  @Test
-  public void testSimpleWord() throws Exception {
-    Reader reader =
-            resource().path(META_PATH)
-            .type("application/msword")
-                    .put(Reader.class, ClassLoader.getSystemResourceAsStream(TikaResourceTest.TEST_DOC));
+public class MetadataResourceTest extends CXFTestBase {
+	private static final String META_PATH = "/meta";
 
-    CSVReader csvReader = new CSVReader(reader);
+	private Server server;
 
-    Map<String,String> metadata = new HashMap<String, String>();
+	/*
+	 * (non-Javadoc)
+	 * 
+	 * @see junit.framework.TestCase#setUp()
+	 */
+	@Override
+	protected void setUp() throws Exception {
+		JAXRSServerFactoryBean sf = new JAXRSServerFactoryBean();
+		sf.setResourceClasses(MetadataResource.class);
+		sf.setResourceProvider(MetadataResource.class,
+				new SingletonResourceProvider(new MetadataResource()));
+		sf.setAddress("http://localhost:" + TikaServerCli.DEFAULT_PORT + "/");
+		BindingFactoryManager manager = sf.getBus().getExtension(
+				BindingFactoryManager.class);
+		JAXRSBindingFactory factory = new JAXRSBindingFactory();
+		factory.setBus(sf.getBus());
+		manager.registerBindingFactory(JAXRSBindingFactory.JAXRS_BINDING_ID,
+				factory);
+		server = sf.create();
+	}
+	
 
-    String[] nextLine;
-    while ((nextLine = csvReader.readNext()) != null) {
-      metadata.put(nextLine[0], nextLine[1]);
-    }
+	/*
+	 * (non-Javadoc)
+	 * 
+	 * @see junit.framework.TestCase#tearDown()
+	 */
+	@Override
+	protected void tearDown() throws Exception {
+		server.stop();
+		server.destroy();
+	}
+	
 
-    assertNotNull(metadata.get("Author"));
-    assertEquals("Maxim Valyanskiy", metadata.get("Author"));
-  }
-/*
-  @Test
-  public void testXLSX() throws Exception {
-    Reader reader =
-            webResource.path(META_PATH)
-            .type("application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
-                    .header("File-Name", TikaResourceTest.TEST_XLSX)
-                    .put(Reader.class, ClassLoader.getSystemResourceAsStream(TikaResourceTest.TEST_XLSX));
+	@Test
+	public void testSimpleWord() throws Exception {
+		Map<String, String> metadata = putAndGetMet("http://localhost:"
+				+ TikaServerCli.DEFAULT_PORT + META_PATH+ "/" + TikaResourceTest.TEST_DOC,
+				ClassLoader
+						.getSystemResourceAsStream(TikaResourceTest.TEST_DOC));
+		System.out.println(metadata);
 
-    CSVReader csvReader = new CSVReader(reader);
+		assertNotNull(metadata.get("Author"));
+		assertEquals("Maxim Valyanskiy", metadata.get("Author"));
+	}
 
-    final Map < String, String > metadataActual = new HashMap < String, String > (),
-            metadataExpected = new HashMap < String, String > ();
 
-    String[] nextLine;
-    while ((nextLine = csvReader.readNext()) != null) {
-      metadataActual.put(nextLine[0], nextLine[1]);
-    }
-    metadataExpected.put("Author", "jet");
-    metadataExpected.put("Application-Name", "Microsoft Excel");
-    metadataExpected.put("description", " ");
-    metadataExpected.put("resourceName", TikaResourceTest.TEST_XLSX);
-    metadataExpected.put("protected", "false");
-    metadataExpected.put("Creation-Date", "2010-05-11T12:37:42Z");
-    metadataExpected.put("Last-Modified", "2010-05-11T14:46:20Z");
-    assertEquals( true, metadataActual.size() >= metadataExpected.size() );
-    for ( final Map.Entry < String, String > field : metadataExpected.entrySet() ) {
-      final String key = field.getKey(), valueActual = metadataActual.get(key), valueExpected = field.getValue();
-      assertNotNull( valueActual );
-      assertEquals( valueExpected, valueActual );
-    }
-  }
-*/
 }
diff --git a/tika-server/src/test/java/org/apache/tika/server/TikaResourceTest.java b/tika-server/src/test/java/org/apache/tika/server/TikaResourceTest.java
index 7a9aaad34..e6983ef30 100644
--- a/tika-server/src/test/java/org/apache/tika/server/TikaResourceTest.java
+++ b/tika-server/src/test/java/org/apache/tika/server/TikaResourceTest.java
@@ -17,58 +17,87 @@
 
 package org.apache.tika.server;
 
-import com.sun.jersey.api.client.ClientResponse;
-import com.sun.jersey.core.header.MediaTypes;
-import com.sun.jersey.test.framework.JerseyTest;
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertTrue;
+import java.io.IOException;
+import org.apache.commons.httpclient.HttpException;
+import org.apache.cxf.binding.BindingFactoryManager;
+import org.apache.cxf.endpoint.Server;
+import org.apache.cxf.jaxrs.JAXRSBindingFactory;
+import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;
+import org.apache.cxf.jaxrs.lifecycle.SingletonResourceProvider;
 import org.junit.Test;
 
-public class TikaResourceTest extends JerseyTest {
-  private static final String TIKA_PATH = "tika";
-  public static final String TEST_DOC = "test.doc";
-  public static final String TEST_XLSX = "16637.xlsx";
-  private static final int UNPROCESSEABLE = 422;
+public class TikaResourceTest extends CXFTestBase {
+	private static final String TIKA_PATH = "tika";
+	public static final String TEST_DOC = "test.doc";
+	public static final String TEST_XLSX = "16637.xlsx";
+	private static final int UNPROCESSEABLE = 422;
+	private static final String service = "http://localhost:"
+			+ TikaServerCli.DEFAULT_PORT + "/";
+	private static final String endPoint = "http://localhost:"
+			+ TikaServerCli.DEFAULT_PORT + "/" + TIKA_PATH;
 
-  public TikaResourceTest() throws Exception {
-    super("org.apache.tika.server");
-  }
+	private Server server;
 
-  /**
-   * Test to see that the message "Hello World" is sent in the response.
-   */
-  @Test
-  public void testHelloWorld() {
-    String responseMsg = resource().path(TIKA_PATH).get(String.class);
-    assertEquals(TikaResource.GREETING, responseMsg);
-  }
+	/*
+	 * (non-Javadoc)
+	 * 
+	 * @see junit.framework.TestCase#setUp()
+	 */
+	@Override
+	protected void setUp() throws Exception {
+		JAXRSServerFactoryBean sf = new JAXRSServerFactoryBean();
+		sf.setResourceClasses(TikaResource.class);
+		sf.setResourceProvider(TikaResource.class,
+				new SingletonResourceProvider(new TikaResource()));
+		sf.setAddress(service);
+		BindingFactoryManager manager = sf.getBus().getExtension(
+				BindingFactoryManager.class);
+		JAXRSBindingFactory factory = new JAXRSBindingFactory();
+		factory.setBus(sf.getBus());
+		manager.registerBindingFactory(JAXRSBindingFactory.JAXRS_BINDING_ID,
+				factory);
+		server = sf.create();
+	}
+	
 
-  @Test
-  public void testSimpleWord() {
-    String responseMsg =
-            resource().path(TIKA_PATH)
-            .type("application/msword")
-                    .put(String.class, ClassLoader.getSystemResourceAsStream(TEST_DOC));
+	/*
+	 * (non-Javadoc)
+	 * 
+	 * @see junit.framework.TestCase#tearDown()
+	 */
+	@Override
+	protected void tearDown() throws Exception {
+		server.stop();
+		server.destroy();
+	}
+	
 
-    assertTrue(responseMsg.contains("test"));
-  }
+	@Test
+	public void testHelloWorld() throws Exception {
+		getAndCompare(endPoint, TikaResource.GREETING, "text/plain",
+				"text/plain", 200);
+	}
 
-  @Test
-  public void testApplicationWadl() {
-    String serviceWadl = resource().path("application.wadl").
-            accept(MediaTypes.WADL).get(String.class);
+	@Test
+	public void testSimpleWord() throws Exception {
+		String responseMsg = putAndGetString(endPoint,
+				ClassLoader
+						.getSystemResourceAsStream(TikaResourceTest.TEST_DOC));
 
-    assertTrue(serviceWadl.length() > 0);
-  }
+		assertTrue(responseMsg.contains("test"));
+	}
 
-  @Test
-  public void testPasswordXLS() throws Exception {
-    ClientResponse cr =
-            resource()
-                    .path(TIKA_PATH)
-                    .type("application/vnd.ms-excel")                    
-                    .put(ClientResponse.class, ClassLoader.getSystemResourceAsStream("password.xls"));
+	@Test
+	public void testApplicationWadl() throws HttpException, IOException {
+		String serviceWadl = endPoint + "/application.wadl";
+		String resp = getAndReturnResp(serviceWadl);
+		assertTrue(resp.length() > 0);
+	}
 
-    assertEquals(UNPROCESSEABLE, cr.getStatus());
-  }
+	@Test
+	public void testPasswordXLS() throws Exception {
+		putAndCheckStatus(endPoint,
+				ClassLoader.getSystemResourceAsStream("password.xls"),
+				UNPROCESSEABLE);
+	}
 }
diff --git a/tika-server/src/test/java/org/apache/tika/server/UnpackerResourceTest.java b/tika-server/src/test/java/org/apache/tika/server/UnpackerResourceTest.java
index 4ba0ee5dc..7955e0e76 100644
--- a/tika-server/src/test/java/org/apache/tika/server/UnpackerResourceTest.java
+++ b/tika-server/src/test/java/org/apache/tika/server/UnpackerResourceTest.java
@@ -17,252 +17,170 @@
 
 package org.apache.tika.server;
 
-import com.sun.jersey.api.client.ClientResponse;
-import com.sun.jersey.test.framework.JerseyTest;
-import org.apache.commons.codec.digest.DigestUtils;
-import org.apache.commons.compress.archivers.ArchiveEntry;
-import org.apache.commons.compress.archivers.ArchiveInputStream;
-import org.apache.commons.compress.archivers.tar.TarArchiveInputStream;
-import org.apache.commons.compress.archivers.zip.ZipArchiveInputStream;
-import org.apache.tika.io.IOUtils;
+import org.apache.cxf.binding.BindingFactoryManager;
+import org.apache.cxf.endpoint.Server;
+import org.apache.cxf.jaxrs.JAXRSBindingFactory;
+import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;
+import org.apache.cxf.jaxrs.lifecycle.SingletonResourceProvider;
 import org.junit.Test;
 
-import java.io.ByteArrayOutputStream;
-import java.io.IOException;
-import java.io.InputStream;
-import java.util.HashMap;
+import java.util.ArrayList;
+import java.util.List;
 import java.util.Map;
 
-import static org.junit.Assert.*;
+public class UnpackerResourceTest extends CXFTestBase {
+	private static final String UNPACKER_PATH = "/unpacker";
+	private static final String ALL_PATH = "/all";
+
+	private static final String endPoint = "http://localhost:"
+			+ TikaServerCli.DEFAULT_PORT;
+
+	private static final String TEST_DOC_WAV = "Doc1_ole.doc";
+	private static final String WAV1_MD5 = "bdd0a78a54968e362445364f95d8dc96";
+	private static final String WAV1_NAME = "_1310388059/MSj00974840000[1].wav";
+	private static final String WAV2_MD5 = "3bbd42fb1ac0e46a95350285f16d9596";
+	private static final String WAV2_NAME = "_1310388058/MSj00748450000[1].wav";
+	private static final String JPG_NAME = "image1.jpg";
+	private static final String XSL_IMAGE1_MD5 = "68ead8f4995a3555f48a2f738b2b0c3d";
+	private static final String JPG_MD5 = XSL_IMAGE1_MD5;
+	private static final String JPG2_NAME = "image2.jpg";
+	private static final String JPG2_MD5 = "b27a41d12c646d7fc4f3826cf8183c68";
+	private static final String TEST_DOCX_IMAGE = "2pic.docx";
+	private static final String DOCX_IMAGE1_MD5 = "5516590467b069fa59397432677bad4d";
+	private static final String DOCX_IMAGE2_MD5 = "a5dd81567427070ce0a2ff3e3ef13a4c";
+	private static final String DOCX_IMAGE1_NAME = "image1.jpeg";
+	private static final String DOCX_IMAGE2_NAME = "image2.jpeg";
+	private static final String DOCX_EXE1_MD5 = "d71ffa0623014df725f8fd2710de4411";
+	private static final String DOCX_EXE1_NAME = "GMapTool.exe";
+	private static final String DOCX_EXE2_MD5 = "2485435c7c22d35f2de9b4c98c0c2e1a";
+	private static final String DOCX_EXE2_NAME = "Setup.exe";
+	private static final String XSL_IMAGE2_MD5 = "8969288f4245120e7c3870287cce0ff3";
+
+
+	private Server server;
+
+	/*
+	 * (non-Javadoc)
+	 * 
+	 * @see junit.framework.TestCase#setUp()
+	 */
+	@Override
+	protected void setUp() throws Exception {
+		JAXRSServerFactoryBean sf = new JAXRSServerFactoryBean();
+		List providers = new ArrayList();
+		providers.add(new TarWriter());
+		providers.add(new ZipWriter());
+		sf.setProviders(providers);
+		sf.setResourceClasses(UnpackerResource.class);
+		sf.setResourceProvider(UnpackerResource.class,
+				new SingletonResourceProvider(new UnpackerResource()));
+		sf.setAddress(endPoint+"/");
+		BindingFactoryManager manager = sf.getBus().getExtension(
+				BindingFactoryManager.class);
+		JAXRSBindingFactory factory = new JAXRSBindingFactory();
+		factory.setBus(sf.getBus());
+		manager.registerBindingFactory(JAXRSBindingFactory.JAXRS_BINDING_ID,
+				factory);
+		server = sf.create();
+	}
+
+	/*
+	 * (non-Javadoc)
+	 * 
+	 * @see junit.framework.TestCase#tearDown()
+	 */
+	@Override
+	protected void tearDown() throws Exception {
+		server.stop();
+		server.destroy();
+	}
+
+	@Test
+	public void testDocWAV() throws Exception {
+		Map<String, String> data = putAndGetMapData(endPoint + UNPACKER_PATH + 
+				"/" + TEST_DOC_WAV,
+				ClassLoader.getSystemResourceAsStream(TEST_DOC_WAV), true);
+		assertEquals(WAV1_MD5, data.get(WAV1_NAME));
+		assertEquals(WAV2_MD5, data.get(WAV2_NAME));
+		assertFalse(data.containsKey(UnpackerResource.TEXT_FILENAME));
+	}
+
+	@Test
+	public void testDocWAVText() throws Exception {
+		Map<String, String> data = putAndGetMapData(endPoint + ALL_PATH + 
+				"/" + TEST_DOC_WAV,
+				ClassLoader.getSystemResourceAsStream(TEST_DOC_WAV), true);
+		assertEquals(WAV1_MD5, data.get(WAV1_NAME));
+		assertEquals(WAV2_MD5, data.get(WAV2_NAME));
+		assertTrue(data.containsKey(UnpackerResource.TEXT_FILENAME));
+	}
+
+	@Test
+	public void testDocPicture() throws Exception {
+		Map<String, String> data = putAndGetMapData(endPoint + UNPACKER_PATH + 
+				"/" + TEST_DOC_WAV,
+				ClassLoader.getSystemResourceAsStream(TEST_DOC_WAV), true);
+		assertEquals(JPG_MD5, data.get(JPG_NAME));
+	}
+
+	@Test
+	public void testDocPictureNoOle() throws Exception {
+		Map<String, String> data = putAndGetMapData(endPoint + UNPACKER_PATH + 
+				"/2pic.doc",
+				ClassLoader.getSystemResourceAsStream("2pic.doc"), true);
+		assertEquals(JPG2_MD5, data.get(JPG2_NAME));
+	}
+
+	@Test
+	public void testImageDOCX() throws Exception {
+		Map<String, String> data = putAndGetMapData(endPoint + UNPACKER_PATH + 
+				"/" + TEST_DOCX_IMAGE,
+				ClassLoader.getSystemResourceAsStream(TEST_DOCX_IMAGE), true);
+		assertEquals(DOCX_IMAGE1_MD5, data.get(DOCX_IMAGE1_NAME));
+		assertEquals(DOCX_IMAGE2_MD5, data.get(DOCX_IMAGE2_NAME));
+	}
+
+	//FIXME: Disabled for now, pending TIKA-593 @Test
+	public void Xtest415() throws Exception {
+		putAndCheckStatus(endPoint + UNPACKER_PATH + "/" + TEST_DOC_WAV,
+				"xxx/xxx", ClassLoader.getSystemResourceAsStream(TEST_DOC_WAV), 415);
+	}
+
+	@Test
+	public void testExeDOCX() throws Exception {
+		String TEST_DOCX_EXE = "2exe.docx";
+		Map<String, String> data = putAndGetMapData(endPoint + UNPACKER_PATH 
+				+ "/" + TEST_DOCX_EXE,
+				ClassLoader.getSystemResourceAsStream(TEST_DOCX_EXE), true);
+		assertEquals(DOCX_EXE1_MD5, data.get(DOCX_EXE1_NAME));
+		assertEquals(DOCX_EXE2_MD5, data.get(DOCX_EXE2_NAME));
+	}
+
+	@Test
+	public void testImageXSL() throws Exception {
+		Map<String, String> data = putAndGetMapData(endPoint + UNPACKER_PATH + "/" 
+				+ "pic.xls",
+				ClassLoader.getSystemResourceAsStream("pic.xls"), true);
+		assertEquals(XSL_IMAGE1_MD5, data.get("0.jpg"));
+		assertEquals(XSL_IMAGE2_MD5, data.get("1.jpg"));
+	}
+
+	//FIXME: Disabled for now @Test
+	public void XtestTarDocPicture() throws Exception {
+		Map<String, String> data = putAndGetMapData(endPoint + UNPACKER_PATH + "/" + 
+				TEST_DOC_WAV,
+				ClassLoader.getSystemResourceAsStream(TEST_DOC_WAV), false);
+		assertEquals(JPG_MD5, data.get(JPG_NAME));
+	}
+
+	//FIXME: Disabled for now @Test
+	public void XtestText() throws Exception {
+		String responseMsg = putAndGetArchiveText(endPoint + UNPACKER_PATH + "/" + 
+				"test.doc",
+				ClassLoader.getSystemResourceAsStream("test.doc"), true);
+		assertNotNull(responseMsg);
+		assertTrue(responseMsg.contains("test"));
+	}
 
-public class UnpackerResourceTest extends JerseyTest {
-  private static final String UNPACKER_PATH = "/unpacker";
-  private static final String ALL_PATH = "/all";
 
-  private static final String TEST_DOC_WAV = "Doc1_ole.doc";
-  private static final String WAV1_MD5 = "bdd0a78a54968e362445364f95d8dc96";
-  private static final String WAV1_NAME = "_1310388059/MSj00974840000[1].wav";
-  private static final String WAV2_MD5 = "3bbd42fb1ac0e46a95350285f16d9596";
-  private static final String WAV2_NAME = "_1310388058/MSj00748450000[1].wav";
-  private static final String APPLICATION_MSWORD = "application/msword";
-  private static final int NO_CONTENT = 204;
-  private static final String JPG_NAME = "image1.jpg";
-  private static final String XSL_IMAGE1_MD5 = "68ead8f4995a3555f48a2f738b2b0c3d";
-  private static final String JPG_MD5 = XSL_IMAGE1_MD5;
-  private static final String JPG2_NAME = "image2.jpg";
-  private static final String JPG2_MD5 = "b27a41d12c646d7fc4f3826cf8183c68";
-  private static final String TEST_DOCX_IMAGE = "2pic.docx";
-  private static final String DOCX_IMAGE1_MD5 = "5516590467b069fa59397432677bad4d";
-  private static final String DOCX_IMAGE2_MD5 = "a5dd81567427070ce0a2ff3e3ef13a4c";
-  private static final String DOCX_IMAGE1_NAME = "image1.jpeg";
-  private static final String DOCX_IMAGE2_NAME = "image2.jpeg";
-  private static final String DOCX_EXE1_MD5 = "d71ffa0623014df725f8fd2710de4411";
-  private static final String DOCX_EXE1_NAME = "GMapTool.exe";
-  private static final String DOCX_EXE2_MD5 = "2485435c7c22d35f2de9b4c98c0c2e1a";
-  private static final String DOCX_EXE2_NAME = "Setup.exe";
-  private static final String XSLX_IMAGE1_NAME = "image1.jpeg";
-  private static final String XSLX_IMAGE2_NAME = "image2.jpeg";
-  private static final String XSL_IMAGE2_MD5 = "8969288f4245120e7c3870287cce0ff3";
-  private static final String COVER_JPG_MD5SUM = "4d236dab6e711735ed11686641b1fba9";
-  private static final String COVER_JPG = "cover.jpg";
-  private static final String APPLICATION_XML = "application/xml";
-  private static final String CONTENT_TYPE = "Content-type";
-
-  public UnpackerResourceTest() throws Exception {
-    super("org.apache.tika.server");
-  }
-
-  @Test
-  public void testDocWAV() throws Exception {
-    InputStream is =
-            resource()
-                    .path(UNPACKER_PATH)
-                    .type(APPLICATION_MSWORD)
-                    .put(InputStream.class, ClassLoader.getSystemResourceAsStream(TEST_DOC_WAV));
-
-    ArchiveInputStream zip = new ZipArchiveInputStream(is);
-
-    Map<String, String> data = readArchive(zip);
-
-    assertEquals(WAV1_MD5, data.get(WAV1_NAME));
-    assertEquals(WAV2_MD5, data.get(WAV2_NAME));
-
-    assertFalse(data.containsKey(UnpackerResource.TEXT_FILENAME));
-  }
-
-  @Test
-  public void testDocWAVText() throws Exception {
-    InputStream is =
-            resource()
-                    .path(ALL_PATH)
-                    .type(APPLICATION_MSWORD)
-                    .put(InputStream.class, ClassLoader.getSystemResourceAsStream(TEST_DOC_WAV));
-
-    ArchiveInputStream zip = new ZipArchiveInputStream(is);
-
-    Map<String, String> data = readArchive(zip);
-
-    assertEquals(WAV1_MD5, data.get(WAV1_NAME));
-    assertEquals(WAV2_MD5, data.get(WAV2_NAME));
-
-    assertTrue(data.containsKey(UnpackerResource.TEXT_FILENAME));
-  }
-
-  @Test
-  public void testDocPicture() throws Exception {
-    InputStream is =
-            resource()
-                    .path(UNPACKER_PATH)
-                    .type(APPLICATION_MSWORD)
-                    .put(InputStream.class, ClassLoader.getSystemResourceAsStream(TEST_DOC_WAV));
-
-    ZipArchiveInputStream zip = new ZipArchiveInputStream(is);
-
-    Map<String, String> data = readArchive(zip);
-
-    assertEquals(JPG_MD5, data.get(JPG_NAME));
-  }
-
-  @Test
-  public void testDocPictureNoOle() throws Exception {
-    InputStream is =
-            resource()
-                    .path(UNPACKER_PATH)
-                    .type(APPLICATION_MSWORD)
-                    .put(InputStream.class, ClassLoader.getSystemResourceAsStream("2pic.doc"));
-
-    ZipArchiveInputStream zip = new ZipArchiveInputStream(is);
-
-    Map<String, String> data = readArchive(zip);
-
-    assertEquals(JPG2_MD5, data.get(JPG2_NAME));
-  }
-
-  @Test
-  public void testImageDOCX() throws Exception {
-    InputStream is =
-            resource()
-                    .path(UNPACKER_PATH)
-                    .put(InputStream.class, ClassLoader.getSystemResourceAsStream(TEST_DOCX_IMAGE));
-
-    ZipArchiveInputStream zip = new ZipArchiveInputStream(is);
-
-    Map<String, String> data = readArchive(zip);
-
-    assertEquals(DOCX_IMAGE1_MD5, data.get(DOCX_IMAGE1_NAME));
-    assertEquals(DOCX_IMAGE2_MD5, data.get(DOCX_IMAGE2_NAME));
-  }
-
-  @Test
-  public void test415() throws Exception {
-    ClientResponse cr =
-            resource()
-                    .path(UNPACKER_PATH)
-                    .type("xxx/xxx")
-                    .put(ClientResponse.class, ClassLoader.getSystemResourceAsStream(TEST_DOC_WAV));
-
-    assertEquals(415, cr.getStatus());
-  }
-
-  @Test
-  public void testExeDOCX() throws Exception {
-    String TEST_DOCX_EXE = "2exe.docx";
-    InputStream is =
-            resource()
-                    .path(UNPACKER_PATH)
-                    .put(InputStream.class, ClassLoader.getSystemResourceAsStream(TEST_DOCX_EXE));
-
-    ZipArchiveInputStream zip = new ZipArchiveInputStream(is);
-
-    Map<String, String> data = readArchive(zip);
-
-    assertEquals(DOCX_EXE1_MD5, data.get(DOCX_EXE1_NAME));
-    assertEquals(DOCX_EXE2_MD5, data.get(DOCX_EXE2_NAME));
-  }
-
-  @Test
-  public void testImageXSL() throws Exception {
-    InputStream is =
-            resource()
-                    .path(UNPACKER_PATH)
-                    .put(InputStream.class, ClassLoader.getSystemResourceAsStream("pic.xls"));
-
-    ZipArchiveInputStream zip = new ZipArchiveInputStream(is);
-
-    Map<String, String> data = readArchive(zip);
-
-    assertEquals(XSL_IMAGE1_MD5, data.get("0.jpg"));
-    assertEquals(XSL_IMAGE2_MD5, data.get("1.jpg"));
-  }
-
-  private static Map<String, String> readArchive(ArchiveInputStream zip) throws IOException {
-    Map<String, String> data = new HashMap<String, String>();
-
-    while (true) {
-      ArchiveEntry entry = zip.getNextEntry();
-
-      if (entry==null) {
-        break;
-      }
-
-      ByteArrayOutputStream bos = new ByteArrayOutputStream();
-
-      IOUtils.copy(zip, bos);
-
-      data.put(entry.getName(), DigestUtils.md5Hex(bos.toByteArray()));
-    }
-
-    return data;
-  }
-
-  private static String readArchiveText(ArchiveInputStream zip) throws IOException {
-    while (true) {
-      ArchiveEntry entry = zip.getNextEntry();
-
-      if (entry==null) {
-        break;
-      }
-
-      if (!entry.getName().equals(UnpackerResource.TEXT_FILENAME)) {
-        continue;
-      }
-
-      ByteArrayOutputStream bos = new ByteArrayOutputStream();
-
-      IOUtils.copy(zip, bos);
-
-      return bos.toString("UTF-8");
-    }
-
-    return null;
-  }
-
-  @Test
-  public void testTarDocPicture() throws Exception {
-    InputStream is =
-            resource()
-                    .path(UNPACKER_PATH)
-                    .type(APPLICATION_MSWORD)
-                    .accept("application/x-tar")
-                    .put(InputStream.class, ClassLoader.getSystemResourceAsStream(TEST_DOC_WAV));
-
-    ArchiveInputStream zip = new TarArchiveInputStream(is);
-
-    Map<String, String> data = readArchive(zip);
-
-    assertEquals(JPG_MD5, data.get(JPG_NAME));
-  }
-
-  @Test
-  public void testText() throws IOException {
-    InputStream is
-            = resource()
-                    .path(ALL_PATH)
-                    .header(CONTENT_TYPE, APPLICATION_XML)
-                    .put(InputStream.class, ClassLoader.getSystemResourceAsStream("test.doc"));
-    String responseMsg = readArchiveText(new ZipArchiveInputStream(is));
-
-    assertNotNull(responseMsg);
-    assertTrue(responseMsg.contains("test"));
-  }
 }

Commit:
16c92d0345873591dab9f9fad199d83fe11ce7b1
Jukka Zitting
jukka@apache.org
2012-03-27 17:32:35 +0000
TIKA-884: Dynamic loading of Parser and Detector services
diff --git a/tika-core/src/main/java/org/apache/tika/config/ServiceLoader.java b/tika-core/src/main/java/org/apache/tika/config/ServiceLoader.java
index 5d2bc04af..619319139 100644
--- a/tika-core/src/main/java/org/apache/tika/config/ServiceLoader.java
+++ b/tika-core/src/main/java/org/apache/tika/config/ServiceLoader.java
@@ -194,9 +194,25 @@ public class ServiceLoader {
      * @param iface service provider interface
      * @return available service providers
      */
-    @SuppressWarnings("unchecked")
     public <T> List<T> loadServiceProviders(Class<T> iface) {
         List<T> providers = new ArrayList<T>();
+        providers.addAll(loadDynamicServiceProviders(iface));
+        providers.addAll(loadStaticServiceProviders(iface));
+        return providers;
+    }
+
+    /**
+     * Returns the available dynamic service providers of the given type.
+     * The returned list is newly allocated and may be freely modified
+     * by the caller.
+     *
+     * @since Apache Tika 1.2
+     * @param iface service provider interface
+     * @return dynamic service providers
+     */
+    @SuppressWarnings("unchecked")
+    public <T> List<T> loadDynamicServiceProviders(Class<T> iface) {
+        List<T> providers = new ArrayList<T>();
 
         if (dynamic) {
             synchronized (services) {
@@ -208,6 +224,23 @@ public class ServiceLoader {
             }
         }
 
+        return providers;
+    }
+
+    /**
+     * Returns the available static service providers of the given type.
+     * The providers are loaded using the service provider mechanism using
+     * the configured class loader (if any). The returned list is newly
+     * allocated and may be freely modified by the caller.
+     *
+     * @since Apache Tika 1.2
+     * @param iface service provider interface
+     * @return static service providers
+     */
+    @SuppressWarnings("unchecked")
+    public <T> List<T> loadStaticServiceProviders(Class<T> iface) {
+        List<T> providers = new ArrayList<T>();
+
         if (loader != null) {
             Set<String> names = new HashSet<String>();
 
diff --git a/tika-core/src/main/java/org/apache/tika/detect/CompositeDetector.java b/tika-core/src/main/java/org/apache/tika/detect/CompositeDetector.java
index 4a4db2d1a..4ea245e85 100644
--- a/tika-core/src/main/java/org/apache/tika/detect/CompositeDetector.java
+++ b/tika-core/src/main/java/org/apache/tika/detect/CompositeDetector.java
@@ -57,7 +57,7 @@ public class CompositeDetector implements Detector {
     public MediaType detect(InputStream input, Metadata metadata)
             throws IOException { 
         MediaType type = MediaType.OCTET_STREAM;
-        for (Detector detector : detectors) {
+        for (Detector detector : getDetectors()) {
             MediaType detected = detector.detect(input, metadata);
             if (registry.isSpecializationOf(detected, type)) {
                 type = detected;
diff --git a/tika-core/src/main/java/org/apache/tika/detect/DefaultDetector.java b/tika-core/src/main/java/org/apache/tika/detect/DefaultDetector.java
index 1291563a6..c16d7bb86 100644
--- a/tika-core/src/main/java/org/apache/tika/detect/DefaultDetector.java
+++ b/tika-core/src/main/java/org/apache/tika/detect/DefaultDetector.java
@@ -16,7 +16,6 @@
  */
 package org.apache.tika.detect;
 
-import java.util.ArrayList;
 import java.util.Collections;
 import java.util.Comparator;
 import java.util.List;
@@ -43,42 +42,44 @@ public class DefaultDetector extends CompositeDetector {
     /** Serial version UID */
     private static final long serialVersionUID = -8170114575326908027L;
 
+    /**
+     * Finds all statically loadable detectors and sort the list by name,
+     * rather than discovery order. Detectors are used in the given order,
+     * so put the Tika parsers last so that non-Tika (user supplied)
+     * parsers can take precedence.
+     *
+     * @param loader service loader
+     * @return ordered list of statically loadable detectors
+     */
     private static List<Detector> getDefaultDetectors(
             MimeTypes types, ServiceLoader loader) {
-        // Find all the detectors available as services
-        List<Detector> svcDetectors = loader.loadServiceProviders(Detector.class);
-        List<Detector> detectors = new ArrayList<Detector>(svcDetectors.size()+1);
-        
-        // Sort the list by classname, rather than discovery order 
-        Collections.sort(svcDetectors, new Comparator<Detector>() {
+        List<Detector> detectors =
+                loader.loadStaticServiceProviders(Detector.class);
+        Collections.sort(detectors, new Comparator<Detector>() {
             public int compare(Detector d1, Detector d2) {
-               return d1.getClass().getName().compareTo(
-                     d2.getClass().getName());
+                String n1 = d1.getClass().getName();
+                String n2 = d2.getClass().getName();
+                boolean t1 = n1.startsWith("org.apache.tika.");
+                boolean t2 = n2.startsWith("org.apache.tika.");
+                if (t1 == t2) {
+                    return n1.compareTo(n2);
+                } else if (t1) {
+                    return 1;
+                } else {
+                    return -1;
+                }
             }
         });
-        
-        // Add the non-Tika (user supplied) detectors First
-        for (Detector d : svcDetectors) {
-           if (! d.getClass().getName().startsWith("org.apache.tika")) {
-              detectors.add(d);
-           }
-        }
-        
-        // Add the Tika detectors next
-        for (Detector d : svcDetectors) {
-           if (d.getClass().getName().startsWith("org.apache.tika")) {
-              detectors.add(d);
-           }
-        }
-        
-        // Finally add the Tika MimeTypes as a fallback
+        // Finally the Tika MimeTypes as a fallback
         detectors.add(types);
-        
         return detectors;
     }
 
+    private transient final ServiceLoader loader;
+
     public DefaultDetector(MimeTypes types, ServiceLoader loader) {
         super(types.getMediaTypeRegistry(), getDefaultDetectors(types, loader));
+        this.loader = loader;
     }
 
     public DefaultDetector(MimeTypes types, ClassLoader loader) {
@@ -97,4 +98,16 @@ public class DefaultDetector extends CompositeDetector {
         this(MimeTypes.getDefaultMimeTypes());
     }
 
+    @Override
+    public List<Detector> getDetectors() {
+        if (loader != null) {
+            List<Detector> detectors =
+                    loader.loadDynamicServiceProviders(Detector.class);
+            detectors.addAll(super.getDetectors());
+            return detectors;
+        } else {
+            return super.getDetectors();
+        }
+    }
+
 }
diff --git a/tika-core/src/main/java/org/apache/tika/parser/DefaultParser.java b/tika-core/src/main/java/org/apache/tika/parser/DefaultParser.java
index 6aa418257..f1e02ba07 100644
--- a/tika-core/src/main/java/org/apache/tika/parser/DefaultParser.java
+++ b/tika-core/src/main/java/org/apache/tika/parser/DefaultParser.java
@@ -16,57 +16,62 @@
  */
 package org.apache.tika.parser;
 
-import java.util.ArrayList;
 import java.util.Collections;
 import java.util.Comparator;
 import java.util.List;
-
-import javax.imageio.spi.ServiceRegistry;
+import java.util.Map;
 
 import org.apache.tika.config.ServiceLoader;
+import org.apache.tika.mime.MediaType;
 import org.apache.tika.mime.MediaTypeRegistry;
 
 /**
  * A composite parser based on all the {@link Parser} implementations
- * available through the {@link ServiceRegistry service provider mechanism}.
+ * available through the
+ * {@link javax.imageio.spi.ServiceRegistry service provider mechanism}.
  *
  * @since Apache Tika 0.8
  */
 public class DefaultParser extends CompositeParser {
+
     /** Serial version UID */
     private static final long serialVersionUID = 3612324825403757520L;
 
+    /**
+     * Finds all statically loadable parsers and sort the list by name,
+     * rather than discovery order. CompositeParser takes the last
+     * parser for any given media type, so put the Tika parsers first
+     * so that non-Tika (user supplied) parsers can take precedence.
+     *
+     * @param loader service loader
+     * @return ordered list of statically loadable parsers
+     */
     private static List<Parser> getDefaultParsers(ServiceLoader loader) {
-        // Find all the Parsers available as services
-        List<Parser> svcParsers = loader.loadServiceProviders(Parser.class);
-        List<Parser> parsers = new ArrayList<Parser>(svcParsers.size());
-
-        // Sort the list by classname, rather than discovery order 
-        Collections.sort(svcParsers, new Comparator<Parser>() {
-           public int compare(Parser p1, Parser p2) {
-              return p1.getClass().getName().compareTo(
-                   p2.getClass().getName());
-           }
+        List<Parser> parsers =
+                loader.loadStaticServiceProviders(Parser.class);
+        Collections.sort(parsers, new Comparator<Parser>() {
+            public int compare(Parser p1, Parser p2) {
+                String n1 = p1.getClass().getName();
+                String n2 = p2.getClass().getName();
+                boolean t1 = n1.startsWith("org.apache.tika.");
+                boolean t2 = n2.startsWith("org.apache.tika.");
+                if (t1 == t2) {
+                    return n1.compareTo(n2);
+                } else if (t1) {
+                    return -1;
+                } else {
+                    return 1;
+                }
+            }
         });
-        
-        // CompositeParser takes the last parser for any given mime type, so put the 
-        // TikaParsers first so that non-Tika (user supplied) parsers can take presidence
-        for (Parser p : svcParsers) {
-           if (p.getClass().getName().startsWith("org.apache.tika")) {
-              parsers.add(p);
-           }
-        }
-        for (Parser p : svcParsers) {
-           if (!p.getClass().getName().startsWith("org.apache.tika")) {
-              parsers.add(p);
-           }
-        }
-        
         return parsers;
     }
 
+    private transient final ServiceLoader loader;
+
     public DefaultParser(MediaTypeRegistry registry, ServiceLoader loader) {
         super(registry, getDefaultParsers(loader));
+        this.loader = loader;
     }
 
     public DefaultParser(MediaTypeRegistry registry, ClassLoader loader) {
@@ -85,4 +90,22 @@ public class DefaultParser extends CompositeParser {
         this(MediaTypeRegistry.getDefaultRegistry());
     }
 
+    @Override
+    public Map<MediaType, Parser> getParsers(ParseContext context) {
+        Map<MediaType, Parser> map = super.getParsers(context);
+
+        if (loader != null) {
+            // Add dynamic parser service (they always override static ones)
+            MediaTypeRegistry registry = getMediaTypeRegistry();
+            for (Parser parser
+                    : loader.loadDynamicServiceProviders(Parser.class)) {
+                for (MediaType type : parser.getSupportedTypes(context)) {
+                    map.put(registry.normalize(type), parser);
+                }
+            }
+        }
+
+        return map;
+    }
+
 }

Commit:
66bdd0b3162ada79db13e684f918a0883be25d45
Jukka Zitting
jukka@apache.org
2012-03-27 17:31:02 +0000
TIKA-866: Invalid configuration file causes OutOfMemoryException
diff --git a/tika-core/src/test/java/org/apache/tika/config/TikaConfigTest.java b/tika-core/src/test/java/org/apache/tika/config/TikaConfigTest.java
index bff4fcc21..5b9a18cf4 100644
--- a/tika-core/src/test/java/org/apache/tika/config/TikaConfigTest.java
+++ b/tika-core/src/test/java/org/apache/tika/config/TikaConfigTest.java
@@ -39,6 +39,8 @@ public class TikaConfigTest extends TestCase {
             new TikaConfig();
             fail("AutoDetectParser allowed in a <parser> element");
         } catch (TikaException expected) {
+        } finally {
+            System.clearProperty("tika.config");
         }
     }
 
@@ -56,6 +58,8 @@ public class TikaConfigTest extends TestCase {
             new TikaConfig();
         } catch (TikaException e) {
             fail("Unexpected TikaException: " + e);
+        } finally {
+            System.clearProperty("tika.config");
         }
     }
 
@@ -72,6 +76,8 @@ public class TikaConfigTest extends TestCase {
             new TikaConfig();
         } catch (TikaException e) {
             fail("Unexpected TikaException: " + e);
+        } finally {
+            System.clearProperty("tika.config");
         }
     }
 

Commit:
a2bf1f815fb81ab32521501554c78296f8f23135
Maxim Valyanskiy
maxcom@apache.org
2012-03-26 12:55:42 +0000
tika-server: update java version because jersey-core requires java6
diff --git a/tika-server/pom.xml b/tika-server/pom.xml
index b7d43a10f..94aa76bf7 100644
--- a/tika-server/pom.xml
+++ b/tika-server/pom.xml
@@ -151,8 +151,8 @@
                 <artifactId>maven-compiler-plugin</artifactId>
                 <inherited>true</inherited>
                 <configuration>
-                    <source>1.5</source>
-                    <target>1.5</target>
+                    <source>1.6</source>
+                    <target>1.6</target>
                 </configuration>
             </plugin>
       <plugin>

Commit:
2e2137311ace0a718caaaa6cabee93498074ecea
Maxim Valyanskiy
maxcom@apache.org
2012-03-26 11:53:30 +0000
tika-server: remove java.net repository
diff --git a/tika-server/pom.xml b/tika-server/pom.xml
index b1431b46c..b7d43a10f 100644
--- a/tika-server/pom.xml
+++ b/tika-server/pom.xml
@@ -183,20 +183,5 @@
             </plugin>
         </plugins>
     </build>
-
-     <repositories>
-        <repository>
-            <id>maven2-repository.dev.java.net</id>
-            <name>Java.net Repository for Maven</name>
-            <url>http://download.java.net/maven/2/</url>
-            <layout>default</layout>
-        </repository>
-        <repository>
-            <id>maven-repository.dev.java.net</id>
-            <name>Java.net Maven 1 Repository (legacy)</name>
-            <url>http://download.java.net/maven/1</url>
-            <layout>legacy</layout>
-        </repository>
-    </repositories>
 </project>
 

Commit:
f1a9287b9ee7c9cc1ae9e668ac154ef1dff99e95
Maxim Valyanskiy
maxcom@apache.org
2012-03-26 10:53:00 +0000
TIKA-593 - enable jax-rs network server module
diff --git a/pom.xml b/pom.xml
index dd33d8dd1..5ed9e9251 100644
--- a/pom.xml
+++ b/pom.xml
@@ -50,7 +50,7 @@
     <module>tika-parsers</module>
     <module>tika-app</module>
     <module>tika-bundle</module>
-    <!-- <module>tika-server</module> -->
+    <module>tika-server</module>
   </modules>
 
   <build>
diff --git a/tika-server/pom.xml b/tika-server/pom.xml
index d0ac86c1f..b1431b46c 100644
--- a/tika-server/pom.xml
+++ b/tika-server/pom.xml
@@ -40,7 +40,7 @@
   <parent>
     <groupId>org.apache.tika</groupId>
     <artifactId>tika-parent</artifactId>
-    <version>1.1-SNAPSHOT</version>
+    <version>1.2-SNAPSHOT</version>
     <relativePath>../tika-parent/pom.xml</relativePath>
   </parent>
 

Commit:
fcfdec738459fcf1a9d13ee945d2cb0cacf4c853
Chris Mattmann
mattmann@apache.org
2012-03-24 05:30:32 +0000
- update template for 1.1
diff --git a/src/site/apt/index.apt b/src/site/apt/index.apt
index 32d340859..9a127ff49 100644
--- a/src/site/apt/index.apt
+++ b/src/site/apt/index.apt
@@ -17,15 +17,15 @@
 ~~ See the License for the specific language governing permissions and
 ~~ limitations under the License.
 
-Apache Tika 0.9
+Apache Tika 1.1
 
 
-   The most notable changes in Tika 0.9 over the previous release are:
+   The most notable changes in Tika 1.1 over the previous release are:
 
       * TBD
    
 
-   The following people have contributed to Tika 0.9 by submitting or
+   The following people have contributed to Tika 1.1 by submitting or
    commenting on the issues resolved in this release:
 
       * TBD

Commit:
61532805e1d21bf58ddf6a914c58dd8d8dd9f050
Maxim Valyanskiy
maxcom@apache.org
2012-03-23 12:05:21 +0000
TIKA-883 - Extract embedded images in PPT
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/HSLFExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/HSLFExtractor.java
index be9806450..98e845a2e 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/HSLFExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/HSLFExtractor.java
@@ -16,18 +16,10 @@
  */
 package org.apache.tika.parser.microsoft;
 
-import java.io.IOException;
-import java.util.HashSet;
-
 import org.apache.poi.hslf.HSLFSlideShow;
-import org.apache.poi.hslf.model.Comment;
-import org.apache.poi.hslf.model.HeadersFooters;
-import org.apache.poi.hslf.model.Notes;
-import org.apache.poi.hslf.model.OLEShape;
-import org.apache.poi.hslf.model.Shape;
-import org.apache.poi.hslf.model.Slide;
-import org.apache.poi.hslf.model.TextRun;
+import org.apache.poi.hslf.model.*;
 import org.apache.poi.hslf.usermodel.ObjectData;
+import org.apache.poi.hslf.usermodel.PictureData;
 import org.apache.poi.hslf.usermodel.SlideShow;
 import org.apache.poi.poifs.filesystem.DirectoryNode;
 import org.apache.poi.poifs.filesystem.NPOIFSFileSystem;
@@ -37,6 +29,9 @@ import org.apache.tika.parser.ParseContext;
 import org.apache.tika.sax.XHTMLContentHandler;
 import org.xml.sax.SAXException;
 
+import java.io.IOException;
+import java.util.HashSet;
+
 public class HSLFExtractor extends AbstractPOIFSExtractor {
    public HSLFExtractor(ParseContext context) {
       super(context);
@@ -164,6 +159,8 @@ public class HSLFExtractor extends AbstractPOIFSExtractor {
          }
       }
 
+      handleSlideEmbeddedPictures(_show, xhtml);
+
       xhtml.endElement("div");
    }
 
@@ -181,7 +178,36 @@ public class HSLFExtractor extends AbstractPOIFSExtractor {
       }
    }
 
-   private void handleSlideEmbeddedResources(Slide slide, XHTMLContentHandler xhtml) 
+    private void handleSlideEmbeddedPictures(SlideShow slideshow, XHTMLContentHandler xhtml)
+            throws TikaException, SAXException, IOException {
+        for (PictureData pic : slideshow.getPictureData()) {
+            String mediaType = null;
+
+            switch (pic.getType()) {
+                case Picture.EMF:
+                    mediaType = "application/x-emf";
+                    break;
+                case Picture.JPEG:
+                    mediaType = "image/jpeg";
+                    break;
+                case Picture.PNG:
+                    mediaType = "image/png";
+                    break;
+                case Picture.WMF:
+                    mediaType = "application/x-msmetafile";
+                    break;
+                case Picture.DIB:
+                    mediaType = "image/bmp";
+                    break;
+            }
+
+            handleEmbeddedResource(
+                  TikaInputStream.get(pic.getData()), null,
+                  mediaType, xhtml, false);
+        }
+    }
+
+    private void handleSlideEmbeddedResources(Slide slide, XHTMLContentHandler xhtml)
                 throws TikaException, SAXException, IOException {
       Shape[] shapes;
       try {
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/POIContainerExtractionTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/POIContainerExtractionTest.java
index dae50c2de..19819b353 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/POIContainerExtractionTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/POIContainerExtractionTest.java
@@ -134,8 +134,8 @@ public class POIContainerExtractionTest extends AbstractPOIContainerExtractionTe
        
        // With recursion, should get the images embedded in the office files too
        handler = process("testEXCEL_embeded.xls", extractor, true);
-       assertEquals(12, handler.filenames.size());
-       assertEquals(12, handler.mediaTypes.size());
+       assertEquals(17, handler.filenames.size());
+       assertEquals(17, handler.mediaTypes.size());
        
        assertEquals(null, handler.filenames.get(0));
        assertEquals(null, handler.filenames.get(1));
@@ -147,7 +147,7 @@ public class POIContainerExtractionTest extends AbstractPOIContainerExtractionTe
        assertEquals("image1.png", handler.filenames.get(7));
        assertEquals("image2.jpg", handler.filenames.get(8));
        assertEquals("image3.png", handler.filenames.get(9));
-       assertEquals("image1.png", handler.filenames.get(11));
+       assertEquals("image1.png", handler.filenames.get(16));
 
        assertEquals(TYPE_EMF, handler.mediaTypes.get(0)); // Icon of embedded office doc
        assertEquals(TYPE_EMF, handler.mediaTypes.get(1)); // Icon of embedded office doc
@@ -159,8 +159,8 @@ public class POIContainerExtractionTest extends AbstractPOIContainerExtractionTe
        assertEquals(TYPE_PNG, handler.mediaTypes.get(7)); // Embedded image
        assertEquals(TYPE_JPG, handler.mediaTypes.get(8)); // Embedded image
        assertEquals(TYPE_PNG, handler.mediaTypes.get(9)); // Embedded image
-       assertEquals(TYPE_DOC, handler.mediaTypes.get(10)); // Embedded office doc
-       assertEquals(TYPE_PNG, handler.mediaTypes.get(11)); // Embedded image
+       assertEquals(TYPE_DOC, handler.mediaTypes.get(15)); // Embedded office doc
+       assertEquals(TYPE_PNG, handler.mediaTypes.get(16)); // Embedded image
 
        // Word with .docx, powerpoint and excel
        handler = process("testWORD_embeded.doc", extractor, false);
@@ -193,8 +193,8 @@ public class POIContainerExtractionTest extends AbstractPOIContainerExtractionTe
        
        // With recursion, should get their images too
        handler = process("testWORD_embeded.doc", extractor, true);
-       assertEquals(13, handler.filenames.size());
-       assertEquals(13, handler.mediaTypes.size());
+       assertEquals(16, handler.filenames.size());
+       assertEquals(16, handler.mediaTypes.size());
        
        // We don't know their filenames, except for doc images + docx
        assertEquals("image1.emf", handler.filenames.get(0));
@@ -207,7 +207,7 @@ public class POIContainerExtractionTest extends AbstractPOIContainerExtractionTe
        assertEquals("image2.png", handler.filenames.get(7));
        assertEquals("image3.jpeg", handler.filenames.get(8));
        assertEquals("image4.png", handler.filenames.get(9));
-       for(int i=12; i<handler.filenames.size(); i++) {
+       for(int i=11; i<14; i++) {
           assertNull(handler.filenames.get(i));
        }
        // But we do know their types
@@ -222,8 +222,8 @@ public class POIContainerExtractionTest extends AbstractPOIContainerExtractionTe
        assertEquals(TYPE_JPG, handler.mediaTypes.get(8));  //    JPG inside .docx
        assertEquals(TYPE_PNG, handler.mediaTypes.get(9));  //    PNG inside .docx
        assertEquals(TYPE_PPT, handler.mediaTypes.get(10)); // Embedded office doc
-       assertEquals(TYPE_XLS, handler.mediaTypes.get(11)); // Embedded office doc
-       assertEquals(TYPE_PNG, handler.mediaTypes.get(12)); //    PNG inside .xls
+       assertEquals(TYPE_XLS, handler.mediaTypes.get(14)); // Embedded office doc
+       assertEquals(TYPE_PNG, handler.mediaTypes.get(15)); //    PNG inside .xls
        
        
        // PowerPoint with excel and word
@@ -262,4 +262,13 @@ public class POIContainerExtractionTest extends AbstractPOIContainerExtractionTe
         assertTrue(handler.filenames.contains("Microsoft_Office_Excel_97-2003_Worksheet1.bin"));
         assertEquals(2, handler.filenames.size());
     }
+
+    public void testPowerpointImages() throws Exception {
+        ContainerExtractor extractor = new ParserContainerExtractor();
+        TrackingHandler handler;
+
+        handler = process("pictures.ppt", extractor, false);
+        assertTrue(handler.mediaTypes.contains(new MediaType("image", "jpeg")));
+        assertTrue(handler.mediaTypes.contains(new MediaType("image", "png")));
+    }
 }
diff --git a/tika-parsers/src/test/resources/test-documents/pictures.ppt b/tika-parsers/src/test/resources/test-documents/pictures.ppt
new file mode 100644
index 000000000..9f6ce6dea
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/pictures.ppt differ

Commit:
6d5a229a34fe3e03bd615f6495953d19f4f98d34
Maxim Valyanskiy
maxcom@apache.org
2012-03-23 09:53:31 +0000
tika-server: configure surefire plugin
diff --git a/tika-server/pom.xml b/tika-server/pom.xml
index f031af89e..d0ac86c1f 100644
--- a/tika-server/pom.xml
+++ b/tika-server/pom.xml
@@ -172,6 +172,15 @@
           </instructions>
         </configuration>
       </plugin>
+            <plugin>
+                <groupId>org.apache.maven.plugins</groupId>
+                <artifactId>maven-surefire-plugin</artifactId>
+                <version>2.12</version>
+                <configuration>
+                    <redirectTestOutputToFile>true</redirectTestOutputToFile>
+                    <argLine>-da -XX:+HeapDumpOnOutOfMemoryError -Xmx512m</argLine>
+                </configuration>
+            </plugin>
         </plugins>
     </build>
 

Commit:
44d14a51ff1c93fc597aa85fc828507d214269d3
Maxim Valyanskiy
maxcom@apache.org
2012-03-23 09:45:34 +0000
New rewritten UnpackerResource for TIKA-593:
diff --git a/tika-server/src/main/java/org/apache/tika/server/MetadataResource.java b/tika-server/src/main/java/org/apache/tika/server/MetadataResource.java
index 123cbcd0c..1f0eef2f3 100644
--- a/tika-server/src/main/java/org/apache/tika/server/MetadataResource.java
+++ b/tika-server/src/main/java/org/apache/tika/server/MetadataResource.java
@@ -55,16 +55,22 @@ public class MetadataResource {
 
     return new StreamingOutput() {
       public void write(OutputStream outputStream) throws IOException, WebApplicationException {
-        CSVWriter writer = new CSVWriter(new OutputStreamWriter(outputStream));
-        for (String name : metadata.names()) {
-          String[] values = metadata.getValues(name);
-          ArrayList<String> list = new ArrayList<String>(values.length+1);
-          list.add(name);
-          list.addAll(Arrays.asList(values));
-          writer.writeNext(list.toArray(values));
-        }
-        writer.close();
+        metadataToCsv(metadata, outputStream);
       }
     };
   }
+
+  public static void metadataToCsv(Metadata metadata, OutputStream outputStream) throws IOException {
+    CSVWriter writer = new CSVWriter(new OutputStreamWriter(outputStream, "UTF-8"));
+
+    for (String name : metadata.names()) {
+      String[] values = metadata.getValues(name);
+      ArrayList<String> list = new ArrayList<String>(values.length+1);
+      list.add(name);
+      list.addAll(Arrays.asList(values));
+      writer.writeNext(list.toArray(values));
+    }
+
+    writer.close();
+  }
 }
diff --git a/tika-server/src/main/java/org/apache/tika/server/PartExtractor.java b/tika-server/src/main/java/org/apache/tika/server/PartExtractor.java
deleted file mode 100644
index 9166710ae..000000000
--- a/tika-server/src/main/java/org/apache/tika/server/PartExtractor.java
+++ /dev/null
@@ -1,25 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.server;
-
-import java.io.IOException;
-import java.util.zip.ZipOutputStream;
-
-public interface PartExtractor<T> {
-  void extract(T part, ZipOutputStream output) throws IOException;
-}
diff --git a/tika-server/src/main/java/org/apache/tika/server/TarWriter.java b/tika-server/src/main/java/org/apache/tika/server/TarWriter.java
new file mode 100644
index 000000000..d6d19f229
--- /dev/null
+++ b/tika-server/src/main/java/org/apache/tika/server/TarWriter.java
@@ -0,0 +1,67 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.server;
+
+import org.apache.commons.compress.archivers.tar.TarArchiveEntry;
+import org.apache.commons.compress.archivers.tar.TarArchiveOutputStream;
+
+import javax.ws.rs.Produces;
+import javax.ws.rs.WebApplicationException;
+import javax.ws.rs.core.MediaType;
+import javax.ws.rs.core.MultivaluedMap;
+import javax.ws.rs.ext.MessageBodyWriter;
+import javax.ws.rs.ext.Provider;
+import java.io.IOException;
+import java.io.OutputStream;
+import java.lang.annotation.Annotation;
+import java.lang.reflect.Type;
+import java.util.Map;
+
+@Provider
+@Produces("application/x-tar")
+public class TarWriter implements MessageBodyWriter<Map<String, byte[]>> {
+  private static void tarStoreBuffer(TarArchiveOutputStream zip, String name, byte[] dataBuffer) throws IOException {
+    TarArchiveEntry entry = new TarArchiveEntry(name);
+
+    entry.setSize(dataBuffer.length);
+
+    zip.putArchiveEntry(entry);
+
+    zip.write(dataBuffer);
+
+    zip.closeArchiveEntry();
+  }
+
+  public boolean isWriteable(Class<?> type, Type genericType, Annotation[] annotations, MediaType mediaType) {
+    return Map.class.isAssignableFrom(type);
+  }
+
+  public long getSize(Map<String, byte[]> stringMap, Class<?> type, Type genericType, Annotation[] annotations, MediaType mediaType) {
+    return -1;
+  }
+
+  public void writeTo(Map<String, byte[]> parts, Class<?> type, Type genericType, Annotation[] annotations, MediaType mediaType, MultivaluedMap<String, Object> httpHeaders, OutputStream entityStream) throws IOException, WebApplicationException {
+    TarArchiveOutputStream zip = new TarArchiveOutputStream(entityStream);
+
+    for (Map.Entry<String, byte[]> entry : parts.entrySet()) {
+      tarStoreBuffer(zip, entry.getKey(), entry.getValue());
+    }
+
+    zip.close();
+  }
+}
diff --git a/tika-server/src/main/java/org/apache/tika/server/UnpackerResource.java b/tika-server/src/main/java/org/apache/tika/server/UnpackerResource.java
index 26c2e2ea3..dde7d8d30 100644
--- a/tika-server/src/main/java/org/apache/tika/server/UnpackerResource.java
+++ b/tika-server/src/main/java/org/apache/tika/server/UnpackerResource.java
@@ -20,19 +20,19 @@ package org.apache.tika.server;
 import org.apache.commons.lang.mutable.MutableInt;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
-import org.apache.poi.poifs.filesystem.Ole10Native;
-import org.apache.poi.poifs.filesystem.Ole10NativeException;
-import org.apache.poi.poifs.filesystem.POIFSFileSystem;
+import org.apache.poi.poifs.filesystem.*;
 import org.apache.poi.util.IOUtils;
 import org.apache.tika.config.TikaConfig;
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.extractor.EmbeddedDocumentExtractor;
+import org.apache.tika.io.TikaInputStream;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.TikaMetadataKeys;
 import org.apache.tika.mime.MimeTypeException;
 import org.apache.tika.parser.AutoDetectParser;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.parser.microsoft.OfficeParser;
+import org.apache.tika.sax.BodyContentHandler;
 import org.xml.sax.ContentHandler;
 import org.xml.sax.SAXException;
 import org.xml.sax.helpers.DefaultHandler;
@@ -41,17 +41,19 @@ import javax.ws.rs.PUT;
 import javax.ws.rs.Path;
 import javax.ws.rs.Produces;
 import javax.ws.rs.WebApplicationException;
-import javax.ws.rs.core.*;
-import java.io.ByteArrayInputStream;
-import java.io.ByteArrayOutputStream;
-import java.io.IOException;
-import java.io.InputStream;
-import java.util.Collections;
-import java.util.zip.ZipOutputStream;
-
-@Path("/unpacker{id:(/.*)?}")
+import javax.ws.rs.core.Context;
+import javax.ws.rs.core.HttpHeaders;
+import javax.ws.rs.core.Response;
+import javax.ws.rs.core.UriInfo;
+import java.io.*;
+import java.util.HashMap;
+import java.util.Map;
+
+@Path("/")
 public class UnpackerResource {
   private static final Log logger = LogFactory.getLog(UnpackerResource.class);
+  public static final String TEXT_FILENAME = "__TEXT__";
+  private static final String META_FILENAME = "__METADATA__";
 
   private final TikaConfig tikaConfig;
 
@@ -59,12 +61,33 @@ public class UnpackerResource {
     tikaConfig = TikaConfig.getDefaultConfig();
   }
 
+  @Path("unpacker{id:(/.*)?}")
   @PUT
-  @Produces("application/zip")
-  public StreamingOutput getText(
+  @Produces({"application/zip", "application/x-tar"})
+  public Map<String, byte[]> unpack(
           InputStream is,
           @Context HttpHeaders httpHeaders,
           @Context UriInfo info
+  ) throws Exception {
+    return process(is, httpHeaders, info, false);
+  }
+
+  @Path("all{id:(/.*)?}")
+  @PUT
+  @Produces({"application/zip", "application/x-tar"})
+  public Map<String, byte[]> unpackAll(
+          InputStream is,
+          @Context HttpHeaders httpHeaders,
+          @Context UriInfo info
+  ) throws Exception {
+    return process(is, httpHeaders, info, true);
+  }
+
+  private Map<String, byte[]> process(
+          InputStream is,
+          @Context HttpHeaders httpHeaders,
+          @Context UriInfo info,
+          boolean saveAll
   ) throws Exception {
     Metadata metadata = new Metadata();
 
@@ -73,14 +96,21 @@ public class UnpackerResource {
     TikaResource.fillMetadata(parser, metadata, httpHeaders);
     TikaResource.logRequest(logger, info, metadata);
 
-    ContentHandler ch = new DefaultHandler();
+    ContentHandler ch;
+    ByteArrayOutputStream text = new ByteArrayOutputStream();
+
+    if (saveAll) {
+      ch = new BodyContentHandler(new RichTextContentHandler(new OutputStreamWriter(text, "UTF-8")));
+    } else {
+      ch = new DefaultHandler();
+    }
 
     ParseContext pc = new ParseContext();
 
-    ZipOutput zout = new ZipOutput();
+    Map<String, byte[]> files = new HashMap<String, byte[]>();
     MutableInt count = new MutableInt();
 
-    pc.set(EmbeddedDocumentExtractor.class, new MyEmbeddedDocumentExtractor(count, zout));
+    pc.set(EmbeddedDocumentExtractor.class, new MyEmbeddedDocumentExtractor(count, files));
 
     try {
       parser.parse(is, ch, metadata, pc);
@@ -89,20 +119,31 @@ public class UnpackerResource {
               "%s: Unpacker failed",
               info.getPath()
       ), ex);
+
+      throw ex;
     }
 
-    if (count.intValue() == 0) {
+    if (count.intValue() == 0 && !saveAll) {
       throw new WebApplicationException(Response.Status.NO_CONTENT);
     }
 
-    return zout;
+    if (saveAll) {
+      files.put(TEXT_FILENAME, text.toByteArray());
+
+      ByteArrayOutputStream metaStream = new ByteArrayOutputStream();
+      MetadataResource.metadataToCsv(metadata, metaStream);
+
+      files.put(META_FILENAME, metaStream.toByteArray());
+    }
+
+    return files;
   }
 
   private class MyEmbeddedDocumentExtractor implements EmbeddedDocumentExtractor {
     private final MutableInt count;
-    private final ZipOutput zout;
+    private final Map<String, byte[]> zout;
 
-    MyEmbeddedDocumentExtractor(MutableInt count, ZipOutput zout) {
+    MyEmbeddedDocumentExtractor(MutableInt count, Map<String, byte[]> zout) {
       this.count = count;
       this.zout = zout;
     }
@@ -123,7 +164,7 @@ public class UnpackerResource {
         name = Integer.toString(count.intValue());
       }
 
-      if (!name.contains(".")) {
+      if (!name.contains(".") && contentType!=null) {
         try {
           String ext = tikaConfig.getMimeRepository().forName(contentType).getExtension();
 
@@ -159,17 +200,48 @@ public class UnpackerResource {
         } else {
           name += '.' + type.getExtension();
         }
-      }      
+      }
 
       final String finalName = name;
 
-      zout.put(new PartExtractor<byte[]>() {
-        public void extract(byte[] part, ZipOutputStream output) throws IOException {
-          ZipUtils.zipStoreBuffer(output, finalName, part);
+      if (data.length > 0) {
+        zout.put(finalName, data);
+
+        count.increment();
+      } else {
+        if (inputStream instanceof TikaInputStream) {
+          TikaInputStream tin = (TikaInputStream)  inputStream;
+
+          if (tin.getOpenContainer()!=null && tin.getOpenContainer() instanceof DirectoryEntry) {
+            POIFSFileSystem fs = new POIFSFileSystem();
+            copy((DirectoryEntry) tin.getOpenContainer(), fs.getRoot());
+            ByteArrayOutputStream bos2 = new ByteArrayOutputStream();
+            fs.writeFilesystem(bos2);
+            bos2.close();
+
+            zout.put(finalName, bos2.toByteArray());
+          }
         }
-      }, Collections.singletonList(data));
+      }
+    }
 
-      count.increment();
+    protected void copy(DirectoryEntry sourceDir, DirectoryEntry destDir)
+            throws IOException {
+      for (Entry entry : sourceDir) {
+        if (entry instanceof DirectoryEntry) {
+          // Need to recurse
+          DirectoryEntry newDir = destDir.createDirectory(entry.getName());
+          copy((DirectoryEntry) entry, newDir);
+        } else {
+          // Copy entry
+          InputStream contents = new DocumentInputStream((DocumentEntry) entry);
+          try {
+            destDir.createDocument(entry.getName(), contents);
+          } finally {
+            contents.close();
+          }
+        }
+      }
     }
   }
-}
+}
\ No newline at end of file
diff --git a/tika-server/src/main/java/org/apache/tika/server/ZipOutput.java b/tika-server/src/main/java/org/apache/tika/server/ZipOutput.java
deleted file mode 100644
index baea9804d..000000000
--- a/tika-server/src/main/java/org/apache/tika/server/ZipOutput.java
+++ /dev/null
@@ -1,61 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.server;
-
-import javax.ws.rs.WebApplicationException;
-import javax.ws.rs.core.StreamingOutput;
-import java.io.IOException;
-import java.io.OutputStream;
-import java.util.Collection;
-import java.util.HashMap;
-import java.util.Map;
-import java.util.zip.ZipOutputStream;
-
-public class ZipOutput implements StreamingOutput {
-  private final Map<PartExtractor, Collection> parts = new HashMap<PartExtractor, Collection>();
-
-  public <T> void put(PartExtractor<T> extractor, Collection<T> parts) {
-    if (parts.isEmpty()) {
-      return;
-    }
-
-    this.parts.put(extractor, parts);
-  }
-
-  public void write(OutputStream outputStream) throws IOException, WebApplicationException {
-    ZipOutputStream zip = new ZipOutputStream(outputStream);
-
-    zip.setMethod(ZipOutputStream.STORED);
-
-    addParts(zip);
-
-    zip.close();
-  }
-
-  private void addParts(ZipOutputStream zip) throws IOException {
-    for (Map.Entry<PartExtractor, Collection> entry : parts.entrySet()) {
-      for (Object part : entry.getValue()) {
-        entry.getKey().extract(part, zip);
-      }
-    }
-  }
-
-  public boolean isEmpty() {
-    return parts.isEmpty();
-  }
-}
diff --git a/tika-server/src/main/java/org/apache/tika/server/ZipUtils.java b/tika-server/src/main/java/org/apache/tika/server/ZipUtils.java
deleted file mode 100644
index 926ea6973..000000000
--- a/tika-server/src/main/java/org/apache/tika/server/ZipUtils.java
+++ /dev/null
@@ -1,61 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.tika.server;
-
-import java.io.IOException;
-import java.util.zip.CRC32;
-import java.util.zip.ZipEntry;
-import java.util.zip.ZipOutputStream;
-import java.util.zip.ZipException;
-import java.util.UUID;
-
-public class ZipUtils {
-  private ZipUtils() {
-  }
-
-  public static void zipStoreBuffer(ZipOutputStream zip, String name, byte[] dataBuffer) throws IOException {
-    ZipEntry zipEntry = new ZipEntry(name!=null?name: UUID.randomUUID().toString());
-    zipEntry.setMethod(ZipOutputStream.STORED);
-
-    zipEntry.setSize(dataBuffer.length);
-    CRC32 crc32 = new CRC32();
-    crc32.update(dataBuffer);
-    zipEntry.setCrc(crc32.getValue());
-
-    try {
-      zip.putNextEntry(zipEntry);
-    } catch (ZipException ex) {
-      if (name!=null) {
-        zipStoreBuffer(zip, null, dataBuffer);
-        return;
-      }
-    }
-
-    zip.write(dataBuffer);
-
-    zip.closeEntry();
-  }
-
-  public static String cleanupFilename(String name) {
-    if (name.charAt(0)=='/') {
-      name = name.substring(1);
-    }
-
-    return name;
-  }
-}
diff --git a/tika-server/src/main/java/org/apache/tika/server/ZipWriter.java b/tika-server/src/main/java/org/apache/tika/server/ZipWriter.java
new file mode 100644
index 000000000..9bd89348f
--- /dev/null
+++ b/tika-server/src/main/java/org/apache/tika/server/ZipWriter.java
@@ -0,0 +1,85 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.server;
+
+import org.apache.commons.compress.archivers.zip.ZipArchiveEntry;
+import org.apache.commons.compress.archivers.zip.ZipArchiveOutputStream;
+
+import javax.ws.rs.Produces;
+import javax.ws.rs.WebApplicationException;
+import javax.ws.rs.core.MediaType;
+import javax.ws.rs.core.MultivaluedMap;
+import javax.ws.rs.ext.MessageBodyWriter;
+import javax.ws.rs.ext.Provider;
+import java.io.IOException;
+import java.io.OutputStream;
+import java.lang.annotation.Annotation;
+import java.lang.reflect.Type;
+import java.util.Map;
+import java.util.UUID;
+import java.util.zip.CRC32;
+import java.util.zip.ZipEntry;
+import java.util.zip.ZipException;
+import java.util.zip.ZipOutputStream;
+
+@Provider
+@Produces("application/zip")
+public class ZipWriter implements MessageBodyWriter<Map<String, byte[]>> {
+  private static void zipStoreBuffer(ZipArchiveOutputStream zip, String name, byte[] dataBuffer) throws IOException {
+    ZipEntry zipEntry = new ZipEntry(name!=null?name: UUID.randomUUID().toString());
+    zipEntry.setMethod(ZipOutputStream.STORED);
+
+    zipEntry.setSize(dataBuffer.length);
+    CRC32 crc32 = new CRC32();
+    crc32.update(dataBuffer);
+    zipEntry.setCrc(crc32.getValue());
+
+    try {
+      zip.putArchiveEntry(new ZipArchiveEntry(zipEntry));
+    } catch (ZipException ex) {
+      if (name!=null) {
+        zipStoreBuffer(zip, "x-"+name, dataBuffer);
+        return;
+      }
+    }
+
+    zip.write(dataBuffer);
+
+    zip.closeArchiveEntry();
+  }
+
+  public boolean isWriteable(Class<?> type, Type genericType, Annotation[] annotations, MediaType mediaType) {
+    return Map.class.isAssignableFrom(type);
+  }
+
+  public long getSize(Map<String, byte[]> stringMap, Class<?> type, Type genericType, Annotation[] annotations, MediaType mediaType) {
+    return -1;
+  }
+
+  public void writeTo(Map<String, byte[]> parts, Class<?> type, Type genericType, Annotation[] annotations, MediaType mediaType, MultivaluedMap<String, Object> httpHeaders, OutputStream entityStream) throws IOException, WebApplicationException {
+    ZipArchiveOutputStream zip = new ZipArchiveOutputStream(entityStream);
+
+    zip.setMethod(ZipArchiveOutputStream.STORED);
+
+    for (Map.Entry<String, byte[]> entry : parts.entrySet()) {
+      zipStoreBuffer(zip, entry.getKey(), entry.getValue());
+    }
+
+    zip.close();
+  }
+}
diff --git a/tika-server/src/test/java/org/apache/tika/server/UnpackerResourceTest.java b/tika-server/src/test/java/org/apache/tika/server/UnpackerResourceTest.java
index e67afa38b..4ba0ee5dc 100644
--- a/tika-server/src/test/java/org/apache/tika/server/UnpackerResourceTest.java
+++ b/tika-server/src/test/java/org/apache/tika/server/UnpackerResourceTest.java
@@ -17,21 +17,27 @@
 
 package org.apache.tika.server;
 
+import com.sun.jersey.api.client.ClientResponse;
 import com.sun.jersey.test.framework.JerseyTest;
 import org.apache.commons.codec.digest.DigestUtils;
+import org.apache.commons.compress.archivers.ArchiveEntry;
+import org.apache.commons.compress.archivers.ArchiveInputStream;
+import org.apache.commons.compress.archivers.tar.TarArchiveInputStream;
+import org.apache.commons.compress.archivers.zip.ZipArchiveInputStream;
 import org.apache.tika.io.IOUtils;
 import org.junit.Test;
 
-import java.io.*;
+import java.io.ByteArrayOutputStream;
+import java.io.IOException;
+import java.io.InputStream;
 import java.util.HashMap;
 import java.util.Map;
-import java.util.zip.ZipEntry;
-import java.util.zip.ZipInputStream;
 
-import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.*;
 
 public class UnpackerResourceTest extends JerseyTest {
   private static final String UNPACKER_PATH = "/unpacker";
+  private static final String ALL_PATH = "/all";
 
   private static final String TEST_DOC_WAV = "Doc1_ole.doc";
   private static final String WAV1_MD5 = "bdd0a78a54968e362445364f95d8dc96";
@@ -74,12 +80,32 @@ public class UnpackerResourceTest extends JerseyTest {
                     .type(APPLICATION_MSWORD)
                     .put(InputStream.class, ClassLoader.getSystemResourceAsStream(TEST_DOC_WAV));
 
-    ZipInputStream zip = new ZipInputStream(is);
+    ArchiveInputStream zip = new ZipArchiveInputStream(is);
 
-    Map<String, String> data = readZip(zip);
+    Map<String, String> data = readArchive(zip);
 
     assertEquals(WAV1_MD5, data.get(WAV1_NAME));
     assertEquals(WAV2_MD5, data.get(WAV2_NAME));
+
+    assertFalse(data.containsKey(UnpackerResource.TEXT_FILENAME));
+  }
+
+  @Test
+  public void testDocWAVText() throws Exception {
+    InputStream is =
+            resource()
+                    .path(ALL_PATH)
+                    .type(APPLICATION_MSWORD)
+                    .put(InputStream.class, ClassLoader.getSystemResourceAsStream(TEST_DOC_WAV));
+
+    ArchiveInputStream zip = new ZipArchiveInputStream(is);
+
+    Map<String, String> data = readArchive(zip);
+
+    assertEquals(WAV1_MD5, data.get(WAV1_NAME));
+    assertEquals(WAV2_MD5, data.get(WAV2_NAME));
+
+    assertTrue(data.containsKey(UnpackerResource.TEXT_FILENAME));
   }
 
   @Test
@@ -90,9 +116,9 @@ public class UnpackerResourceTest extends JerseyTest {
                     .type(APPLICATION_MSWORD)
                     .put(InputStream.class, ClassLoader.getSystemResourceAsStream(TEST_DOC_WAV));
 
-    ZipInputStream zip = new ZipInputStream(is);
+    ZipArchiveInputStream zip = new ZipArchiveInputStream(is);
 
-    Map<String, String> data = readZip(zip);
+    Map<String, String> data = readArchive(zip);
 
     assertEquals(JPG_MD5, data.get(JPG_NAME));
   }
@@ -105,9 +131,9 @@ public class UnpackerResourceTest extends JerseyTest {
                     .type(APPLICATION_MSWORD)
                     .put(InputStream.class, ClassLoader.getSystemResourceAsStream("2pic.doc"));
 
-    ZipInputStream zip = new ZipInputStream(is);
+    ZipArchiveInputStream zip = new ZipArchiveInputStream(is);
 
-    Map<String, String> data = readZip(zip);
+    Map<String, String> data = readArchive(zip);
 
     assertEquals(JPG2_MD5, data.get(JPG2_NAME));
   }
@@ -119,14 +145,25 @@ public class UnpackerResourceTest extends JerseyTest {
                     .path(UNPACKER_PATH)
                     .put(InputStream.class, ClassLoader.getSystemResourceAsStream(TEST_DOCX_IMAGE));
 
-    ZipInputStream zip = new ZipInputStream(is);
+    ZipArchiveInputStream zip = new ZipArchiveInputStream(is);
 
-    Map<String, String> data = readZip(zip);
+    Map<String, String> data = readArchive(zip);
 
     assertEquals(DOCX_IMAGE1_MD5, data.get(DOCX_IMAGE1_NAME));
     assertEquals(DOCX_IMAGE2_MD5, data.get(DOCX_IMAGE2_NAME));
   }
 
+  @Test
+  public void test415() throws Exception {
+    ClientResponse cr =
+            resource()
+                    .path(UNPACKER_PATH)
+                    .type("xxx/xxx")
+                    .put(ClientResponse.class, ClassLoader.getSystemResourceAsStream(TEST_DOC_WAV));
+
+    assertEquals(415, cr.getStatus());
+  }
+
   @Test
   public void testExeDOCX() throws Exception {
     String TEST_DOCX_EXE = "2exe.docx";
@@ -135,29 +172,14 @@ public class UnpackerResourceTest extends JerseyTest {
                     .path(UNPACKER_PATH)
                     .put(InputStream.class, ClassLoader.getSystemResourceAsStream(TEST_DOCX_EXE));
 
-    ZipInputStream zip = new ZipInputStream(is);
+    ZipArchiveInputStream zip = new ZipArchiveInputStream(is);
 
-    Map<String, String> data = readZip(zip);
+    Map<String, String> data = readArchive(zip);
 
     assertEquals(DOCX_EXE1_MD5, data.get(DOCX_EXE1_NAME));
     assertEquals(DOCX_EXE2_MD5, data.get(DOCX_EXE2_NAME));
   }
-/*
-  @Test
-  public void testImageXSLX() throws Exception {
-    InputStream is =
-            webResource
-                    .path(UNPACKER_PATH)
-                    .put(InputStream.class, ClassLoader.getSystemResourceAsStream("pic.xlsx"));
-
-    ZipInputStream zip = new ZipInputStream(is);
-
-    Map<String, String> data = readZip(zip);
 
-    assertEquals(XSL_IMAGE1_MD5, data.get(XSLX_IMAGE1_NAME));
-    assertEquals(XSL_IMAGE2_MD5, data.get(XSLX_IMAGE2_NAME));
-  }
-*/
   @Test
   public void testImageXSL() throws Exception {
     InputStream is =
@@ -165,19 +187,19 @@ public class UnpackerResourceTest extends JerseyTest {
                     .path(UNPACKER_PATH)
                     .put(InputStream.class, ClassLoader.getSystemResourceAsStream("pic.xls"));
 
-    ZipInputStream zip = new ZipInputStream(is);
+    ZipArchiveInputStream zip = new ZipArchiveInputStream(is);
 
-    Map<String, String> data = readZip(zip);
+    Map<String, String> data = readArchive(zip);
 
     assertEquals(XSL_IMAGE1_MD5, data.get("0.jpg"));
     assertEquals(XSL_IMAGE2_MD5, data.get("1.jpg"));
   }
 
-  private static Map<String, String> readZip(ZipInputStream zip) throws IOException {
+  private static Map<String, String> readArchive(ArchiveInputStream zip) throws IOException {
     Map<String, String> data = new HashMap<String, String>();
 
     while (true) {
-      ZipEntry entry = zip.getNextEntry();
+      ArchiveEntry entry = zip.getNextEntry();
 
       if (entry==null) {
         break;
@@ -192,4 +214,55 @@ public class UnpackerResourceTest extends JerseyTest {
 
     return data;
   }
+
+  private static String readArchiveText(ArchiveInputStream zip) throws IOException {
+    while (true) {
+      ArchiveEntry entry = zip.getNextEntry();
+
+      if (entry==null) {
+        break;
+      }
+
+      if (!entry.getName().equals(UnpackerResource.TEXT_FILENAME)) {
+        continue;
+      }
+
+      ByteArrayOutputStream bos = new ByteArrayOutputStream();
+
+      IOUtils.copy(zip, bos);
+
+      return bos.toString("UTF-8");
+    }
+
+    return null;
+  }
+
+  @Test
+  public void testTarDocPicture() throws Exception {
+    InputStream is =
+            resource()
+                    .path(UNPACKER_PATH)
+                    .type(APPLICATION_MSWORD)
+                    .accept("application/x-tar")
+                    .put(InputStream.class, ClassLoader.getSystemResourceAsStream(TEST_DOC_WAV));
+
+    ArchiveInputStream zip = new TarArchiveInputStream(is);
+
+    Map<String, String> data = readArchive(zip);
+
+    assertEquals(JPG_MD5, data.get(JPG_NAME));
+  }
+
+  @Test
+  public void testText() throws IOException {
+    InputStream is
+            = resource()
+                    .path(ALL_PATH)
+                    .header(CONTENT_TYPE, APPLICATION_XML)
+                    .put(InputStream.class, ClassLoader.getSystemResourceAsStream("test.doc"));
+    String responseMsg = readArchiveText(new ZipArchiveInputStream(is));
+
+    assertNotNull(responseMsg);
+    assertTrue(responseMsg.contains("test"));
+  }
 }

Commit:
830f702d509197abd15e91bcacd40f1287a6dc0d
Maxim Valyanskiy
maxcom@apache.org
2012-03-23 08:49:22 +0000
TikaResource: extract anonymous class
diff --git a/tika-server/src/main/java/org/apache/tika/server/RichTextContentHandler.java b/tika-server/src/main/java/org/apache/tika/server/RichTextContentHandler.java
new file mode 100644
index 000000000..2c5ff2765
--- /dev/null
+++ b/tika-server/src/main/java/org/apache/tika/server/RichTextContentHandler.java
@@ -0,0 +1,47 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.tika.server;
+
+import org.apache.tika.sax.WriteOutContentHandler;
+import org.xml.sax.Attributes;
+import org.xml.sax.SAXException;
+
+import java.io.Writer;
+
+class RichTextContentHandler extends WriteOutContentHandler {
+  public RichTextContentHandler(Writer writer) {
+    super(writer);
+  }
+
+  @Override
+  public void startElement(String uri, String localName, String qName, Attributes attributes) throws SAXException {
+    super.startElement(uri, localName, qName, attributes);
+
+    if ("img".equals(localName) && attributes.getValue("alt")!=null) {
+      String nfo = "[image: "+attributes.getValue("alt")+ ']';
+
+      characters(nfo.toCharArray(), 0, nfo.length());
+    }
+
+    if ("a".equals(localName) && attributes.getValue("name")!=null) {
+      String nfo = "[bookmark: "+attributes.getValue("name")+ ']';
+
+      characters(nfo.toCharArray(), 0, nfo.length());
+    }
+  }
+}
diff --git a/tika-server/src/main/java/org/apache/tika/server/TikaResource.java b/tika-server/src/main/java/org/apache/tika/server/TikaResource.java
index 97ef42edf..9fee8aa80 100644
--- a/tika-server/src/main/java/org/apache/tika/server/TikaResource.java
+++ b/tika-server/src/main/java/org/apache/tika/server/TikaResource.java
@@ -33,8 +33,6 @@ import org.apache.tika.parser.ParseContext;
 import org.apache.tika.parser.Parser;
 import org.apache.tika.parser.html.HtmlParser;
 import org.apache.tika.sax.BodyContentHandler;
-import org.apache.tika.sax.WriteOutContentHandler;
-import org.xml.sax.Attributes;
 import org.xml.sax.ContentHandler;
 import org.xml.sax.SAXException;
 
@@ -130,24 +128,7 @@ public class TikaResource {
       public void write(OutputStream outputStream) throws IOException, WebApplicationException {
         Writer writer = new OutputStreamWriter(outputStream, "UTF-8");
 
-        BodyContentHandler body = new BodyContentHandler(new WriteOutContentHandler(writer) {
-          @Override
-          public void startElement(String uri, String localName, String qName, Attributes attributes) throws SAXException {
-            super.startElement(uri, localName, qName, attributes);
-
-            if ("img".equals(localName) && attributes.getValue("alt")!=null) {
-              String nfo = "[image: "+attributes.getValue("alt")+ ']';
-
-              characters(nfo.toCharArray(), 0, nfo.length());
-            }
-
-            if ("a".equals(localName) && attributes.getValue("name")!=null) {
-              String nfo = "[bookmark: "+attributes.getValue("name")+ ']';
-
-              characters(nfo.toCharArray(), 0, nfo.length());
-            }
-          }
-        });
+        BodyContentHandler body = new BodyContentHandler(new RichTextContentHandler(writer));
 
         TikaInputStream tis = TikaInputStream.get(is);
 

Commit:
2c25c2a8e4aa15e033e0cdaf7e36cfc41959792c
Maxim Valyanskiy
maxcom@apache.org
2012-03-23 08:39:24 +0000
TikaResource: improve exception logging/processing
diff --git a/tika-server/src/main/java/org/apache/tika/server/TikaResource.java b/tika-server/src/main/java/org/apache/tika/server/TikaResource.java
index a85ec029c..97ef42edf 100644
--- a/tika-server/src/main/java/org/apache/tika/server/TikaResource.java
+++ b/tika-server/src/main/java/org/apache/tika/server/TikaResource.java
@@ -19,10 +19,10 @@ package org.apache.tika.server;
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
-import org.apache.poi.EncryptedDocumentException;
 import org.apache.poi.extractor.ExtractorFactory;
 import org.apache.poi.hwpf.OldWordFileFormatException;
 import org.apache.tika.detect.Detector;
+import org.apache.tika.exception.EncryptedDocumentException;
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.io.TikaInputStream;
 import org.apache.tika.metadata.Metadata;
@@ -157,7 +157,19 @@ public class TikaResource {
           parser.parse(tis, body, metadata);
         } catch (SAXException e) {
           throw new WebApplicationException(e);
+        } catch (EncryptedDocumentException e) {
+          logger.warn(String.format(
+                  "%s: Encrypted document",
+                  info.getPath()
+          ), e);
+
+          throw new WebApplicationException(e, Response.status(422).build());
         } catch (TikaException e) {
+          logger.warn(String.format(
+            "%s: Text extraction failed",
+            info.getPath()
+          ), e);
+
           if (e.getCause()!=null && e.getCause() instanceof WebApplicationException) {
             throw (WebApplicationException) e.getCause();
           }
@@ -166,19 +178,10 @@ public class TikaResource {
             throw new WebApplicationException(Response.status(422).build());
           }
 
-          if (e.getCause()!=null && e.getCause() instanceof EncryptedDocumentException) {
-            throw new WebApplicationException(Response.status(422).build());
-          }
-
           if (e.getCause()!=null && e.getCause() instanceof OldWordFileFormatException) {
             throw new WebApplicationException(Response.status(422).build());
           }
 
-          logger.warn(String.format(
-                  "%s: Text extraction failed",
-                  info.getPath()
-          ), e);
-
           throw new WebApplicationException(Response.Status.INTERNAL_SERVER_ERROR);
         } finally {
           tis.close();

Commit:
8618f64178761414c9b2919bf3abec06c3b4c24a
Maxim Valyanskiy
maxcom@apache.org
2012-03-23 08:29:59 +0000
TikaResource: force UTF-8 output
diff --git a/tika-server/src/main/java/org/apache/tika/server/TikaResource.java b/tika-server/src/main/java/org/apache/tika/server/TikaResource.java
index 234927f7b..a85ec029c 100644
--- a/tika-server/src/main/java/org/apache/tika/server/TikaResource.java
+++ b/tika-server/src/main/java/org/apache/tika/server/TikaResource.java
@@ -40,9 +40,7 @@ import org.xml.sax.SAXException;
 
 import javax.ws.rs.*;
 import javax.ws.rs.core.*;
-import java.io.IOException;
-import java.io.InputStream;
-import java.io.OutputStream;
+import java.io.*;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
@@ -130,7 +128,9 @@ public class TikaResource {
 
     return new StreamingOutput() {
       public void write(OutputStream outputStream) throws IOException, WebApplicationException {
-        BodyContentHandler body = new BodyContentHandler(new WriteOutContentHandler(outputStream) {
+        Writer writer = new OutputStreamWriter(outputStream, "UTF-8");
+
+        BodyContentHandler body = new BodyContentHandler(new WriteOutContentHandler(writer) {
           @Override
           public void startElement(String uri, String localName, String qName, Attributes attributes) throws SAXException {
             super.startElement(uri, localName, qName, attributes);

Commit:
49613a107d84c1ac7d295f2e54506342784c5adc
Maxim Valyanskiy
maxcom@apache.org
2012-03-23 08:16:18 +0000
TikaResource: remove obsolete Parser.parse() implementation
diff --git a/tika-server/src/main/java/org/apache/tika/server/TikaResource.java b/tika-server/src/main/java/org/apache/tika/server/TikaResource.java
index 1ae42f56c..234927f7b 100644
--- a/tika-server/src/main/java/org/apache/tika/server/TikaResource.java
+++ b/tika-server/src/main/java/org/apache/tika/server/TikaResource.java
@@ -78,10 +78,6 @@ public class TikaResource {
       public void parse(InputStream inputStream, ContentHandler contentHandler, Metadata metadata, ParseContext parseContext) {
         throw new WebApplicationException(Response.Status.UNSUPPORTED_MEDIA_TYPE);
       }
-
-      public void parse(InputStream inputStream, ContentHandler contentHandler, Metadata metadata) {
-        throw new WebApplicationException(Response.Status.UNSUPPORTED_MEDIA_TYPE);
-      }
     });
 
     return parser;

Commit:
e48876756c9b1042e27529e71756df079af70e12
Maxim Valyanskiy
maxcom@apache.org
2012-03-22 14:44:15 +0000
TIKA-882 - ignore incorrect part references in OOXML Extractor
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/AbstractOOXMLExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/AbstractOOXMLExtractor.java
index 8bc031374..9de5de2eb 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/AbstractOOXMLExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/AbstractOOXMLExtractor.java
@@ -115,7 +115,13 @@ public abstract class AbstractOOXMLExtractor implements OOXMLExtractor {
             for (PackagePart source : getMainDocumentParts()) {
                 for (PackageRelationship rel : source.getRelationships()) {
                     if (rel.getTargetMode() == TargetMode.INTERNAL) {
-                        PackagePart target = source.getRelatedPart(rel);
+                        PackagePart target;
+
+                        try {
+                            target = source.getRelatedPart(rel);
+                        } catch (IllegalArgumentException ex) {
+                            continue;
+                        }
 
                         String type = rel.getRelationshipType();
                         if (RELATION_OLE_OBJECT.equals(type)

Commit:
e91ba0c53057f51623ede0a4c0440f7651444501
Maxim Valyanskiy
maxcom@apache.org
2012-03-21 11:05:04 +0000
TIKA-877 - fix extraction for OLE-attachements in TikaCli
diff --git a/tika-app/pom.xml b/tika-app/pom.xml
index a9903a08e..6d8272398 100644
--- a/tika-app/pom.xml
+++ b/tika-app/pom.xml
@@ -62,6 +62,12 @@
       <artifactId>junit</artifactId>
       <scope>test</scope>
     </dependency>
+    <dependency>
+      <artifactId>commons-io</artifactId>
+      <groupId>commons-io</groupId>
+      <version>2.1</version>
+      <scope>test</scope>
+    </dependency>
   </dependencies>
 
   <build>
diff --git a/tika-app/src/main/java/org/apache/tika/cli/TikaCLI.java b/tika-app/src/main/java/org/apache/tika/cli/TikaCLI.java
index e0e193963..236c23f06 100644
--- a/tika-app/src/main/java/org/apache/tika/cli/TikaCLI.java
+++ b/tika-app/src/main/java/org/apache/tika/cli/TikaCLI.java
@@ -16,16 +16,7 @@
  */
 package org.apache.tika.cli;
 
-import java.io.File;
-import java.io.FileOutputStream;
-import java.io.IOException;
-import java.io.InputStream;
-import java.io.OutputStream;
-import java.io.OutputStreamWriter;
-import java.io.PrintStream;
-import java.io.PrintWriter;
-import java.io.UnsupportedEncodingException;
-import java.io.Writer;
+import java.io.*;
 import java.lang.reflect.Field;
 import java.net.ServerSocket;
 import java.net.Socket;
@@ -53,6 +44,10 @@ import org.apache.log4j.Level;
 import org.apache.log4j.Logger;
 import org.apache.log4j.SimpleLayout;
 import org.apache.log4j.WriterAppender;
+import org.apache.poi.poifs.filesystem.DirectoryEntry;
+import org.apache.poi.poifs.filesystem.DocumentEntry;
+import org.apache.poi.poifs.filesystem.DocumentInputStream;
+import org.apache.poi.poifs.filesystem.POIFSFileSystem;
 import org.apache.tika.Tika;
 import org.apache.tika.config.TikaConfig;
 import org.apache.tika.detect.CompositeDetector;
@@ -89,6 +84,7 @@ import com.google.gson.Gson;
  * Simple command line interface for Apache Tika.
  */
 public class TikaCLI {
+    private File extractDir = new File(".");
 
     public static void main(String[] args) throws Exception {
         BasicConfigurator.configure(
@@ -353,6 +349,8 @@ public class TikaCLI {
             type = LANGUAGE;
         } else if (arg.equals("-d") || arg.equals("--detect")) {
             type = DETECT;
+        } else if (arg.startsWith("--extract-dir=")) {
+            extractDir = new File(arg.substring("--extract-dir=".length()));
         } else if (arg.equals("-z") || arg.equals("--extract")) {
             type = NO_OUTPUT;
             context.set(EmbeddedDocumentExtractor.class, new FileEmbeddedDocumentExtractor());
@@ -427,6 +425,7 @@ public class TikaCLI {
         out.println("    -d  or --detect        Detect document type");
         out.println("    -eX or --encoding=X    Use output encoding X");
         out.println("    -z  or --extract       Extract all attachements into current directory");        
+        out.println("    --extract-dir=<dir>    Specify target directory for -z");        
         out.println("    -r  or --pretty-print  For XML and XHTML outputs, adds newlines and");
         out.println("                           whitespace, for better readability");
         out.println();
@@ -685,7 +684,7 @@ public class TikaCLI {
                 }
             }
 
-            File outputFile = new File(name);
+            File outputFile = new File(extractDir, name);
             if (outputFile.exists()) {
                 System.err.println("File '"+name+"' already exists; skipping");
                 return;
@@ -695,10 +694,41 @@ public class TikaCLI {
 
             FileOutputStream os = new FileOutputStream(outputFile);
 
-            IOUtils.copy(inputStream, os);
+            if (inputStream instanceof TikaInputStream) {
+                TikaInputStream tin = (TikaInputStream) inputStream;
+
+                if (tin.getOpenContainer() != null && tin.getOpenContainer() instanceof DirectoryEntry) {
+                    POIFSFileSystem fs = new POIFSFileSystem();
+                    copy((DirectoryEntry) tin.getOpenContainer(), fs.getRoot());
+                    fs.writeFilesystem(os);
+                } else {
+                    IOUtils.copy(inputStream, os);
+                }
+            } else {
+                IOUtils.copy(inputStream, os);
+            }
 
             os.close();
         }
+
+        protected void copy(DirectoryEntry sourceDir, DirectoryEntry destDir)
+                throws IOException {
+            for (org.apache.poi.poifs.filesystem.Entry entry : sourceDir) {
+                if (entry instanceof DirectoryEntry) {
+                    // Need to recurse
+                    DirectoryEntry newDir = destDir.createDirectory(entry.getName());
+                    copy((DirectoryEntry) entry, newDir);
+                } else {
+                    // Copy entry
+                    InputStream contents = new DocumentInputStream((DocumentEntry) entry);
+                    try {
+                        destDir.createDocument(entry.getName(), contents);
+                    } finally {
+                        contents.close();
+                    }
+                }
+            }
+        }
     }
 
     private class TikaServer extends Thread {
diff --git a/tika-app/src/test/java/org/apache/tika/cli/TikaCLITest.java b/tika-app/src/test/java/org/apache/tika/cli/TikaCLITest.java
index e6c1e6968..1510421ed 100644
--- a/tika-app/src/test/java/org/apache/tika/cli/TikaCLITest.java
+++ b/tika-app/src/test/java/org/apache/tika/cli/TikaCLITest.java
@@ -23,6 +23,7 @@ import java.net.URI;
 
 import junit.framework.Assert;
 import junit.framework.TestCase;
+import org.apache.commons.io.FileUtils;
 
 /**
  * Tests the Tika's cli
@@ -173,4 +174,28 @@ public class TikaCLITest extends TestCase{
         System.setOut(stdout);
     }
 
+    public void testExtract() throws Exception {
+        File tempFile = File.createTempFile("tika-test-", "");
+        tempFile.delete();
+        tempFile.mkdir(); // not really good method for production usage, but ok for tests
+                          // google guava library has better solution
+
+        try {
+            String[] params = {"--extract-dir="+tempFile.getAbsolutePath(),"-z", resorcePrefix + "/coffee.xls"};
+            
+            TikaCLI.main(params);
+            
+            File expected1 = new File(tempFile, "MBD002B040A.wps");
+            File expected2 = new File(tempFile, "file5");
+            
+            assertTrue(expected1.exists());
+            assertTrue(expected2.exists());
+            
+            assertTrue(expected1.length()>0);
+            assertTrue(expected2.length()>0);
+        } finally {
+            FileUtils.deleteDirectory(tempFile);
+        }
+
+    }
 }
diff --git a/tika-app/src/test/resources/test-data/coffee.xls b/tika-app/src/test/resources/test-data/coffee.xls
new file mode 100644
index 000000000..1a4af467d
Binary files /dev/null and b/tika-app/src/test/resources/test-data/coffee.xls differ

Commit:
b11403daaddbbfd5385180a611b84ed5d131772e
Michael McCandless
mikemccand@apache.org
2012-03-13 13:59:50 +0000
TIKA-875: fix file handle leak in ImageParser
diff --git a/CHANGES.txt b/CHANGES.txt
index b4314c8ec..04e8ead8f 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -1,15 +1,14 @@
-Apache Tika Change Log
-======================
-
- * Tika: parseToString now lets you specify the max string length
-   per-call, in addition to per-Tika-instance. (TIKA-870)
-
 Release 1.2 - Current Development
 ---------------------------------
 
+  * Tika: parseToString now lets you specify the max string length
+    per-call, in addition to per-Tika-instance. (TIKA-870)
+
   * Tika now has the ability to detect FITS (Flexible Image Transport System) 
     files (TIKA-874).
 
+  * Images: Fixed file handle leak in ImageParser. (TIKA-875)
+
 Release 1.1 - 3/7/2012
 ---------------------------------
 
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/image/ImageParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/image/ImageParser.java
index d33c6293e..bba76dd27 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/image/ImageParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/image/ImageParser.java
@@ -28,6 +28,7 @@ import javax.imageio.IIOException;
 import javax.imageio.ImageIO;
 import javax.imageio.ImageReader;
 import javax.imageio.metadata.IIOMetadata;
+import javax.imageio.stream.ImageInputStream;
 
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.io.CloseShieldInputStream;
@@ -81,17 +82,24 @@ public class ImageParser extends AbstractParser {
                     ImageIO.getImageReadersByMIMEType(type);
                 if (iterator.hasNext()) {
                     ImageReader reader = iterator.next();
-                    reader.setInput(ImageIO.createImageInputStream(
-                            new CloseShieldInputStream(stream)));
-                    
-                    metadata.set(Metadata.IMAGE_WIDTH, Integer.toString(reader.getWidth(0)));
-                    metadata.set(Metadata.IMAGE_LENGTH, Integer.toString(reader.getHeight(0)));
-                    metadata.set("height", Integer.toString(reader.getHeight(0)));
-                    metadata.set("width", Integer.toString(reader.getWidth(0)));
-
-                    loadMetadata(reader.getImageMetadata(0), metadata);
-
-                    reader.dispose();
+                    try {
+                        ImageInputStream imageStream = ImageIO.createImageInputStream(
+                                new CloseShieldInputStream(stream));
+                        try {
+                            reader.setInput(imageStream);
+                            
+                            metadata.set(Metadata.IMAGE_WIDTH, Integer.toString(reader.getWidth(0)));
+                            metadata.set(Metadata.IMAGE_LENGTH, Integer.toString(reader.getHeight(0)));
+                            metadata.set("height", Integer.toString(reader.getHeight(0)));
+                            metadata.set("width", Integer.toString(reader.getWidth(0)));
+
+                            loadMetadata(reader.getImageMetadata(0), metadata);
+                        } finally {
+                            imageStream.close();
+                        }
+                    } finally {
+                        reader.dispose();
+                    }
                 }
                 
                 // Translate certain Metadata tags from the ImageIO

Commit:
f1f4b036714ad08a8e5d52670a5ab334ea86f9be
Chris Mattmann
mattmann@apache.org
2012-03-12 15:07:53 +0000
- patch for TIKA-874 Identify FITS (Flexible Image Transport System) files contributed by Peter May
diff --git a/CHANGES.txt b/CHANGES.txt
index c165149c4..b4314c8ec 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -4,6 +4,12 @@ Apache Tika Change Log
  * Tika: parseToString now lets you specify the max string length
    per-call, in addition to per-Tika-instance. (TIKA-870)
 
+Release 1.2 - Current Development
+---------------------------------
+
+  * Tika now has the ability to detect FITS (Flexible Image Transport System) 
+    files (TIKA-874).
+
 Release 1.1 - 3/7/2012
 ---------------------------------
 
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 31dfcc8d4..7b007aa0e 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -138,7 +138,18 @@
   <mime-type type="application/example"/>
   <mime-type type="application/fastinfoset"/>
   <mime-type type="application/fastsoap"/>
-  <mime-type type="application/fits"/>
+  
+  <mime-type type="application/fits">
+    <acronym>FITS</acronym>
+    <_comment>Flexible Image Transport System</_comment>
+    <magic priority="50">
+      <match value="SIMPLE  =                    T" type="string" offset="0"/>
+    </magic>
+    <glob pattern="*.fits"/>
+    <glob pattern="*.fit"/>
+    <glob pattern="*.fts"/>
+  </mime-type>
+  
   <mime-type type="application/font-tdpfr">
     <glob pattern="*.pfr"/>
   </mime-type>
diff --git a/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java b/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
index 6cbd17109..81c9eb455 100644
--- a/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
+++ b/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
@@ -287,6 +287,13 @@ public class TestMimeTypes extends TestCase {
        assertTypeByData("application/x-gzip", "test-documents.tgz"); // See GZIP, not tar contents of it
        assertTypeByData("application/x-cpio", "test-documents.cpio");
     }
+    
+    public void testFitsDetection() throws Exception {
+        // FITS image created using imagemagick convert of testJPEG.jpg
+        assertType("application/fits", "testFITS.fits");
+        assertTypeByData("application/fits", "testFITS.fits");
+        assertTypeByName("application/fits", "testFITS.fits");
+    }
 
     public void testJpegDetection() throws Exception {
         assertType("image/jpeg", "testJPEG.jpg");
diff --git a/tika-parsers/src/test/resources/test-documents/testFITS.fits b/tika-parsers/src/test/resources/test-documents/testFITS.fits
new file mode 100644
index 000000000..b2f444357
--- /dev/null
+++ b/tika-parsers/src/test/resources/test-documents/testFITS.fits
@@ -0,0 +1,5 @@
+SIMPLE  =                    T                                                  BITPIX  =                    8                                                  NAXIS   =                    3                                                  NAXIS1  =                  100                                                  NAXIS2  =                   75                                                  NAXIS3  =                    3                                                  BSCALE  =         1.000000E+000                                                 BZERO   =         0.000000E+000                                                 DATAMAX =         2.550000E+002                                                 DATAMIN =         0.000000E+000                                                 HISTORY ImageMagick 6.7.3-7 2011-11-17 Q16 http://www.imagemagick.org           END                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ZMODGY`^KKBHR]Pcu}P==CFIMD;?URGA>DK.109@54;920:?-3+$#'#%*74AT:!"+/*.&-U<7/B=ZJEUFD40+;N]iZD9;=3#)-#]X<LVP^Z_\QRU^_NJVNAAAA@F8?CCEQKD??16::561/,1:4-$25%!,&!'!+-++!F/<7;:G<=BCKGTE=<77+ER\WNE?20.!"!!QSMCJSJX@`QO^GNdOC>/;EE9;;B?A:AE5FJI@B2528>50943*-3("#-%!$'.-')E-/28<<?:B6RuJ:<52=3d_XO'=./!D[NPSNAPYCUBHP47@QHK^B@?:17@@A>::6=9BKB3523=2666,&0:- #&-'%+)%"1'-0*042>=7<<KTf:AGG/FffW@4#%53#%*$1]gSRTZXU^NfOTZUUDFW:-SC<79>9CA<D1<NA&1*7175*48,&48:$1#"#"/&%&+-'---'26-5C7<>JMB\SJ;0GS^UM?%&;S755>WS:PJaT^PUW]MCDJ@SHLXjE==/80;2:418=BI43)(12H:51,:7;6>7-%"*)0"#,,- *$,14-08:3E<AI?N@()Y\D-V^kM84<656+)(1`d`TRZQ_JFC@DC;IEV\IE;GDAHC9;9.69266`G>@7<;/26C<?+)$/(&72-/'+*0+24*-09:;;@<6C46$7:B3CtJIfX=)(&(#*_ZX]qQMDP82-7/0*.D87=*(7C:8;6MG5=3&3224=;7:?D:5=63.&&&-68908,'+8;/-;86CIA>=HA4C$1RGF<ke`_QJ 049;BRSKgwlqllZ59VL4/6,94"$?,13?377-&,),:@L19C9DG=>604:095>0-2/46;91C80CBCDJ@B>F6?F5J]nPdcfXC(&&0-/5@EHaLUuwumhe7%@B/8Tp;76/8<A3349:+.3?<IL197<58>3;/8;55434295/39@E:CC@7C@8;<==4-VU_EmnCaZe5%((-1/);>?Vk[V{s_gmqjJ'BD6X`NK?leQ<>G@2,1B37=6E1@[DM`995137I,*620469027?7<=HI:PIA?.;99*5WJKaf]lMCVb+$.'0,<4GC>FSVQVIUeqjoO8ORX^YVaIVQO@E:=>78AB;8X30.+AZ]B41,376.3(0368/.;<1<=?><8;=KA1=CART]FTnkchaedN.87923?@HO8PcGVIJWD(&&KGOdc`SC7CA39B=AA6810:IeI+:<501:6)%'*=0.(1))-%+(#-70;82<=D698J00NtNK:Pg[VlThT?24(996>FK;FoeLJ@O*"A^g[ONI4F=A=62=<77*>PCHL98-5*&&,0  75'(/+1.*,/+$9>;=6=ORPJ&B\N;46M[GQzqsfM@<<-@;CJFB=OU``QKTl[VBGFW2YTQ982epK:2.4-5BO{t1I/-1' 3#'&(0'"*%%02;*'$*,81u{vPV=DZSV\DBE?[o{mTK:3X^GUSQCEBOB\KLPB;ESY^aSC`Z:TQVIKCL<42#,8>on#-*84!(0'#)3'&/)3)'.))!@_*0A<MRWPCEV;SaTE@8>IQSaHHKTU@EPRKKUDFB?DHU@1R^>LFJPIE-09&"'4G}i4%-')//&& !'"%/%!*10),,&(nk-223<LbY,*@(@A<6CRSNQ?K[\e_jVQQU[]MULIZOSRLLAFGK.IN6/BA/2),04G~{S@:2,#(11)'$.".%%">aS)-0%Emf==90:57a7=9>>FEFWZ][`N=-fcdbW^_`WTOPW]ZQPPMK=FgpmcYAFH*4;9:451DqK''),(  !+ "!$*$$&!'Qx|wJA;;TsI8>+7>@:5@C6+IJIROYj[^GJTYT]`bPaahT^XTTTZOIHM\\qxPCI64<-20)/8-01(4)(&*&&(4JYVS*%"*^tu=<6;\t`:H<=AI?CA>NLLNauvoRUO?-v0C_gimmb^IPMT]]]LOOHNLDVV;@?F>1J'49:80& 9!&2.(("&E^gsmgJ+(:elz?.)(Rjv\FA6GO@@3>7(?Qd|`VQLe*)ilkmg_aLWGDG@JGIcbPGLJRF8E;656F8205;7),!!"*!fzye[87E3abkg %Uj~Q6<WaE50=QIS`_Uhg]VWS)8SW5ZqkofcfQE_HGF>?GEYbiW{VMLE7HLKD7JCO=35@4`b*,,4*"&X]drO*Ebq{l<42GE:c_b[XWXVFAWSF`4/-}`_hr`aecDHFHBMIKJBFITZV]QUMOSME@D868=-
+!<;EPMND3"*&!FL='4>Ufr}78GNHcZXWXXHOWGRVUBLQ>B\`[[ksukggTOMHCFNCGA?HB96;MPMRVROEAH>0.2414MWZLY`]P<8-6D0$:R`oyHO_Y_TU`RZVMUHBSTJGLV]WlYQlrieklqUQOJSUMGNLODRTEORTN<SJO[QHPFFC
+CYWVa^\]fX^\ROTRNM[Wkp{`a_^SQ:EQMH^T:4DEFNKV`fnq_Wljw{LTOR]WTKSZSUTNOJIMPUNOReKNTUHG<$RfjbdgfZZU\YPWY[^hcltzzy}dWWHSJF[\OUDHHPEMO_[^kkmo@:aTdexT[\PXj`TOMCJUPPTQOPSRQFCALKMKI9CfnbgbecXG/:7*>[dkov~xmo}vC:IJGNGG7PMHOKNZdkuvuma\Pfmc[iLSTSUNbTOMUHJLMPHPGGL@;BENIHTN4"Oik\fbPU28fquxxrmuPMICLKWM?AQU`Zalvkrnc^jceRPe<fYdXSRSXYV[NQKOLKJJFKCIVOPNHYLN93WlfaYA*4$T]EFixt{}LOW]e\KZVcltqv|mkabllnbjfip[fROUMOSUZWQOQVQMMOMRNWGRKSPCKB?3!2YneV; (( Tfs~~Z_fdfedb`johhcrqqohlnrok]YSVRPNUSSXVVQPSNTHLLOSMPQkFKN7.^mP5/6Pz~vrkbqlfeiewmebXS_f`fmlxmebbYbhcZ^YOUWZJPPKTXNPMH%8+%9CEH+&$6\P+$6f}dZOBLEBIS|\Ydficngdptsmfioi]abcddYbNYTW[fhd`UNM/Ye?RL5>>>20)4N#@pfbd\]UU^\[hhvp{srgqjoxlqnunwhpz_}Oa[}mfnvWTCSlhiZ]gif5CW4=0 9D3uzzv_b_fd_hnp{m`kniruryloj\nhjohid98hv\MIpllKbioNWBYLTE^cPI9pFD=7#E6(i{xz~sqltjzv|lrssn^fqoi]YiigsnSQ>+.)F>SmslIRE\ZAPBa@G[TBG[KH-B_T%)[DD{|{wyuy{uufkp~~rofvvxrsst{zprx:@SKRVKYoSI`CH4H]`rZ>OQVbe[idJ)$6bF'5b=E{tfdaX<AX~{yxdeghrqv|lcoqd~xu}|vtOMSJRMN_aYuZXYe}viUGN[R[QZlumF&'GE-*Y=TfjjBNRSBopYXSnhqts~s_bdoljowvhqf[IJPOMcWP``^W`JGY6iBG)/V`]t9'5Sn:#axqgiacTStvraokwffmlupsoo[tynoecTHCV[RKQOY\U[D[RNBFI&'#!)'. (-<E!6If.9<I;.lbduds}eTNmMzo{igV~_Qd`[]ULc[PU[F@Y\TC82&)3+'"+2.8'%"N8!)Hn"?]sbx~bnog|vpY}LHPzx[SNTLP\VPNLIGVE4+0))"&7L<;3&!\(!#;>**<ZTwnl_hTjdudUrJKTYS_`udU`UZTUQJGMGI<E;<=6("9KE>CMB/$!#z' !61)$48Kxwsa[cf[on`f`MXZO[pXniwpck_UYCGSLMZORNHC=LOJ.!(8B8HMDFOTH1++*)&+)&##/:?QHC]RJGSI# $EZ>&5xuqch^Ub]U]Z^\cYc\Thgo]llsnVQ[EOb`UWQNRXIQMA&$=<_OR[jKGPMidfv{qvie{sfNo$3=c/.:gnoztdxkdcffkfimofY]ensgs`_PSSUQHQS`Z\NI-%/GiYLX}n]upz_jQ|2!&('*+"Bldfwrdcgkrrqszqx{l{utwmigjkdOOKBIDDPSMOG4" -YwZaVioqvyjq|{|ve{L5+" **/)$3`rhrxpvn~tys}nvq{vkaLJOLMMJPY]P9#$*og}e`pevrrxy{nszkL3)=?HNJ7,Fhds~z{~}q}}zbXXPQHLOOU^?#*oqet{adm}uvmp}ulUx|pC<kjojtwJ]z}n[NhZTJNGTZK$'2hnzfo}lyy|~nYloxsv|taU\Y_VYMO_*!  /lryuuouuv}YSnQVTGMSD  *Noqzqvwtmzx{wt\UoUV]XPb="'%=[wwyz|vxy}}zw_FoU]VWU`;%(,SRytvz}Y<nYZPAZbB'(2RIzow|U>hWST^hnc=6A]^sr}xtb[i\y|}f[kd^uqm\fjjx{m|y]~uxtrn{}}WNRGHZ`bUYQRZdYdyWJHIKTSKDI^\QLHIR768HK>=CA96:>./+*)*&-+<8BT?($-$$-)-]C>3HD]MK[NM7*"4EOWM;6;=2"&XV@OZT`^gh][[hgQOYTMKGILOAHMMOZUNDH=;DI?B;948@7.'17-(/)(("&-/33# ;+;><FODCKIKHVJEE:1!?JOJC<:0.-LQPHQXM\Hl\XcPUgVGD:GKNHEEKLNGJNAKTUHLA??EI>8B75--50$%&4&&++15/".<,0;<JGGBK=RsL?C=56,`ZND5)+=QQRQPI[`IZJKS<AL[KL]CHMH>DLLOLIICE@HPJ?A@?J??<9/)5?0")-5,+31,*9/,1-6=;JI=FDPTa9AMK0GecP9, /- 'P[VTUZ[X_NnY]a]]LJ\<.TJHDELFPNHQ>HWJ2<5D@F?3=A3-<@@+6& ',*5,-.3506.0,8>6>L:CHSPC\UI9.EQ\TJ5 6L1-+4NI4PJaVbTVReWMNTFXMQ[mIHI;@=H=EA>CGLSBA66>=SC=:5C@D=F=3+'216(+445(2*29<69AC8MILPERC%#SYA+S[aD2-5-++%#",_b^TT\S_OLLKMI@OLZ_OPGSOLSOBDA6>B>DClTKKBED8;?KDF10*4.-?837/3283;=59<CDE?JHDO<<&79?0?nB?ZP6" "$^[X\pVVPXA<6?31-4KAAF54ENHED?TL=C=2>=:;BFCGINB=D=95,,/5??A9B505BG;9GEANTJIJUM;E"/OA@6e]UVKE+.018IUOj~vylBAVH2;A9F;'&.L7:<G;>=0,525@DN=FNCMPFC?:=D:B?H74<9>@EC>PD=PONOXMPJQ=?C0BUfL_^aRA'&&1./5@DFgTZt|I2IH7Ph}C95#;CEJ<;;C@25:FCOQ9A>C=BG<D9AE?>>=:8B>8<CJOGOOMDOIFGGGI?2UQY=fj?]U_3$))/311CFC^qaXvrgu~[9Y[Pvz`R?f_RKIOI;5;I;?C<K9H`FM`=A>=?@R53?;8=<B9<AIAGGRUF\ULJ>HAC5BbQM`bXgH;L\'#-(2.>4IGBFTYX]PXm~dSmll|v`_L\XYIRFGF?@EB=AX7>41@X\A7:7@=>7<19>A@88GH>HGKF?@GKXO=BCKkrrRUplae[cbF+;;<55DFNT=PdIXPRcR4-4nqozzfOAJLADHHNL?A;:DKcTDQUH65=9,+*.C9:4:115-44.8@8@A9EFI888E9:N{d_;N_MIdRfP?5;0B?<FPUEPqgQVUh5+&QsvneQ=QBF+E>>JHAC7JaLL\VRLN4-,25&"8;03:373/486)',?@?EBHSSQL']{X<A?BT?IvsucBAAA3I@IMOKFU[cbTP`srSRThDruhPJ9cw[E>;@8AO]{2F301)!#9+2..7/,4-+35A0/%,34=7Y]EOqnf_C?<7Vn|jM?.8`eL\[WELIUF^PRXJGSdoy|n^|wRtqsffUWHC?/6CI{~.007.! !&'$06+*/9,,305,-424+Jm46G;MV^UABU9OZG73-7S[\lVWV^cNP[SPU^PPJJH_sWFp|MiejpkU/>E3/1>Rt84A/-+;1"$)""*')"1('255,/202v{9<79?Kc\2/G.C>30BWVNVCMcitjta\\_^dW]VSeYX][[OUXbBfg@6PO;=7:;@SaLBBB2-.@<- ($/"0'' 'FiW,.2+NwqIHB8CBBh9@AIHNKOdlphfO9'dhke[hig^[YY^bb]^Z[YEKsk^Ve_9AFEGBC@R|X)3035""*1  "#*,&&'"(V}K?:?[{W@F.9AE?;FF:3TRXcagtcfJJOY_lnl^oosYh`\]^eZWTXhg~bRXGEM;=81;E;<<1>*+,'/'42%8Pb]V+&$1i{@<:CfnDOIJGJCGIHZ_eShxrreiYE,r/ImqnuuooQXU[dgfTZ]TZYRabMPLPH<Y6<FHG<0'@#(96.*'%&(FbnyynN-+>jtH5/,UphKB>MRKL>G?3PdqshZK`+0vwrsmfjT]QOPITSUmhUMTS[RERJDBDTA>=AE@,0!%(!'."mpdA=H7gjtn&#)Yp[:;YcG>8EZQ`sy_pmea]N".LS<g}qvqnn]OhSRPHIUQ^dmZ}ZPRQEWYVLCULZG< 9C7el:43;.(,^dhvS.IgyxA78NMJmila`di[OIYTG^*%#w|eiu}jlspMTQQKVSTSKPRZ`\aX\SV[URPPDABF3	!="=HUSWI7%.,'LT@*7B[n|A<OYQsfca`bS\XMYYWFLJ3<Xaafu}zspq]XWPMRXKOKIRKDBGTXVZ^]ZPNRG::8!	97:S\_R^dcUC=19G2&<VhzSVfel^]k]dcZaKK]]RTW[\Xl[Srytostz][ZT\]TOZVZOZ[NXUXWH_SS][SXQTP#	I_]\gecbkbfcYUWTON`]ryfbdfZ_FR`WOcZ@?QRO\[`hnwt`WosRYV[e^\PZb\\ZVWRUWXZSRTeRW]aWXC)[lpkmonacZb`X_abgnkwd[^QWRRiiZ`PLT]MS[mejxuqm@=bTedu[baT\odYXUNV`VXZ^]]\ZYKGOWUZ[W?!Imrhnkli\H4?9)Aamwy|~tu|IDSVUZURD[XX\TZkuw|}zvnj]puldnQVXWXTi\XW_QRSTUSXPPSFAIQWTSa[<(XprblhVY5 >oy|~zu{YVSR[Y_VHJ[^lflvtxrhfuor`[g;bYdYXXZ`]_eVYTWUVTSNQIOZTXXRbY[>:bumg_F.6*^aJKp}VXaemdSb_fn|||}llfhvw{pxsvtWa|VRZSTWZ^^YWU^[VWWUYR[MWPZWHRKF5!8dwl\A!,($[o{beoklkjfemqi~sl~|}uw|zspd^Z^[YV\YZ]ZZZZ[W]QSQSXPUSmJOP87hvU9
+
+3<Xyxqkvunmpkwnkja]holswv{pmm\fomcf`SXX\MUUOWaVYTL&6*&8DGI+&(>fW- (;ohcXKUPLWW}_cqprnwrq|xmrwp_cbccdX`LXSX\gf`_VMN.S]5QK4>?=36,<V) Gxmjjab__ifdorzzzp{txu|u|qyejtXuL\X{nipuVQAQi`aNPdda0=T6E3%BK 8}zcebikhqqysbotqv}|twrcvllrdf^3/]kQMInjhH`ibDR?SAF6Z_F:)eFMJA'N<.r~wpuyu}y}}vuvtpUe{|sc^qgftqON8&(#=3NglkMWDVW>M<V4=TK:;M<=+Hk]*/dII{{w|{wrlnt|viuz|xy}ux~4=PHPUFRgMGZ:A5OaboO0ENUVYNZV@%&>iL,<mBKyiecZ?>\~~{dqoovsvrjw}ozxzyIGOJSMK\\QjTWZasviR;ATR]DO`ib<#,LJ22dCYhmlCPZKBqreb_sjsvxt^jlvsmpzxbk`YIKPNM[SO^ZSOZ?BT+^=F&%MVUl3$-8Zw@$dthmfgXSvu_nl|lnrouospp\qu{fe_^SGAV[QQQIQVRV?HKK8=F%$"+"-0@M';Ri.=BJC/ed_xs~lNFgHvnwebNz\M`]YZRLg^OQU?3V\M=71#.&$#/21>+$'U: %Ku$:VmSxvtk_v|rjRwFCNus|UPRWKP[TNJDMKQ>5,'&$&8N=?6#  a(:K+&/c^}aS^Pb]mZ|OpC?INIX[{j_SZRZNSTJPQFK>E8650!$7D;4:E=0$ '! , 85,&49OyvWOW^VfbV^ZGPPCPeOh_qkV`^X[GJTNO\SQXNE:BC@&#36,9<49EOE,$&('"&$! +69KA?[NACTO"L\;%6|tjqnVIWUOUPTU^R\RI]\fWacheVYfLNffW_XQX\GIC7#"!!1/R@AKX;7BB`Z\}{qsio]cri^Mm*=\'*:imny_m`\[_\d_bfi]NR\em{u^shoUMX^TX`_bYZKC*#"$,@wZIANrbRhsakzw{|uTgE~5#$(" Bhbe|s]W\akkvjltkorapkkq{d__dqsVKTNNVU\YSVK4#)KgLQO`eflm^ekljfrzVrI5)*0- "2Wiborejbtkoxit{}vvd}mgrpmpXO[YTYUS[aV?"",gysr[q~UQ}cZlgdgik`gx}|n|^A,&9;EF@0%>a_hsxwnpzxytmxx}tbbY\SUXPS]A %/jguuZzbsoVXbsji^e~ro~l|_Jprc63edgs\qekAVtyrv{tqRq_\WVSYcR"/ibnvX`z|coyrrs|}}t{ew~Udajbkwrn_nYgaaPbe2 !+oqrjgywcyqyljg{yz~z{y}yzvzq{b[`^ZMYbJ#*Jsotghiir~bunmqq~z|}ly~s{edbdYg^h<!#=Zzutr}uv|wovku|ipt}xrvmri_^[^cd]:"#*WV|qm~sn~y{~}vuxiPR\VQYbC%&3XPzlnw~{teIwWSb^fvh:7@_drpz}|pl{kbtXyg]iebxx|pXntqu~x~[}|uzutv|onm{{~{~w}{~x{||N@A>BT^S:@20B\H\||G.&-5CG;10MC8,/5B&"!+-)(+62,8:(0! %!"&87:V9!!,,$++N1,2>4TB?WA:,,'<Xhq_N=;=.#)-"UJ)>IF]PPPG<M`\HHNF70+14>,5254E=5.3'%+,&*#%020&/* !&" #  ,((A(6.427-C6;K@UD:415)K_i^SM@11+" ! IB1(0ADN3TL;\KN`F88)1/3'-,802)7=)5<?11$'%++-+1,*$+(#,! #*&"(?'(&.0)/78+TxI;;..>4nqiT(D/," DZ@<B: =P-S3@H%(4PRPeH;41$&6453,,/6.>L;')&+.!,20&".;)%&%!(&$, '+&,,&21/.7JVg5AKL2Lsv`A9$'=9#!0aiC>EPPQZFp@HQFE7IV92YB4(!+,424?*:D5,$*''*.!')2/ )&&#&'%./#)7/1-@G=daO:1Sgqd]>#$=T3**2SQ6DBUAG9HXX<23;<TIJ`vH81#1#./7%"5<DH)'$$,1.0' 0-/-11' #&,')*#&,/%&.0$6+;H;SH,/_dRAhflI44<0,/11.2[caTSWNa821-8ICA<]fKB1;A<B9/32'/1(*/`B--$03%&,<54%  -"%2.'*"&%+$(,$%&+,-./0-;/0%CAH;MzMHn[> "))*,$(LIVnPC<K,##446&&D0(5' ,@'+3,MP09%0/+)+5+-05*&2++#&,-,$* )/##/)#065+0;7+8#:XKLDqjckWL$""18+/9NH8cewtlR.6^_?19(,) #8&%'806;7 "!"2CM)*.(23+/*!*,"-$/'"$!&(,($6,#41017//4@-?J7OdqZuuu`F%&&,)-+6?I[=Dyy}smb1 HX98_E8; -227+.3:6 #*63CK",,1(*2)/ .-')#%.*/)#'+14-773*74//)/5/8g_cHvyMlli4$#$&&"./4SqUJ}z\hwueI#<G3^mdXArmL*9B6( 0S.45.A*=d8Mh<2+''+A ".()*./$$(0&),9?0FA<<$.4:-;\WYnp_mOFWf()"% 1(3,+:O`PM>OVheq]@Qa`tdalU\HP468>9*)HB0>`:/2/NeZ?0'&&1/&) (-05' /0$4<514)/>Q>)<EJgruRi}nnghoU"("+$(&,4='PhFS@EYS&#ggbw{ybO9BD2>F7=<.,"2<WhX/?OD6642%#5(& )"&*! (/+:<14)25>8B4;Xb]@[l\So_q_A,+!/1./7:*5~\=JFb/&%NtohUD:SHI:A094)-&Jk]OYDE=H,& (.0-")$-,)%'& 5=064D^XSK)LkZA8:R[JVnJ9-*'.)-82.+;Q\]ILV}wsKJEX,Tnb@:2qZ44*2*+>`7W>)1(/ $!"'"!+"!(*7$"!"'93VcPQgiurIFQBj|{TI0!7;5;450-*9+Q<HK=1BRlru]MfXBslndaIOD0+!-5E '058"!*"+7& $ 0#&!#"Lv+4GIYbqhLKcD`bN6*1>K@?J3.4;B-.9A:=I,52*9Wg;3nr8d__klU,'7(3T7%$.97+  !!*#.!'4.!$$%45$07HYuo>2@$:9*".AMNO5?:=KH@?::=KE2E4.=>B?20,BPR)ba5.SR#/ !*,O~X7B?-*,=60"")$+$"+Qt`10/'Wu?8--B;DxPQC90714HR]WXG8+WQ[\BEFF?:7:<K=7=57607]xq^XG]U$05/-(,Cx'$' #!/1*!&+%!,i_M@@eJ3734:A81<;,&LG9?;NlTWCJSYAKJG;LLQEFHD>CG:4.8PVu~J;E73:*/-"#1!&.@Y"  )+5;+D`kpi- 7SF;Frq,=/0;LDH:@Zfa<FgyGFP714?ILX`fSC9C=KTLQEJ9,6..QV36:E=+B/*.*&%9\:"!%1)$''7XnY,$=}M-%-dfDD3IKC>.24"=PUW>EPg&)\YQQKGO=S91;4;/=bdO?<6>.'6-+.+1.&,+,+!KM4$&!#/$!wu<1A:wuv$(ed;Ae|B--8?FO]\^s_VQQT)7Tb,KWUTGP_76W328-02;appaY?6-+DGE=/DGI/'/* #<L,"+{v0'++,t~V/Rz;,*G5@vkTSIFIT>4LOIa+#!y_PISOJRT8.1<8C:?@:8?V\ZmHJ97CFA6:03*5/(-Q%"J[h_^E8  #X_E/<Ki6.DI@hf_IK?1KR?GNL8@D70WYUDZ[c^UOB9<A4.@4B3.:83./D@9BF?80274$40  MGFapsbq}{kK@4>P12Qo}CD^MPCP]?LGI_DJTLC:5EGFjPPdgLL\\[6989GNL:6>:-MT=EDIF2IBEOB5A114)-%!#cwwt}xvv~l}vkcfmdjvsrd^[RF:HC??\L69=4:B7EQY\kdadX[ljq6CFHZWMJRWIJN?2-??AD?GSoJ:>=..<*&"=||~slm|sktx~xbLV@F:<PXIR:;<C577ICR^\px>2gLW`~IPMCNhe_CJ>>RRMLD<?GMNEH6F:,,=;(& "5m~|wdGSP2;T{;,HJ<D4D*KJ4>76AKS[[feTPLoiQrJMJIMFYGC<F@EKMQBI?=C:79=F61E?-*(%#!>yxprH)"/& /VXC;+06PA55BCH@JSWUlcd[de`GSZ7pal^TLHKLNMAB7@B8<B?C=EL>K?9M=?8%%%#*-V}ycIK" @y~hiK9?P^YFJD[adZ`ohni^[YaOUW\QThHGSSXZSMVB?DF97<HFQU\CC9JEBK6>B"%($#9XvW.3%,E@1=wMKT[ji`UOblkeYTdn\YgYedYCGJOJDAJMJGII;7CDH@KJED;?RyMR_M)&&#5XuT+" "'#"+N^}~jeZzdcV^gpg_PEU^VW\[cZREKSUPKFOPEOZYDONALPGHB>!7&=IBC5@C3& $0btD,$ 5E[kNC:D236HuNHUWUPfRCTZUV[SRQQXZ[^b^kQ`alq{{yqh[S4_j>YS961BOXK,&'2`}C# %6deS^MN:FKAEPO^aphbUYQ[fX\V[^lpv~`S`cr\bN_~wpXZmw4GgOi\9(-0cu4 1U}b\QTJI\V\ss_XZfwhYa\b]Q_]kgsoj52koUUU|xvSmutOYJ]ISMhmQ?*m^tte7+Bu^,$Fh^dbWhrz]`YbkPPVQ[YH\hdnf^UD-,'>AUs|sLSIdhIVJd>Hf\IEM7A@lH0Io+ "#gobc`euto`}aiecibejvnnpBD[OQSJdvWJ\=H:Umnz]=NWcdgX]UA4?cpBXj) 'o|yrfDEhpgruwnpXjg_}meyvicUU]JNMRgc^x^]_pq[GK\ZiKWlujD,'JrpPVe#   3Xeq`ZQ?;_ipqdxocUWdadjgskwfyn^GFRTOfa]lfa\hEI[3fDN1&Raby?$'3AOaZ%     !"9qmalnml^hbV[^kkkjkTxsnkdNEBT]V_]S^b[Z<NRR@BM-*#!+)6('*,7JYmq=&!    """ #0[{FVZhZN__Yo`}tPSkNvvvcySLaX^c]XreTRYF<afTA=7$-5-+%&))*8JTT`H.(&$###"!$$!#!4=Q*)1<n;c^wVuyj}xZRJSqpxaY]^PRaa\YOYWXE:1*-+#&%&'&/>TeYbY@0,&$$$##"    $""$&/B'&*)@SG5Ihyy}rSf^wdxeY~JKOVQ`W{hc^h[fNa]RU\XZKQCB@:1& $+//-;MTC5?TQO<110*)'$#"%'5.+,&4@/)'.D6?;P>hbSam\wnaidQ[YMVkTl`qh]dckjSSY][h__dZQEMOK3""*,.19JJ8@F?CMVXJFD@?9<88359GEYQPp_\Zhq4'#+1/fV5Trb`TK]bYbY]]eZdZQcbk[ghlhbfx^SrvfljbfgRTLB.%')/24EAcGILT<BOJccgxtvgfwkU''&.-G_?AVxsjpb[qdgfgekfimmbTZajqyy_u{~iOkogesmqgeTM5'/.6CAGu]TQVvfN_mdpwn|v{}Xr]F&++*2<75.Zgmvmeadlrr~qsxotuexspusi`\n}hLe^adgjg_`T@)127@brKRIenjmqbeqifi|m\A6(34H;;0Drllx~vtl}lxqy}yzlrostfRgjfigdjmbK,408Erunr_qw_T}m`mkdmlk_gupoO>7\Vb^[@5Shevy~}xtzwyntlkbpefib`kN-14:CqhqnXzbuoR{bp|rrca}wl~m}iN}}tGFsnv~i~luThz{v]esjialj\,,18D~dnrU]xzhnxyq{|~j~lqpgjssie~ulaq{?',3B~yynfyweyponl~{|~zv|qngkh]ouZ1-3Dctvfefgrfyrqqr~zrxn{kggzxxJ16;Ulzqowlrzypxoy}nqu}v}v{sugfkywfJ59?c_xnwzsp~}||xkZhf^ijW;>HfXuqzy|tgU_mjt{UU_vrzuwvruU|tym|Y|^u~|uuyok}y~~{                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
\ No newline at end of file

Commit:
6a8b23bf65adba79c60e8d1b0e21e2d6fdef59fd
Michael McCandless
mikemccand@apache.org
2012-03-11 17:32:16 +0000
TIKA-870: allow setting maxStringLength per-call to Tika.parseToString
diff --git a/CHANGES.txt b/CHANGES.txt
index fad6f25ad..c165149c4 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -1,6 +1,9 @@
 Apache Tika Change Log
 ======================
 
+ * Tika: parseToString now lets you specify the max string length
+   per-call, in addition to per-Tika-instance. (TIKA-870)
+
 Release 1.1 - 3/7/2012
 ---------------------------------
 
diff --git a/tika-core/src/main/java/org/apache/tika/Tika.java b/tika-core/src/main/java/org/apache/tika/Tika.java
index ecc9f973f..022b83c43 100644
--- a/tika-core/src/main/java/org/apache/tika/Tika.java
+++ b/tika-core/src/main/java/org/apache/tika/Tika.java
@@ -390,6 +390,47 @@ public class Tika {
         return handler.toString();
     }
 
+    /**
+     * Parses the given document and returns the extracted text content.
+     * The given input stream is closed by this method. This method lets
+     * you control the maxStringLength per call.
+     * <p>
+     * To avoid unpredictable excess memory use, the returned string contains
+     * only up to maxLength (parameter) first characters extracted
+     * from the input document.
+     * <p>
+     * <strong>NOTE:</strong> Unlike most other Tika methods that take an
+     * {@link InputStream}, this method will close the given stream for
+     * you as a convenience. With other methods you are still responsible
+     * for closing the stream or a wrapper instance returned by Tika.
+     *
+     * @param stream the document to be parsed
+     * @param metadata document metadata
+     * @param maxLength maximum length of the returned string
+     * @return extracted text content
+     * @throws IOException if the document can not be read
+     * @throws TikaException if the document can not be parsed
+     */
+    public String parseToString(InputStream stream, Metadata metadata, int maxLength)
+        throws IOException, TikaException {
+        WriteOutContentHandler handler =
+            new WriteOutContentHandler(maxLength);
+        try {
+            ParseContext context = new ParseContext();
+            context.set(Parser.class, parser);
+            parser.parse(
+                         stream, new BodyContentHandler(handler), metadata, context);
+        } catch (SAXException e) {
+            if (!handler.isWriteLimitReached(e)) {
+                // This should never happen with BodyContentHandler...
+                throw new TikaException("Unexpected SAX processing failure", e);
+            }
+        } finally {
+            stream.close();
+        }
+        return handler.toString();
+    }
+
     /**
      * Parses the given document and returns the extracted text content.
      * The given input stream is closed by this method.
diff --git a/tika-core/src/main/java/org/apache/tika/sax/WriteOutContentHandler.java b/tika-core/src/main/java/org/apache/tika/sax/WriteOutContentHandler.java
index dd45537c9..684f13529 100644
--- a/tika-core/src/main/java/org/apache/tika/sax/WriteOutContentHandler.java
+++ b/tika-core/src/main/java/org/apache/tika/sax/WriteOutContentHandler.java
@@ -146,6 +146,24 @@ public class WriteOutContentHandler extends ContentHandlerDecorator {
         }
     }
 
+    @Override
+    public void ignorableWhitespace(char[] ch, int start, int length)
+            throws SAXException {
+        if (writeLimit == -1 || writeCount + length <= writeLimit) {
+            super.ignorableWhitespace(ch, start, length);
+            writeCount += length;
+        } else {
+            super.ignorableWhitespace(ch, start, writeLimit - writeCount);
+            writeCount = writeLimit;
+            throw new WriteLimitReachedException(
+                    "Your document contained more than " + writeLimit
+                    + " characters, and so your requested limit has been"
+                    + " reached. To receive the full text of the document,"
+                    + " increase your limit. (Text up to the limit is"
+                    + " however available).", tag);
+        }
+    }
+
     /**
      * Checks whether the given exception (or any of it's root causes) was
      * thrown by this handler as a signal of reaching the write limit.
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/rtf/RTFParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/rtf/RTFParserTest.java
index 7c87395cd..c1152f0ea 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/rtf/RTFParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/rtf/RTFParserTest.java
@@ -28,6 +28,7 @@ import javax.xml.transform.stream.StreamResult;
 
 import org.apache.tika.Tika;
 import org.apache.tika.TikaTest;
+import org.apache.tika.io.TikaInputStream;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.sax.WriteOutContentHandler;
@@ -165,6 +166,35 @@ public class RTFParserTest extends TikaTest {
         assertContains("\u6771\u4eac\u90fd\u4e09\u9df9\u5e02", content);
     }
 
+    public void testMaxLength() throws Exception {
+        File file = getResourceAsFile("/test-documents/testRTFJapanese.rtf");
+        Metadata metadata = new Metadata();
+        InputStream stream = TikaInputStream.get(file, metadata);
+
+        // Test w/ default limit:
+        Tika localTika = new Tika();
+        String content = localTika.parseToString(stream, metadata);
+        // parseToString closes for convenience:
+        //stream.close();
+        assertTrue(content.length() > 500);
+
+        // Test setting max length on the instance:
+        localTika.setMaxStringLength(200);
+        stream = TikaInputStream.get(file, metadata);
+        content = localTika.parseToString(stream, metadata);
+        
+        // parseToString closes for convenience:
+        //stream.close();
+        assertTrue(content.length() <= 200);
+        
+        // Test setting max length per-call:
+        stream = TikaInputStream.get(file, metadata);
+        content = localTika.parseToString(stream, metadata, 100);
+        // parseToString closes for convenience:
+        //stream.close();
+        assertTrue(content.length() <= 100);
+    }
+
     public void testTextWithCurlyBraces() throws Exception {
         String content = getText("testRTFWithCurlyBraces.rtf");
         assertContains("{ some text inside curly brackets }", content);

Commit:
bbd71acee3f8e17cf9d2efa772dd531b892bd42f
Chris Mattmann
mattmann@apache.org
2012-03-07 20:46:01 +0000
[maven-release-plugin] prepare for next development iteration
diff --git a/pom.xml b/pom.xml
index cfb154790..dd33d8dd1 100644
--- a/pom.xml
+++ b/pom.xml
@@ -25,7 +25,7 @@
   <parent>
     <groupId>org.apache.tika</groupId>
     <artifactId>tika-parent</artifactId>
-    <version>1.1</version>
+    <version>1.2-SNAPSHOT</version>
     <relativePath>tika-parent/pom.xml</relativePath>
   </parent>
 
@@ -36,12 +36,12 @@
 
   <scm>
     <connection>
-      scm:svn:http://svn.apache.org/repos/asf/tika/tags/1.1
+      scm:svn:http://svn.apache.org/repos/asf/tika/trunk
     </connection>
     <developerConnection>
-      scm:svn:https://svn.apache.org/repos/asf/tika/tags/1.1
+      scm:svn:https://svn.apache.org/repos/asf/tika/trunk
     </developerConnection>
-    <url>http://svn.apache.org/viewvc/tika/tags/1.1</url>
+    <url>http://svn.apache.org/viewvc/tika/trunk</url>
   </scm>
 
   <modules>
diff --git a/tika-app/pom.xml b/tika-app/pom.xml
index 900d51c62..a9903a08e 100644
--- a/tika-app/pom.xml
+++ b/tika-app/pom.xml
@@ -25,7 +25,7 @@
   <parent>
     <groupId>org.apache.tika</groupId>
     <artifactId>tika-parent</artifactId>
-    <version>1.1</version>
+    <version>1.2-SNAPSHOT</version>
     <relativePath>../tika-parent/pom.xml</relativePath>
   </parent>
 
diff --git a/tika-bundle/pom.xml b/tika-bundle/pom.xml
index 3f1dfc1d1..1210469b6 100644
--- a/tika-bundle/pom.xml
+++ b/tika-bundle/pom.xml
@@ -25,7 +25,7 @@
   <parent>
     <groupId>org.apache.tika</groupId>
     <artifactId>tika-parent</artifactId>
-    <version>1.1</version>
+    <version>1.2-SNAPSHOT</version>
     <relativePath>../tika-parent/pom.xml</relativePath>
   </parent>
 
diff --git a/tika-core/pom.xml b/tika-core/pom.xml
index 5a7c55713..3fc46ad92 100644
--- a/tika-core/pom.xml
+++ b/tika-core/pom.xml
@@ -25,7 +25,7 @@
   <parent>
     <groupId>org.apache.tika</groupId>
     <artifactId>tika-parent</artifactId>
-    <version>1.1</version>
+    <version>1.2-SNAPSHOT</version>
     <relativePath>../tika-parent/pom.xml</relativePath>
   </parent>
 
diff --git a/tika-parent/pom.xml b/tika-parent/pom.xml
index bd06b8b35..a94164f4b 100644
--- a/tika-parent/pom.xml
+++ b/tika-parent/pom.xml
@@ -31,7 +31,7 @@
 
   <groupId>org.apache.tika</groupId>
   <artifactId>tika-parent</artifactId>
-  <version>1.1</version>
+  <version>1.2-SNAPSHOT</version>
   <packaging>pom</packaging>
 
   <name>Apache Tika parent</name>
@@ -302,10 +302,4 @@
       </build>
     </profile>
   </profiles>
-
-  <scm>
-    <connection>scm:svn:http://svn.apache.org/repos/asf/maven/pom/tags/1.1/tika-parent</connection>
-    <developerConnection>scm:svn:https://svn.apache.org/repos/asf/maven/pom/tags/1.1/tika-parent</developerConnection>
-    <url>http://svn.apache.org/viewvc/maven/pom/tags/1.1/tika-parent</url>
-  </scm>
 </project>
diff --git a/tika-parsers/pom.xml b/tika-parsers/pom.xml
index ac9927c16..586177d24 100644
--- a/tika-parsers/pom.xml
+++ b/tika-parsers/pom.xml
@@ -25,7 +25,7 @@
   <parent>
     <groupId>org.apache.tika</groupId>
     <artifactId>tika-parent</artifactId>
-    <version>1.1</version>
+    <version>1.2-SNAPSHOT</version>
     <relativePath>../tika-parent/pom.xml</relativePath>
   </parent>
 

Commit:
963aa1b85a6a9748d7df3764dcdb369275ecc3c1
Chris Mattmann
mattmann@apache.org
2012-03-07 20:45:55 +0000
[maven-release-plugin] prepare release 1.1
diff --git a/pom.xml b/pom.xml
index f8496d32c..cfb154790 100644
--- a/pom.xml
+++ b/pom.xml
@@ -25,7 +25,7 @@
   <parent>
     <groupId>org.apache.tika</groupId>
     <artifactId>tika-parent</artifactId>
-    <version>1.1-SNAPSHOT</version>
+    <version>1.1</version>
     <relativePath>tika-parent/pom.xml</relativePath>
   </parent>
 
@@ -36,12 +36,12 @@
 
   <scm>
     <connection>
-      scm:svn:http://svn.apache.org/repos/asf/tika/trunk
+      scm:svn:http://svn.apache.org/repos/asf/tika/tags/1.1
     </connection>
     <developerConnection>
-      scm:svn:https://svn.apache.org/repos/asf/tika/trunk
+      scm:svn:https://svn.apache.org/repos/asf/tika/tags/1.1
     </developerConnection>
-    <url>http://svn.apache.org/viewvc/tika/trunk</url>
+    <url>http://svn.apache.org/viewvc/tika/tags/1.1</url>
   </scm>
 
   <modules>
diff --git a/tika-app/pom.xml b/tika-app/pom.xml
index 1671fd1e2..900d51c62 100644
--- a/tika-app/pom.xml
+++ b/tika-app/pom.xml
@@ -25,7 +25,7 @@
   <parent>
     <groupId>org.apache.tika</groupId>
     <artifactId>tika-parent</artifactId>
-    <version>1.1-SNAPSHOT</version>
+    <version>1.1</version>
     <relativePath>../tika-parent/pom.xml</relativePath>
   </parent>
 
@@ -141,20 +141,20 @@
                 <configuration>
                   <target>
                     <exec executable="${ikvm}/bin/ikvmc.exe">
-                      <arg value="-nowarn:0100"/>
-                      <arg value="-nowarn:0105"/>
-                      <arg value="-nowarn:0109"/>
-                      <arg value="-nowarn:0111"/>
-                      <arg value="-nowarn:0112"/>
-                      <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.Util.dll"/>
-                      <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.Charsets.dll"/>
-                      <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.Text.dll"/>
-                      <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.Core.dll"/>
-                      <arg value="-reference:${ikvm}/bin/IKVM.AWT.WinForms.dll"/>
-                      <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.Media.dll"/>
-                      <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.Misc.dll"/>
-                      <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.Security.dll"/>
-                      <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.SwingAWT.dll"/>
+                      <arg value="-nowarn:0100" />
+                      <arg value="-nowarn:0105" />
+                      <arg value="-nowarn:0109" />
+                      <arg value="-nowarn:0111" />
+                      <arg value="-nowarn:0112" />
+                      <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.Util.dll" />
+                      <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.Charsets.dll" />
+                      <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.Text.dll" />
+                      <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.Core.dll" />
+                      <arg value="-reference:${ikvm}/bin/IKVM.AWT.WinForms.dll" />
+                      <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.Media.dll" />
+                      <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.Misc.dll" />
+                      <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.Security.dll" />
+                      <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.SwingAWT.dll" />
                       <arg value="-target:library" />
                       <arg value="-compressresources" />
                       <arg value="-out:${project.build.directory}/${project.build.finalName}.dll" />
diff --git a/tika-bundle/pom.xml b/tika-bundle/pom.xml
index 69e9565f3..3f1dfc1d1 100644
--- a/tika-bundle/pom.xml
+++ b/tika-bundle/pom.xml
@@ -25,7 +25,7 @@
   <parent>
     <groupId>org.apache.tika</groupId>
     <artifactId>tika-parent</artifactId>
-    <version>1.1-SNAPSHOT</version>
+    <version>1.1</version>
     <relativePath>../tika-parent/pom.xml</relativePath>
   </parent>
 
diff --git a/tika-core/pom.xml b/tika-core/pom.xml
index f7e9af16b..5a7c55713 100644
--- a/tika-core/pom.xml
+++ b/tika-core/pom.xml
@@ -25,7 +25,7 @@
   <parent>
     <groupId>org.apache.tika</groupId>
     <artifactId>tika-parent</artifactId>
-    <version>1.1-SNAPSHOT</version>
+    <version>1.1</version>
     <relativePath>../tika-parent/pom.xml</relativePath>
   </parent>
 
diff --git a/tika-parent/pom.xml b/tika-parent/pom.xml
index 1fe698741..bd06b8b35 100644
--- a/tika-parent/pom.xml
+++ b/tika-parent/pom.xml
@@ -31,7 +31,7 @@
 
   <groupId>org.apache.tika</groupId>
   <artifactId>tika-parent</artifactId>
-  <version>1.1-SNAPSHOT</version>
+  <version>1.1</version>
   <packaging>pom</packaging>
 
   <name>Apache Tika parent</name>
@@ -302,4 +302,10 @@
       </build>
     </profile>
   </profiles>
+
+  <scm>
+    <connection>scm:svn:http://svn.apache.org/repos/asf/maven/pom/tags/1.1/tika-parent</connection>
+    <developerConnection>scm:svn:https://svn.apache.org/repos/asf/maven/pom/tags/1.1/tika-parent</developerConnection>
+    <url>http://svn.apache.org/viewvc/maven/pom/tags/1.1/tika-parent</url>
+  </scm>
 </project>
diff --git a/tika-parsers/pom.xml b/tika-parsers/pom.xml
index 8f017a7d8..ac9927c16 100644
--- a/tika-parsers/pom.xml
+++ b/tika-parsers/pom.xml
@@ -25,7 +25,7 @@
   <parent>
     <groupId>org.apache.tika</groupId>
     <artifactId>tika-parent</artifactId>
-    <version>1.1-SNAPSHOT</version>
+    <version>1.1</version>
     <relativePath>../tika-parent/pom.xml</relativePath>
   </parent>
 
@@ -255,7 +255,7 @@
                     </goals>
                   </pluginExecutionFilter>
                   <action>
-                    <execute/>
+                    <execute />
                   </action>
                 </pluginExecution>
               </pluginExecutions>
