Commit:
8c111b977aeaf99ef8252b17457a849ec90de15f
Chris Mattmann
mattmann@apache.org
2012-03-07 19:06:29 +0000
update CHANGES.txt in prep for release.
diff --git a/CHANGES.txt b/CHANGES.txt
index e03855588..fad6f25ad 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -1,7 +1,7 @@
 Apache Tika Change Log
 ======================
 
-Release 1.1 - Current Development
+Release 1.1 - 3/7/2012
 ---------------------------------
 
  * Link Extraction: The rel attribute is now extracted from 

Commit:
8cdd3dc0c6a95fca84b49d64734362236adc126b
Chris Mattmann
mattmann@apache.org
2012-03-07 15:29:39 +0000
- upgrade to 1.1-SNAPSHOT dependency.
diff --git a/tika-server/pom.xml b/tika-server/pom.xml
index 37e63baf2..f031af89e 100644
--- a/tika-server/pom.xml
+++ b/tika-server/pom.xml
@@ -40,7 +40,7 @@
   <parent>
     <groupId>org.apache.tika</groupId>
     <artifactId>tika-parent</artifactId>
-    <version>0.10-SNAPSHOT</version>
+    <version>1.1-SNAPSHOT</version>
     <relativePath>../tika-parent/pom.xml</relativePath>
   </parent>
 
@@ -125,7 +125,6 @@
             <groupId>junit</groupId>
             <artifactId>junit</artifactId>
             <scope>test</scope>
-            <version>4.8</version>
         </dependency>
     </dependencies>
 
@@ -173,17 +172,6 @@
           </instructions>
         </configuration>
       </plugin>
-
-            <plugin>
-                <groupId>org.apache.maven.plugins</groupId>
-                <artifactId>maven-surefire-plugin</artifactId>
-                <version>2.6</version>
-                <configuration>
-                    <redirectTestOutputToFile>true</redirectTestOutputToFile>
-                    <argLine>-da -XX:+HeapDumpOnOutOfMemoryError -Xmx512m</argLine>
-<!--                    <argLine>-agentlib:jprofilerti=port=8849  -Xbootclasspath/a:/arc/opt/jprofiler5/bin/agent.jar</argLine> -->
-                </configuration>
-            </plugin>
         </plugins>
     </build>
 

Commit:
fbd2d6db793746fbb5f605731157b5181dd6ee9d
Jukka Zitting
jukka@apache.org
2012-02-19 13:41:49 +0000
TIKA-866: Invalid configuration file causes OutOfMemoryException
diff --git a/tika-core/src/main/java/org/apache/tika/config/ServiceLoader.java b/tika-core/src/main/java/org/apache/tika/config/ServiceLoader.java
index 7b617b084..5d2bc04af 100644
--- a/tika-core/src/main/java/org/apache/tika/config/ServiceLoader.java
+++ b/tika-core/src/main/java/org/apache/tika/config/ServiceLoader.java
@@ -122,6 +122,55 @@ public class ServiceLoader {
         this(getContextClassLoader(), LoadErrorHandler.IGNORE, true);
     }
 
+    /**
+     * Returns an input stream for reading the specified resource from the
+     * configured class loader.
+     *
+     * @param name resource name
+     * @return input stream, or <code>null</code> if the resource was not found
+     * @see ClassLoader#getResourceAsStream(String)
+     * @since Apache Tika 1.1
+     */
+    public InputStream getResourceAsStream(String name) {
+        if (loader != null) {
+            return loader.getResourceAsStream(name);
+        } else {
+            return null;
+        }
+    }
+
+    /**
+     * Loads and returns the named service class that's expected to implement
+     * the given interface.
+     *
+     * @param iface service interface
+     * @param name service class name
+     * @return service class
+     * @throws ClassNotFoundException if the service class can not be found
+     *                                or does not implement the given interface
+     * @see Class#forName(String, boolean, ClassLoader)
+     * @since Apache Tika 1.1
+     */
+    @SuppressWarnings("unchecked")
+    public <T> Class<? extends T> getServiceClass(Class<T> iface, String name)
+            throws ClassNotFoundException {
+        if (loader == null) {
+            throw new ClassNotFoundException(
+                    "Service class " + name + " is not available");
+        }
+        Class<?> klass = Class.forName(name, true, loader);
+        if (klass.isInterface()) {
+            throw new ClassNotFoundException(
+                    "Service class " + name + " is an interface");
+        } else if (!iface.isAssignableFrom(klass)) {
+            throw new ClassNotFoundException(
+                    "Service class " + name
+                    + " does not implement " + iface.getName());
+        } else {
+            return (Class<? extends T>) klass;
+        }
+    }
+
     /**
      * Returns all the available service resources matching the
      *  given pattern, such as all instances of tika-mimetypes.xml 
diff --git a/tika-core/src/main/java/org/apache/tika/config/TikaConfig.java b/tika-core/src/main/java/org/apache/tika/config/TikaConfig.java
index 0f4fc7943..cb3d01007 100644
--- a/tika-core/src/main/java/org/apache/tika/config/TikaConfig.java
+++ b/tika-core/src/main/java/org/apache/tika/config/TikaConfig.java
@@ -61,12 +61,12 @@ public class TikaConfig {
     }
 
     private static Detector getDefaultDetector(
-            MimeTypes types, ClassLoader loader) {
+            MimeTypes types, ServiceLoader loader) {
         return new DefaultDetector(types, loader);
     }
 
     private static CompositeParser getDefaultParser(
-            MimeTypes types, ClassLoader loader) {
+            MimeTypes types, ServiceLoader loader) {
         return new DefaultParser(types.getMediaTypeRegistry(), loader);
     }
 
@@ -105,11 +105,16 @@ public class TikaConfig {
     }
 
     public TikaConfig(Element element) throws TikaException, IOException {
-        this(element, ServiceLoader.getContextClassLoader());
+        this(element, new ServiceLoader());
     }
 
     public TikaConfig(Element element, ClassLoader loader)
             throws TikaException, IOException {
+        this(element, new ServiceLoader(loader));
+    }
+
+    private TikaConfig(Element element, ServiceLoader loader)
+            throws TikaException, IOException {
         this.mimeTypes = typesFromDomElement(element);
         this.detector = detectorFromDomElement(element, mimeTypes, loader);
         this.parser = parserFromDomElement(element, mimeTypes, loader);
@@ -129,9 +134,10 @@ public class TikaConfig {
      */
     public TikaConfig(ClassLoader loader)
             throws MimeTypeException, IOException {
+        ServiceLoader serviceLoader = new ServiceLoader(loader);
         this.mimeTypes = getDefaultMimeTypes();
-        this.detector = getDefaultDetector(mimeTypes, loader);
-        this.parser = getDefaultParser(mimeTypes, loader);
+        this.detector = getDefaultDetector(mimeTypes, serviceLoader);
+        this.parser = getDefaultParser(mimeTypes, serviceLoader);
     }
 
     /**
@@ -152,7 +158,7 @@ public class TikaConfig {
      * @throws TikaException if problem with MimeTypes or parsing XML config
      */
     public TikaConfig() throws TikaException, IOException {
-        ClassLoader loader = ServiceLoader.getContextClassLoader();
+        ServiceLoader loader = new ServiceLoader();
 
         String config = System.getProperty("tika.config");
         if (config == null) {
@@ -300,7 +306,7 @@ public class TikaConfig {
     }
 
     private static CompositeParser parserFromDomElement(
-            Element element, MimeTypes mimeTypes, ClassLoader loader)
+            Element element, MimeTypes mimeTypes, ServiceLoader loader)
             throws TikaException, IOException {
         List<Parser> parsers = new ArrayList<Parser>();
         NodeList nodes = element.getElementsByTagName("parser");
@@ -309,20 +315,15 @@ public class TikaConfig {
             String name = node.getAttribute("class");
 
             try {
-                Class<?> parserClass = Class.forName(name, true, loader);
+                Class<? extends Parser> parserClass =
+                        loader.getServiceClass(Parser.class, name);
                 // https://issues.apache.org/jira/browse/TIKA-866
                 if (AutoDetectParser.class.isAssignableFrom(parserClass)) {
                     throw new TikaException(
                             "AutoDetectParser not supported in a <parser>"
                             + " configuration element: " + name);
                 }
-
-                Object instance = parserClass.newInstance();
-                if (!(instance instanceof Parser)) {
-                    throw new TikaException(
-                            "Configured class is not a Tika Parser: " + name);
-                }
-                Parser parser = (Parser) instance;
+                Parser parser = parserClass.newInstance();
 
                 NodeList mimes = node.getElementsByTagName("mime");
                 if (mimes.getLength() > 0) {
@@ -343,7 +344,7 @@ public class TikaConfig {
                 parsers.add(parser);
             } catch (ClassNotFoundException e) {
                 throw new TikaException(
-                        "Configured parser class not found: " + name, e);
+                        "Unable to find a parser class: " + name, e);
             } catch (IllegalAccessException e) {
                 throw new TikaException(
                         "Unable to access a parser class: " + name, e);
@@ -361,7 +362,7 @@ public class TikaConfig {
     }
 
     private static Detector detectorFromDomElement(
-          Element element, MimeTypes mimeTypes, ClassLoader loader)
+          Element element, MimeTypes mimeTypes, ServiceLoader loader)
           throws TikaException, IOException {
        List<Detector> detectors = new ArrayList<Detector>();
        NodeList nodes = element.getElementsByTagName("detector");
@@ -370,17 +371,12 @@ public class TikaConfig {
            String name = node.getAttribute("class");
 
            try {
-               Class<?> detectorClass = Class.forName(name, true, loader);
-               Object instance = detectorClass.newInstance();
-               if (!(instance instanceof Detector)) {
-                   throw new TikaException(
-                           "Configured class is not a Tika Detector: " + name);
-               }
-               Detector detector = (Detector) instance;
-               detectors.add(detector);
+               Class<? extends Detector> detectorClass =
+                       loader.getServiceClass(Detector.class, name);
+               detectors.add(detectorClass.newInstance());
            } catch (ClassNotFoundException e) {
                throw new TikaException(
-                       "Configured detector class not found: " + name, e);
+                       "Unable to find a detector class: " + name, e);
            } catch (IllegalAccessException e) {
                throw new TikaException(
                        "Unable to access a detector class: " + name, e);
diff --git a/tika-core/src/main/java/org/apache/tika/detect/DefaultDetector.java b/tika-core/src/main/java/org/apache/tika/detect/DefaultDetector.java
index 749871b24..1291563a6 100644
--- a/tika-core/src/main/java/org/apache/tika/detect/DefaultDetector.java
+++ b/tika-core/src/main/java/org/apache/tika/detect/DefaultDetector.java
@@ -77,7 +77,7 @@ public class DefaultDetector extends CompositeDetector {
         return detectors;
     }
 
-    private DefaultDetector(MimeTypes types, ServiceLoader loader) {
+    public DefaultDetector(MimeTypes types, ServiceLoader loader) {
         super(types.getMediaTypeRegistry(), getDefaultDetectors(types, loader));
     }
 
diff --git a/tika-core/src/main/java/org/apache/tika/parser/DefaultParser.java b/tika-core/src/main/java/org/apache/tika/parser/DefaultParser.java
index 098f087ae..6aa418257 100644
--- a/tika-core/src/main/java/org/apache/tika/parser/DefaultParser.java
+++ b/tika-core/src/main/java/org/apache/tika/parser/DefaultParser.java
@@ -64,8 +64,8 @@ public class DefaultParser extends CompositeParser {
         
         return parsers;
     }
-    
-    private DefaultParser(MediaTypeRegistry registry, ServiceLoader loader) {
+
+    public DefaultParser(MediaTypeRegistry registry, ServiceLoader loader) {
         super(registry, getDefaultParsers(loader));
     }
 

Commit:
a547dde812cce268518796e116f63ef0a3f4c8f3
Jukka Zitting
jukka@apache.org
2012-02-17 18:23:39 +0000
TIKA-866: Invalid configuration file causes OutOfMemoryException
diff --git a/tika-core/src/main/java/org/apache/tika/config/TikaConfig.java b/tika-core/src/main/java/org/apache/tika/config/TikaConfig.java
index ba710e174..0f4fc7943 100644
--- a/tika-core/src/main/java/org/apache/tika/config/TikaConfig.java
+++ b/tika-core/src/main/java/org/apache/tika/config/TikaConfig.java
@@ -56,6 +56,20 @@ import org.xml.sax.SAXException;
  */
 public class TikaConfig {
 
+    private static MimeTypes getDefaultMimeTypes() {
+        return MimeTypes.getDefaultMimeTypes();
+    }
+
+    private static Detector getDefaultDetector(
+            MimeTypes types, ClassLoader loader) {
+        return new DefaultDetector(types, loader);
+    }
+
+    private static CompositeParser getDefaultParser(
+            MimeTypes types, ClassLoader loader) {
+        return new DefaultParser(types.getMediaTypeRegistry(), loader);
+    }
+
     private final CompositeParser parser;
     private final Detector detector;
 
@@ -115,9 +129,9 @@ public class TikaConfig {
      */
     public TikaConfig(ClassLoader loader)
             throws MimeTypeException, IOException {
-        this.mimeTypes = MimeTypes.getDefaultMimeTypes();
-        this.detector = new DefaultDetector(mimeTypes, loader);
-        this.parser = new DefaultParser(mimeTypes.getMediaTypeRegistry(), loader);
+        this.mimeTypes = getDefaultMimeTypes();
+        this.detector = getDefaultDetector(mimeTypes, loader);
+        this.parser = getDefaultParser(mimeTypes, loader);
     }
 
     /**
@@ -138,43 +152,53 @@ public class TikaConfig {
      * @throws TikaException if problem with MimeTypes or parsing XML config
      */
     public TikaConfig() throws TikaException, IOException {
+        ClassLoader loader = ServiceLoader.getContextClassLoader();
+
         String config = System.getProperty("tika.config");
         if (config == null) {
             config = System.getenv("TIKA_CONFIG");
         }
+
         if (config == null) {
-            this.mimeTypes = MimeTypes.getDefaultMimeTypes();
-            this.parser = new DefaultParser(mimeTypes.getMediaTypeRegistry());
-            this.detector = new DefaultDetector(mimeTypes);
+            this.mimeTypes = getDefaultMimeTypes();
+            this.parser = getDefaultParser(mimeTypes, loader);
+            this.detector = getDefaultDetector(mimeTypes, loader);
         } else {
-            ClassLoader loader = ServiceLoader.getContextClassLoader();
-            InputStream stream;
+            // Locate the given configuration file
+            InputStream stream = null;
             File file = new File(config);
             if (file.isFile()) {
                 stream = new FileInputStream(file);
-            } else {
-                stream = loader.getResourceAsStream(config);
             }
-            if (stream != null) {
+            if (stream == null) {
                 try {
-                    Element element =
-                        getBuilder().parse(stream).getDocumentElement();
-                    this.mimeTypes = typesFromDomElement(element);
-                    this.parser =
-                        parserFromDomElement(element, mimeTypes, loader);
-                    this.detector =
-                       detectorFromDomElement(element, mimeTypes, loader);
-                } catch (SAXException e) {
-                    throw new TikaException(
-                            "Specified Tika configuration has syntax errors: "
-                            + config, e);
-                } finally {
-                    stream.close();
+                    stream = new URL(config).openStream();
+                } catch (IOException ignore) {
                 }
-            } else {
+            }
+            if (stream == null) {
+                stream = loader.getResourceAsStream(config);
+            }
+            if (stream == null) {
                 throw new TikaException(
                         "Specified Tika configuration not found: " + config);
             }
+
+            try {
+                Element element =
+                        getBuilder().parse(stream).getDocumentElement();
+                this.mimeTypes = typesFromDomElement(element);
+                this.parser =
+                        parserFromDomElement(element, mimeTypes, loader);
+                this.detector =
+                        detectorFromDomElement(element, mimeTypes, loader);
+            } catch (SAXException e) {
+                throw new TikaException(
+                        "Specified Tika configuration has syntax errors: "
+                                + config, e);
+            } finally {
+                stream.close();
+            }
         }
     }
 
@@ -271,7 +295,7 @@ public class TikaConfig {
         if (mtr != null && mtr.hasAttribute("resource")) {
             return MimeTypesFactory.create(mtr.getAttribute("resource"));
         } else {
-            return MimeTypes.getDefaultMimeTypes();
+            return getDefaultMimeTypes();
         }
     }
 
@@ -287,12 +311,12 @@ public class TikaConfig {
             try {
                 Class<?> parserClass = Class.forName(name, true, loader);
                 // https://issues.apache.org/jira/browse/TIKA-866
-                if (DefaultParser.class.isAssignableFrom(parserClass)
-                        || AutoDetectParser.class.isAssignableFrom(parserClass)) {
+                if (AutoDetectParser.class.isAssignableFrom(parserClass)) {
                     throw new TikaException(
-                            "Composite parsers not supported in <parser>"
-                            + " configuration elements: " + name);
+                            "AutoDetectParser not supported in a <parser>"
+                            + " configuration element: " + name);
                 }
+
                 Object instance = parserClass.newInstance();
                 if (!(instance instanceof Parser)) {
                     throw new TikaException(
@@ -328,7 +352,12 @@ public class TikaConfig {
                         "Unable to instantiate a parser class: " + name, e);
             }
         }
-        return new CompositeParser(mimeTypes.getMediaTypeRegistry(), parsers);
+        if (parsers.isEmpty()) {
+            return getDefaultParser(mimeTypes, loader);
+        } else {
+            MediaTypeRegistry registry = mimeTypes.getMediaTypeRegistry();
+            return new CompositeParser(registry, parsers);
+        }
     }
 
     private static Detector detectorFromDomElement(
@@ -360,7 +389,11 @@ public class TikaConfig {
                        "Unable to instantiate a detector class: " + name, e);
            }
        }
-       
-       return new CompositeDetector(mimeTypes.getMediaTypeRegistry(), detectors);
+       if (detectors.isEmpty()) {
+           return getDefaultDetector(mimeTypes, loader);
+       } else {
+           MediaTypeRegistry registry = mimeTypes.getMediaTypeRegistry();
+           return new CompositeDetector(registry, detectors);
+       }
     }
 }
diff --git a/tika-core/src/main/java/org/apache/tika/detect/EmptyDetector.java b/tika-core/src/main/java/org/apache/tika/detect/EmptyDetector.java
new file mode 100644
index 000000000..37fee04ea
--- /dev/null
+++ b/tika-core/src/main/java/org/apache/tika/detect/EmptyDetector.java
@@ -0,0 +1,40 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.detect;
+
+import java.io.IOException;
+import java.io.InputStream;
+
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.mime.MediaType;
+
+/**
+ * Dummy detector that returns application/octet-stream for all documents.
+ */
+public class EmptyDetector implements Detector {
+
+    /**
+     * Singleton instance of this class.
+     */
+    public static final EmptyDetector INSTANCE = new EmptyDetector();
+
+    public MediaType detect(InputStream input, Metadata metadata)
+            throws IOException {
+        return MediaType.OCTET_STREAM;
+    }
+
+}
diff --git a/tika-core/src/main/java/org/apache/tika/mime/MediaTypeRegistry.java b/tika-core/src/main/java/org/apache/tika/mime/MediaTypeRegistry.java
index d2bfd6642..97f0678b3 100644
--- a/tika-core/src/main/java/org/apache/tika/mime/MediaTypeRegistry.java
+++ b/tika-core/src/main/java/org/apache/tika/mime/MediaTypeRegistry.java
@@ -22,8 +22,6 @@ import java.util.Map;
 import java.util.SortedSet;
 import java.util.TreeSet;
 
-import org.apache.tika.config.TikaConfig;
-
 /**
  * Registry of known Internet media types.
  */
@@ -39,7 +37,7 @@ public class MediaTypeRegistry implements Serializable {
      * @return default media type registry
      */
     public static MediaTypeRegistry getDefaultRegistry() {
-        return TikaConfig.getDefaultConfig().getMediaTypeRegistry();
+        return MimeTypes.getDefaultMimeTypes().getMediaTypeRegistry();
     }
 
     /**
diff --git a/tika-core/src/test/java/org/apache/tika/config/TikaConfigTest.java b/tika-core/src/test/java/org/apache/tika/config/TikaConfigTest.java
index 199e5a84a..bff4fcc21 100644
--- a/tika-core/src/test/java/org/apache/tika/config/TikaConfigTest.java
+++ b/tika-core/src/test/java/org/apache/tika/config/TikaConfigTest.java
@@ -16,32 +16,46 @@
  */
 package org.apache.tika.config;
 
-import java.io.InputStream;
+import java.net.URL;
 
 import junit.framework.TestCase;
 
 import org.apache.tika.exception.TikaException;
+import org.apache.tika.parser.AutoDetectParser;
 import org.apache.tika.parser.DefaultParser;
 
 public class TikaConfigTest extends TestCase {
 
     /**
-     * Make sure that a configuration file can't reference to composite
-     * parser classes like {@link DefaultParser} in the &lt;parser&gt;
-     * configuration elements.
+     * Make sure that a configuration file can't reference the
+     * {@link AutoDetectParser} class a &lt;parser&gt; configuration element.
      *
      * @see <a href="https://issues.apache.org/jira/browse/TIKA-866">TIKA-866</a>
      */
     public void testInvalidParser() throws Exception {
-        InputStream xml = TikaConfigTest.class.getResourceAsStream(
-                "TIKA-866-invalid.xml");
+        URL url = TikaConfigTest.class.getResource("TIKA-866-invalid.xml");
+        System.setProperty("tika.config", url.toExternalForm());
         try {
-            new TikaConfig(xml);
-            fail("Composite parser class was allowed in <parser>");
+            new TikaConfig();
+            fail("AutoDetectParser allowed in a <parser> element");
         } catch (TikaException expected) {
-            // OK
-        } finally {
-            xml.close();
+        }
+    }
+
+    /**
+     * Make sure that a configuration file can reference also a composite
+     * parser class like {@link DefaultParser} in a &lt;parser&gt;
+     * configuration element.
+     *
+     * @see <a href="https://issues.apache.org/jira/browse/TIKA-866">TIKA-866</a>
+     */
+    public void testCompositeParser() throws Exception {
+        URL url = TikaConfigTest.class.getResource("TIKA-866-composite.xml");
+        System.setProperty("tika.config", url.toExternalForm());
+        try {
+            new TikaConfig();
+        } catch (TikaException e) {
+            fail("Unexpected TikaException: " + e);
         }
     }
 
@@ -52,13 +66,12 @@ public class TikaConfigTest extends TestCase {
      * @see <a href="https://issues.apache.org/jira/browse/TIKA-866">TIKA-866</a>
      */
     public void testValidParser() throws Exception {
-        InputStream xml = TikaConfigTest.class.getResourceAsStream(
-                "TIKA-866-valid.xml");
+        URL url = TikaConfigTest.class.getResource("TIKA-866-valid.xml");
+        System.setProperty("tika.config", url.toExternalForm());
         try {
-            new TikaConfig(xml);
-            // OK
-        } finally {
-            xml.close();
+            new TikaConfig();
+        } catch (TikaException e) {
+            fail("Unexpected TikaException: " + e);
         }
     }
 
diff --git a/tika-core/src/test/resources/org/apache/tika/config/TIKA-866-composite.xml b/tika-core/src/test/resources/org/apache/tika/config/TIKA-866-composite.xml
new file mode 100644
index 000000000..d5afb3395
--- /dev/null
+++ b/tika-core/src/test/resources/org/apache/tika/config/TIKA-866-composite.xml
@@ -0,0 +1,22 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<!--
+  Licensed to the Apache Software Foundation (ASF) under one or more
+  contributor license agreements.  See the NOTICE file distributed with
+  this work for additional information regarding copyright ownership.
+  The ASF licenses this file to You under the Apache License, Version 2.0
+  (the "License"); you may not use this file except in compliance with
+  the License.  You may obtain a copy of the License at
+
+  http://www.apache.org/licenses/LICENSE-2.0
+
+  Unless required by applicable law or agreed to in writing, software
+  distributed under the License is distributed on an "AS IS" BASIS,
+  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  See the License for the specific language governing permissions and
+  limitations under the License.
+-->
+<properties>
+  <parsers>
+    <parser class="org.apache.tika.parser.DefaultParser"/>
+  </parsers>
+</properties>
diff --git a/tika-core/src/test/resources/org/apache/tika/config/TIKA-866-invalid.xml b/tika-core/src/test/resources/org/apache/tika/config/TIKA-866-invalid.xml
index d5afb3395..c19cd6423 100644
--- a/tika-core/src/test/resources/org/apache/tika/config/TIKA-866-invalid.xml
+++ b/tika-core/src/test/resources/org/apache/tika/config/TIKA-866-invalid.xml
@@ -17,6 +17,6 @@
 -->
 <properties>
   <parsers>
-    <parser class="org.apache.tika.parser.DefaultParser"/>
+    <parser class="org.apache.tika.parser.AutoDetectParser"/>
   </parsers>
 </properties>

Commit:
929f7535e99bac0a604206212253a60a1fdd816f
Jukka Zitting
jukka@apache.org
2012-02-17 15:09:21 +0000
TIKA-864: Metadata.formatDate causes blocking in concurrent use
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java b/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
index d3f105e65..99c25f45a 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
@@ -21,8 +21,10 @@ import java.text.DateFormat;
 import java.text.DateFormatSymbols;
 import java.text.ParseException;
 import java.text.SimpleDateFormat;
+import java.util.Calendar;
 import java.util.Date;
 import java.util.Enumeration;
+import java.util.GregorianCalendar;
 import java.util.HashMap;
 import java.util.Locale;
 import java.util.Map;
@@ -45,11 +47,22 @@ public class Metadata implements CreativeCommons, DublinCore, Geographic, HttpHe
     private Map<String, String[]> metadata = null;
 
     /**
-     * The ISO-8601 format string we use for Dates.
-     * All dates are represented as UTC
+     * The UTC time zone. Not sure if {@link TimeZone#getTimeZone(String)}
+     * understands "UTC" in all environments, but it'll fall back to GMT
+     * in such cases, which is in practice equivalent to UTC.
      */
-    private static final DateFormat iso8601Format =
-        createDateFormat("yyyy-MM-dd'T'HH:mm:ss'Z'", "UTC");
+    private static final TimeZone UTC = TimeZone.getTimeZone("UTC");
+
+    /**
+     * Custom time zone used to interpret date values without a time
+     * component in a way that most likely falls within the same day
+     * regardless of in which time zone it is later interpreted. For
+     * example, the "2012-02-17" date would map to "2012-02-17T12:00:00Z"
+     * (instead of the default "2012-02-17T00:00:00Z"), which would still
+     * map to "2012-02-17" if interpreted in say Pacific time (while the
+     * default mapping would result in "2012-02-16" for UTC-8).
+     */
+    private static final TimeZone MIDDAY = TimeZone.getTimeZone("GMT-12:00");
 
     /**
      * Some parsers will have the date as a ISO-8601 string
@@ -61,23 +74,23 @@ public class Metadata implements CreativeCommons, DublinCore, Geographic, HttpHe
      */
     private static final DateFormat[] iso8601InputFormats = new DateFormat[] {
         // yyyy-mm-ddThh...
-        iso8601Format,                                       // UTC/Zulu
+        createDateFormat("yyyy-MM-dd'T'HH:mm:ss'Z'", UTC),   // UTC/Zulu
         createDateFormat("yyyy-MM-dd'T'HH:mm:ssZ", null),    // With timezone
         createDateFormat("yyyy-MM-dd'T'HH:mm:ss", null),     // Without timezone
         // yyyy-mm-dd hh...
-        createDateFormat("yyyy-MM-dd' 'HH:mm:ss'Z'", "UTC"), // UTC/Zulu
+        createDateFormat("yyyy-MM-dd' 'HH:mm:ss'Z'", UTC),   // UTC/Zulu
         createDateFormat("yyyy-MM-dd' 'HH:mm:ssZ", null),    // With timezone
         createDateFormat("yyyy-MM-dd' 'HH:mm:ss", null),     // Without timezone
         // Date without time, set to Midday UTC
-        createDateFormat("yyyy-MM-dd", "GMT-12:00"), // Normal date format
-        createDateFormat("yyyy:MM:dd", "GMT-12:00"), // Image (IPTC/EXIF) format
+        createDateFormat("yyyy-MM-dd", MIDDAY),              // Normal date format
+        createDateFormat("yyyy:MM:dd", MIDDAY),              // Image (IPTC/EXIF) format
     };
 
-    private static DateFormat createDateFormat(String format, String timezone) {
+    private static DateFormat createDateFormat(String format, TimeZone timezone) {
         SimpleDateFormat sdf =
             new SimpleDateFormat(format, new DateFormatSymbols(Locale.US));
         if (timezone != null) {
-            sdf.setTimeZone(TimeZone.getTimeZone(timezone));
+            sdf.setTimeZone(timezone);
         }
         return sdf;
     }
@@ -118,8 +131,17 @@ public class Metadata implements CreativeCommons, DublinCore, Geographic, HttpHe
      * @param date given date
      * @return ISO 8601 date string
      */
-    private static synchronized String formatDate(Date date) {
-        return iso8601Format.format(date);
+    private static String formatDate(Date date) {
+        Calendar calendar = GregorianCalendar.getInstance(UTC, Locale.US);
+        calendar.setTime(date);
+        return String.format(
+                "%04d-%02d-%02dT%02d:%02d:%02dZ",
+                calendar.get(Calendar.YEAR),
+                calendar.get(Calendar.MONTH) + 1,
+                calendar.get(Calendar.DAY_OF_MONTH),
+                calendar.get(Calendar.HOUR_OF_DAY),
+                calendar.get(Calendar.MINUTE),
+                calendar.get(Calendar.SECOND));
     }
 
     /**

Commit:
84a2a2757c2b8080b450d5341fb20a321a85923e
Nick Burch
nick@apache.org
2012-02-17 14:10:21 +0000
TIKA-865 Tweak what we lock on
diff --git a/tika-core/src/main/java/org/apache/tika/mime/MimeTypes.java b/tika-core/src/main/java/org/apache/tika/mime/MimeTypes.java
index c33e588ff..3316fd73e 100644
--- a/tika-core/src/main/java/org/apache/tika/mime/MimeTypes.java
+++ b/tika-core/src/main/java/org/apache/tika/mime/MimeTypes.java
@@ -269,7 +269,7 @@ public final class MimeTypes implements Detector, Serializable {
             MimeType mime = types.get(normalisedType);
             
             if (mime == null) {
-                synchronized (types) {
+                synchronized (this) {
                    // Double check it didn't already get added while 
                    //  we were waiting for the lock
                    mime = types.get(normalisedType);
diff --git a/tika-core/src/main/java/org/apache/tika/parser/external/ExternalParsersFactory.java b/tika-core/src/main/java/org/apache/tika/parser/external/ExternalParsersFactory.java
index 6190250ad..05814de92 100644
--- a/tika-core/src/main/java/org/apache/tika/parser/external/ExternalParsersFactory.java
+++ b/tika-core/src/main/java/org/apache/tika/parser/external/ExternalParsersFactory.java
@@ -23,10 +23,14 @@ import java.util.ArrayList;
 import java.util.Collections;
 import java.util.Enumeration;
 import java.util.List;
+import java.util.Map;
 
 import org.apache.tika.config.ServiceLoader;
 import org.apache.tika.config.TikaConfig;
 import org.apache.tika.exception.TikaException;
+import org.apache.tika.mime.MediaType;
+import org.apache.tika.parser.CompositeParser;
+import org.apache.tika.parser.Parser;
 
 /**
  * Creates instances of ExternalParser based on XML 
@@ -75,6 +79,11 @@ public class ExternalParsersFactory {
    }
    
    public static void attachExternalParsers(List<ExternalParser> parsers, TikaConfig config) {
+      Parser parser = config.getParser();
+      if (parser instanceof CompositeParser) {
+         CompositeParser cParser = (CompositeParser)parser;
+         Map<MediaType,Parser> parserMap = cParser.getParsers();
+      }
       // TODO
    }
 }

Commit:
1f16bf8e5ef4848d9d2e91e1566c1cfb5617f311
Jukka Zitting
jukka@apache.org
2012-02-17 13:41:46 +0000
TIKA-866: Invalid configuration file causes OutOfMemoryException
diff --git a/tika-core/src/main/java/org/apache/tika/config/TikaConfig.java b/tika-core/src/main/java/org/apache/tika/config/TikaConfig.java
index 7d30cbb0c..ba710e174 100644
--- a/tika-core/src/main/java/org/apache/tika/config/TikaConfig.java
+++ b/tika-core/src/main/java/org/apache/tika/config/TikaConfig.java
@@ -40,6 +40,7 @@ import org.apache.tika.mime.MediaTypeRegistry;
 import org.apache.tika.mime.MimeTypeException;
 import org.apache.tika.mime.MimeTypes;
 import org.apache.tika.mime.MimeTypesFactory;
+import org.apache.tika.parser.AutoDetectParser;
 import org.apache.tika.parser.CompositeParser;
 import org.apache.tika.parser.DefaultParser;
 import org.apache.tika.parser.Parser;
@@ -285,6 +286,13 @@ public class TikaConfig {
 
             try {
                 Class<?> parserClass = Class.forName(name, true, loader);
+                // https://issues.apache.org/jira/browse/TIKA-866
+                if (DefaultParser.class.isAssignableFrom(parserClass)
+                        || AutoDetectParser.class.isAssignableFrom(parserClass)) {
+                    throw new TikaException(
+                            "Composite parsers not supported in <parser>"
+                            + " configuration elements: " + name);
+                }
                 Object instance = parserClass.newInstance();
                 if (!(instance instanceof Parser)) {
                     throw new TikaException(
diff --git a/tika-core/src/test/java/org/apache/tika/config/TikaConfigTest.java b/tika-core/src/test/java/org/apache/tika/config/TikaConfigTest.java
new file mode 100644
index 000000000..199e5a84a
--- /dev/null
+++ b/tika-core/src/test/java/org/apache/tika/config/TikaConfigTest.java
@@ -0,0 +1,65 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.config;
+
+import java.io.InputStream;
+
+import junit.framework.TestCase;
+
+import org.apache.tika.exception.TikaException;
+import org.apache.tika.parser.DefaultParser;
+
+public class TikaConfigTest extends TestCase {
+
+    /**
+     * Make sure that a configuration file can't reference to composite
+     * parser classes like {@link DefaultParser} in the &lt;parser&gt;
+     * configuration elements.
+     *
+     * @see <a href="https://issues.apache.org/jira/browse/TIKA-866">TIKA-866</a>
+     */
+    public void testInvalidParser() throws Exception {
+        InputStream xml = TikaConfigTest.class.getResourceAsStream(
+                "TIKA-866-invalid.xml");
+        try {
+            new TikaConfig(xml);
+            fail("Composite parser class was allowed in <parser>");
+        } catch (TikaException expected) {
+            // OK
+        } finally {
+            xml.close();
+        }
+    }
+
+    /**
+     * Make sure that a valid configuration file without mimetypes or
+     * detector entries can be loaded without problems.
+     *
+     * @see <a href="https://issues.apache.org/jira/browse/TIKA-866">TIKA-866</a>
+     */
+    public void testValidParser() throws Exception {
+        InputStream xml = TikaConfigTest.class.getResourceAsStream(
+                "TIKA-866-valid.xml");
+        try {
+            new TikaConfig(xml);
+            // OK
+        } finally {
+            xml.close();
+        }
+    }
+
+}
\ No newline at end of file
diff --git a/tika-core/src/test/resources/org/apache/tika/config/TIKA-866-invalid.xml b/tika-core/src/test/resources/org/apache/tika/config/TIKA-866-invalid.xml
new file mode 100644
index 000000000..d5afb3395
--- /dev/null
+++ b/tika-core/src/test/resources/org/apache/tika/config/TIKA-866-invalid.xml
@@ -0,0 +1,22 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<!--
+  Licensed to the Apache Software Foundation (ASF) under one or more
+  contributor license agreements.  See the NOTICE file distributed with
+  this work for additional information regarding copyright ownership.
+  The ASF licenses this file to You under the Apache License, Version 2.0
+  (the "License"); you may not use this file except in compliance with
+  the License.  You may obtain a copy of the License at
+
+  http://www.apache.org/licenses/LICENSE-2.0
+
+  Unless required by applicable law or agreed to in writing, software
+  distributed under the License is distributed on an "AS IS" BASIS,
+  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  See the License for the specific language governing permissions and
+  limitations under the License.
+-->
+<properties>
+  <parsers>
+    <parser class="org.apache.tika.parser.DefaultParser"/>
+  </parsers>
+</properties>
diff --git a/tika-core/src/test/resources/org/apache/tika/config/TIKA-866-valid.xml b/tika-core/src/test/resources/org/apache/tika/config/TIKA-866-valid.xml
new file mode 100644
index 000000000..56504c4d0
--- /dev/null
+++ b/tika-core/src/test/resources/org/apache/tika/config/TIKA-866-valid.xml
@@ -0,0 +1,22 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<!--
+  Licensed to the Apache Software Foundation (ASF) under one or more
+  contributor license agreements.  See the NOTICE file distributed with
+  this work for additional information regarding copyright ownership.
+  The ASF licenses this file to You under the Apache License, Version 2.0
+  (the "License"); you may not use this file except in compliance with
+  the License.  You may obtain a copy of the License at
+
+  http://www.apache.org/licenses/LICENSE-2.0
+
+  Unless required by applicable law or agreed to in writing, software
+  distributed under the License is distributed on an "AS IS" BASIS,
+  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  See the License for the specific language governing permissions and
+  limitations under the License.
+-->
+<properties>
+  <parsers>
+    <parser class="org.apache.tika.parser.EmptyParser"/>
+  </parsers>
+</properties>

Commit:
eb6207836f8eb7a3353aa6088785d22fd3cd4f64
Nick Burch
nick@apache.org
2012-02-17 12:24:33 +0000
TIKA-865 Reduce the amount of MimeTypes.forName that needs to be synchronized
diff --git a/tika-core/src/main/java/org/apache/tika/mime/MimeTypes.java b/tika-core/src/main/java/org/apache/tika/mime/MimeTypes.java
index cb7beb1ad..c33e588ff 100644
--- a/tika-core/src/main/java/org/apache/tika/mime/MimeTypes.java
+++ b/tika-core/src/main/java/org/apache/tika/mime/MimeTypes.java
@@ -262,15 +262,23 @@ public final class MimeTypes implements Detector, Serializable {
      * @return the registered media type with the given name or alias
      * @throws MimeTypeException if the given media type name is invalid
      */
-    public synchronized MimeType forName(String name)
-            throws MimeTypeException {
+    public MimeType forName(String name) throws MimeTypeException {
         MediaType type = MediaType.parse(name);
         if (type != null) {
-            MimeType mime = types.get(registry.normalize(type));
+            MediaType normalisedType = registry.normalize(type);
+            MimeType mime = types.get(normalisedType);
+            
             if (mime == null) {
-                mime = new MimeType(type);
-                add(mime);
-                types.put(type, mime);
+                synchronized (types) {
+                   // Double check it didn't already get added while 
+                   //  we were waiting for the lock
+                   mime = types.get(normalisedType);
+                   if (mime == null) {
+                      mime = new MimeType(type);
+                      add(mime);
+                      types.put(type, mime);
+                   }
+                }
             }
             return mime;
         } else {

Commit:
dc9ffcc36bf27b2feaa066bcf950e87847bb4bf7
Nick Burch
nick@apache.org
2012-02-16 11:20:11 +0000
TIKA-850 Update OfficeParser to support the new style password fetching via PasswordProvider
diff --git a/CHANGES.txt b/CHANGES.txt
index ca700e19d..e03855588 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -58,6 +58,11 @@ Release 1.1 - Current Development
    limited audio and video metadata, along with the iTunes media metadata
    (such as Artist and Title) (TIKA-852)
 
+ * Document Passwords: A new ParseContext object, PasswordProvider,
+   has been added. This provides a way to supply the password for 
+   a document during processing. Currently, only password protected
+   PDFs and Microsoft OOXML Files are supported. (TIKA-850)
+
 Release 1.0 - 11/4/2011
 ---------------------------------
 
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java
index 005c14935..0315f6a0b 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java
@@ -42,6 +42,7 @@ import org.apache.tika.metadata.Metadata;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.parser.AbstractParser;
 import org.apache.tika.parser.ParseContext;
+import org.apache.tika.parser.PasswordProvider;
 import org.apache.tika.parser.microsoft.ooxml.OOXMLParser;
 import org.apache.tika.sax.BodyContentHandler;
 import org.apache.tika.sax.EmbeddedContentHandler;
@@ -212,8 +213,17 @@ public class OfficeParser extends AbstractParser {
            Decryptor d = Decryptor.getInstance(info);
 
            try {
-              // TODO Allow the user to specify the password via the ParseContext
-              if (!d.verifyPassword(Decryptor.DEFAULT_PASSWORD)) {
+              // By default, use the default Office Password
+              String password = Decryptor.DEFAULT_PASSWORD;
+              
+              // If they supplyed a Password Provider, ask that for the password
+              PasswordProvider passwordProvider = context.get(PasswordProvider.class);
+              if (passwordProvider != null) {
+                 password = passwordProvider.getPassword(metadata);
+              }
+              
+              // Check if we've the right password or not
+              if (!d.verifyPassword(password)) {
                  throw new EncryptedDocumentException();
               }
 

Commit:
f68f1a4e35941721e21768a60d6aea8827601b5f
Nick Burch
nick@apache.org
2012-02-10 17:06:35 +0000
Add the older audio/x-mpeg alias for audio/mpeg
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index a0cb91ba6..31dfcc8d4 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -3071,6 +3071,7 @@
   <mime-type type="audio/mpa-robust"/>
 
   <mime-type type="audio/mpeg">
+    <alias type="audio/x-mpeg"/>
     <acronym>MP3</acronym>
     <_comment>MPEG-1 Audio Layer 3</_comment>
     <magic priority="20">

Commit:
72564dd2d15397bd68ec4d08cdf45bd1fd7fd558
Nick Burch
nick@apache.org
2012-02-10 17:05:35 +0000
Mark text/javascript as an alias of the official application/javascript mimetype, rather than being seperate, and add the application/x-javascript which is sometimes used in older things too
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 2195bb011..a0cb91ba6 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -171,6 +171,8 @@
   </mime-type>
 
   <mime-type type="application/javascript">
+    <alias type="application/x-javascript"/>
+    <alias type="text/javascript"/>
     <sub-class-of type="text/plain"/>
     <glob pattern="*.js"/>
   </mime-type>
@@ -3923,7 +3925,6 @@
     <glob pattern="*.htm"/>
   </mime-type>
 
-  <mime-type type="text/javascript"/>
   <mime-type type="text/parityfec"/>
 
   <mime-type type="text/plain">

Commit:
59cab5fc06a07387c8e71c3e2dfd0f7a887e4180
Nick Burch
nick@apache.org
2012-02-10 14:20:49 +0000
TIKA-818 Use a temp file for PDFBox resource processing, if the input is a file based TikaInputStream
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java
index 92a927628..523a06e5f 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java
@@ -28,10 +28,14 @@ import org.apache.pdfbox.cos.COSArray;
 import org.apache.pdfbox.cos.COSBase;
 import org.apache.pdfbox.cos.COSName;
 import org.apache.pdfbox.cos.COSString;
+import org.apache.pdfbox.io.RandomAccess;
+import org.apache.pdfbox.io.RandomAccessFile;
 import org.apache.pdfbox.pdmodel.PDDocument;
 import org.apache.pdfbox.pdmodel.PDDocumentInformation;
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.io.CloseShieldInputStream;
+import org.apache.tika.io.TemporaryResources;
+import org.apache.tika.io.TikaInputStream;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.PagedText;
 import org.apache.tika.metadata.Property;
@@ -88,9 +92,24 @@ public class PDFParser extends AbstractParser {
             InputStream stream, ContentHandler handler,
             Metadata metadata, ParseContext context)
             throws IOException, SAXException, TikaException {
-        PDDocument pdfDocument =
-            PDDocument.load(new CloseShieldInputStream(stream), true);
+       
+        PDDocument pdfDocument = null;
+        TemporaryResources tmp = new TemporaryResources();
+
         try {
+            // PDFBox can process entirely in memory, or can use a temp file
+            //  for unpacked / processed resources
+            // Decide which to do based on if we're reading from a file or not already
+            TikaInputStream tstream = TikaInputStream.cast(stream);
+            if (tstream != null && tstream.hasFile()) {
+               // File based, take that as a cue to use a temporary file
+               RandomAccess scratchFile = new RandomAccessFile(tmp.createTemporaryFile(), "rw");
+               pdfDocument = PDDocument.load(new CloseShieldInputStream(stream), scratchFile, true);
+            } else {
+               // Go for the normal, stream based in-memory parsing
+               pdfDocument = PDDocument.load(new CloseShieldInputStream(stream), true);
+            }
+           
             if (pdfDocument.isEncrypted()) {
                 String password = null;
                 
@@ -122,7 +141,10 @@ public class PDFParser extends AbstractParser {
                               extractAnnotationText, enableAutoSpace,
                               suppressDuplicateOverlappingText, sortByPosition);
         } finally {
-            pdfDocument.close();
+            if (pdfDocument != null) {
+               pdfDocument.close();
+            }
+            tmp.dispose();
         }
     }
 

Commit:
0ec2c05776be567650d3a100d313429cf86b712d
Nick Burch
nick@apache.org
2012-02-10 10:33:39 +0000
Update CHANGES with recent new parsers
diff --git a/CHANGES.txt b/CHANGES.txt
index 0d1688cbd..ca700e19d 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -48,6 +48,16 @@ Release 1.1 - Current Development
  * Outlook: fixed NullPointerException in TikaGUI when messages with
    embedded RTF or HTML content were filtered (TIKA-801).
 
+ * Ogg Vorbis and FLAC: Parser added for Ogg Vorbis and FLAC audio
+   files, which extract audio metadata and tags (TIKA-747)
+
+ * MP4: Improved mime magic detection for MP4 based formats (including
+   QuickTime, MP4 Video and Audio, and 3GPP) (TIKA-851)
+
+ * MP4: Basic metadata extracting parser for MP4 files added, which includes
+   limited audio and video metadata, along with the iTunes media metadata
+   (such as Artist and Title) (TIKA-852)
+
 Release 1.0 - 11/4/2011
 ---------------------------------
 

Commit:
4cf76141d00d705324dceeec7c6dfe1c1a2c75ce
Nick Burch
nick@apache.org
2012-02-09 18:50:45 +0000
Re-enable the iWorks tests disabled in r1023712 as part of TIKA-533, as they work properly again now
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/AutoDetectParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/AutoDetectParserTest.java
index 5a2fe7f05..abd1194b7 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/AutoDetectParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/AutoDetectParserTest.java
@@ -145,15 +145,15 @@ public class AutoDetectParserTest extends TestCase {
     }
 
     public void testKeynote() throws Exception {
-        // assertAutoDetect("testKeynote.key", KEYNOTE, "A sample presentation");
+        assertAutoDetect("testKeynote.key", KEYNOTE, "A sample presentation");
     }
 
     public void testPages() throws Exception {
-        // assertAutoDetect("testPages.pages", PAGES, "Sample pages document");
+        assertAutoDetect("testPages.pages", PAGES, "Sample pages document");
     }
 
     public void testNumbers() throws Exception {
-        // assertAutoDetect("testNumbers.numbers", NUMBERS, "Checking Account: 300545668");
+        assertAutoDetect("testNumbers.numbers", NUMBERS, "Checking Account: 300545668");
     }
 
     public void testEpub() throws Exception {

Commit:
5e104ccf22ca2034de46854d5a84392b5798d090
Nick Burch
nick@apache.org
2012-02-09 16:39:57 +0000
TIKA-747 Add the Vorbis and FLAC parsers, along with a simple integration test
diff --git a/tika-bundle/pom.xml b/tika-bundle/pom.xml
index daa502256..69e9565f3 100644
--- a/tika-bundle/pom.xml
+++ b/tika-bundle/pom.xml
@@ -117,6 +117,7 @@
               xmlbeans, dom4j,
               tagsoup,
               asm, 
+              vorbis-java-core, vorbis-java-tika,
               isoparser, scannotation, javassist,
               metadata-extractor,
               boilerpipe, rome,
diff --git a/tika-parsers/pom.xml b/tika-parsers/pom.xml
index 2d946f814..8f017a7d8 100644
--- a/tika-parsers/pom.xml
+++ b/tika-parsers/pom.xml
@@ -38,6 +38,7 @@
     <poi.version>3.8-beta5</poi.version>
     <codec.version>1.5</codec.version> <!-- NOTE: sync with POI -->
     <mime4j.version>0.7</mime4j.version>
+    <vorbis.version>0.1</vorbis.version>
   </properties>
 
   <dependencies>
@@ -47,6 +48,13 @@
       <version>${project.version}</version>
     </dependency>
 
+    <!-- Externally Maintained Parsers -->
+    <dependency>
+      <groupId>org.gagravarr</groupId>
+      <artifactId>vorbis-java-tika</artifactId>
+      <version>${vorbis.version}</version>
+    </dependency>
+
     <!-- Optional OSGi dependencies, used only when running within OSGi -->
     <dependency>
       <groupId>org.apache.felix</groupId>
@@ -158,6 +166,11 @@
       <artifactId>rome</artifactId>
       <version>0.9</version>
     </dependency>
+    <dependency>
+      <groupId>org.gagravarr</groupId>
+      <artifactId>vorbis-java-core</artifactId>
+      <version>${vorbis.version}</version>
+    </dependency>
 
     <!-- Test dependencies -->
     <dependency>
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/AutoDetectParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/AutoDetectParserTest.java
index 699b972d8..5a2fe7f05 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/AutoDetectParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/AutoDetectParserTest.java
@@ -16,23 +16,25 @@
  */
 package org.apache.tika.parser;
 
+import java.io.ByteArrayInputStream;
+import java.io.IOException;
+import java.io.InputStream;
+import java.util.HashSet;
+import java.util.Set;
+
 import junit.framework.TestCase;
 
+import org.apache.tika.config.TikaConfig;
 import org.apache.tika.detect.Detector;
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.XMPDM;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.sax.BodyContentHandler;
 import org.xml.sax.ContentHandler;
-import org.xml.sax.SAXException;
-
-import java.io.ByteArrayInputStream;
-import java.io.IOException;
-import java.io.InputStream;
-import java.util.HashSet;
-import java.util.Set;
 
 public class AutoDetectParserTest extends TestCase {
+    private TikaConfig tika = TikaConfig.getDefaultConfig();
 
     // Easy to read constants for the MIME types:
     private static final String RAW        = "application/octet-stream";
@@ -52,6 +54,9 @@ public class AutoDetectParserTest extends TestCase {
     private static final String GIF        = "image/gif";
     private static final String JPEG       = "image/jpeg";
     private static final String PNG        = "image/png";
+    private static final String OGG_VORBIS = "audio/vorbis";
+    private static final String OGG_FLAC   = "audio/x-flac";
+    private static final String FLAC_NATIVE= "audio/x-flac";
     private static final String OPENOFFICE
             = "application/vnd.oasis.opendocument.text";
 
@@ -76,7 +81,7 @@ public class AutoDetectParserTest extends TestCase {
             metadata.set(Metadata.RESOURCE_NAME_KEY, tp.resourceStatedName);
             metadata.set(Metadata.CONTENT_TYPE, tp.statedType);
             ContentHandler handler = new BodyContentHandler();
-            new AutoDetectParser().parse(input, handler, metadata);
+            new AutoDetectParser(tika).parse(input, handler, metadata);
 
             assertEquals("Bad content type: " + tp,
                     tp.realType, metadata.get(Metadata.CONTENT_TYPE));
@@ -221,7 +226,7 @@ public class AutoDetectParserTest extends TestCase {
         try {
             Metadata metadata = new Metadata();
             ContentHandler handler = new BodyContentHandler(-1);
-            new AutoDetectParser().parse(tgz, handler, metadata);
+            new AutoDetectParser(tika).parse(tgz, handler, metadata);
             fail("Zip bomb was not detected");
         } catch (TikaException e) {
             // expected
@@ -231,6 +236,64 @@ public class AutoDetectParserTest extends TestCase {
     
     }
     
+    /**
+     * Test to ensure that the Vorbis and FLAC parsers have been correctly
+     *  included, and are available
+     */
+    public void testVorbisFlac() throws Exception {
+       // The three test files should all have similar test data
+       String[] testFiles = new String[] {
+             "testVORBIS.ogg", "testFLAC.oga", "testFLAC.flac"
+       };
+       String[] mimetypes = new String[] {
+             OGG_VORBIS, OGG_FLAC, FLAC_NATIVE
+       };
+       
+       // Check we found the parser
+       CompositeParser parser = (CompositeParser)tika.getParser();
+       for (String type : mimetypes) {
+          MediaType mt = MediaType.parse(type);
+          assertNotNull("Parser not found for " + type, parser.getParsers().get(mt) );
+       }
+       
+       // Have each file parsed, and check
+       for (int i=0; i<testFiles.length; i++) {
+          String file = testFiles[i];
+          InputStream input = AutoDetectParserTest.class.getResourceAsStream(
+                "/test-documents/"+file);
+
+          if (input == null) {
+             fail("Could not find test file " + file);
+          }
+          
+          try {
+             Metadata metadata = new Metadata();
+             ContentHandler handler = new BodyContentHandler();
+             new AutoDetectParser(tika).parse(input, handler, metadata);
+
+             assertEquals("Incorrect content type for " + file,
+                   mimetypes[i], metadata.get(Metadata.CONTENT_TYPE));
+
+             // Check some of the common metadata
+             assertEquals("Test Artist", metadata.get(Metadata.AUTHOR));
+             assertEquals("Test Title", metadata.get(Metadata.TITLE));
+             
+             // Check some of the XMPDM metadata
+             assertEquals("Test Album", metadata.get(XMPDM.ALBUM));
+             assertEquals("Test Artist", metadata.get(XMPDM.ARTIST));
+             assertEquals("Stereo", metadata.get(XMPDM.AUDIO_CHANNEL_TYPE));
+             assertEquals("44100", metadata.get(XMPDM.AUDIO_SAMPLE_RATE));
+             
+             // Check some of the text
+             String content = handler.toString();
+             assertTrue(content.contains("Test Title"));
+             assertTrue(content.contains("Test Artist"));
+          } finally {
+             input.close();
+          }
+       }
+    }
+    
     /**
      * Test case for TIKA-514. Provide constructor for AutoDetectParser that has explicit
      * list of supported parsers.

Commit:
5a42442339c34f6e42d1353673df343b8b5070b0
Nick Burch
nick@apache.org
2012-02-09 16:11:24 +0000
TIKA-747 Add Vorbis and FLAC test files, for integration tests
diff --git a/tika-parsers/src/test/resources/test-documents/testFLAC.flac b/tika-parsers/src/test/resources/test-documents/testFLAC.flac
new file mode 100644
index 000000000..ccec94717
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testFLAC.flac differ
diff --git a/tika-parsers/src/test/resources/test-documents/testFLAC.oga b/tika-parsers/src/test/resources/test-documents/testFLAC.oga
new file mode 100644
index 000000000..37a12477e
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testFLAC.oga differ
diff --git a/tika-parsers/src/test/resources/test-documents/testVORBIS.ogg b/tika-parsers/src/test/resources/test-documents/testVORBIS.ogg
new file mode 100644
index 000000000..1a02d2205
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testVORBIS.ogg differ

Commit:
6454566da5e6c3ae9fe989145277d3b657f8de65
Nick Burch
nick@apache.org
2012-02-08 17:59:47 +0000
TIKA-852 Support setting the channel type from a channel count in mp4, via a couple of different possible routes (see dev@tika discussions)
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/XMPDM.java b/tika-core/src/main/java/org/apache/tika/metadata/XMPDM.java
index 258bbe716..b263f4970 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/XMPDM.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/XMPDM.java
@@ -16,6 +16,8 @@
  */
 package org.apache.tika.metadata;
 
+import java.util.Date;
+
 /**
  * XMP Dynamic Media schema. This is a collection of
  * {@link Property property definition} constants for the dynamic media
@@ -80,6 +82,53 @@ public interface XMPDM {
      */
     Property AUDIO_CHANNEL_TYPE = Property.internalClosedChoise(
             "xmpDM:audioChannelType", "Mono", "Stereo", "5.1", "7.1");
+    /**
+     * Converter for {@link XMPDM#AUDIO_CHANNEL_TYPE} 
+     * @deprecated Experimental method, will change shortly
+     */
+    static class ChannelTypePropertyConverter {
+       private static Property property = AUDIO_CHANNEL_TYPE;
+       
+       /**
+        * How a standalone converter might work
+        */
+       public static String convert(Object value) {
+          if (value instanceof String) {
+             // Assume already done
+             return (String)value;
+          }
+          if (value instanceof Integer) {
+             int channelCount = (Integer)value;
+             if(channelCount == 1) {
+                return "Mono";
+             } else if(channelCount == 2) {
+                return "Stereo";
+             } else if(channelCount == 5) {
+                return "5.1";
+             } else if(channelCount == 7) {
+                return "7.1";
+             }
+          }
+          return null;
+       }
+       /**
+        * How convert+set might work
+        */
+       public static void convertAndSet(Metadata metadata, Object value) {
+          if (value instanceof Integer || value instanceof Long) {
+             metadata.set(property, convert(value));
+          }
+          if (value instanceof Date) {
+             // Won't happen in this case, just an example of already
+             //  converted to a type metadata.set(property) handles
+             metadata.set(property, (Date)value);
+          }
+          if (value instanceof String) {
+             // Already converted, or so we hope!
+             metadata.set(property, (String)value);
+          }
+       }
+    }
 
     /**
      * "The audio compression used. For example, MP3."
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java b/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java
index 1507e762e..654ee96c9 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java
@@ -208,7 +208,7 @@ public class MP4Parser extends AbstractParser {
               // Look for the first Audio Sample, if present
               AudioSampleEntry sample = getOrNull(sampleDesc, AudioSampleEntry.class);
               if (sample != null) {
-                 //metadata.set(XMPDM.AUDIO_CHANNEL_TYPE, sample.getChannelCount()); // TODO Num -> Name mapping
+                 XMPDM.ChannelTypePropertyConverter.convertAndSet(metadata, sample.getChannelCount());
                  //metadata.set(XMPDM.AUDIO_SAMPLE_TYPE, sample.getSampleSize());    // TODO Num -> Type mapping
                  metadata.set(XMPDM.AUDIO_SAMPLE_RATE, (int)sample.getSampleRate());
                  //metadata.set(XMPDM.AUDIO_, sample.getSamplesPerPacket());

Commit:
53ef1b992d779676987d737e634b66f45d58310b
Nick Burch
nick@apache.org
2012-02-08 17:03:36 +0000
TIKA-852 Avoid NPE on missing metadata boxes
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java b/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java
index fa0a274dc..1507e762e 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java
@@ -307,6 +307,8 @@ public class MP4Parser extends AbstractParser {
     private static final long EPOC_AS_MP4_TIME = 2082844800l;
     
     private static <T extends Box> T getOrNull(ContainerBox box, Class<T> clazz) {
+       if (box == null) return null;
+
        List<T> boxes = box.getBoxes(clazz);
        if (boxes.size() == 0) {
           return null;

Commit:
5498c0eeea7d2a5d6d314bcddc7d307830e97c27
Maxim Valyanskiy
maxcom@apache.org
2012-01-31 14:38:43 +0000
TIKA-854: No text extraction for Word macroenabled template
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/pkg/ZipContainerDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/pkg/ZipContainerDetector.java
index ee5a45465..edad4a7ef 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/pkg/ZipContainerDetector.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/pkg/ZipContainerDetector.java
@@ -18,6 +18,7 @@ package org.apache.tika.parser.pkg;
 
 import java.io.IOException;
 import java.io.InputStream;
+import java.util.regex.Pattern;
 
 import org.apache.commons.compress.archivers.zip.ZipArchiveEntry;
 import org.apache.commons.compress.archivers.zip.ZipFile;
@@ -40,6 +41,7 @@ import org.apache.tika.parser.iwork.IWorkPackageParser.IWORKDocumentType;
  *  to figure out exactly what the file is
  */
 public class ZipContainerDetector implements Detector {
+    private static final Pattern MACRO_TEMPLATE_PATTERN = Pattern.compile("macroenabledtemplate$", Pattern.CASE_INSENSITIVE);
 
     /** Serial version UID */
     private static final long serialVersionUID = 2891763938430295453L;
@@ -163,6 +165,10 @@ public class ZipContainerDetector implements Detector {
             docType = docType.toLowerCase() + ".12";
         }
 
+        if(docType.toLowerCase().endsWith("macroenabledtemplate")) {
+            docType = MACRO_TEMPLATE_PATTERN.matcher(docType).replaceAll("macroenabled.12");
+        }
+
         // Build the MediaType object and return
         return MediaType.parse(docType);
     }
diff --git a/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java b/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
index cbffa9d1b..e4a748b5b 100644
--- a/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
+++ b/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
@@ -178,7 +178,8 @@ public class TestContainerAwareDetector extends TestCase {
         assertTypeByData("testPPT.pptm", "application/vnd.ms-powerpoint.presentation.macroenabled.12");
         assertTypeByData("testPPT.ppsx", "application/vnd.openxmlformats-officedocument.presentationml.slideshow");
         assertTypeByData("testPPT.ppsm", "application/vnd.ms-powerpoint.slideshow.macroEnabled.12");
-        
+        assertTypeByData("testDOTM.dotm", "application/vnd.ms-word.template.macroEnabled.12");
+
         // .xlsb is an OOXML file containing the binary parts, and not
         //  an OLE2 file as you might initially expect!
         assertTypeByData("testEXCEL.xlsb", "application/vnd.ms-excel.sheet.binary.macroEnabled.12");
diff --git a/tika-parsers/src/test/resources/test-documents/testDOTM.dotm b/tika-parsers/src/test/resources/test-documents/testDOTM.dotm
new file mode 100644
index 000000000..17b0c512b
--- /dev/null
+++ b/tika-parsers/src/test/resources/test-documents/testDOTM.dotm
@@ -0,0 +1,649 @@
+      1822 .  1843 .        ( , ),    .     ,   2 ,       ,    1853 .   .
+  ,      ,  ,        .
+    :
+
+    *       .
+    *    2     ,     ()   ,    ().
+    *       ()           ( ).
+    *                         (  ).
+    *           .
+    *       (  )     .
+
+    ,        .     ,   ,           .
+              .          ,       .
+    " "    Punnett,       ,  .        .
+    , -   ,          .      ,        ,    , -    .
+    X  Y     :
+  - XY        X-,   Y- .   - XX ,        X-.
+  ,     50%      50% - .
+       -    2:2  50/50.
+       ,        .   ,    ,     ,        
+  ?
+	  ^
+ ,   ?  -     ,     .
+ !    !  -     3- :
+
+    * ;
+    * ;
+    * 
+
+    .
+           .            ,       (,     ).
+               .       ,       ,   . ,  ,  .        , ,  ,    .    ,         : ,      - .
+       , -  . ,    :    ,      .
+,     ,       .   :
+
+    * "" -    ,     .
+    * "" -          .
+    * "" -        
+
+    , ,         -      .
+  -     :
+,   !
+       ,    - .     ,   .         .         (   b     B).       "",  ,     ,       .
+ ,        ,        ( ).
+      . !
+ 
+	  ^
+         ?
+  ,     .
+ 1:          ,   :          (Ll  LL,      L -).
+,       (L-)    (ll).
+ 1:      : Ll.
+          1:1,             .
+.                  . ,  CFA         AOV (Any Other Variety -   )       .         , -          , -            AOV.
+   ,   FIFe,        ,    .
+ 2 :      : LL.
+            ,        l.
+           .
+     ,         (           )  Variants (       "").           : EXO d Var.  ,           -   !
+ 2:          ,         (LL)   (Ll).
+ 1:        : Ll.
+          3:1,  50%      , 25%         25%  -     .
+ ,             .             .
+:    ,     ,     .
+ 2 :    :
+     : LL.
+     : Ll.
+         (  )        .        ,        .
+       50%        .
+   -          .
+              .
+ 
+	  ^
+B -  ,       - .      ,    ,       .
+     ,   ,   ,       :
+b -   (   ).         .
+bl - -  (   ). -      ,         ,   .
+    :
+Black - 
+Blue - 
+Seal - -, 
+Sable - 
+Chocolate - 
+Chestnut - 
+Ruddy - 
+Cinnamon -  -, 
+Lilac - 
+Fawn -  ,  
+Platinum - 
+O - Orange  (     ) -     - .        ,    ,         .
+   ,    (   )  (..  , ).      ,       .      ,     . ,     ,      ,        ,       ,      bl ().
+   2 : red & cream (  ).
+     "" ( ) -      , -       .  "o"     -       .  ,    : /.
+ "o" ( )   ,          .    .
+  
+	  ^
+    ?
+         ,     :    ?
+     2,  1           .
+       ,     ,         (Ll)   ,           (l).       ,        ,     .         .           ,          .
+          ,       .
+              .         (l)   .   - ,         .     -       -  !
+ 
+	  ^
+D -   .  ,     ,   .      D -        .    D  : black, seal, sable, chocolate, ruddy, cinnamon & red.
+d -     .    .    d  : blue, lilac, fawn, platinum & cream.
+                .     .          .
+      ,      ,        . ,     : "     ( ) !"
+         ,       .    ,      ,               ,   -  .  (     -)      "d ".      b - chocolate   bl - cinnamon.
+    -    ,       ,   ,     .
+ 
+	  ^
+I -  ,           .       ,     .
+i -   -,       .
+ 
+	  ^
+C -     , ..         . Black, blue, chocolate, ruddy, cinnamon, fawn, seal, lilac, red, cream -      .
+ -   ,    ,     ,    . , ,   :
+
+    * Seal (,  )
+    * Chocolate ( ,  )
+    * Blue ( )
+    * Lilac (,  )
+    *     "c".        "c".
+
+    "c"     .      ,        , ,       -          :      ,   .     .
+      "c".        .         - ,         ( ).           ,         "d ".
+    4  :
+c -     
+c -  
+         "":
+b -  ,        ,       :    ,   ,    .
+s -  ,          ,   -  .
+  b ,    s     ,        .      ,    , -   .
+,       : ,   .    ,    ""    "d "      :     .     : ""  "d "    .
+        :   "b"    "s".  "s"    ,   'chocolate'    .   ,  ,   -     ''   "b"     "s",       .
+     D  d  .          ,      -       -   , .     ,    .         Orange (:      ),        .
+   (  d),       , -        ,       . :       ( b),   ( d)     cbcb ,     ,     (   ).    b, d,  C     ,    b, d,  cbcb   ,    - .
+ 
+	  ^
+   ,   ,           ,     ,     .     , -             (, -   ),      ,           (        ).     , -         .        -     (      )     .
+      ?            ,             .          , -        ,   .
+            (   ) .  ,     -      ,         .   ,     ,  -    ,    .
+              .               ,     ,        -.      ,    .      ,        (   )  .       ,         ,        .
+  -   ,     (   ,   );        . ,  ,        -           . ,      ,     ,   Havana Brown,        .     ,        ?     ?           .       ,     ,              .  , ,        .      !
+ 
+	  ^
+ -  (         ,      (non-orange)  ).       .         ,   ,   ,    .
+ - - (      ). -        Orange ,             . "   !"           "  ".              ,   .
+        .
+Ta -  ,         ,      ,         . ,  ,      ,      .   , ,   ,   (     )   , ,   .
+T -  ( ) ,             :  ""  ,   ,            .
+tb -     ,      , ""  .
+t -     .  ,         .          ,    ,       .  ,    - ,        .
+ 
+	  ^
+          2 :
+
+    *  -  (XX & XY)
+    *  - 
+    *  - 
+
+      ,   ,    .          ,      d .   BB/Dd.    BB     -       bb      .   D -       d -    .  ,           (BB) -          , ..               ,    .         -     ,      .
+              .    :
+     3    1 .         .       ,        .   ,           ,   10 ,          .     :     ,           .      , 2-   ( )        1:2:1.
+         ,    .        ?           ?            .   -   .
+         (     !) -         :
+    ,      Dd - ,     .
+       "". DD     , dd   , ,   ,     . Dd      D,   d.                  ""  .       ,        ,   .        ,     ,      Dd      D ( ),   d ( ).
+  ,    ,        .         D, -   . ,    ,        ,  ,  .        ,     ,  -     . ,     ,  :    -   !
+       .           .    OO/Dd,   - OY/Dd ( ,    ).     OY , ..         (    "   O (Orange)").
+     1:2:1.   ""  ,        ()   ""  .    3:1.
+       . ,          (dd)    (Dd),    .
+        F1  F3  ..                  .       - x.           .     ( ),  - (   ).     P (    parenta - ).          .     F (    filii - )   ,     . ,    F1,      F2,   - F3  ..
+        .
+  
+	  ^
+W -   ,      ,   B, C  D,    W    ,        .  W    ,      ,         .         " ".
+w -  ,  .    ,     ,  w,   w    ,  :      W.
+S -     'piebald'  -  ,      ,    -.         B, C, D  W.
+s -   ( -).
+G -   ; " "   ,    -     g.
+g -   . ,     S,      .   ,                -     cs,     g        ,   ,      ,      .
+   O (Orange)
+	  ^
+,      ,     -    .   ,        , (, ,       !),        .   X  Y . , , ,    - XX,    - XY.  ,     , -    ,    X  Y.          X  Y. Y-    X-      ,   -,   .      ,    ,      X-,    .      ,   . (, ,    ).
+   O (Orange)       X-,      Y-,         O (Orange)  Y-. -   O  o  X-,     .     O, -     ,     o -   -  ( ) .      X-    Y- - ,     .      O , ..  Y-       .        ,    D,    B  ,   . -,   ,   X-    .  X-      .      , -      ,       -       ,            ( ),     ,      ,       .           .       ,  ,     , ( XXY),    .
+       .       : O_/XY (    Orange  Y-).       oo/XX (  ,         ,    DD      BB), ..   ,      .
+  "/"     ,       .        ,   .  ,           .
+  -        -.             .    .      ?       .
+ -          ,       ,    -   .   ,   ,  -      .
+       -    ,       .           .        , -      ()         .
+:    (Ww),        (Dd) -      .     : Ww/Dd.  4  : WD, Wd, wD, wd.        Ww/Dd,      :
+   ()  :
+
+   1.  ,  
+   2.  ,  ,  
+   3.  ,  
+   4.  ,  ,  
+   5.  ,  ,  
+   6.  ,  
+   7.  ,  ,  
+   8.  ,  
+   9.  ,  
+  10.  ,  ,  
+  11.  
+  12.  ,  
+  13.  ,  ,  
+  14.  ,  
+  15.  ,  
+  16.  
+
+  ,     , -     16 .       12 , 3   1   ,  2 :   ,   12:4   3:1.    (2 :   )     3:1 - 3   1  .
+      ,  ,     .
+:      CPC -  (Ccs),     (Dd)     .     : Ccs/Dd.  4  : D, Cd, csD, csd.        Ccs /Dd,      :
+  ,      :
+
+   1.      , 
+   2.      , ,  
+   3. , 
+   4. , ,  
+   5.      , ,  
+   6.      , 
+   7. , ,  
+   8. , 
+   9. , 
+  10. , ,  
+  11. , -
+  12. , -,  
+  13.      , ,  
+  14.      , 
+  15. , -,  
+  16. ,  -
+
+      9 , 3 , 3 -  1 -  -    9:3:3:1. ,  2 :    ,   12:4   3:1.     (2 :   )     3:1 - 9   3        (2 :   )     3:1 - 3 -  1 - .
+  
+	  ^
+L -  ,   L,       .
+       :   L  ""  "",   ""    ""! (   ,      ,    ,       -                 ). : L -    .
+l -    .
+ 
+	  ^
+            : "- ...,    ,    -    ."  ,                  .         .        .   ?    ?      ?
+  ,       -   .   ,  ;       - .    .                  .    .       . ,     -   ,    - ,  ..
+ ""    .       " " (1901-1903 ..).     ,    .     .          ,        ( ,         ):
+
+   1.   .
+   2.   .
+   3.    .
+   4.     ,   .
+   5.    .
+
+      .      ,     (, ,      ,    - Dwarf ( dw), ).  ,    ,   ,     ,     (    -      ,      , Dominant White ( W)),      , ,    .
+      :
+M	 	m	 
+Fd	 	fd	 
+Cr	 	cr	 
+HR	 	hr	 ()
+R	 	r	 
+Re	 	re	 
+Wh	 	wh	 
+Rs	 	rs	 
+                .          .     -   ,     -    ,         ,  ,       .      ,   ,         .   ,           ,       .
+      ,  .     ,      : , ,  , .
+,       , , , , , . (  ,  ,      ...)              ,   .
+             .         ,     .   -      , -        .            ,       !
+
+	  ^
+       .        :          ,    (, , , , , , )  ,        ,      .    ,     ,      :
+-			 	
+A	Agouti		AA
+Aa	    ( )  
+a	Non-agouti		aa	    ( )  
+B	Black		BB
+Bb
+Bbl	  -.
+ , , 
+   Seal.
+     Ebony.
+b	Chocolate		bb
+bbl	  .
+     Havana.
+bl	Cinnamon		blbl	  ,  .
+C	Full Color		CC
+Ccs
+Ccb	  ,  .
+cb	Burmese points		cbcb
+cbcs	  -   - ( Sable),       .     ,   .
+ 
+cs	Siamese points		cscs	  .
+  , , ,     ,  -.
+ca	Blue eyed Albino		caca	    - .
+     ( W).
+c	Albino		cc	  ,     ( ).
+Cu	Curled Ears		CuCu
+Cucu	 ,    .     .
+cu	Straight ears		cucu	,  .
+D	Density,
+non-diluted		DD
+Dd	   : , , , .
+d	Diluted		dd	 : , , , .
+Fd	Folded ears		FdFd
+Fdfd	  .
+   -.
+fd	Straight ears		fdfd	,  .
+HR	Normal coat		Hrhr
+Hrhr	  ,  .
+hr	Hairless		hrhr	  ,   .
+I	Inhibitor		II
+Ii	    ,     ,   - .
+i	Non Silver		ii	   .
+L	Shorthair		LL
+Ll	 .
+l	Longhair		ll	 .
+            -        .
+    :
+
+    * BLACK
+    * ORANGE
+
+   :
+
+    * BLUE
+    * CREAM
+    * LILAC
+    * FAWN
+    * PLATINUM
+
+    BLACK:
+
+    * CHOCOLATE
+    * CINNAMON
+
+  ()    olor,     Black,  :
+
+    * cb - SABLE
+    * cs - SEAL POINT
+    * cbcs - NATURAL (Tonkinese)
+
+     d  :
+
+    * BLUE (  BLACK)
+    * CREAM (  RED)
+    * LILAC (  CHOCOLATE)
+    * FAWN (  CINNAMON)
+    * PLATINUM (  SABLE)
+
+    .   ,       .   ,     () ,      ,    .
+  (Dilute)      ,    -     .
+        , , :   ,    .     : " -  ,   ! ".
+  , Jean-Paul Maas
+
+a	, - ( 33)
+b	,  -  , - -    (b 33)
+c	, - ( 33)
+d	, - (d 33)
+e	, - ( 33)
+f	, - (f 33)
+g	-, -- (g 33)
+h	 , -- (h 33)
+j	 , -- (j 33)
+n	, - (n 33),  -  ,  -    
+o	, , 
+p	 
+q	 
+r	  
+s	, 
+w	
+y	
+x	 
+    
+	
+01	
+02	
+03	
+11	
+12	, 
+21	 
+22	,  
+23	, , 
+24	, 
+25	 
+31	 
+32	 
+33	  (-)
+ 
+	 
+61	 
+62	 
+63	  
+64	 
+65	  
+66	  
+67	  
+
+
+.. 
+
+      
+
+   -    ,   .    .           ,              .
+
+         ,       ,    .              .         ,            .
+
+   -  ,     .      .
+
+ ,    ,     ,       : ,    .    ,     .
+
+       ,  ,  ,    -  .     ,   ,   .     ,                .           .     "",    - "",   - "",   - ""     .
+
+    ,       .       .
+
+  () -    ,  ,   .       .
+
+                      -  .           .      ,    -   .
+
+           .           ,   -  .       .     .
+
+      : , ,  ().         .            ,         .
+
+            ,     .          .  ,    ,      .
+
+     ,    ,          .            .
+
+,     ,         ,            .     , , --, -.      .
+
+    .          ,       :  ,    ,  ,      ,   .
+
+  .   ,    ,      :  ,   ,   .   ().   ,      ,  "" -    ,     .    - ,    ,  ,    .
+
+     .     ,   ,    ,      ,   ( ,  ,  , ).
+
+       ,      (   ).         ,       .
+
+         ,       ,     .                .
+
+      : , ,   .
+
+        ,     ,    .     :     .
+
+        ,               .   ,    ,    ,     .
+
+    ,   ,      ,     .
+
+         , , .
+
+      (, , ,  ).      ,        ,      .
+
+  ,      ,      .     ,     .        .
+
+ ,    , .     , ,  .        -                   , , ,   .
+
+ ,   ,  , ,       .   ,  ,           ,   ,          (   - !).
+
+  ,         .
+
+  ,  ,  .      ,    .      (; ; ).
+
+  ,       ,     ,     ,   (:   . .).
+
+   ,   -  .      .        39   .        ,  -  .
+
+      -.     ,       ,  .      (; ;   . .).        .          ,       .    ,      (;  ..),   ,   (;  . .).
+
+     .       ,    . ,   ,      () .        () .      >. ,  ,             B > .
+
+                 .    ,  ,             ,      .        .
+
+   ,             ,          ()   ,     :
+
+   = 
+( ) ( ) ( )
+
+        ,      .         . , ,       ,      ,    .       -         .       (),         .             -.  ,         ,    .          , .
+
+        - ,   .     -     .         ,         ,      .         :    DD  gg  SS tt ww ( - ).     ,         ,          ,    ,        ,        .
+
+      ,       ,     .      ,         .
+
+      .
+
+ -   ,       .         ,  .
+
+y -   ;
+
+g - "", - ;
+
+w - ; t - .
+
+      ,   > y > ag > > aw > aw        .       ,      y; g; w  t   .
+
+ - ,    :     ;
+
+ -    (, , );
+
+ -  (, ),          , , .                ,
+
+t -   (, -, -);
+
+t -  (, , -).              ,   .
+
+ -   ,   .         .      ;      ; '" "" -             .        .
+
+    ,            .         -      .  ,         .       -  "  "  .
+
+  -   ( ).    ,    , , ,  - .       .        () ,         ,  ,     . :
+
+   = 
+( ) ( ) (  )
+
+       ,          .   -     .     ,     , , .   ,    , .     .        ,        .
+
+    :  > cd > cch > > cb > ca.
+
+D - ,   .  D  .       ,    .                 .    ,    d,   .
+D -  ;
+
+d -   ( );
+
+bD -  ;
+
+bd - -,   ( ).
+
+        .
+
+,     "" -  'D  'bd.       ,    ,          .
+
+          .
+    (    bb)   .
+      (      .        .
+
+   ( )     .     (),    ( bb).
+t -  .      -      .    , , ;
+
+m, m -    ;
+
+m, m bb -       ;
+br - ;
+
+br -     ;
+
+br, br bb -        ;
+
+e -         ;
+
+ -     ;
+
+bb -  - ()   .             .
+ ,   ,        :   .    .   :  > m > br > e.      .
+G -   .  G    .        ,     .       ,   .
+  -   .   ,   .        .      --.
+ g    .      g.
+ M    "". (      , -,    ).  m -  .
+ -    .    ,               .       ,     ,     .
+     .      :
+
+Mm  Mm =  : Mm : mm = 1:2:1
+( ( ( ( ( ) ) ) ) )
+,         .
+
+Mm  mm = Mm:mm = 1:1
+( ) ( )
+
+    , -,   .       ,   ,   ,          .       ,    -.
+. .   1932 .        ,    .        , ,   ,  .
+    ,             (p ).           ,          .        ,         .       ,            .       , ,    ,   .
+S -   ,      ,  .
+
+           .           .     .         :             ,    ( -    )     .          .
+              .    .   , ,     .
+  S      :
+S -  ;
+
+st -   ;
+
+Sp - ,    80%    ;
+
+sw -   ,      .
+S > st > sp > sw.
+
+    ,              -.       .            ,     S,     -,   .               ,     .    ,    ,  ,   ,     ,              :
+ss X Ss = Ss : ss = 1 : 1
+    Ss    ,   - -     ,    -    .
+         . ,   ,         , :
+CCbbSs  ccBBss = CcBbss  CcBbSs
+( ) ( ) (   ( ) )
+    ,         .         ,   ,   .
+   S       .
+  ().  T -       -  ( , ,  ).  t -  .
+ -        (   , ,    5 - 8 ).
+ R   ,   r -  .
+W -    ; w -   .
+
+      .                  W.
+ ,  ,    . ,            -  ,   ,       .       ,      .
+
+ABCDEgmStrw
+( )
+
+A -     ,   ;
+
+ -   ;
+
+ -  ;
+
+D -   ;
+
+E -      ;
+
+g -    ;
+
+m -   ;
+
+S -   ;
+
+t -  ;
+
+r -  ;
+
+w -    .
+
+       .     ,    .
+  - ABE.          ,      ,        .
+-  - atBE
+
+  - AbE,  ,  ,     ,   b.
+
+-  - atbE -    -    ,   ,     .
+
+  - ABEd  ABEg -  .
+
+agBE - - .
+
+ag (w, y)  ch E -    "  ".
+
+ABET - - ,       .
+
+ABER -  ,   -             .
+
+ .
+
+BW  Bc -     .
+
+bw  bc -     .
+
+cb -     . ca -     .
+
+MM -    ,      - .
+

Commit:
a170fbe96fae15406d34d84b42f804ad828df745
Nick Burch
nick@apache.org
2012-01-31 14:36:02 +0000
TIKA-850 Add a new interface, PasswordProvider, which can be set on the ParseContext to provide a way to supply document passwords. Updates PDFParser to use this in preference
diff --git a/tika-core/src/main/java/org/apache/tika/parser/PasswordProvider.java b/tika-core/src/main/java/org/apache/tika/parser/PasswordProvider.java
new file mode 100644
index 000000000..64ce09fae
--- /dev/null
+++ b/tika-core/src/main/java/org/apache/tika/parser/PasswordProvider.java
@@ -0,0 +1,43 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.parser;
+
+import org.apache.tika.metadata.Metadata;
+
+/**
+ * Interface for providing a password to a Parser for handling Encrypted
+ *  and Password Protected Documents.
+ * An implementation of this should be set on the {@link ParseContext}
+ *  supplied to {@link Parser#parse(java.io.InputStream, org.xml.sax.ContentHandler, Metadata, ParseContext)}
+ *  to provide a way to get the document password. 
+ * An implementation of this interface defines some specific selection
+ *  or lookup criteria, to be applied against the document metadata passed
+ *  to the {@link #getPassword(Metadata)} method.
+ *
+ * @since Apache Tika 1.1
+ */
+public interface PasswordProvider {
+    /**
+     * Looks up the password for a document with the given metadata,
+     * and returns it for the Parser. If no password is available
+     * for the document, will return null.
+     *
+     * @param metadata document metadata
+     * @return The document decryption password, or <code>null</code> if not known
+     */
+    String getPassword(Metadata metadata);
+}
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java
index fc2948eb9..92a927628 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java
@@ -38,6 +38,7 @@ import org.apache.tika.metadata.Property;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.parser.AbstractParser;
 import org.apache.tika.parser.ParseContext;
+import org.apache.tika.parser.PasswordProvider;
 import org.xml.sax.ContentHandler;
 import org.xml.sax.SAXException;
 
@@ -72,6 +73,7 @@ public class PDFParser extends AbstractParser {
      * Metadata key for giving the document password to the parser.
      *
      * @since Apache Tika 0.5
+     * @deprecated Supply a {@link PasswordProvider} on the {@link ParseContext} instead
      */
     public static final String PASSWORD = "org.apache.tika.parser.pdf.password";
 
@@ -90,11 +92,25 @@ public class PDFParser extends AbstractParser {
             PDDocument.load(new CloseShieldInputStream(stream), true);
         try {
             if (pdfDocument.isEncrypted()) {
+                String password = null;
+                
+                // Did they supply a new style Password Provider?
+                PasswordProvider passwordProvider = context.get(PasswordProvider.class);
+                if (passwordProvider != null) {
+                   password = passwordProvider.getPassword(metadata);
+                }
+                
+                // Fall back on the old style metadata if set
+                if (password == null && metadata.get(PASSWORD) != null) {
+                   password = metadata.get(PASSWORD);
+                }
+                
+                // If no password is given, use an empty string as the default
+                if (password == null) {
+                   password = "";
+                }
+               
                 try {
-                    String password = metadata.get(PASSWORD);
-                    if (password == null) {
-                        password = "";
-                    }
                     pdfDocument.decrypt(password);
                 } catch (Exception e) {
                     // Ignore
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java
index f3631762e..7e7901739 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java
@@ -29,6 +29,7 @@ import org.apache.tika.metadata.Metadata;
 import org.apache.tika.parser.AutoDetectParser;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.parser.Parser;
+import org.apache.tika.parser.PasswordProvider;
 import org.apache.tika.sax.BodyContentHandler;
 import org.xml.sax.ContentHandler;
 /**
@@ -126,6 +127,35 @@ public class PDFParserTest extends TikaTest {
        assertTrue(content.contains("RETHINKING THE FINANCIAL NETWORK"));
        assertTrue(content.contains("On 16 November 2002"));
        assertTrue(content.contains("In many important respects"));
+       
+       
+       // Try again with an explicit empty password
+       handler = new BodyContentHandler();
+       metadata = new Metadata();
+       
+       context = new ParseContext();
+       context.set(PasswordProvider.class, new PasswordProvider() {
+           public String getPassword(Metadata metadata) {
+              return "";
+          }
+       });
+       
+       stream = PDFParserTest.class.getResourceAsStream(
+                  "/test-documents/testPDF_protected.pdf");
+       try {
+          parser.parse(stream, handler, metadata, context);
+       } finally {
+          stream.close();
+       }
+
+       assertEquals("application/pdf", metadata.get(Metadata.CONTENT_TYPE));
+       assertEquals("The Bank of England", metadata.get(Metadata.AUTHOR));
+       assertEquals("Speeches by Andrew G Haldane", metadata.get(Metadata.SUBJECT));
+       assertEquals("Rethinking the Financial Network, Speech by Andrew G Haldane, Executive Director, Financial Stability delivered at the Financial Student Association, Amsterdam on 28 April 2009", metadata.get(Metadata.TITLE));
+
+       assertTrue(content.contains("RETHINKING THE FINANCIAL NETWORK"));
+       assertTrue(content.contains("On 16 November 2002"));
+       assertTrue(content.contains("In many important respects"));
     }
 
     public void testTwoTextBoxes() throws Exception {

Commit:
ab54c210f11e15dfcb8b30489da739306308b4e8
Nick Burch
nick@apache.org
2012-01-31 14:23:45 +0000
TIKA-757 Remove POI related TODO, now that we have upgraded to a version with the fix
diff --git a/tika-core/src/main/java/org/apache/tika/extractor/ParsingEmbeddedDocumentExtractor.java b/tika-core/src/main/java/org/apache/tika/extractor/ParsingEmbeddedDocumentExtractor.java
index 64ced548c..c2e3cf3d4 100644
--- a/tika-core/src/main/java/org/apache/tika/extractor/ParsingEmbeddedDocumentExtractor.java
+++ b/tika-core/src/main/java/org/apache/tika/extractor/ParsingEmbeddedDocumentExtractor.java
@@ -95,14 +95,7 @@ public class ParsingEmbeddedDocumentExtractor implements EmbeddedDocumentExtract
             final TikaInputStream newStream = TikaInputStream.get(new CloseShieldInputStream(stream), tmp);
             if (stream instanceof TikaInputStream) {
                 final Object container = ((TikaInputStream) stream).getOpenContainer();
-
-                // TODO: we can't let ZipPackage through,
-                // becase of POI bug 51949.  This is less
-                // efficient because the inner parser will
-                // have to re-open the zip archive again.
-                // Once we upgrade to POI 3.8 beta 5 we can
-                // remove this:
-                if ((container != null && !(container.getClass().getSimpleName().equals("ZipPackage")))) {
+                if (container != null) {
                     newStream.setOpenContainer(container);
                 }
             }

Commit:
24bc3dc6f752d342a2d994da24545d4f9698ce90
Nick Burch
nick@apache.org
2012-01-30 12:02:44 +0000
TIKA-853 Close the stream in the MP4 Parser, and use a cleaner way to get two of the metadata boxes
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java b/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java
index cf639a016..fa0a274dc 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java
@@ -41,12 +41,14 @@ import org.xml.sax.SAXException;
 import com.coremedia.iso.IsoBufferWrapper;
 import com.coremedia.iso.IsoBufferWrapperImpl;
 import com.coremedia.iso.IsoFile;
-import com.coremedia.iso.boxes.AbstractContainerBox;
 import com.coremedia.iso.boxes.Box;
+import com.coremedia.iso.boxes.ContainerBox;
 import com.coremedia.iso.boxes.FileTypeBox;
 import com.coremedia.iso.boxes.MetaBox;
 import com.coremedia.iso.boxes.MovieBox;
 import com.coremedia.iso.boxes.MovieHeaderBox;
+import com.coremedia.iso.boxes.SampleDescriptionBox;
+import com.coremedia.iso.boxes.SampleTableBox;
 import com.coremedia.iso.boxes.TrackBox;
 import com.coremedia.iso.boxes.TrackHeaderBox;
 import com.coremedia.iso.boxes.UserDataBox;
@@ -62,6 +64,7 @@ import com.coremedia.iso.boxes.apple.AppleStandardGenreBox;
 import com.coremedia.iso.boxes.apple.AppleTrackAuthorBox;
 import com.coremedia.iso.boxes.apple.AppleTrackNumberBox;
 import com.coremedia.iso.boxes.apple.AppleTrackTitleBox;
+import com.coremedia.iso.boxes.sampleentry.AudioSampleEntry;
 
 /**
  * Parser for the MP4 media container format, as well as the older
@@ -105,14 +108,20 @@ public class MP4Parser extends AbstractParser {
             InputStream stream, ContentHandler handler,
             Metadata metadata, ParseContext context)
             throws IOException, SAXException, TikaException {
+        IsoFile isoFile;
+        
         // The MP4Parser library accepts either a File, or a byte array
         // As MP4 video files are typically large, always use a file to
         //  avoid OOMs that may occur with in-memory buffering
         TikaInputStream tstream = TikaInputStream.get(stream);
-        IsoBufferWrapper isoBufferWrapper = 
-           new IsoBufferWrapperImpl(tstream.getFile());
-        IsoFile isoFile = new IsoFile(isoBufferWrapper);
-        isoFile.parse();
+        try {
+           IsoBufferWrapper isoBufferWrapper = 
+              new IsoBufferWrapperImpl(tstream.getFile());
+           isoFile = new IsoFile(isoBufferWrapper);
+           isoFile.parse();
+        } finally {
+           tstream.close();
+        }
         
         
         // Grab the file type box
@@ -175,21 +184,36 @@ public class MP4Parser extends AbstractParser {
         // TODO Decide how to handle multiple tracks
         List<TrackBox> tb = moov.getBoxes(TrackBox.class);
         if (tb.size() > 0) {
-           TrackHeaderBox header = getOrNull(tb.get(0), TrackHeaderBox.class);
-           if (header != null) {
-              // Get the creation and modification dates
-              metadata.set(
-                    Metadata.CREATION_DATE, 
-                    MP4TimeToDate(header.getCreationTime())
-              );
-              metadata.set(
-                    Property.externalDate(Metadata.MODIFIED), // TODO Should be a real property
-                    MP4TimeToDate(header.getModificationTime())
-              );
-              
-              // Get the video with and height
-              metadata.set(Metadata.IMAGE_WIDTH,  (int)header.getWidth());
-              metadata.set(Metadata.IMAGE_LENGTH, (int)header.getHeight());
+           TrackBox track = tb.get(0);
+           
+           TrackHeaderBox header = track.getTrackHeaderBox();
+           // Get the creation and modification dates
+           metadata.set(
+                 Metadata.CREATION_DATE, 
+                 MP4TimeToDate(header.getCreationTime())
+           );
+           metadata.set(
+                 Property.externalDate(Metadata.MODIFIED), // TODO Should be a real property
+                 MP4TimeToDate(header.getModificationTime())
+           );
+           
+           // Get the video with and height
+           metadata.set(Metadata.IMAGE_WIDTH,  (int)header.getWidth());
+           metadata.set(Metadata.IMAGE_LENGTH, (int)header.getHeight());
+           
+           // Get the sample information
+           SampleTableBox samples = track.getSampleTableBox();
+           SampleDescriptionBox sampleDesc = samples.getSampleDescriptionBox();
+           if (sampleDesc != null) {
+              // Look for the first Audio Sample, if present
+              AudioSampleEntry sample = getOrNull(sampleDesc, AudioSampleEntry.class);
+              if (sample != null) {
+                 //metadata.set(XMPDM.AUDIO_CHANNEL_TYPE, sample.getChannelCount()); // TODO Num -> Name mapping
+                 //metadata.set(XMPDM.AUDIO_SAMPLE_TYPE, sample.getSampleSize());    // TODO Num -> Type mapping
+                 metadata.set(XMPDM.AUDIO_SAMPLE_RATE, (int)sample.getSampleRate());
+                 //metadata.set(XMPDM.AUDIO_, sample.getSamplesPerPacket());
+                 //metadata.set(XMPDM.AUDIO_, sample.getBytesPerSample());
+              }
            }
         }
         
@@ -282,7 +306,7 @@ public class MP4Parser extends AbstractParser {
     }
     private static final long EPOC_AS_MP4_TIME = 2082844800l;
     
-    private static <T extends Box> T getOrNull(AbstractContainerBox box, Class<T> clazz) {
+    private static <T extends Box> T getOrNull(ContainerBox box, Class<T> clazz) {
        List<T> boxes = box.getBoxes(clazz);
        if (boxes.size() == 0) {
           return null;

Commit:
fe9897c60c7f8326200b2dbe17b48acc890913b8
Nick Burch
nick@apache.org
2012-01-28 21:02:04 +0000
TIKA-852 MP4 files can be very large, so avoid trying to buffer them in memory
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java b/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java
index 149ea495a..cf639a016 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java
@@ -27,7 +27,6 @@ import java.util.Map;
 import java.util.Set;
 
 import org.apache.tika.exception.TikaException;
-import org.apache.tika.io.IOUtils;
 import org.apache.tika.io.TikaInputStream;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.Property;
@@ -106,16 +105,12 @@ public class MP4Parser extends AbstractParser {
             InputStream stream, ContentHandler handler,
             Metadata metadata, ParseContext context)
             throws IOException, SAXException, TikaException {
-        IsoBufferWrapper isoBufferWrapper = null;
-        TikaInputStream tstream = TikaInputStream.cast(stream);
-
-        // Have MP4Parser process the stream / file
-        if (tstream != null && tstream.hasFile()) {
-           isoBufferWrapper = new IsoBufferWrapperImpl(tstream.getFile());
-        } else {
-           isoBufferWrapper = new IsoBufferWrapperImpl(
-                 IOUtils.toByteArray(stream));
-        }
+        // The MP4Parser library accepts either a File, or a byte array
+        // As MP4 video files are typically large, always use a file to
+        //  avoid OOMs that may occur with in-memory buffering
+        TikaInputStream tstream = TikaInputStream.get(stream);
+        IsoBufferWrapper isoBufferWrapper = 
+           new IsoBufferWrapperImpl(tstream.getFile());
         IsoFile isoFile = new IsoFile(isoBufferWrapper);
         isoFile.parse();
         

Commit:
d53216ae46a0309f9977644ffd288029ebcc77c1
Nick Burch
nick@apache.org
2012-01-28 20:54:44 +0000
Update the bundling defintions to include MP4Parser and dependencies
diff --git a/tika-app/pom.xml b/tika-app/pom.xml
index 6fa79b9e7..1671fd1e2 100644
--- a/tika-app/pom.xml
+++ b/tika-app/pom.xml
@@ -86,7 +86,7 @@
               org.apache.tika.cli,
               org.apache.tika.gui
             </Export-Package>
-            <Embed-Dependency>!netcdf;scope=provided;inline=net/**|javax/**|org/**|com/**|de/**|font_metrics.properties|repackage/**|schema*/**|META-INF/services/**|META-INF/maven/**</Embed-Dependency>
+            <Embed-Dependency>!netcdf;scope=provided;inline=net/**|javax/**|org/**|com/**|de/**|javassist/**|*.properties|repackage/**|schema*/**|META-INF/services/**|META-INF/maven/**</Embed-Dependency>
             <Embed-Transitive>true</Embed-Transitive>
             <Bundle-DocURL>${project.url}</Bundle-DocURL>
             <Main-Class>org.apache.tika.cli.TikaCLI</Main-Class>
diff --git a/tika-bundle/pom.xml b/tika-bundle/pom.xml
index cf781c9ac..daa502256 100644
--- a/tika-bundle/pom.xml
+++ b/tika-bundle/pom.xml
@@ -116,7 +116,8 @@
               poi,poi-scratchpad,poi-ooxml,poi-ooxml-schemas,
               xmlbeans, dom4j,
               tagsoup,
-              asm,
+              asm, 
+              isoparser, scannotation, javassist,
               metadata-extractor,
               boilerpipe, rome,
               apache-mime4j-core, apache-mime4j-dom

Commit:
fa10b69d9a0d19894d65d15dfb92d0087af13e56
Nick Burch
nick@apache.org
2012-01-28 20:53:46 +0000
TIKA-852 Initial MP4 Parser, powered by MP4Parser from Google Code
diff --git a/tika-parsers/pom.xml b/tika-parsers/pom.xml
index ba8df5684..2d946f814 100644
--- a/tika-parsers/pom.xml
+++ b/tika-parsers/pom.xml
@@ -138,6 +138,11 @@
       <artifactId>asm</artifactId>
       <version>3.1</version>
     </dependency>
+    <dependency>
+      <groupId>com.googlecode.mp4parser</groupId> 
+      <artifactId>isoparser</artifactId> 
+      <version>1.0-beta-5</version> 
+    </dependency> 
     <dependency>
        <groupId>com.drewnoakes</groupId>
        <artifactId>metadata-extractor</artifactId>
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java b/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java
new file mode 100644
index 000000000..149ea495a
--- /dev/null
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mp4/MP4Parser.java
@@ -0,0 +1,297 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.parser.mp4;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.util.Arrays;
+import java.util.Collections;
+import java.util.Date;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+
+import org.apache.tika.exception.TikaException;
+import org.apache.tika.io.IOUtils;
+import org.apache.tika.io.TikaInputStream;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.Property;
+import org.apache.tika.metadata.XMPDM;
+import org.apache.tika.mime.MediaType;
+import org.apache.tika.parser.AbstractParser;
+import org.apache.tika.parser.ParseContext;
+import org.apache.tika.sax.XHTMLContentHandler;
+import org.xml.sax.ContentHandler;
+import org.xml.sax.SAXException;
+
+import com.coremedia.iso.IsoBufferWrapper;
+import com.coremedia.iso.IsoBufferWrapperImpl;
+import com.coremedia.iso.IsoFile;
+import com.coremedia.iso.boxes.AbstractContainerBox;
+import com.coremedia.iso.boxes.Box;
+import com.coremedia.iso.boxes.FileTypeBox;
+import com.coremedia.iso.boxes.MetaBox;
+import com.coremedia.iso.boxes.MovieBox;
+import com.coremedia.iso.boxes.MovieHeaderBox;
+import com.coremedia.iso.boxes.TrackBox;
+import com.coremedia.iso.boxes.TrackHeaderBox;
+import com.coremedia.iso.boxes.UserDataBox;
+import com.coremedia.iso.boxes.apple.AbstractAppleMetaDataBox;
+import com.coremedia.iso.boxes.apple.AppleAlbumBox;
+import com.coremedia.iso.boxes.apple.AppleArtistBox;
+import com.coremedia.iso.boxes.apple.AppleCommentBox;
+import com.coremedia.iso.boxes.apple.AppleCustomGenreBox;
+import com.coremedia.iso.boxes.apple.AppleEncoderBox;
+import com.coremedia.iso.boxes.apple.AppleItemListBox;
+import com.coremedia.iso.boxes.apple.AppleRecordingYearBox;
+import com.coremedia.iso.boxes.apple.AppleStandardGenreBox;
+import com.coremedia.iso.boxes.apple.AppleTrackAuthorBox;
+import com.coremedia.iso.boxes.apple.AppleTrackNumberBox;
+import com.coremedia.iso.boxes.apple.AppleTrackTitleBox;
+
+/**
+ * Parser for the MP4 media container format, as well as the older
+ *  QuickTime format that MP4 is based on.
+ * 
+ * This uses the MP4Parser project from http://code.google.com/p/mp4parser/
+ *  to do the underlying parsing
+ */
+public class MP4Parser extends AbstractParser {
+    /** Serial version UID */
+    private static final long serialVersionUID = 84011216792285L;
+    
+    // Ensure this stays in Sync with the entries in tika-mimetypes.xml
+    private static final Map<MediaType,List<String>> typesMap = new HashMap<MediaType, List<String>>();
+    static {
+       // All types should be 4 bytes long, space padded as needed
+       typesMap.put(MediaType.audio("mp4"), Arrays.asList(
+             "M4A ", "M4B ", "F4A ", "F4B "));
+       typesMap.put(MediaType.video("3gpp"), Arrays.asList(
+             "3ge6", "3ge7", "3gg6", "3gp1", "3gp2", "3gp3", "3gp4", "3gp5", "3gp6", "3gs7"));
+       typesMap.put(MediaType.video("3gpp2"), Arrays.asList(
+             "3g2a", "3g2b", "3g2c"));
+       typesMap.put(MediaType.video("mp4"), Arrays.asList(
+             "mp41", "mp42"));
+       typesMap.put(MediaType.video("x-m4v"), Arrays.asList(
+             "M4V ", "M4VH", "M4VP"));
+       
+       typesMap.put(MediaType.video("quicktime"), Collections.<String>emptyList());
+       typesMap.put(MediaType.application("mp4"), Collections.<String>emptyList());
+    }
+
+    private static final Set<MediaType> SUPPORTED_TYPES =
+       Collections.unmodifiableSet(typesMap.keySet());
+
+    public Set<MediaType> getSupportedTypes(ParseContext context) {
+        return SUPPORTED_TYPES;
+    }
+
+
+    public void parse(
+            InputStream stream, ContentHandler handler,
+            Metadata metadata, ParseContext context)
+            throws IOException, SAXException, TikaException {
+        IsoBufferWrapper isoBufferWrapper = null;
+        TikaInputStream tstream = TikaInputStream.cast(stream);
+
+        // Have MP4Parser process the stream / file
+        if (tstream != null && tstream.hasFile()) {
+           isoBufferWrapper = new IsoBufferWrapperImpl(tstream.getFile());
+        } else {
+           isoBufferWrapper = new IsoBufferWrapperImpl(
+                 IOUtils.toByteArray(stream));
+        }
+        IsoFile isoFile = new IsoFile(isoBufferWrapper);
+        isoFile.parse();
+        
+        
+        // Grab the file type box
+        FileTypeBox fileType = getOrNull(isoFile, FileTypeBox.class);
+        if (fileType != null) {
+           // Identify the type
+           MediaType type = MediaType.application("mp4");
+           for (MediaType t : typesMap.keySet()) {
+              if (typesMap.get(t).contains(fileType.getMajorBrand())) {
+                 type = t;
+                 break;
+              }
+           }
+           metadata.set(Metadata.CONTENT_TYPE, type.toString());
+           
+           if (type.getType().equals("audio")) {
+              metadata.set(XMPDM.AUDIO_COMPRESSOR, fileType.getMajorBrand().trim());
+           }
+        } else {
+           // Some older QuickTime files lack the FileType
+           metadata.set(Metadata.CONTENT_TYPE, "video/quicktime");
+        }
+        
+        
+        // Get the main MOOV box
+        MovieBox moov = getOrNull(isoFile, MovieBox.class);
+        if (moov == null) {
+           // Bail out
+           return;
+        }
+
+        
+        XHTMLContentHandler xhtml = new XHTMLContentHandler(handler, metadata);
+        xhtml.startDocument();
+        
+        
+        // Pull out some information from the header box
+        MovieHeaderBox mHeader = getOrNull(moov, MovieHeaderBox.class);
+        if (mHeader != null) {
+           // Get the creation and modification dates
+           metadata.set(
+                 Metadata.CREATION_DATE, 
+                 MP4TimeToDate(mHeader.getCreationTime())
+           );
+           metadata.set(
+                 Property.externalDate(Metadata.MODIFIED), // TODO Should be a real property
+                 MP4TimeToDate(mHeader.getModificationTime())
+           );
+           
+           // Get the duration
+           double durationSeconds = ((double)mHeader.getDuration()) / mHeader.getTimescale();
+           // TODO Use this
+           
+           // The timescale is normally the sampling rate
+           metadata.set(XMPDM.AUDIO_SAMPLE_RATE, (int)mHeader.getTimescale());
+        }
+        
+        
+        // Get some more information from the track header
+        // TODO Decide how to handle multiple tracks
+        List<TrackBox> tb = moov.getBoxes(TrackBox.class);
+        if (tb.size() > 0) {
+           TrackHeaderBox header = getOrNull(tb.get(0), TrackHeaderBox.class);
+           if (header != null) {
+              // Get the creation and modification dates
+              metadata.set(
+                    Metadata.CREATION_DATE, 
+                    MP4TimeToDate(header.getCreationTime())
+              );
+              metadata.set(
+                    Property.externalDate(Metadata.MODIFIED), // TODO Should be a real property
+                    MP4TimeToDate(header.getModificationTime())
+              );
+              
+              // Get the video with and height
+              metadata.set(Metadata.IMAGE_WIDTH,  (int)header.getWidth());
+              metadata.set(Metadata.IMAGE_LENGTH, (int)header.getHeight());
+           }
+        }
+        
+        // Get metadata from the User Data Box
+        UserDataBox userData = getOrNull(moov, UserDataBox.class);
+        if (userData != null) {
+           MetaBox meta = getOrNull(userData, MetaBox.class);
+
+           // Check for iTunes Metadata
+           // See http://atomicparsley.sourceforge.net/mpeg-4files.html and
+           //  http://code.google.com/p/mp4v2/wiki/iTunesMetadata for more on these
+           AppleItemListBox apple = getOrNull(meta, AppleItemListBox.class);
+           if (apple != null) {
+              // Title
+              AppleTrackTitleBox title = getOrNull(apple, AppleTrackTitleBox.class);
+              addMetadata(Metadata.TITLE, metadata, title);
+
+              // Artist
+              AppleArtistBox artist = getOrNull(apple, AppleArtistBox.class);
+              addMetadata(Metadata.AUTHOR, metadata, artist);
+              addMetadata(XMPDM.ARTIST, metadata, artist);
+              
+              // Album
+              AppleAlbumBox album = getOrNull(apple, AppleAlbumBox.class);
+              addMetadata(XMPDM.ALBUM, metadata, album);
+              
+              // Composer
+              AppleTrackAuthorBox composer = getOrNull(apple, AppleTrackAuthorBox.class);
+              addMetadata(XMPDM.COMPOSER, metadata, composer);
+              
+              // Genre
+              AppleStandardGenreBox sGenre = getOrNull(apple, AppleStandardGenreBox.class);
+              AppleCustomGenreBox   cGenre = getOrNull(apple, AppleCustomGenreBox.class);
+              addMetadata(XMPDM.GENRE, metadata, sGenre);
+              addMetadata(XMPDM.GENRE, metadata, cGenre);
+              
+              // Year
+              AppleRecordingYearBox year = getOrNull(apple, AppleRecordingYearBox.class);
+              addMetadata(XMPDM.RELEASE_DATE, metadata, year);
+              
+              // Track number 
+              AppleTrackNumberBox trackNum = getOrNull(apple, AppleTrackNumberBox.class);
+              if (trackNum != null) {
+                 metadata.set(XMPDM.TRACK_NUMBER, trackNum.getTrackNumber());
+                 //metadata.set(XMPDM.NUMBER_OF_TRACKS, trackNum.getNumberOfTracks()); // TODO
+              }
+              
+              // Comment
+              AppleCommentBox comment = getOrNull(apple, AppleCommentBox.class);
+              addMetadata(XMPDM.LOG_COMMENT, metadata, comment);
+              
+              // Encoder
+              AppleEncoderBox encoder = getOrNull(apple, AppleEncoderBox.class);
+              // addMetadata(XMPDM.???, metadata, encoder); // TODO
+              
+              
+              // As text
+              for (Box box : apple.getBoxes()) {
+                 if (box instanceof AbstractAppleMetaDataBox) {
+                    xhtml.element("p", ((AbstractAppleMetaDataBox)box).getValue());
+                 }
+              }
+           }
+           
+           // TODO Check for other kinds too
+        }
+
+        // All done
+        xhtml.endDocument();
+    }
+    
+    private static void addMetadata(String key, Metadata m, AbstractAppleMetaDataBox metadata) {
+       if (metadata != null) {
+          m.add(key, metadata.getValue());
+       }
+    }
+    private static void addMetadata(Property prop, Metadata m, AbstractAppleMetaDataBox metadata) {
+       if (metadata != null) {
+          m.set(prop, metadata.getValue());
+       }
+    }
+    
+    /**
+     * MP4 Dates are stored as 32-bit integer, which represent the seconds 
+     * since midnight, January 1, 1904, and are generally in UTC 
+     */
+    private static Date MP4TimeToDate(long mp4Time) {
+       long unix = mp4Time - EPOC_AS_MP4_TIME;
+       return new Date(unix*1000);
+    }
+    private static final long EPOC_AS_MP4_TIME = 2082844800l;
+    
+    private static <T extends Box> T getOrNull(AbstractContainerBox box, Class<T> clazz) {
+       List<T> boxes = box.getBoxes(clazz);
+       if (boxes.size() == 0) {
+          return null;
+       }
+       return boxes.get(0);
+    }
+}
diff --git a/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.parser.Parser b/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.parser.Parser
index c1090aecd..60e4358ff 100644
--- a/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.parser.Parser
+++ b/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.parser.Parser
@@ -33,6 +33,7 @@ org.apache.tika.parser.microsoft.OfficeParser
 org.apache.tika.parser.microsoft.TNEFParser
 org.apache.tika.parser.microsoft.ooxml.OOXMLParser
 org.apache.tika.parser.mp3.Mp3Parser
+org.apache.tika.parser.mp4.MP4Parser
 org.apache.tika.parser.hdf.HDFParser
 org.apache.tika.parser.netcdf.NetCDFParser
 org.apache.tika.parser.odf.OpenDocumentParser
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/mp4/MP4ParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/mp4/MP4ParserTest.java
new file mode 100644
index 000000000..a0f733fe8
--- /dev/null
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/mp4/MP4ParserTest.java
@@ -0,0 +1,98 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.parser.mp4;
+
+import java.io.InputStream;
+
+import junit.framework.TestCase;
+
+import org.apache.tika.io.TikaInputStream;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.XMPDM;
+import org.apache.tika.parser.AutoDetectParser;
+import org.apache.tika.parser.ParseContext;
+import org.apache.tika.parser.Parser;
+import org.apache.tika.sax.BodyContentHandler;
+import org.xml.sax.ContentHandler;
+
+/**
+ * Test case for parsing mp4 files.
+ * 
+ * TODO Work out why this test passes in Eclipse, but fails from Maven
+ */
+public abstract class MP4ParserTest extends TestCase {
+    /**
+     * Test that we can extract information from
+     *  a M4A MP4 Audio file
+     */
+    public void testMP4ParsingAudio() throws Exception {
+        Parser parser = new AutoDetectParser(); // Should auto-detect!
+        ContentHandler handler = new BodyContentHandler();
+        Metadata metadata = new Metadata();
+
+        InputStream stream = MP4ParserTest.class.getResourceAsStream(
+                "/test-documents/testMP4.m4a");
+        try {
+            parser.parse(stream, handler, metadata, new ParseContext());
+        } finally {
+            stream.close();
+        }
+
+        // Check core properties
+        assertEquals("audio/mp4", metadata.get(Metadata.CONTENT_TYPE));
+        assertEquals("Test Title", metadata.get(Metadata.TITLE));
+        assertEquals("Test Artist", metadata.get(Metadata.AUTHOR));
+        assertEquals("2012-01-28T18:39:18Z", metadata.get(Metadata.CREATION_DATE));
+        assertEquals("2012-01-28T18:40:25Z", metadata.get(Metadata.MODIFIED));
+
+        // Check the textual contents
+        String content = handler.toString();
+        assertTrue(content.contains("Test Title"));
+        assertTrue(content.contains("Test Artist"));
+        assertTrue(content.contains("Test Album"));
+        assertTrue(content.contains("2008"));
+        assertTrue(content.contains("Test Comment"));
+        assertTrue(content.contains("Test Genre"));
+        
+        // Check XMPDM-typed audio properties
+        assertEquals("Test Album", metadata.get(XMPDM.ALBUM));
+        assertEquals("Test Artist", metadata.get(XMPDM.ARTIST));
+        assertEquals("Test Composer", metadata.get(XMPDM.COMPOSER));
+        assertEquals("2008", metadata.get(XMPDM.RELEASE_DATE));
+        assertEquals("Test Genre", metadata.get(XMPDM.GENRE));
+        assertEquals("Test Comments", metadata.get(XMPDM.LOG_COMMENT.getName()));
+        assertEquals("1", metadata.get(XMPDM.TRACK_NUMBER));
+        
+        assertEquals("44100", metadata.get(XMPDM.AUDIO_SAMPLE_RATE));
+        //assertEquals("Stereo", metadata.get(XMPDM.AUDIO_CHANNEL_TYPE)); // TODO Extract
+        assertEquals("M4A", metadata.get(XMPDM.AUDIO_COMPRESSOR));
+        
+        
+        // Check again by file, rather than stream
+        TikaInputStream tstream = TikaInputStream.get(
+              MP4ParserTest.class.getResourceAsStream("/test-documents/testMP4.m4a"));
+        tstream.getFile();
+        try {
+           parser.parse(tstream, handler, metadata, new ParseContext());
+        } finally {
+           tstream.close();
+        }
+    }
+    
+    // TODO Test a MP4 Video file
+    // TODO Test an old QuickTime Video File
+}

Commit:
20dfa5a12ea97baaed6ff89c83fdb82a95d0db90
Nick Burch
nick@apache.org
2012-01-28 18:42:35 +0000
TIKA-852 Sample MP4 Audio (M4A) file
diff --git a/tika-parsers/src/test/resources/test-documents/testMP4.m4a b/tika-parsers/src/test/resources/test-documents/testMP4.m4a
new file mode 100644
index 000000000..a9bc73127
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testMP4.m4a differ

Commit:
bd764ccb90cb61f40f22a0da1327e29f90590488
Nick Burch
nick@apache.org
2012-01-28 17:59:30 +0000
TIKA-851 Add another MP4 audio extension
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 92a7cbbfd..2195bb011 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -3062,6 +3062,7 @@
     </magic>
     <glob pattern="*.mp4a"/>
     <glob pattern="*.m4a"/>
+    <glob pattern="*.m4b"/>
   </mime-type>
   <mime-type type="audio/mp4a-latm"/>
   <mime-type type="audio/mpa"/>

Commit:
7901a55eb6421f6b505f45a649ef41e717db6f5b
Nick Burch
nick@apache.org
2012-01-27 17:03:03 +0000
TIKA-842 Avoid property name clash with IPTC and the old-style values from DublinCore
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/DublinCore.java b/tika-core/src/main/java/org/apache/tika/metadata/DublinCore.java
index 34d82a615..bb8fd9683 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/DublinCore.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/DublinCore.java
@@ -19,6 +19,8 @@ package org.apache.tika.metadata;
 /**
  * A collection of Dublin Core metadata names.
  * 
+ * TODO Prefix these keys with the dc: prefix
+ * 
  * @see <a href="http://dublincore.org">dublincore.org</a>
  */
 public interface DublinCore {
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/IPTC.java b/tika-core/src/main/java/org/apache/tika/metadata/IPTC.java
index be01ebc83..2e3b3cddd 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/IPTC.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/IPTC.java
@@ -24,6 +24,8 @@ package org.apache.tika.metadata;
  * IPTC Photo Metadata schema. This is a collection of
  * {@link Property property definition} constants for the Photo Metadata
  * properties defined in the IPTC standard.
+ * 
+ * Note - the Properties with the _DCPROPERTY are expected to change shortly
  *
  * @since Apache Tika 1.1
  * @see <a href="http://www.iptc.org/std/photometadata/specification/IPTC-PhotoMetadata-201007_1.pdf">IPTC Photo Metadata</a>
@@ -109,7 +111,7 @@ public interface IPTC {
 	 * <p>
 	 * Maps to this IIM property: 2:120 Caption/Abstract
 	 */
-	Property DESCRIPTION = Property.internalText(
+	Property DESCRIPTION_DCPROPERTY = Property.internalText(
 			PREFIX_DC + PREFIX_DELIMITER + "description");
 
 	/**
@@ -144,7 +146,7 @@ public interface IPTC {
 	 * <p>
 	 * Maps to this IIM property: 2:25 Keywords
 	 */
-	Property KEYWORDS = Property.internalTextBag(
+	Property KEYWORDS_DCPROPERTY = Property.internalTextBag(
 			PREFIX_DC + PREFIX_DELIMITER + "subject");
 
 	/**
@@ -278,7 +280,7 @@ public interface IPTC {
 	 * <p>
 	 * Maps to this IIM property: 2:05 Object Name
 	 */
-	Property TITLE = Property.internalText(
+	Property TITLE_DCPROPERTY = Property.internalText(
 			PREFIX_DC + PREFIX_DELIMITER + "title");
 
 	/**
@@ -316,7 +318,7 @@ public interface IPTC {
 	 * <p>
 	 * Maps to this IIM property: 2:80 By-line
 	 */
-	Property CREATOR = Property.internalText(
+	Property CREATOR_DCPROPERTY = Property.internalText(
 			PREFIX_DC + PREFIX_DELIMITER + "creator");
 
 	/**
@@ -490,12 +492,12 @@ public interface IPTC {
 	/**
 	 * As this metadata element pertains to distribution management, it was not
 	 * adopted. However, this data is still synchronised with the XMP property
-	 * photoshop:Urgency, and hence, available for future use, but outside the
+	 * [photoshop:Urgency], and hence, available for future use, but outside the
 	 * IPTC Core.
 	 *
 	 * @deprecated
 	 */
-	Property URGENCY = Property.internalText(
+	Property PHOTOSHOP_URGENCY = Property.internalText(
 			PREFIX_PHOTOSHOP + PREFIX_DELIMITER + "Urgency");
 
 	/**
@@ -508,7 +510,7 @@ public interface IPTC {
 	 *
 	 * @deprecated
 	 */
-	Property CATEGORY = Property.internalText(
+	Property PHOTOSHOP_CATEGORY = Property.internalText(
 			PREFIX_PHOTOSHOP + PREFIX_DELIMITER + "Category");
 
 	/**
@@ -519,7 +521,7 @@ public interface IPTC {
 	 *
 	 * @deprecated
 	 */
-	Property SUPPLEMENTAL_CATEGORIES = Property.internalTextBag(
+	Property PHOTOSHOP_SUPPLEMENTAL_CATEGORIES = Property.internalTextBag(
 			PREFIX_PHOTOSHOP + PREFIX_DELIMITER + "SupplementalCategories");
 
 	/**
@@ -1197,10 +1199,10 @@ public interface IPTC {
 		CITY,
 		COUNTRY,
 		COUNTRY_CODE,
-		DESCRIPTION,
+		DESCRIPTION_DCPROPERTY,
 		HEADLINE,
 		INTELLECTUAL_GENRE,
-		KEYWORDS,
+		KEYWORDS_DCPROPERTY,
 		PROVINCE_OR_STATE,
 		SCENE_CODE,
 		SUBJECT_CODE,
@@ -1209,9 +1211,9 @@ public interface IPTC {
 		DESCRIPTION_WRITER,
 		INSTRUCTIONS,
 		JOB_ID,
-		TITLE,
+		TITLE_DCPROPERTY,
 		COPYRIGHT_NOTICE,
-		CREATOR,
+		CREATOR_DCPROPERTY,
 		CREATORS_JOB_TITLE,
 		CREDIT_LINE,
 		RIGHTS_USAGE_TERMS,

Commit:
34c029356e5548badbe4e36006036d1c6a0086af
Nick Burch
nick@apache.org
2012-01-27 16:49:20 +0000
TIKA-842 IPTC Metadata Properties, including full descriptions of all the properties taken from the Specification, along with appropriate License/Notice information for this.
diff --git a/LICENSE.txt b/LICENSE.txt
index 65491e88c..2c98686b5 100644
--- a/LICENSE.txt
+++ b/LICENSE.txt
@@ -300,3 +300,25 @@ Parsing functionality provided by the NetCDF Java Library (http://www.unidata.uc
     DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION 
     OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE ACCESS, 
     USE OR PERFORMANCE OF THIS SOFTWARE.
+
+
+IPTC Photo Metadata descriptions are taken from the IPTC Photo Metadata 
+Standard, July 2010, Copyright 2010 International Press Telecommunications 
+Council.
+
+  1. The Specifications and Materials are licensed for use only on the condition that you agree to be bound by the terms of this license. Subject to this and other licensing requirements contained herein, you may, on a non-exclusive basis, use the Specifications and Materials.
+  2. The IPTC openly provides the Specifications and Materials for voluntary use by individuals, partnerships, companies, corporations, organizations and any other entity for use at the entity's own risk. This disclaimer, license and release is intended to apply to the IPTC, its officers, directors, agents, representatives, members, contributors, affiliates, contractors, or co-venturers acting jointly or severally.
+  3. The Document and translations thereof may be copied and furnished to others, and derivative works that comment on or otherwise explain it or assist in its implementation may be prepared, copied, published and distributed, in whole or in part, without restriction of any kind, provided that the copyright and license notices and references to the IPTC appearing in the Document and the terms of this Specifications License Agreement are included on all such copies and derivative works. Further, upon the receipt of written permission from the IPTC, the Document may be modified for the purpose of developing applications that use IPTC Specifications or as required to translate the Document into languages other than English.
+  4. Any use, duplication, distribution, or exploitation of the Document and Specifications and Materials in any manner is at your own risk.
+  5. NO WARRANTY, EXPRESSED OR IMPLIED, IS MADE REGARDING THE ACCURACY, ADEQUACY, COMPLETENESS, LEGALITY, RELIABILITY OR USEFULNESS OF ANY INFORMATION CONTAINED IN THE DOCUMENT OR IN ANY SPECIFICATION OR OTHER PRODUCT OR SERVICE PRODUCED OR SPONSORED BY THE IPTC. THE DOCUMENT AND THE INFORMATION CONTAINED HEREIN AND INCLUDED IN ANY SPECIFICATION OR OTHER PRODUCT OR SERVICE OF THE IPTC IS PROVIDED ON AN "AS IS" BASIS. THE IPTC DISCLAIMS ALL WARRANTIES OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, ANY ACTUAL OR ASSERTED WARRANTY OF NON-INFRINGEMENT OF PROPRIETARY RIGHTS, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE. NEITHER THE IPTC NOR ITS CONTRIBUTORS SHALL BE HELD LIABLE FOR ANY IMPROPER OR INCORRECT USE OF INFORMATION. NEITHER THE IPTC NOR ITS CONTRIBUTORS ASSUME ANY RESPONSIBILITY FOR ANYONE'S USE OF INFORMATION PROVIDED BY THE IPTC. IN NO EVENT SHALL THE IPTC OR ITS CONTRIBUTORS BE LIABLE TO ANYONE FOR DAMAGES OF ANY KIND, INCLUDING BUT NOT LIMITED TO, COMPENSATORY DAMAGES, LOST PROFITS, LOST DATA OR ANY FORM OF SPECIAL, INCIDENTAL, INDIRECT, CONSEQUENTIAL OR PUNITIVE DAMAGES OF ANY KIND WHETHER BASED ON BREACH OF CONTRACT OR WARRANTY, TORT, PRODUCT LIABILITY OR OTHERWISE.
+  6. The IPTC takes no position regarding the validity or scope of any Intellectual Property or other rights that might be claimed to pertain to the implementation or use of the technology described in the Document or the extent to which any license under such rights might or might not be available. The IPTC does not represent that it has made any effort to identify any such rights. Copies of claims of rights made available for publication, assurances of licenses to be made available, or the result of an attempt made to obtain a general license or permission for the use of such proprietary rights by implementers or users of the Specifications and Materials, can be obtained from the Managing Director of the IPTC.
+  7. By using the Specifications and Materials including the Document in any manner or for any purpose, you release the IPTC from all liabilities, claims, causes of action, allegations, losses, injuries, damages, or detriments of any nature arising from or relating to the use of the Specifications, Materials or any portion thereof. You further agree not to file a lawsuit, make a claim, or take any other formal or informal legal action against the IPTC, resulting from your acquisition, use, duplication, distribution, or exploitation of the Specifications, Materials or any portion thereof. Finally, you hereby agree that the IPTC is not liable for any direct, indirect, special or consequential damages arising from or relating to your acquisition, use, duplication, distribution, or exploitation of the Specifications, Materials or any portion thereof.
+  8. Specifications and Materials may be downloaded or copied provided that ALL copies retain the ownership, copyright and license notices.
+  9. Materials may not be edited, modified, or presented in a context that creates a misleading or false impression or statement as to the positions, actions, or statements of the IPTC.
+  10. The name and trademarks of the IPTC may not be used in advertising, publicity, or in relation to products or services and their names without the specific, written prior permission of the IPTC. Any permitted use of the trademarks of the IPTC, whether registered or not, shall be accompanied by an appropriate mark and attribution, as agreed with the IPTC.
+  11. Specifications may be extended by both members and non-members to provide additional functionality (Extension Specifications) provided that there is a clear recognition of the IPTC IP and its ownership in the Extension Specifications and the related documentation and provided that the extensions are clearly identified and provided that a perpetual license is granted by the creator of the Extension Specifications for other members and non-members to use the Extension Specifications and to continue extensions of the Extension Specifications. The IPTC does not waive any of its rights in the Specifications and Materials in this context. The Extension Specifications may be considered the intellectual property of their creator. The IPTC expressly disclaims any responsibility for damage caused by an extension to the Specifications.
+  12. Specifications and Materials may be included in derivative work of both members and non-members provided that there is a clear recognition of the IPTC IP and its ownership in the derivative work and its related documentation. The IPTC does not waive any of its rights in the Specifications and Materials in this context. Derivative work in its entirety may be considered the intellectual property of the creator of the work .The IPTC expressly disclaims any responsibility for damage caused when its IP is used in a derivative context.
+  13. This Specifications License Agreement is perpetual subject to your conformance to the terms of this Agreement. The IPTC may terminate this Specifications License Agreement immediately upon your breach of this Agreement and, upon such termination you will cease all use, duplication, distribution, and/or exploitation in any manner of the Specifications and Materials.
+  14. This Specifications License Agreement reflects the entire agreement of the parties regarding the subject matter hereof and supersedes all prior agreements or representations regarding such matters, whether written or oral. To the extent any portion or provision of this Specifications License Agreement is found to be illegal or unenforceable, then the remaining provisions of this Specifications License Agreement will remain in full force and effect and the illegal or unenforceable provision will be construed to give it such effect as it may properly have that is consistent with the intentions of the parties.
+  15. This Specifications License Agreement may only be modified in writing signed by an authorized representative of the IPTC.
+  16. This Specifications License Agreement is governed by the law of United Kingdom, as such law is applied to contracts made and fully performed in the United Kingdom. Any disputes arising from or relating to this Specifications License Agreement will be resolved in the courts of the United Kingdom. You consent to the jurisdiction of such courts over you and covenant not to assert before such courts any objection to proceeding in such forums.
diff --git a/NOTICE.txt b/NOTICE.txt
index de8590f62..a1bf62058 100644
--- a/NOTICE.txt
+++ b/NOTICE.txt
@@ -12,3 +12,4 @@ Grizzly (http://grizzly.java.net/)
 
 OpenCSV: Copyright 2005 Bytecode Pty Ltd. Licensed under the Apache License, Version 2.0
 
+IPTC Photo Metadata descriptions Copyright 2010 International Press Telecommunications Council.
diff --git a/tika-core/src/main/appended-resources/META-INF/LICENSE b/tika-core/src/main/appended-resources/META-INF/LICENSE
index de6817057..b834fe542 100644
--- a/tika-core/src/main/appended-resources/META-INF/LICENSE
+++ b/tika-core/src/main/appended-resources/META-INF/LICENSE
@@ -34,3 +34,25 @@ MIME type information from file-4.26.tar.gz (http://www.darwinsys.com/file/)
     LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
     OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
     SUCH DAMAGE.
+
+
+IPTC Photo Metadata descriptions are taken from the IPTC Photo Metadata 
+Standard, July 2010, Copyright 2010 International Press Telecommunications 
+Council.
+
+  1. The Specifications and Materials are licensed for use only on the condition that you agree to be bound by the terms of this license. Subject to this and other licensing requirements contained herein, you may, on a non-exclusive basis, use the Specifications and Materials.
+  2. The IPTC openly provides the Specifications and Materials for voluntary use by individuals, partnerships, companies, corporations, organizations and any other entity for use at the entity's own risk. This disclaimer, license and release is intended to apply to the IPTC, its officers, directors, agents, representatives, members, contributors, affiliates, contractors, or co-venturers acting jointly or severally.
+  3. The Document and translations thereof may be copied and furnished to others, and derivative works that comment on or otherwise explain it or assist in its implementation may be prepared, copied, published and distributed, in whole or in part, without restriction of any kind, provided that the copyright and license notices and references to the IPTC appearing in the Document and the terms of this Specifications License Agreement are included on all such copies and derivative works. Further, upon the receipt of written permission from the IPTC, the Document may be modified for the purpose of developing applications that use IPTC Specifications or as required to translate the Document into languages other than English.
+  4. Any use, duplication, distribution, or exploitation of the Document and Specifications and Materials in any manner is at your own risk.
+  5. NO WARRANTY, EXPRESSED OR IMPLIED, IS MADE REGARDING THE ACCURACY, ADEQUACY, COMPLETENESS, LEGALITY, RELIABILITY OR USEFULNESS OF ANY INFORMATION CONTAINED IN THE DOCUMENT OR IN ANY SPECIFICATION OR OTHER PRODUCT OR SERVICE PRODUCED OR SPONSORED BY THE IPTC. THE DOCUMENT AND THE INFORMATION CONTAINED HEREIN AND INCLUDED IN ANY SPECIFICATION OR OTHER PRODUCT OR SERVICE OF THE IPTC IS PROVIDED ON AN "AS IS" BASIS. THE IPTC DISCLAIMS ALL WARRANTIES OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, ANY ACTUAL OR ASSERTED WARRANTY OF NON-INFRINGEMENT OF PROPRIETARY RIGHTS, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE. NEITHER THE IPTC NOR ITS CONTRIBUTORS SHALL BE HELD LIABLE FOR ANY IMPROPER OR INCORRECT USE OF INFORMATION. NEITHER THE IPTC NOR ITS CONTRIBUTORS ASSUME ANY RESPONSIBILITY FOR ANYONE'S USE OF INFORMATION PROVIDED BY THE IPTC. IN NO EVENT SHALL THE IPTC OR ITS CONTRIBUTORS BE LIABLE TO ANYONE FOR DAMAGES OF ANY KIND, INCLUDING BUT NOT LIMITED TO, COMPENSATORY DAMAGES, LOST PROFITS, LOST DATA OR ANY FORM OF SPECIAL, INCIDENTAL, INDIRECT, CONSEQUENTIAL OR PUNITIVE DAMAGES OF ANY KIND WHETHER BASED ON BREACH OF CONTRACT OR WARRANTY, TORT, PRODUCT LIABILITY OR OTHERWISE.
+  6. The IPTC takes no position regarding the validity or scope of any Intellectual Property or other rights that might be claimed to pertain to the implementation or use of the technology described in the Document or the extent to which any license under such rights might or might not be available. The IPTC does not represent that it has made any effort to identify any such rights. Copies of claims of rights made available for publication, assurances of licenses to be made available, or the result of an attempt made to obtain a general license or permission for the use of such proprietary rights by implementers or users of the Specifications and Materials, can be obtained from the Managing Director of the IPTC.
+  7. By using the Specifications and Materials including the Document in any manner or for any purpose, you release the IPTC from all liabilities, claims, causes of action, allegations, losses, injuries, damages, or detriments of any nature arising from or relating to the use of the Specifications, Materials or any portion thereof. You further agree not to file a lawsuit, make a claim, or take any other formal or informal legal action against the IPTC, resulting from your acquisition, use, duplication, distribution, or exploitation of the Specifications, Materials or any portion thereof. Finally, you hereby agree that the IPTC is not liable for any direct, indirect, special or consequential damages arising from or relating to your acquisition, use, duplication, distribution, or exploitation of the Specifications, Materials or any portion thereof.
+  8. Specifications and Materials may be downloaded or copied provided that ALL copies retain the ownership, copyright and license notices.
+  9. Materials may not be edited, modified, or presented in a context that creates a misleading or false impression or statement as to the positions, actions, or statements of the IPTC.
+  10. The name and trademarks of the IPTC may not be used in advertising, publicity, or in relation to products or services and their names without the specific, written prior permission of the IPTC. Any permitted use of the trademarks of the IPTC, whether registered or not, shall be accompanied by an appropriate mark and attribution, as agreed with the IPTC.
+  11. Specifications may be extended by both members and non-members to provide additional functionality (Extension Specifications) provided that there is a clear recognition of the IPTC IP and its ownership in the Extension Specifications and the related documentation and provided that the extensions are clearly identified and provided that a perpetual license is granted by the creator of the Extension Specifications for other members and non-members to use the Extension Specifications and to continue extensions of the Extension Specifications. The IPTC does not waive any of its rights in the Specifications and Materials in this context. The Extension Specifications may be considered the intellectual property of their creator. The IPTC expressly disclaims any responsibility for damage caused by an extension to the Specifications.
+  12. Specifications and Materials may be included in derivative work of both members and non-members provided that there is a clear recognition of the IPTC IP and its ownership in the derivative work and its related documentation. The IPTC does not waive any of its rights in the Specifications and Materials in this context. Derivative work in its entirety may be considered the intellectual property of the creator of the work .The IPTC expressly disclaims any responsibility for damage caused when its IP is used in a derivative context.
+  13. This Specifications License Agreement is perpetual subject to your conformance to the terms of this Agreement. The IPTC may terminate this Specifications License Agreement immediately upon your breach of this Agreement and, upon such termination you will cease all use, duplication, distribution, and/or exploitation in any manner of the Specifications and Materials.
+  14. This Specifications License Agreement reflects the entire agreement of the parties regarding the subject matter hereof and supersedes all prior agreements or representations regarding such matters, whether written or oral. To the extent any portion or provision of this Specifications License Agreement is found to be illegal or unenforceable, then the remaining provisions of this Specifications License Agreement will remain in full force and effect and the illegal or unenforceable provision will be construed to give it such effect as it may properly have that is consistent with the intentions of the parties.
+  15. This Specifications License Agreement may only be modified in writing signed by an authorized representative of the IPTC.
+  16. This Specifications License Agreement is governed by the law of United Kingdom, as such law is applied to contracts made and fully performed in the United Kingdom. Any disputes arising from or relating to this Specifications License Agreement will be resolved in the courts of the United Kingdom. You consent to the jurisdiction of such courts over you and covenant not to assert before such courts any objection to proceeding in such forums.
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/IPTC.java b/tika-core/src/main/java/org/apache/tika/metadata/IPTC.java
new file mode 100644
index 000000000..be01ebc83
--- /dev/null
+++ b/tika-core/src/main/java/org/apache/tika/metadata/IPTC.java
@@ -0,0 +1,1288 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * IPTC Metadata Descriptions taken from the IPTC Photo Metadata (July 2010) 
+ * standard. These parts Copyright 2010 International Press Telecommunications 
+ * Council.
+ */
+package org.apache.tika.metadata;
+
+/**
+ * IPTC Photo Metadata schema. This is a collection of
+ * {@link Property property definition} constants for the Photo Metadata
+ * properties defined in the IPTC standard.
+ *
+ * @since Apache Tika 1.1
+ * @see <a href="http://www.iptc.org/std/photometadata/specification/IPTC-PhotoMetadata-201007_1.pdf">IPTC Photo Metadata</a>
+ */
+public interface IPTC {
+
+	String NAMESPACE_URI_DC = "http://purl.org/dc/elements/1.1/";
+	String NAMESPACE_URI_IPTC_CORE = "http://iptc.org/std/Iptc4xmpCore/1.0/xmlns/";
+	String NAMESPACE_URI_IPTC_EXT = "http://iptc.org/std/Iptc4xmpExt/2008-02-29/";
+	String NAMESPACE_URI_PHOTOSHOP = "http://ns.adobe.com/photoshop/1.0/";
+	String NAMESPACE_URI_PLUS = "http://ns.useplus.org/ldf/xmp/1.0/";
+	String NAMESPACE_URI_XMP_RIGHTS = "http://ns.adobe.com/xap/1.0/rights/";
+
+	String PREFIX_DC = "dc";
+	String PREFIX_IPTC_CORE = "Iptc4xmpCore";
+	String PREFIX_IPTC_EXT = "Iptc4xmpExt";
+	String PREFIX_PHOTOSHOP = "photoshop";
+	String PREFIX_PLUS = "plus";
+	String PREFIX_XMP_RIGHTS = "xmpRights";
+
+	String PREFIX_DELIMITER = ":";
+
+	/**
+	 * Name of the city the content is focussing on -- either the place shown
+	 * in visual media or referenced by text or audio media. This element is at
+	 * the third level of a top-down geographical hierarchy.
+	 * <p>
+	 * This is a detail of a location with blurred semantics as it does not
+	 * clearly indicate whether it is the location in the image or the location
+	 * the photo was taken - which can be different. Two more concise properties
+	 * are available in IPTC Extension with Location Created and Location Shown
+	 * in the Image.
+	 * <p>
+	 * Maps to this IIM property: 2:90 City
+	 */
+	Property CITY = Property.internalText(
+			PREFIX_PHOTOSHOP + PREFIX_DELIMITER + "City");
+
+	/**
+	 * Full name of the country the content is focussing on -- either the
+	 * country shown in visual media or referenced in text or audio media. This
+	 * element is at the top/first level of a top- down geographical hierarchy.
+	 * The full name should be expressed as a verbal name and not as a code, a
+	 * code should go to the element "CountryCode"
+	 * <p>
+	 * This is a detail of a location with blurred semantics as it does not
+	 * clearly indicate whether it is the location in the image or the location
+	 * the photo was taken - which can be different. Two more concise properties
+	 * are available in IPTC Extension with Location Created and Location Shown
+	 * in the Image.
+	 * <p>
+	 * Maps to this IIM property: 2:101 Country/Primary Location Name
+	 */
+	Property COUNTRY = Property.internalText(
+			PREFIX_PHOTOSHOP + PREFIX_DELIMITER + "Country");
+
+	/**
+	 * Code of the country the content is focussing on -- either the country
+	 * shown in visual media or referenced in text or audio media. This element
+	 * is at the top/first level of a top-down geographical hierarchy. The code
+	 * should be taken from ISO 3166 two or three letter code. The full name of
+	 * a country should go to the "Country" element.
+	 * <p>
+	 * This is a detail of a location with blurred semantics as it does not
+	 * clearly indicate whether it is the location in the image or the location
+	 * the photo was taken - which can be different. Two more concise properties
+	 * are available in IPTC Extension with Location Created and Location Shown
+	 * in the Image.
+	 * <p>
+	 * Maps to this IIM property: 2:100 Country/Primary Location Code
+	 */
+	Property COUNTRY_CODE = Property.internalText(
+			PREFIX_IPTC_CORE + PREFIX_DELIMITER + "CountryCode");
+
+	/**
+	 * A textual description, including captions, of the item's content,
+	 * particularly used where the object is not text.
+	 * <p>
+	 * Note: the XMP property (dc:description) which stores the value of this
+	 * IPTC Core property is of type Lang Alt. Hence any software agent dealing
+	 * with this property must abide to the processing rules for
+	 * Lang Alt value type as specified by the XMP specifications.
+	 * <p>
+	 * Maps to this IIM property: 2:120 Caption/Abstract
+	 */
+	Property DESCRIPTION = Property.internalText(
+			PREFIX_DC + PREFIX_DELIMITER + "description");
+
+	/**
+	 * A brief synopsis of the caption. Headline is not the same as Title.
+	 * <p>
+	 * Maps to this IIM property: 2:105 Headline
+	 */
+	Property HEADLINE = Property.internalText(
+			PREFIX_PHOTOSHOP + PREFIX_DELIMITER + "Headline");
+
+	/**
+	 * Describes the nature, intellectual, artistic or journalistic
+	 * characteristic of a item, not specifically its content.
+	 * <p>
+	 * The IPTC recognizes that the corresponding IPTC Genre NewsCodes needs
+	 * photo specific extension to be better usable with this field (as of the
+	 * release of this standard in the year 2008).
+	 * <p>
+	 * Maps to this IIM property: 2:04 Object Attribute Reference
+	 */
+	Property INTELLECTUAL_GENRE = Property.internalText(
+			PREFIX_IPTC_CORE + PREFIX_DELIMITER + "IntellectualGenre");
+
+	/**
+	 * Keywords to express the subject of the content. Keywords may be free
+	 * text and don't have to be taken from a controlled vocabulary. Codes from
+	 * the controlled vocabulary IPTC Subject NewsCodes must go to the
+	 * "Subject Code" field.
+	 * <p>
+	 * Single values of this field should not be restricted to single words
+	 * but must allow for phrases as well.
+	 * <p>
+	 * Maps to this IIM property: 2:25 Keywords
+	 */
+	Property KEYWORDS = Property.internalTextBag(
+			PREFIX_DC + PREFIX_DELIMITER + "subject");
+
+	/**
+	 * Name of the subregion of a country -- either called province or state or
+	 * anything else -- the content is focussing on -- either the subregion
+	 * shown in visual media or referenced by text or audio media. This element
+	 * is at the second level of a top-down geographical hierarchy.
+	 * <p>
+	 * This is a detail of a location with blurred semantics as it does not
+	 * clearly indicate whether it is the location in the image or the location
+	 * the photo was taken - which can be different. Two more concise properties
+	 * are available in IPTC Extension with Location Created and Location Shown
+	 * in the Image.
+	 * <p>
+	 * Maps to this IIM property: 2:95 Province/State
+	 */
+	Property PROVINCE_OR_STATE = Property.internalText(
+			PREFIX_PHOTOSHOP + PREFIX_DELIMITER + "State");
+
+	/**
+	 * Describes the scene of a news content. Specifies one or more terms
+	 * from the IPTC "Scene-NewsCodes". Each Scene is represented as a string of
+	 * 6 digits in an unordered list.
+	 * <p>
+	 * Note: Only Scene values from this IPTC taxonomy should be used here. More
+	 * about the IPTC Scene-NewsCodes at www.newscodes.org.
+	 */
+	Property SCENE_CODE = Property.internalText(
+			PREFIX_IPTC_CORE + PREFIX_DELIMITER + "Scene");
+
+	/**
+	 * Specifies one or more Subjects from the IPTC Subject-NewsCodes taxonomy
+	 * to categorise the content. Each Subject is represented as a string of 8
+	 * digits in an unordered list.
+	 * <p>
+	 * Note: Only Subjects from a controlled vocabulary should be used here,
+	 * free text has to be put into the Keyword element. More about
+	 * IPTC Subject-NewsCodes at www.newscodes.org.
+	 */
+	Property SUBJECT_CODE = Property.internalTextBag(
+			PREFIX_IPTC_CORE + PREFIX_DELIMITER + "SubjectCode");
+
+	/**
+	 * Name of a sublocation the content is focussing on -- either the
+	 * location shown in visual media or referenced by text or audio media. This
+	 * location name could either be the name of a sublocation to a city or the
+	 * name of a well known location or (natural) monument outside a city. In
+	 * the sense of a sublocation to a city this element is at the fourth level
+	 * of a top-down geographical hierarchy.
+	 * <p>
+	 * This is a detail of a location with blurred semantics as it does not
+	 * clearly indicate whether it is the location in the image or the location
+	 * the photo was taken - which can be different. Two more concise properties
+	 * are available in IPTC Extension with Location Created and Location Shown
+	 * in the Image.
+	 * <p>
+	 * Maps to this IIM property: 2:92 Sublocation
+	 */
+	Property SUBLOCATION = Property.internalText(
+			PREFIX_IPTC_CORE + PREFIX_DELIMITER + "Location");
+
+	/**
+	 * Designates the date and optionally the time the intellectual content was
+	 * created rather than the date of the creation of the physical
+	 * representation.
+	 * <p>
+	 * If a software system requires explicit time values and no time is given
+	 * by the Date Created property the software system should default the time
+	 * to 00:00:00. If the software system does not require an explicit time
+	 * value the time part should be left empty as it is.
+	 * <p>
+	 * Note 1: Any content of the IIM dataset 2:60, Time Created, should be
+	 * merged to this element.
+	 * Note 2: Implementers are encouraged to provide
+	 * the creation date and time from the EXIF data of a digital
+	 * camera to the user for entering this date for the first time.
+	 * <p>
+	 * Maps to this IIM property: 2:55 Date Created
+	 */
+	Property DATE_CREATED = Property.internalDate(
+			PREFIX_PHOTOSHOP + PREFIX_DELIMITER + "DateCreated");
+
+	/**
+	 * Identifier or the name of the person involved in writing, editing or
+	 * correcting the description of the content.
+	 * <p>
+	 * Maps to this IIM property: 2:122 Writer/Editor
+	 */
+	Property DESCRIPTION_WRITER = Property.internalText(
+			PREFIX_PHOTOSHOP + PREFIX_DELIMITER + "CaptionWriter");
+
+	/**
+	 * Any of a number of instructions from the provider or creator to the
+	 * receiver of the item.
+	 * <p>
+	 * Maps to this IIM property: 2:40 Special Instruction
+	 */
+	Property INSTRUCTIONS = Property.internalText(
+			PREFIX_PHOTOSHOP + PREFIX_DELIMITER + "Instructions");
+
+	/**
+	 * Number or identifier for the purpose of improved workflow handling. This
+	 * is a user created identifier related to the job for which the item is
+	 * supplied.
+	 * <p>
+	 * Note: As this identifier references a job of the receiver's workflow it
+	 * must first be issued by the receiver, then transmitted to the creator or
+	 * provider of the news object and finally added by the creator
+	 * to this field.
+	 * <p>
+	 * Maps to this IIM property: 2:103 Original Transmission Reference
+	 */
+	Property JOB_ID = Property.internalText(
+			PREFIX_PHOTOSHOP + PREFIX_DELIMITER + "TransmissionReference");
+
+	/**
+	 * A shorthand reference for the item. Title provides a short human readable
+	 * name which can be a text and/or numeric reference. It is not the same as
+	 * Headline.
+	 * <p>
+	 * Many use the Title field to store the filename of the image, though the
+	 * field may be used in many ways. Formal identifiers are provided by the
+	 * Digital Image Id, or the Registry Entry property of the IPTC Extension.
+	 * <p>
+	 * Note 1: This element aligns with the use of Dublin Core's "Title"
+	 * element.
+	 * Note 2: the XMP property (dc:title) which stores the value of
+	 * this IPTC Core property is of type Lang Alt. Hence any software agent
+	 * dealing with this property must abide to the processing rules for Lang
+	 * Alt value type as specified by the XMP specifications.
+	 * <p>
+	 * Maps to this IIM property: 2:05 Object Name
+	 */
+	Property TITLE = Property.internalText(
+			PREFIX_DC + PREFIX_DELIMITER + "title");
+
+	/**
+	 * Contains any necessary copyright notice for claiming the intellectual
+	 * property for this item and should identify the current owner of the
+	 * copyright for the item. Other entities like the creator of the item may
+	 * be added in the corresponding field. Notes on usage rights should be
+	 * provided in "Rights usage terms".
+	 * <p>
+	 * Copyright ownership can be expressed in a more controlled way using the
+	 * PLUS fields "Copyright Owner", "Copyright Owner ID",
+	 * "Copyright Owner Name" of the IPTC Extension. It is the user's
+	 * responsibility to keep the values of the four fields in sync.
+	 * <p>
+	 * Note: the XMP property (dc:rights) which stores the value of this IPTC
+	 * Core property is of type Lang Alt. Hence any software agent dealing with
+	 * this property must abide to the processing rules for Lang Alt
+	 * value type as specified by the XMP specifications.
+	 * <p>
+	 * Maps to this IIM property: 2:116 Copyright Notice
+	 */
+	Property COPYRIGHT_NOTICE = Property.internalText(
+			PREFIX_DC + PREFIX_DELIMITER + "rights");
+
+	/**
+	 * Contains the name of the person who created the content of this item, a
+	 * photographer for photos, a graphic artist for graphics, or a writer for
+	 * textual news, but in cases where the photographer should not be
+	 * identified the name of a company or organisation may be appropriate.
+	 * <p>
+	 * The creator can be expressed in a more controlled way using the
+	 * "Image Creator" of PLUS in the IPTC Extension additionally. It is the
+	 * user's responsibility to keep the values of the IPTC Core and the PLUS
+	 * fields in sync.
+	 * <p>
+	 * Maps to this IIM property: 2:80 By-line
+	 */
+	Property CREATOR = Property.internalText(
+			PREFIX_DC + PREFIX_DELIMITER + "creator");
+
+	/**
+	 * The creator's contact information provides all necessary information to
+	 * get in contact with the creator of this item and comprises a set of
+	 * sub-properties for proper addressing.
+	 * <p>
+	 * The IPTC Extension Licensor fields should be used instead of these
+	 * Creator's Contact Info fields if you are using IPTC Extension fields. If
+	 * the creator is also the licensor his or her contact information should be
+	 * provided in the Licensor fields.
+	 * <p>
+	 * Note 1 to user interface implementers: All sub-properties of "Creator's
+	 * contact information" should be shown as group on the form.
+	 * Note 2: the
+	 * CreatorContactInfo sub-properties' naming aligns with the vCard
+	 * specification RFC 2426.
+	 */
+	Property CREATORS_CONTACT_INFO = Property.internalText(
+			PREFIX_IPTC_CORE + PREFIX_DELIMITER + "CreatorContactInfo");
+
+	/**
+	 * Contains the job title of the person who created the content of this
+	 * item. As this is sort of a qualifier the Creator element has to be filled
+	 * in as mandatory prerequisite for using Creator's Jobtitle.
+	 * <p>
+	 * Maps to this IIM property: 2:85 By-line Title
+	 */
+	Property CREATORS_JOB_TITLE = Property.internalText(
+			PREFIX_PHOTOSHOP + PREFIX_DELIMITER + "AuthorsPosition");
+
+	/**
+	 * The credit to person(s) and/or organisation(s) required by the supplier
+	 * of the item to be used when published. This is a free-text field.
+	 * <p>
+	 * Note 1: For more formal identifications of the creator or the owner of
+	 * the copyrights of this image other rights properties may be used.
+	 * Note 2:
+	 * This property was named "Credit" by the IIM metadata, then it was renamed
+	 * to "Provider" in IPTC Core 1.0. In IPTC Core 1.1. it has been renamed to
+	 * "Credit Line" as the field is used for this purpose by many users.
+	 * <p>
+	 * Maps to this IIM property: 2:110 Credit
+	 */
+	Property CREDIT_LINE = Property.internalText(
+			PREFIX_PHOTOSHOP + PREFIX_DELIMITER + "Credit");
+
+	/**
+	 * The licensing parameters of the item expressed in free-text.
+	 * <p>
+	 * The PLUS fields of the IPTC Extension can be used in parallel to express
+	 * the licensed usage in more controlled terms.
+	 */
+	Property RIGHTS_USAGE_TERMS = Property.internalText(
+			PREFIX_XMP_RIGHTS + PREFIX_DELIMITER + "UsageTerms");
+
+	/**
+	 * Identifies the original owner of the copyright for the intellectual
+	 * content of the item. This could be an agency, a member of an agency or an
+	 * individual. Source could be different from Creator and from the entities
+	 * in the CopyrightNotice.
+	 * <p>
+	 * The original owner can never change. For that reason the content of this
+	 * property should never be changed or deleted after the information is
+	 * entered following the news object's initial creation.
+	 * <p>
+	 * Maps to this IIM property: 2:115 Source
+	 */
+	Property SOURCE = Property.internalText(
+			PREFIX_PHOTOSHOP + PREFIX_DELIMITER + "Source");
+
+	/**
+	 * The contact information address part. Comprises an optional company name
+	 * and all required information to locate the building or postbox to which
+	 * mail should be sent. To that end, the address is a multiline field.
+	 * <p>
+	 * Note 1: to user interface implementers: This field should be part of a
+	 * "Contact information" group on the form.
+	 * Note 2: the ContactInfo naming aligns with the vCard specification RFC 2426.
+	 */
+	Property CONTACT_INFO_ADDRESS = Property.internalText(
+			PREFIX_IPTC_CORE + PREFIX_DELIMITER + "CiAdrExtadr");
+
+	/**
+	 * The contact information city part.
+	 * <p>
+	 * Note 1: to user interface implementers: This field should be part of a
+	 * "Contact information" group on the form.
+	 * Note 2: the ContactInfo naming aligns with the vCard specification RFC 2426.
+	 */
+	Property CONTACT_INFO_CITY = Property.internalText(
+			PREFIX_IPTC_CORE + PREFIX_DELIMITER + "CiAdrCity");
+
+	/**
+	 * The contact information country part.
+	 * <p>
+	 * Note 1: to user interface implementers: This field should be part of a
+	 * "Contact information" group on the form.
+	 * Note 2: the ContactInfo naming aligns with the vCard specification RFC 2426.
+	 */
+	Property CONTACT_INFO_COUNTRY = Property.internalText(
+			PREFIX_IPTC_CORE + PREFIX_DELIMITER + "CiAdrCtry");
+
+	/**
+	 * The contact information email address part.
+	 * <p>
+	 * Multiple email addresses can be given. May have to be separated by a
+	 * comma in the user interface.
+	 * <p>
+	 * Note 1: to user interface implementers: This field should be part of a
+	 * "Contact information" group on the form.
+	 * Note 2 to user interface
+	 * implementers: provide sufficient space to fill in multiple e-mail
+	 * addresses.
+	 * Note 3: the ContactInfo naming aligns with the vCard
+	 * specification RFC 2426.
+	 */
+	Property CONTACT_INFO_EMAIL = Property.internalText(
+			PREFIX_IPTC_CORE + PREFIX_DELIMITER + "CiEmailWork");
+
+	/**
+	 * The contact information phone number part.
+	 * <p>
+	 * Multiple numbers can be given. May have to be separated by a
+	 * comma in the user interface.
+	 * <p>
+	 * Note 1: to user interface implementers: This field should be part of a
+	 * "Contact information" group on the form.
+	 * Note 2 to user interface
+	 * implementers: provide sufficient space to fill in multiple international
+	 * numbers.
+	 * Note 3: the ContactInfo naming aligns with the vCard
+	 * specification RFC 2426.
+	 */
+	Property CONTACT_INFO_PHONE = Property.internalText(
+			PREFIX_IPTC_CORE + PREFIX_DELIMITER + "CiTelWork");
+
+	/**
+	 * The contact information part denoting the local postal code.
+	 * <p>
+	 * Note 1: to user interface implementers: This field should be part of a
+	 * "Contact information" group on the form.
+	 * Note 2: the ContactInfo naming aligns with the vCard specification RFC 2426.
+	 */
+	Property CONTACT_INFO_POSTAL_CODE = Property.internalText(
+			PREFIX_IPTC_CORE + PREFIX_DELIMITER + "CiAdrPcode");
+
+	/**
+	 * The contact information part denoting regional information such as state or province.
+	 * <p>
+	 * Note 1: to user interface implementers: This field should be part of a
+	 * "Contact information" group on the form.
+	 * Note 2: the ContactInfo naming aligns with the vCard specification RFC 2426.
+	 */
+	Property CONTACT_INFO_STATE_PROVINCE = Property.internalText(
+			PREFIX_IPTC_CORE + PREFIX_DELIMITER + "CiAdrRegion");
+
+	/**
+	 * The contact information web address part. Multiple addresses can be given, separated by a comma.
+	 * <p>
+	 * Note 1: to user interface implementers: This field should be part of a
+	 * "Contact information" group on the form.
+	 * Note 2 to user interface
+	 * implementers: provide sufficient space to fill in multiple URLs.
+	 * Note 3: the ContactInfo naming aligns with the vCard
+	 * specification RFC 2426.
+	 */
+	Property CONTACT_INFO_WEB_URL = Property.internalText(
+			PREFIX_IPTC_CORE + PREFIX_DELIMITER + "CiUrlWork");
+
+	/**
+	 * As this metadata element pertains to distribution management, it was not
+	 * adopted. However, this data is still synchronised with the XMP property
+	 * photoshop:Urgency, and hence, available for future use, but outside the
+	 * IPTC Core.
+	 *
+	 * @deprecated
+	 */
+	Property URGENCY = Property.internalText(
+			PREFIX_PHOTOSHOP + PREFIX_DELIMITER + "Urgency");
+
+	/**
+	 * As this metadata element was earmarked as deprecated already for IIM 4.1,
+	 * it was not adopted. However, this data is still synchronised with the XMP
+	 * property [photoshop:Category], and hence available for future use - but
+	 * outside the IPTC Core. For migrating from Category codes to Subject Codes
+	 * please read the Guideline for mapping Category Codes to Subject NewsCodes
+	 * section below.
+	 *
+	 * @deprecated
+	 */
+	Property CATEGORY = Property.internalText(
+			PREFIX_PHOTOSHOP + PREFIX_DELIMITER + "Category");
+
+	/**
+	 * As this metadata element was earmarked as deprecated already for IIM 4.1,
+	 * it was not adopted. However, this data is still synchronised with the XMP
+	 * property [photoshop:SupplementalCategories], and hence available for
+	 * future use - but outside the IPTC Core.
+	 *
+	 * @deprecated
+	 */
+	Property SUPPLEMENTAL_CATEGORIES = Property.internalTextBag(
+			PREFIX_PHOTOSHOP + PREFIX_DELIMITER + "SupplementalCategories");
+
+	/**
+	 * Information about the ethnicity and other facets of the model(s) in a
+	 * model-released image.
+	 * <p>
+	 * Use the Model Age field for the age of model(s).
+	 */
+	Property ADDITIONAL_MODEL_INFO = Property.internalText(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "AddlModelInfo");
+
+	/**
+	 * A set of metadata about artwork or an object in the item
+	 */
+	Property ARTWORK_OR_OBJECT = Property.internalTextBag(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "ArtworkOrObject");
+
+	/**
+	 * A set of metadata about artwork or an object in the item
+	 */
+	Property ORGANISATION_CODE = Property.internalTextBag(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "OrganisationInImageCode");
+
+	/**
+	 * A term to describe the content of the image by a value from a Controlled
+	 * Vocabulary.
+	 * <p>
+	 * This property is part of the Photo Metadata 2008 specifications, but
+	 * should not released to the public on the standard Adobe Custom Panels for
+	 * IPTC metadata or other user interfaces unless agreed by the IPTC.
+	 */
+	Property CONTROLLED_VOCABULARY_TERM = Property.internalTextBag(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "CVterm");
+
+	/**
+	 * A location the content of the item is about. For photos that is a
+	 * location shown in the image.
+	 * <p>
+	 * If the location the image was taken in is different from this location
+	 * the property Location Created should be used too.
+	 */
+	Property LOCATION_SHOWN = Property.internalTextBag(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "LocationShown");
+
+	/**
+	 * Age of the human model(s) at the time this image was taken in a model
+	 * released image.
+	 * <p>
+	 * The user should be aware of any legal implications of providing ages for
+	 * young models. Ages below 18 years should not be included.
+	 */
+	Property MODEL_AGE = Property.internalTextBag(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "ModelAge");
+
+	/**
+	 * Name of the organisation or company which is featured in the content.
+	 * <p>
+	 * May be supplemented by values from a controlled vocabulary in the
+	 * Organisation Code field.
+	 */
+	Property ORGANISATION_NAME = Property.internalTextBag(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "OrganisationInImageName");
+
+	/**
+	 * Name of a person the content of the item is about. For photos that is a
+	 * person shown in the image.
+	 */
+	Property PERSON = Property.internalTextBag(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "PersonInImage");
+
+	/**
+	 * Globally unique identifier for the item. It is created and applied by the
+	 * creator of the item at the time of its creation . This value shall not be
+	 * changed after that time.
+	 * <p>
+	 * The identifier will probably be generated by the technical means of an
+	 * imaging device or software and should be applied to the digital image
+	 * file as early as possible in its life cycle. This identifier does not
+	 * identify any pictured content, particularly in case of a scan of non-
+	 * digital images, only this digital representation.
+	 * <p>
+	 * Any algorithm to create this identifier has to comply with the technical
+	 * requirements to create a globally unique id. Any device creating digital
+	 * images - e.g. still image cameras, video cameras, scanners - should
+	 * create such an identifer right at the time of the creation of the digital
+	 * data and add the id to the set of metadata without compromising
+	 * performance. It is recommended that this image identifier allows
+	 * identifying the device by which the image data and the GUID were created.
+	 * IPTC's basic requirements for unique ids are:
+	 * - It must be globally unique. Algorithms for this purpose exist.
+	 * - It should identify the camera body.
+	 * - It should identify each individual photo from this camera body.
+	 * - It should identify the date and time of the creation of the picture.
+	 * - It should be secured against tampering.
+	 * This field should be implemented in a way to prove it has not been changed since its value has
+	 * been applied. If the identifier has been created by the imaging device
+	 * its type and brand can be found in the Exif/technical metadata.
+	 */
+	Property DIGITAL_IMAGE_GUID = Property.internalText(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "DigImageGUID");
+
+	/**
+	 * The type of the source digital file.
+	 * <p>
+	 * The IPTC recommends not to implement this property any longer.
+	 *
+	 * @deprecated
+	 */
+	Property DIGITAL_SOURCE_FILE_TYPE = Property.internalText(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "DigitalSourcefileType");
+
+	/**
+	 * The type of the source of this digital image
+	 */
+	Property DIGITAL_SOURCE_TYPE = Property.internalText(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "DigitalSourceType");
+
+	/**
+	 * Names or describes the specific event the content relates to.
+	 * <p>
+	 * Examples are: a press conference, dedication ceremony, etc. If this is a
+	 * sub-event of a larger event both can be provided by the field: e.g. XXXIX
+	 * Olympic Summer Games (Beijing): opening ceremony. Unplanned events could
+	 * be named by this property too.
+	 */
+	Property EVENT = Property.internalText(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "Event");
+
+	/**
+	 * Both a Registry Item Id and a Registry Organisation Id to record any
+	 * registration of this item with a registry.
+	 * <p>
+	 * Typically an id from a registry is negotiated and applied after the
+	 * creation of the digital image.
+	 * <p>
+	 * Any user interface implementation must show both sub-properties - Item Id
+	 * and Organisation Id - as corresponding values. Further an input to both
+	 * fields should be made mandatory.
+	 */
+	Property IMAGE_REGISTRY_ENTRY = Property.internalTextBag(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "RegistryId");
+
+	/**
+	 * Identifies the most recent supplier of the item, who is not necessarily
+	 * its owner or creator.
+	 * <p>
+	 * For identifying the supplier either a well known and/or registered
+	 * company name or a URL of the company's web site may be used. This
+	 * property succeeds the Provider property of IPTC Core 1.0 by its semantics
+	 * as that Provider was renamed to Credit Line.
+	 * <p>
+	 * This is a PLUS version 1.2 property included in the IPTC Extension
+	 * schema.
+	 */
+	Property IMAGE_SUPPLIER = Property.internalText(
+			PREFIX_PLUS + PREFIX_DELIMITER + "ImageSupplier");
+
+	/**
+	 * Identifies the most recent supplier of the item, who is not necessarily
+	 * its owner or creator.
+	 * <p>
+	 * For identifying the supplier either a well known and/or registered
+	 * company name or a URL of the company's web site may be used. This
+	 * property succeeds the Provider property of IPTC Core 1.0 by its semantics
+	 * as that Provider was renamed to Credit Line.
+	 * <p>
+	 * This is a PLUS version 1.2 property included in the IPTC Extension
+	 * schema.
+	 */
+	Property IMAGE_SUPPLIER_ID = Property.internalText(
+			PREFIX_PLUS + PREFIX_DELIMITER + "ImageSupplierId");
+
+	/**
+	 * Identifies the most recent supplier of the item, who is not necessarily
+	 * its owner or creator.
+	 * <p>
+	 * For identifying the supplier either a well known and/or registered
+	 * company name or a URL of the company's web site may be used. This
+	 * property succeeds the Provider property of IPTC Core 1.0 by its semantics
+	 * as that Provider was renamed to Credit Line.
+	 * <p>
+	 * This is a PLUS version 1.2 property included in the IPTC Extension
+	 * schema.
+	 */
+	Property IMAGE_SUPPLIER_NAME = Property.internalText(
+			PREFIX_PLUS + PREFIX_DELIMITER + "ImageSupplierName");
+
+	/**
+	 * Optional identifier assigned by the Image Supplier to the image.
+	 * <p>
+	 * This is a PLUS version 1.2 property included in the IPTC Extension
+	 * schema.
+	 */
+	Property IMAGE_SUPPLIER_IMAGE_ID = Property.internalText(
+			PREFIX_PLUS + PREFIX_DELIMITER + "ImageSupplierImageID");
+
+	/**
+	 * The date and optionally time when any of the IPTC photo metadata fields
+	 * has been last edited
+	 * <p>
+	 * The public use of this property is deprecated by IPTC Extension version
+	 * 1.1. It may only still be used by a private user interface for a use
+	 * scoped to a company. If used this field should be a timestamp of the
+	 * latest change applied to any of the fields.
+	 * <p>
+	 * The value of this property should never be set by software. XMP-aware
+	 * software should reflect any changes to metadata by the xmp:MetadataDate
+	 * property of the XMP Basic scheme.
+	 */
+	Property IPTC_LAST_EDITED = Property.internalDate(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "IptcLastEdited");
+
+	/**
+	 * The location the content of the item was created.
+	 * <p>
+	 * If the location in the image is different from the location the photo was
+	 * taken the IPTC Extension property Location Shown in the Image should be
+	 * used.
+	 */
+	Property LOCATION_CREATED = Property.internalTextBag(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "LocationCreated");
+
+	/**
+	 * The maximum available height in pixels of the original photo from which
+	 * this photo has been derived by downsizing.
+	 */
+	Property MAX_AVAIL_HEIGHT = Property.internalInteger(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "MaxAvailHeight");
+
+	/**
+	 * The maximum available width in pixels of the original photo from which
+	 * this photo has been derived by downsizing.
+	 */
+	Property MAX_AVAIL_WIDTH = Property.internalInteger(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "MaxAvailWidth");
+
+	/**
+	 * The version number of the PLUS standards in place at the time of the
+	 * transaction.
+	 * <p>
+	 * This property was included into the IPTC Extension schema from PLUS
+	 * version 1.2 as all other PLUS properties. To reflect this the value of
+	 * "PLUS Version" should be set to the string "1.2.0"
+	 */
+	Property PLUS_VERSION = Property.internalText(
+			PREFIX_PLUS + PREFIX_DELIMITER + "Version");
+
+	/**
+	 * Owner or owners of the copyright in the licensed image.
+	 * <p>
+	 * Serves to identify the rights holder/s for the image. The Copyright
+	 * Owner, Image Creator and Licensor may be the same or different entities.
+	 * <p>
+	 * This is a PLUS version 1.2 property included in the IPTC Extension
+	 * schema.
+	 */
+	Property COPYRIGHT_OWNER = Property.internalTextBag(
+			PREFIX_PLUS + PREFIX_DELIMITER + "CopyrightOwner");
+
+	/**
+	 * The ID of the owner or owners of the copyright in the licensed image.
+	 * <p>
+	 * Serves to identify the rights holder/s for the image. The Copyright
+	 * Owner, Image Creator and Licensor may be the same or different entities.
+	 * <p>
+	 * This is a PLUS version 1.2 property included in the IPTC Extension
+	 * schema.
+	 */
+	Property COPYRIGHT_OWNER_ID = Property.internalTextBag(
+			PREFIX_PLUS + PREFIX_DELIMITER + "CopyrightOwnerId");
+
+	/**
+	 * The name of the owner or owners of the copyright in the licensed image.
+	 * <p>
+	 * Serves to identify the rights holder/s for the image. The Copyright
+	 * Owner, Image Creator and Licensor may be the same or different entities.
+	 * <p>
+	 * This is a PLUS version 1.2 property included in the IPTC Extension
+	 * schema.
+	 */
+	Property COPYRIGHT_OWNER_NAME = Property.internalTextBag(
+			PREFIX_PLUS + PREFIX_DELIMITER + "CopyrightOwnerName");
+
+	/**
+	 * Creator or creators of the image.
+	 * <p>
+	 * The creator can be additionally expressed in free-text using the IPTC
+	 * Core Creator field. In many countries, the Image Creator must be
+	 * attributed in association with any use of the image. The Image Creator,
+	 * Copyright Owner, Image Supplier and Licensor may be the same or different
+	 * entities.
+	 * <p>
+	 * This is a PLUS version 1.2 property included in the IPTC Extension
+	 * schema.
+	 */
+	Property IMAGE_CREATOR = Property.internalTextBag(
+			PREFIX_PLUS + PREFIX_DELIMITER + "ImageCreator");
+
+	/**
+	 * The ID of the creator or creators of the image.
+	 * <p>
+	 * The creator can be additionally expressed in free-text using the IPTC
+	 * Core Creator field. In many countries, the Image Creator must be
+	 * attributed in association with any use of the image. The Image Creator,
+	 * Copyright Owner, Image Supplier and Licensor may be the same or different
+	 * entities.
+	 * <p>
+	 * This is a PLUS version 1.2 property included in the IPTC Extension
+	 * schema.
+	 */
+	Property IMAGE_CREATOR_ID = Property.internalTextBag(
+			PREFIX_PLUS + PREFIX_DELIMITER + "ImageCreatorId");
+
+	/**
+	 * The name of the creator or creators of the image.
+	 * <p>
+	 * The creator can be additionally expressed in free-text using the IPTC
+	 * Core Creator field. In many countries, the Image Creator must be
+	 * attributed in association with any use of the image. The Image Creator,
+	 * Copyright Owner, Image Supplier and Licensor may be the same or different
+	 * entities.
+	 * <p>
+	 * This is a PLUS version 1.2 property included in the IPTC Extension
+	 * schema.
+	 */
+	Property IMAGE_CREATOR_NAME = Property.internalTextBag(
+			PREFIX_PLUS + PREFIX_DELIMITER + "ImageCreatorName");
+
+	/**
+	 * A person or company that should be contacted to obtain a licence for
+	 * using the item or who has licensed the item.
+	 * <p>
+	 * This is a PLUS version 1.2 property included in the IPTC Extension
+	 * schema.
+	 */
+	Property LICENSOR = Property.internalTextBag(
+			PREFIX_PLUS + PREFIX_DELIMITER + "Licensor");
+
+	/**
+	 * The ID of the person or company that should be contacted to obtain a licence for
+	 * using the item or who has licensed the item.
+	 * <p>
+	 * This is a PLUS version 1.2 property included in the IPTC Extension
+	 * schema.
+	 */
+	Property LICENSOR_ID = Property.internalTextBag(
+			PREFIX_PLUS + PREFIX_DELIMITER + "LicensorId");
+
+	/**
+	 * The name of the person or company that should be contacted to obtain a licence for
+	 * using the item or who has licensed the item.
+	 * <p>
+	 * This is a PLUS version 1.2 property included in the IPTC Extension
+	 * schema.
+	 */
+	Property LICENSOR_NAME = Property.internalTextBag(
+			PREFIX_PLUS + PREFIX_DELIMITER + "LicensorName");
+
+	/**
+	 * The city of a person or company that should be contacted to obtain a licence for
+	 * using the item or who has licensed the item.
+	 * <p>
+	 * This is a PLUS version 1.2 property included in the IPTC Extension
+	 * schema.
+	 */
+	Property LICENSOR_CITY = Property.internalTextBag(
+			PREFIX_PLUS + PREFIX_DELIMITER + "LicensorCity");
+
+	/**
+	 * The country of a person or company that should be contacted to obtain a licence for
+	 * using the item or who has licensed the item.
+	 * <p>
+	 * This is a PLUS version 1.2 property included in the IPTC Extension
+	 * schema.
+	 */
+	Property LICENSOR_COUNTRY = Property.internalTextBag(
+			PREFIX_PLUS + PREFIX_DELIMITER + "LicensorCountry");
+
+	/**
+	 * The email of a person or company that should be contacted to obtain a licence for
+	 * using the item or who has licensed the item.
+	 * <p>
+	 * This is a PLUS version 1.2 property included in the IPTC Extension
+	 * schema.
+	 */
+	Property LICENSOR_EMAIL = Property.internalTextBag(
+			PREFIX_PLUS + PREFIX_DELIMITER + "LicensorEmail");
+
+	/**
+	 * The extended address of a person or company that should be contacted to obtain a licence for
+	 * using the item or who has licensed the item.
+	 * <p>
+	 * This is a PLUS version 1.2 property included in the IPTC Extension
+	 * schema.
+	 */
+	Property LICENSOR_EXTENDED_ADDRESS = Property.internalTextBag(
+			PREFIX_PLUS + PREFIX_DELIMITER + "LicensorExtendedAddress");
+
+	/**
+	 * The postal code of a person or company that should be contacted to obtain a licence for
+	 * using the item or who has licensed the item.
+	 * <p>
+	 * This is a PLUS version 1.2 property included in the IPTC Extension
+	 * schema.
+	 */
+	Property LICENSOR_POSTAL_CODE = Property.internalTextBag(
+			PREFIX_PLUS + PREFIX_DELIMITER + "LicensorPostalCode");
+
+	/**
+	 * The region of a person or company that should be contacted to obtain a licence for
+	 * using the item or who has licensed the item.
+	 * <p>
+	 * This is a PLUS version 1.2 property included in the IPTC Extension
+	 * schema.
+	 */
+	Property LICENSOR_REGION = Property.internalTextBag(
+			PREFIX_PLUS + PREFIX_DELIMITER + "LicensorRegion");
+
+	/**
+	 * The street address of a person or company that should be contacted to obtain a licence for
+	 * using the item or who has licensed the item.
+	 * <p>
+	 * This is a PLUS version 1.2 property included in the IPTC Extension
+	 * schema.
+	 */
+	Property LICENSOR_STREET_ADDRESS = Property.internalTextBag(
+			PREFIX_PLUS + PREFIX_DELIMITER + "LicensorStreetAddress");
+
+	/**
+	 * The phone number of a person or company that should be contacted to obtain a licence for
+	 * using the item or who has licensed the item.
+	 * <p>
+	 * This is a PLUS version 1.2 property included in the IPTC Extension
+	 * schema.
+	 */
+	Property LICENSOR_TELEPHONE_1 = Property.internalTextBag(
+			PREFIX_PLUS + PREFIX_DELIMITER + "LicensorTelephone1");
+
+	/**
+	 * The phone number of a person or company that should be contacted to obtain a licence for
+	 * using the item or who has licensed the item.
+	 * <p>
+	 * This is a PLUS version 1.2 property included in the IPTC Extension
+	 * schema.
+	 */
+	Property LICENSOR_TELEPHONE_2 = Property.internalTextBag(
+			PREFIX_PLUS + PREFIX_DELIMITER + "LicensorTelephone2");
+
+	/**
+	 * The URL of a person or company that should be contacted to obtain a licence for
+	 * using the item or who has licensed the item.
+	 * <p>
+	 * This is a PLUS version 1.2 property included in the IPTC Extension
+	 * schema.
+	 */
+	Property LICENSOR_URL = Property.internalTextBag(
+			PREFIX_PLUS + PREFIX_DELIMITER + "LicensorURL");
+
+	/**
+	 * Age of the youngest model pictured in the image, at the time that the
+	 * image was made.
+	 * <p>
+	 * This age should not be displayed to the public on open web portals and
+	 * the like. But it may be used by image repositories in a
+	 * B2B enviroment.
+	 * <p>
+	 * This is a PLUS version 1.2 property included in the IPTC Extension
+	 * schema.
+	 */
+	Property MINOR_MODEL_AGE_DISCLOSURE = Property.internalText(
+			PREFIX_PLUS + PREFIX_DELIMITER + "MinorModelAgeDisclosure");
+
+	/**
+	 * Optional identifier associated with each Model Release.
+	 * <p>
+	 * This is a PLUS version 1.2 property included in the IPTC Extension
+	 * schema.
+	 */
+	Property MODEL_RELEASE_ID = Property.internalTextBag(
+			PREFIX_PLUS + PREFIX_DELIMITER + "ModelReleaseID");
+
+	/**
+	 * Summarizes the availability and scope of model releases authorizing usage
+	 * of the likenesses of persons appearing in the photograph.
+	 * <p>
+	 * It is recommended to apply the PLUS controlled value Unlimited Model
+	 * Releases (MR- UMR) very carefully and to check the wording of the model
+	 * release thoroughly before applying it.
+	 * <p>
+	 * This is a PLUS version 1.2 property included in the IPTC Extension
+	 * schema.
+	 */
+	Property MODEL_RELEASE_STATUS = Property.internalText(
+			PREFIX_PLUS + PREFIX_DELIMITER + "ModelReleaseStatus");
+
+	/**
+	 * Optional identifier associated with each Property Release.
+	 * <p>
+	 * This is a PLUS version 1.2 property included in the IPTC Extension
+	 * schema.
+	 */
+	Property PROPERTY_RELEASE_ID = Property.internalTextBag(
+			PREFIX_PLUS + PREFIX_DELIMITER + "PropertyReleaseID");
+
+	/**
+	 * Summarises the availability and scope of property releases authorizing
+	 * usage of the properties appearing in the photograph.
+	 * <p>
+	 * It is recommended to apply the value PR-UPR very carefully and to check
+	 * the wording of the property release thoroughly before applying it.
+	 * <p>
+	 * This is a PLUS version 1.2 property included in the IPTC Extension
+	 * schema.
+	 */
+	Property PROPERTY_RELEASE_STATUS = Property.internalText(
+			PREFIX_PLUS + PREFIX_DELIMITER + "PropertyReleaseStatus");
+
+	/**
+	 * Contains any necessary copyright notice for claiming the intellectual
+	 * property for artwork or an object in the image and should identify the
+	 * current owner of the copyright of this work with associated intellectual
+	 * property rights.
+	 */
+	Property ARTWORK_OR_OBJECT_DETAIL_COPYRIGHT_NOTICE = Property.internalText(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "AOCopyrightNotice");
+
+	/**
+	 * Contains the name of the artist who has created artwork or an object in the image.
+	 */
+	Property ARTWORK_OR_OBJECT_DETAIL_CREATOR = Property.internalText(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "AOCreator");
+
+	/**
+	 * Designates the date and optionally the time the artwork or object in the
+	 * image was created. This relates to artwork or objects with associated
+	 * intellectual property rights.
+	 */
+	Property ARTWORK_OR_OBJECT_DETAIL_DATE_CREATED = Property.internalDate(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "AODateCreated");
+
+	/**
+	 * The organisation or body holding and registering the artwork or object in
+	 * the image for inventory purposes.
+	 */
+	Property ARTWORK_OR_OBJECT_DETAIL_SOURCE = Property.internalText(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "AOSource");
+
+	/**
+	 * The inventory number issued by the organisation or body holding and
+	 * registering the artwork or object in the image.
+	 */
+	Property ARTWORK_OR_OBJECT_DETAIL_SOURCE_INVENTORY_NUMBER = Property.internalText(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "AOSourceInvNo");
+
+	/**
+	 * A reference for the artwork or object in the image.
+	 */
+	Property ARTWORK_OR_OBJECT_DETAIL_TITLE = Property.internalText(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "AOTitle");
+
+	/**
+	 * Name of the city of a location. This element is at the fourth level of a
+	 * top-down geographical hierarchy.
+	 */
+	Property LOCATION_SHOWN_CITY = Property.internalText(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "LocationShownCity");
+
+	/**
+	 * The ISO code of a country of a location. This element is at the second
+	 * level of a top-down geographical hierarchy.
+	 * <p>
+	 * Note 1: an implementer would have to derive from the length of the value
+	 * string whether this is the country code from the two or three letter
+	 * scheme as no explicit indication can be provided.
+	 */
+	Property LOCATION_SHOWN_COUNTRY_CODE = Property.internalText(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "LocationShownCountryCode");
+
+	/**
+	 * The name of a country of a location. This element is at the second level
+	 * of a top-down geographical hierarchy.
+	 */
+	Property LOCATION_SHOWN_COUNTRY_NAME = Property.internalText(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "LocationShownCountryName");
+
+	/**
+	 * The name of a subregion of a country - a province or state - of a
+	 * location. This element is at the third level of a top-down geographical
+	 * hierarchy.
+	 */
+	Property LOCATION_SHOWN_PROVINCE_OR_STATE = Property.internalText(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "LocationShownProvinceState");
+
+	/**
+	 * Name of a sublocation. This sublocation name could either be the name of
+	 * a sublocation to a city or the name of a well known location or (natural)
+	 * monument outside a city. In the sense of a sublocation to a city this
+	 * element is at the fifth level of a top-down geographical hierarchy.
+	 */
+	Property LOCATION_SHOWN_SUBLOCATION = Property.internalText(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "LocationShownSublocation");
+
+	/**
+	 * The name of a world region of a location. This element is at the first
+	 * (topI) level of a top- down geographical hierarchy.
+	 */
+	Property LOCATION_SHOWN_WORLD_REGION = Property.internalText(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "LocationShownWorldRegion");
+
+	/**
+	 * Name of the city of a location. This element is at the fourth level of a
+	 * top-down geographical hierarchy.
+	 */
+	Property LOCATION_CREATED_CITY = Property.internalText(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "LocationCreatedCity");
+
+	/**
+	 * The ISO code of a country of a location. This element is at the second
+	 * level of a top-down geographical hierarchy.
+	 * <p>
+	 * Note 1: an implementer would have to derive from the length of the value
+	 * string whether this is the country code from the two or three letter
+	 * scheme as no explicit indication can be provided.
+	 */
+	Property LOCATION_CREATED_COUNTRY_CODE = Property.internalText(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "LocationCreatedCountryCode");
+
+	/**
+	 * The name of a country of a location. This element is at the second level
+	 * of a top-down geographical hierarchy.
+	 */
+	Property LOCATION_CREATED_COUNTRY_NAME = Property.internalText(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "LocationCreatedCountryName");
+
+	/**
+	 * The name of a subregion of a country - a province or state - of a
+	 * location. This element is at the third level of a top-down geographical
+	 * hierarchy.
+	 */
+	Property LOCATION_CREATED_PROVINCE_OR_STATE = Property.internalText(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "LocationCreatedProvinceState");
+
+	/**
+	 * Name of a sublocation. This sublocation name could either be the name of
+	 * a sublocation to a city or the name of a well known location or (natural)
+	 * monument outside a city. In the sense of a sublocation to a city this
+	 * element is at the fifth level of a top-down geographical hierarchy.
+	 */
+	Property LOCATION_CREATED_SUBLOCATION = Property.internalText(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "LocationCreatedSublocation");
+
+	/**
+	 * The name of a world region of a location. This element is at the first
+	 * (topI) level of a top- down geographical hierarchy.
+	 */
+	Property LOCATION_CREATED_WORLD_REGION = Property.internalText(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "LocationCreatedWorldRegion");
+
+	/**
+	 * A unique identifier created by a registry and applied by the creator of
+	 * the item. This value shall not be changed after being applied. This
+	 * identifier is linked to a corresponding Registry Organisation Identifier.
+	 */
+	Property REGISTRY_ENTRY_CREATED_ITEM_ID = Property.internalText(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "RegItemId");
+
+	/**
+	 * An identifier for the registry which issued the corresponding Registry Image Id.
+	 */
+	Property REGISTRY_ENTRY_CREATED_ORGANISATION_ID = Property.internalText(
+			PREFIX_IPTC_EXT + PREFIX_DELIMITER + "RegOrgId");
+
+
+	Property[] PROPERTY_GROUP_IPTC_CORE = new Property[] {
+		CITY,
+		COUNTRY,
+		COUNTRY_CODE,
+		DESCRIPTION,
+		HEADLINE,
+		INTELLECTUAL_GENRE,
+		KEYWORDS,
+		PROVINCE_OR_STATE,
+		SCENE_CODE,
+		SUBJECT_CODE,
+		SUBLOCATION,
+		DATE_CREATED,
+		DESCRIPTION_WRITER,
+		INSTRUCTIONS,
+		JOB_ID,
+		TITLE,
+		COPYRIGHT_NOTICE,
+		CREATOR,
+		CREATORS_JOB_TITLE,
+		CREDIT_LINE,
+		RIGHTS_USAGE_TERMS,
+		SOURCE,
+		CONTACT_INFO_ADDRESS,
+		CONTACT_INFO_CITY,
+		CONTACT_INFO_COUNTRY,
+		CONTACT_INFO_EMAIL,
+		CONTACT_INFO_PHONE,
+		CONTACT_INFO_POSTAL_CODE,
+		CONTACT_INFO_STATE_PROVINCE,
+		CONTACT_INFO_WEB_URL
+	};
+
+	Property[] PROPERTY_GROUP_IPTC_EXT = new Property[] {
+		ADDITIONAL_MODEL_INFO,
+		ORGANISATION_CODE,
+		CONTROLLED_VOCABULARY_TERM,
+		MODEL_AGE,
+		ORGANISATION_NAME,
+		PERSON,
+		DIGITAL_IMAGE_GUID,
+		DIGITAL_SOURCE_TYPE,
+		EVENT,
+		IMAGE_SUPPLIER_ID,
+		IMAGE_SUPPLIER_NAME,
+		IMAGE_SUPPLIER_IMAGE_ID,
+		IPTC_LAST_EDITED,
+		MAX_AVAIL_HEIGHT,
+		MAX_AVAIL_WIDTH,
+		PLUS_VERSION,
+		COPYRIGHT_OWNER_ID,
+		COPYRIGHT_OWNER_NAME,
+		IMAGE_CREATOR_ID,
+		IMAGE_CREATOR_NAME,
+		LICENSOR_ID,
+		LICENSOR_NAME,
+		LICENSOR_CITY,
+		LICENSOR_COUNTRY,
+		LICENSOR_EMAIL,
+		LICENSOR_EXTENDED_ADDRESS,
+		LICENSOR_POSTAL_CODE,
+		LICENSOR_REGION,
+		LICENSOR_STREET_ADDRESS,
+		LICENSOR_TELEPHONE_1,
+		LICENSOR_TELEPHONE_2,
+		LICENSOR_URL,
+		MINOR_MODEL_AGE_DISCLOSURE,
+		MODEL_RELEASE_ID,
+		MODEL_RELEASE_STATUS,
+		PROPERTY_RELEASE_ID,
+		PROPERTY_RELEASE_STATUS,
+		ARTWORK_OR_OBJECT_DETAIL_COPYRIGHT_NOTICE,
+		ARTWORK_OR_OBJECT_DETAIL_CREATOR,
+		ARTWORK_OR_OBJECT_DETAIL_DATE_CREATED,
+		ARTWORK_OR_OBJECT_DETAIL_SOURCE,
+		ARTWORK_OR_OBJECT_DETAIL_SOURCE_INVENTORY_NUMBER,
+		ARTWORK_OR_OBJECT_DETAIL_TITLE,
+		LOCATION_SHOWN_CITY,
+		LOCATION_SHOWN_COUNTRY_CODE,
+		LOCATION_SHOWN_COUNTRY_NAME,
+		LOCATION_SHOWN_PROVINCE_OR_STATE,
+		LOCATION_SHOWN_SUBLOCATION,
+		LOCATION_SHOWN_WORLD_REGION,
+		LOCATION_CREATED_CITY,
+		LOCATION_CREATED_COUNTRY_CODE,
+		LOCATION_CREATED_COUNTRY_NAME,
+		LOCATION_CREATED_PROVINCE_OR_STATE,
+		LOCATION_CREATED_SUBLOCATION,
+		LOCATION_CREATED_WORLD_REGION,
+		REGISTRY_ENTRY_CREATED_ITEM_ID,
+		REGISTRY_ENTRY_CREATED_ORGANISATION_ID
+	};
+}
\ No newline at end of file
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java b/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
index f623143b3..d3f105e65 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
@@ -33,7 +33,7 @@ import java.util.TimeZone;
  * A multi-valued metadata container.
  */
 public class Metadata implements CreativeCommons, DublinCore, Geographic, HttpHeaders,
-        Message, MSOffice, ClimateForcast, TIFF, TikaMetadataKeys, TikaMimeKeys,
+        IPTC, Message, MSOffice, ClimateForcast, TIFF, TikaMetadataKeys, TikaMimeKeys,
         Serializable {
 
     /** Serial version UID */

Commit:
b802cc16c4ee760be34c13f899cba2c8170ad712
Nick Burch
nick@apache.org
2012-01-27 16:25:45 +0000
TIKA-851 Another mp4 audio alias
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index d3ad7e008..92a7cbbfd 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -3052,6 +3052,7 @@
 
   <mime-type type="audio/mobile-xmf"/>
   <mime-type type="audio/mp4">
+    <alias type="audio/x-m4a"/>
     <alias type="audio/x-mp4a"/>
     <magic priority="60">
       <match value="ftypM4A " type="string" offset="4"/>

Commit:
8584631a0ae23130dd8d3b28454479fc40a443c8
Nick Burch
nick@apache.org
2012-01-27 14:50:51 +0000
TIKA-851 More specific quicktime/mp4 matches, for the common subtypes, based on the ftyp atom
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 3043901f7..d3ad7e008 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -3053,7 +3053,14 @@
   <mime-type type="audio/mobile-xmf"/>
   <mime-type type="audio/mp4">
     <alias type="audio/x-mp4a"/>
+    <magic priority="60">
+      <match value="ftypM4A " type="string" offset="4"/>
+      <match value="ftypM4B " type="string" offset="4"/>
+      <match value="ftypF4A " type="string" offset="4"/>
+      <match value="ftypF4B " type="string" offset="4"/>
+    </magic>
     <glob pattern="*.mp4a"/>
+    <glob pattern="*.m4a"/>
   </mime-type>
   <mime-type type="audio/mp4a-latm"/>
   <mime-type type="audio/mpa"/>
@@ -4176,10 +4183,27 @@
   <mime-type type="text/xml"/>
   <mime-type type="text/xml-external-parsed-entity"/>
   <mime-type type="video/3gpp">
+    <magic priority="60">
+      <match value="ftyp3ge6" type="string" offset="4"/>
+      <match value="ftyp3ge7" type="string" offset="4"/>
+      <match value="ftyp3gg6" type="string" offset="4"/>
+      <match value="ftyp3gp1" type="string" offset="4"/>
+      <match value="ftyp3gp2" type="string" offset="4"/>
+      <match value="ftyp3gp3" type="string" offset="4"/>
+      <match value="ftyp3gp4" type="string" offset="4"/>
+      <match value="ftyp3gp5" type="string" offset="4"/>
+      <match value="ftyp3gp6" type="string" offset="4"/>
+      <match value="ftyp3gs7" type="string" offset="4"/>
+    </magic>
     <glob pattern="*.3gp"/>
   </mime-type>
   <mime-type type="video/3gpp-tt"/>
   <mime-type type="video/3gpp2">
+    <magic priority="60">
+      <match value="ftyp3g2a" type="string" offset="4"/>
+      <match value="ftyp3g2b" type="string" offset="4"/>
+      <match value="ftyp3g2c" type="string" offset="4"/>
+    </magic>
     <glob pattern="*.3g2"/>
   </mime-type>
   <mime-type type="video/bmpeg"/>
@@ -4213,10 +4237,16 @@
   <mime-type type="video/mp1s"/>
   <mime-type type="video/mp2p"/>
   <mime-type type="video/mp2t"/>
+
   <mime-type type="video/mp4">
+    <magic priority="60">
+      <match value="ftypmp41" type="string" offset="4"/>
+      <match value="ftypmp42" type="string" offset="4"/>
+    </magic>
     <glob pattern="*.mp4"/>
     <glob pattern="*.mp4v"/>
     <glob pattern="*.mpg4"/>
+    <sub-class-of type="video/quicktime" />
   </mime-type>
   <mime-type type="video/mp4v-es"/>
 
@@ -4251,6 +4281,7 @@
     <magic priority="50">
       <match value="moov" type="string" offset="4"/>
       <match value="mdat" type="string" offset="4"/>
+      <!-- General match, specific ftypXXX ones present for subtypes -->
       <match value="ftyp" type="string" offset="4"/>
     </magic>
     <glob pattern="*.qt"/>
@@ -4321,7 +4352,13 @@
   </mime-type>
 
   <mime-type type="video/x-m4v">
+    <magic priority="60">
+      <match value="ftypM4V " type="string" offset="4"/>
+      <match value="ftypM4VH" type="string" offset="4"/>
+      <match value="ftypM4VP" type="string" offset="4"/>
+    </magic>
     <glob pattern="*.m4v"/>
+    <sub-class-of type="video/mp4" />
   </mime-type>
 
   <mime-type type="video/x-mng">

Commit:
b754b456c3871c453466ff06f60eedf433547eaa
Nick Burch
nick@apache.org
2012-01-24 16:24:04 +0000
TIKA-770 Set all document statistics with Properties rather than Strings, now they are all typed
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/MSOffice.java b/tika-core/src/main/java/org/apache/tika/metadata/MSOffice.java
index eab74bb60..c4010038b 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/MSOffice.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/MSOffice.java
@@ -43,10 +43,6 @@ public interface MSOffice {
 
     String MANAGER = "Manager";
 
-    String LINE_COUNT = "Line-Count";
-
-    String CHARACTER_COUNT_WITH_SPACES = "Character-Count-With-Spaces";
-
     String APPLICATION_VERSION = "Application-Version";
 
     String VERSION = "Version";
@@ -71,6 +67,10 @@ public interface MSOffice {
     /** The number of individual Paragraphs in the document */ 
     Property PARAGRAPH_COUNT = 
        Property.internalInteger("Paragraph-Count");
+    
+    /** The number of lines in the document */
+    Property LINE_COUNT = 
+       Property.internalInteger("Line-Count");
 
     /** The number of Words in the document */
     Property WORD_COUNT = 
@@ -80,6 +80,10 @@ public interface MSOffice {
     Property CHARACTER_COUNT = 
        Property.internalInteger("Character Count");
     
+    /** The number of Characters in the document, including spaces */
+    Property CHARACTER_COUNT_WITH_SPACES = 
+       Property.internalInteger("Character-Count-With-Spaces");
+
     /** The number of Tables in the document */
     Property TABLE_COUNT = 
        Property.internalInteger("Table-Count");
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/SummaryExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/SummaryExtractor.java
index acea82dad..fba7dcdcf 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/SummaryExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/SummaryExtractor.java
@@ -182,6 +182,12 @@ class SummaryExtractor {
         }
     }
 
+    private void set(Property property, int value) {
+        if (value > 0) {
+            metadata.set(property, value);
+        }
+    }
+
     private void set(String name, long value) {
         if (value > 0) {
             metadata.set(name, Long.toString(value));
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java
index 4114dd0ce..b0188d973 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java
@@ -252,9 +252,15 @@ public class MetadataExtractor {
         }
     }
 
-    private void addProperty(Metadata metadata, String name, long value) {
+    private void addProperty(Metadata metadata, Property property, int value) {
+       if (value > 0) {
+           metadata.set(property, value);
+       }
+    }
+    
+    private void addProperty(Metadata metadata, String name, int value) {
         if (value > 0) {
-            metadata.set(name, Long.toString(value));
+            metadata.set(name, Integer.toString(value));
         }
     }
 }

Commit:
85ae815a0f9a15ffd0a3f3870768630e53e5dd1b
Nick Burch
nick@apache.org
2012-01-24 16:10:34 +0000
TIKA-770 Convert the remaining ODF document statistics to be defined properties, and update all of the Office Count statistics to be integer typed properties
diff --git a/tika-core/pom.xml b/tika-core/pom.xml
index bce215c5f..f7e9af16b 100644
--- a/tika-core/pom.xml
+++ b/tika-core/pom.xml
@@ -94,6 +94,7 @@
               <excludes>
                 <exlude>org/apache/tika/metadata/Property$PropertyType</exlude>
                 <exlude>org/apache/tika/metadata/Property$ValueType</exlude>
+                <exlude>org/apache/tika/metadata/MSOffice</exlude>
                 <exlude>org/apache/tika/parser/EmptyParser</exlude>
               </excludes>
               <comparisonArtifacts>
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/MSOffice.java b/tika-core/src/main/java/org/apache/tika/metadata/MSOffice.java
index d708c0ed1..eab74bb60 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/MSOffice.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/MSOffice.java
@@ -29,26 +29,16 @@ public interface MSOffice {
 
     String APPLICATION_NAME = "Application-Name";
 
-    String CHARACTER_COUNT = "Character Count";
-
-    String PAGE_COUNT = "Page-Count";
-
     String REVISION_NUMBER = "Revision-Number";
 
-    String WORD_COUNT = "Word-Count";
-
     String TEMPLATE = "Template";
 
     String AUTHOR = "Author";
 
     String TOTAL_TIME = "Total-Time";
 
-    String SLIDE_COUNT = "Slide-Count";
-
     String PRESENTATION_FORMAT = "Presentation-Format";
 
-    String PARAGRAPH_COUNT = "Paragraph-Count";
-
     String NOTES = "Notes";
 
     String MANAGER = "Manager";
@@ -69,6 +59,44 @@ public interface MSOffice {
 
     String SECURITY = "Security";
 
+    
+    /** The number of Slides are there in the (presentation) document */
+    Property SLIDE_COUNT = 
+       Property.internalInteger("Slide-Count");
+    
+    /** The number of Pages are there in the (paged) document */
+    Property PAGE_COUNT = 
+       Property.internalInteger("Page-Count");
+
+    /** The number of individual Paragraphs in the document */ 
+    Property PARAGRAPH_COUNT = 
+       Property.internalInteger("Paragraph-Count");
+
+    /** The number of Words in the document */
+    Property WORD_COUNT = 
+       Property.internalInteger("Word-Count");
+
+    /** The number of Characters in the document */
+    Property CHARACTER_COUNT = 
+       Property.internalInteger("Character Count");
+    
+    /** The number of Tables in the document */
+    Property TABLE_COUNT = 
+       Property.internalInteger("Table-Count");
+    
+    /** The number of Images in the document */
+    Property IMAGE_COUNT = 
+       Property.internalInteger("Image-Count");
+    
+    /** 
+     * The number of Objects in the document.
+     * This is typically non-Image resources embedded in the
+     *  document, such as other documents or non-Image media. 
+     */
+    Property OBJECT_COUNT = 
+       Property.internalInteger("Object-Count");
+
+    
     /** How long has been spent editing the document? */ 
     String EDIT_TIME = "Edit-Time"; 
 
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/odf/OpenDocumentMetaParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/odf/OpenDocumentMetaParser.java
index 91a7069e1..8e3de9198 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/odf/OpenDocumentMetaParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/odf/OpenDocumentMetaParser.java
@@ -83,23 +83,30 @@ public class OpenDocumentMetaParser extends DcXMLParser {
         ch = getMeta(ch, md, "editing-cycles", "editing-cycles");
         ch = getMeta(ch, md, "initial-creator", "initial-creator");
         ch = getMeta(ch, md, "generator", "generator");
+        
         // Process the user defined Meta Attributes
         ch = getUserDefined(ch, md);
+        
         // Process the OO Statistics Attributes
-        ch = getStatistic(ch, md, "nbTab", "table-count");
-        ch = getStatistic(ch, md, "nbObject", "object-count");
-        ch = getStatistic(ch, md, "nbImg", "image-count");
-        ch = getStatistic(ch, md, Metadata.PAGE_COUNT, "page-count");
-        ch = getStatistic(ch, md, PagedText.N_PAGES.getName(), "page-count");
-        ch = getStatistic(ch, md, Metadata.PARAGRAPH_COUNT, "paragraph-count");
-        ch = getStatistic(ch, md, Metadata.WORD_COUNT, "word-count");
-        ch = getStatistic(ch, md, Metadata.CHARACTER_COUNT, "character-count");
+        ch = getStatistic(ch, md, Metadata.OBJECT_COUNT.getName(), "object-count");
+        ch = getStatistic(ch, md, Metadata.IMAGE_COUNT.getName(),  "image-count");
+        ch = getStatistic(ch, md, Metadata.PAGE_COUNT.getName(),   "page-count");
+        ch = getStatistic(ch, md, PagedText.N_PAGES.getName(),     "page-count");
+        ch = getStatistic(ch, md, Metadata.TABLE_COUNT.getName(),  "table-count");
+        ch = getStatistic(ch, md, Metadata.PARAGRAPH_COUNT.getName(), "paragraph-count");
+        ch = getStatistic(ch, md, Metadata.WORD_COUNT.getName(),      "word-count");
+        ch = getStatistic(ch, md, Metadata.CHARACTER_COUNT.getName(), "character-count");
+        
         // Legacy Statistics Attributes, replaced with real keys above
-        // TODO remove these soon!
+        // TODO Remove these shortly, eg after Tika 1.1 (TIKA-770)
         ch = getStatistic(ch, md, "nbPage", "page-count");
         ch = getStatistic(ch, md, "nbPara", "paragraph-count");
         ch = getStatistic(ch, md, "nbWord", "word-count");
         ch = getStatistic(ch, md, "nbCharacter", "character-count");
+        ch = getStatistic(ch, md, "nbTab", "table-count");
+        ch = getStatistic(ch, md, "nbObject", "object-count");
+        ch = getStatistic(ch, md, "nbImg", "image-count");
+        
         // Normalise the rest
         ch = new NSNormalizerContentHandler(ch);
         return ch;
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/odf/ODFParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/odf/ODFParserTest.java
index 44dc383de..673807fbd 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/odf/ODFParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/odf/ODFParserTest.java
@@ -89,6 +89,9 @@ public class ODFParserTest extends TikaTest {
              assertEquals("1", metadata.get(Metadata.PARAGRAPH_COUNT));
              assertEquals("14", metadata.get(Metadata.WORD_COUNT));
              assertEquals("78", metadata.get(Metadata.CHARACTER_COUNT));
+             assertEquals("0", metadata.get(Metadata.TABLE_COUNT));
+             assertEquals("0", metadata.get(Metadata.OBJECT_COUNT));
+             assertEquals("0", metadata.get(Metadata.IMAGE_COUNT));
              
              // Check the old style statistics (these will be removed shortly)
              assertEquals("0", metadata.get("nbTab"));
@@ -152,6 +155,9 @@ public class ODFParserTest extends TikaTest {
            assertEquals(null, metadata.get(Metadata.PARAGRAPH_COUNT));
            assertEquals(null, metadata.get(Metadata.WORD_COUNT));
            assertEquals(null, metadata.get(Metadata.CHARACTER_COUNT));
+           assertEquals(null, metadata.get(Metadata.TABLE_COUNT));
+           assertEquals(null, metadata.get(Metadata.OBJECT_COUNT));
+           assertEquals(null, metadata.get(Metadata.IMAGE_COUNT));
            assertEquals(null, metadata.get("nbTab"));
            assertEquals(null, metadata.get("nbObject"));
            assertEquals(null, metadata.get("nbImg"));
@@ -207,6 +213,9 @@ public class ODFParserTest extends TikaTest {
            assertEquals("13", metadata.get(Metadata.PARAGRAPH_COUNT));
            assertEquals("54", metadata.get(Metadata.WORD_COUNT));
            assertEquals("351", metadata.get(Metadata.CHARACTER_COUNT));
+           assertEquals("0", metadata.get(Metadata.TABLE_COUNT));
+           assertEquals("2", metadata.get(Metadata.OBJECT_COUNT));
+           assertEquals("0", metadata.get(Metadata.IMAGE_COUNT));
            
            // Check the old style statistics (these will be removed shortly)
            assertEquals("0", metadata.get("nbTab"));

Commit:
f52da719f16ad7379d5b7019ac766a80ab48d6db
Nick Burch
nick@apache.org
2012-01-24 14:48:58 +0000
TIKA-760 Avoid NPE in XHTMLContentHandler if a null string is passed to the characters method
diff --git a/tika-core/src/main/java/org/apache/tika/sax/XHTMLContentHandler.java b/tika-core/src/main/java/org/apache/tika/sax/XHTMLContentHandler.java
index fea8ac35f..fd2b30155 100644
--- a/tika-core/src/main/java/org/apache/tika/sax/XHTMLContentHandler.java
+++ b/tika-core/src/main/java/org/apache/tika/sax/XHTMLContentHandler.java
@@ -291,7 +291,9 @@ public class XHTMLContentHandler extends SafeContentHandler {
     }
 
     public void characters(String characters) throws SAXException {
-        characters(characters.toCharArray(), 0, characters.length());
+        if (characters != null && characters.length() > 0) {
+            characters(characters.toCharArray(), 0, characters.length());
+        }
     }
 
     public void newline() throws SAXException {

Commit:
8f05b4e99721921279f2656663c58b403eff2329
Nick Burch
nick@apache.org
2012-01-24 12:57:08 +0000
TIKA-839 Update the .potm test file to match the others, and enable testing of it - file+patch from John Mastarone
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
index 075ee1c54..6fd3b4d2f 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
@@ -152,7 +152,7 @@ public class OOXMLParserTest extends TikaTest {
      */
     public void testPowerPoint() throws Exception {
 	String[] extensions = new String[] {
-		"pptx", "pptm", "ppsm", "ppsx",
+		"pptx", "pptm", "ppsm", "ppsx", "potm"
 		//"thmx", // TIKA-418: Will be supported in POI 3.7 beta 2 
 		//"xps" // TIKA-418: Not yet supported by POI
 	};
@@ -161,7 +161,8 @@ public class OOXMLParserTest extends TikaTest {
                 "application/vnd.openxmlformats-officedocument.presentationml.presentation",
                 "application/vnd.ms-powerpoint.presentation.macroenabled.12",
                 "application/vnd.ms-powerpoint.slideshow.macroenabled.12",
-                "application/vnd.openxmlformats-officedocument.presentationml.slideshow"
+                "application/vnd.openxmlformats-officedocument.presentationml.slideshow",
+                "application/vnd.ms-powerpoint.template.macroenabled.12"
         };
 
         for (int i=0; i<extensions.length; i++) {
diff --git a/tika-parsers/src/test/resources/test-documents/testPPT.potm b/tika-parsers/src/test/resources/test-documents/testPPT.potm
index bc0abb0c6..b78da7f7a 100644
Binary files a/tika-parsers/src/test/resources/test-documents/testPPT.potm and b/tika-parsers/src/test/resources/test-documents/testPPT.potm differ

Commit:
84e8fc3625d50e956f3295a846c4b21b99070a19
Nick Burch
nick@apache.org
2012-01-24 11:56:45 +0000
TIKA-849 EPub (and iBooks) files typically have multiple xhtml documents making up the whole, so avoid repeatedly starting/ending the document for each part
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/epub/EpubParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/epub/EpubParser.java
index 80e10b8af..9cf954c1e 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/epub/EpubParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/epub/EpubParser.java
@@ -33,6 +33,9 @@ import org.apache.tika.parser.AbstractParser;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.parser.Parser;
 import org.apache.tika.parser.xml.DcXMLParser;
+import org.apache.tika.sax.BodyContentHandler;
+import org.apache.tika.sax.EmbeddedContentHandler;
+import org.apache.tika.sax.XHTMLContentHandler;
 import org.xml.sax.ContentHandler;
 import org.xml.sax.SAXException;
 import org.xml.sax.helpers.DefaultHandler;
@@ -79,6 +82,13 @@ public class EpubParser extends AbstractParser {
             InputStream stream, ContentHandler handler,
             Metadata metadata, ParseContext context)
             throws IOException, SAXException, TikaException {
+        // Because an EPub file is often made up of multiple XHTML files,
+        //  we need explicit control over the start and end of the document
+        XHTMLContentHandler xhtml = new XHTMLContentHandler(handler, metadata);
+        xhtml.startDocument();
+        ContentHandler childHandler = new EmbeddedContentHandler(
+              new BodyContentHandler(xhtml));
+       
         ZipInputStream zip = new ZipInputStream(stream);
         ZipEntry entry = zip.getNextEntry();
         while (entry != null) {
@@ -91,10 +101,13 @@ public class EpubParser extends AbstractParser {
                 meta.parse(zip, new DefaultHandler(), metadata, context);
             } else if (entry.getName().endsWith(".html") || 
             		   entry.getName().endsWith(".xhtml")) {
-                content.parse(zip, handler, metadata, context);
+                content.parse(zip, childHandler, metadata, context);
             }
             entry = zip.getNextEntry();
         }
+        
+        // Finish everything
+        xhtml.endDocument();
     }
 
 }
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/epub/EpubParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/epub/EpubParserTest.java
index b7b1cacbc..b9029f300 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/epub/EpubParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/epub/EpubParserTest.java
@@ -21,6 +21,7 @@ import java.io.InputStream;
 import junit.framework.TestCase;
 
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.parser.ParseContext;
 import org.apache.tika.sax.BodyContentHandler;
 import org.xml.sax.ContentHandler;
 
@@ -32,7 +33,7 @@ public class EpubParserTest extends TestCase {
         try {
             Metadata metadata = new Metadata();
             ContentHandler handler = new BodyContentHandler();
-            new EpubParser().parse(input, handler, metadata);
+            new EpubParser().parse(input, handler, metadata, new ParseContext());
 
             assertEquals("application/epub+zip",
                     metadata.get(Metadata.CONTENT_TYPE));

Commit:
c877ecc800c4085e4f13bd36c7bd3840c3d662e2
Nick Burch
nick@apache.org
2012-01-23 17:10:20 +0000
TIKA-849 Initial ibooks epub support and test, from Andrew Jackson. Metadata only for now though, text isn't coming through as it's within <object> tags
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/epub/EpubParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/epub/EpubParser.java
index 5d53f4e02..80e10b8af 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/epub/EpubParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/epub/EpubParser.java
@@ -18,7 +18,9 @@ package org.apache.tika.parser.epub;
 
 import java.io.IOException;
 import java.io.InputStream;
+import java.util.Arrays;
 import java.util.Collections;
+import java.util.HashSet;
 import java.util.Set;
 import java.util.zip.ZipEntry;
 import java.util.zip.ZipInputStream;
@@ -44,7 +46,10 @@ public class EpubParser extends AbstractParser {
     private static final long serialVersionUID = 215176772484050550L;
 
     private static final Set<MediaType> SUPPORTED_TYPES =
-        Collections.singleton(MediaType.application("epub+zip"));
+            Collections.unmodifiableSet(new HashSet<MediaType>(Arrays.asList(
+            		MediaType.application("epub+zip"),
+                  MediaType.application("x-ibooks+zip")
+            )));
 
     private Parser meta = new DcXMLParser();
 
@@ -84,7 +89,8 @@ public class EpubParser extends AbstractParser {
                 meta.parse(zip, new DefaultHandler(), metadata, context);
             } else if (entry.getName().endsWith(".opf")) {
                 meta.parse(zip, new DefaultHandler(), metadata, context);
-            } else if (entry.getName().endsWith(".html")) {
+            } else if (entry.getName().endsWith(".html") || 
+            		   entry.getName().endsWith(".xhtml")) {
                 content.parse(zip, handler, metadata, context);
             }
             entry = zip.getNextEntry();
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/ibooks/iBooksParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/ibooks/iBooksParserTest.java
new file mode 100644
index 000000000..c15eaed44
--- /dev/null
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/ibooks/iBooksParserTest.java
@@ -0,0 +1,62 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.parser.ibooks;
+
+import java.io.InputStream;
+
+import junit.framework.TestCase;
+
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.parser.ParseContext;
+import org.apache.tika.parser.epub.EpubParser;
+import org.apache.tika.sax.BodyContentHandler;
+import org.xml.sax.ContentHandler;
+
+public class iBooksParserTest extends TestCase {
+
+    public void testiBooksParser() throws Exception {
+        InputStream input = iBooksParserTest.class.getResourceAsStream(
+                "/test-documents/testiBooks.ibooks");
+        try {
+            Metadata metadata = new Metadata();
+            ContentHandler handler = new BodyContentHandler();
+            new EpubParser().parse(input, handler, metadata, new ParseContext());
+
+            assertEquals("application/x-ibooks+zip",
+                    metadata.get(Metadata.CONTENT_TYPE));
+            assertEquals("en-GB",
+                    metadata.get(Metadata.LANGUAGE));
+            assertEquals("iBooks Author v1.0",
+                    metadata.get(Metadata.CONTRIBUTOR));
+            assertEquals("Apache",
+                    metadata.get(Metadata.CREATOR));
+
+            /* TODO For some reason, the xhtml files in iBooks-style ePub are not parsed properly, and the content comes back empty.git che
+            String content = handler.toString();
+            System.out.println("content="+content);
+            assertTrue(content.contains("Plus a simple div"));
+            assertTrue(content.contains("First item"));
+            assertTrue(content.contains("The previous headings were subchapters"));
+            assertTrue(content.contains("Table data"));
+            assertTrue(content.contains("Lorem ipsum dolor rutur amet"));
+            */
+        } finally {
+            input.close();
+        }
+    }
+
+}

Commit:
11184262f9ff36fa4cdda2a88805c0b24a5604e2
Nick Burch
nick@apache.org
2012-01-23 16:57:55 +0000
TIKA-849 iBooks epub mimetype entry, and fix a few comments
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index d497b7838..3043901f7 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -250,7 +250,7 @@
 
   <!-- http://www.iana.org/assignments/media-types/application/msword -->
   <mime-type type="application/msword">
-    <!-- Use org.apache.tika.detect.ContainerAwareDetector for more reliable detection of OLE2 documents -->
+    <!-- Use DefaultDetector / org.apache.tika.parser.microsoft.POIFSContainerDetector for more reliable detection of OLE2 documents -->
     <alias type="application/vnd.ms-word"/>
     <_comment>Microsoft Word Document</_comment>
     <magic priority="50">
@@ -1204,7 +1204,7 @@
 
   <!-- http://www.iana.org/assignments/media-types/application/vnd.ms-excel -->
   <mime-type type="application/vnd.ms-excel">
-    <!-- Use org.apache.tika.detect.ContainerAwareDetector for more reliable detection of OLE2 documents -->
+    <!-- Use DefaultDetector / org.apache.tika.parser.microsoft.POIFSContainerDetector for more reliable detection of OLE2 documents -->
     <alias type="application/msexcel" />
     <_comment>Microsoft Excel Spreadsheet</_comment>
     <magic priority="50">
@@ -1280,7 +1280,7 @@
 
   <!-- http://www.iana.org/assignments/media-types/application/vnd.ms-powerpoint -->
   <mime-type type="application/vnd.ms-powerpoint">
-    <!-- Use org.apache.tika.detect.ContainerAwareDetector for more reliable detection of OLE2 documents -->
+    <!-- Use DefaultDetector / org.apache.tika.parser.microsoft.POIFSContainerDetector for more reliable detection of OLE2 documents -->
     <alias type="application/mspowerpoint"/>
     <_comment>Microsoft Powerpoint Presentation</_comment>
     <magic priority="50">
@@ -2549,6 +2549,18 @@
     </magic>
   </mime-type>
 
+  <mime-type type="application/x-ibooks+zip">
+    <sub-class-of type="application/epub+zip" />
+    <acronym>iBooks</acronym>
+    <_comment>Apple iBooks Author publication format</_comment>
+    <magic priority="50">
+      <match value="PK\003\004" type="string" offset="0">
+        <match value="mimetypeapplication/x-ibooks+zip" type="string" offset="30"/>
+      </match>
+    </magic>
+    <glob pattern="*.ibooks"/>
+  </mime-type>
+
   <mime-type type="application/x-iso9660-image">
     <magic priority="50">
       <match value="CD001" type="string" offset="37633"/>

Commit:
7c43bff1a585550a2e1854e5de05c37c56ec7cde
Nick Burch
nick@apache.org
2012-01-23 16:29:55 +0000
TIKA-849 Add a sample iBooks epub file from Andrew Jackson, and add a unit test for the Zip Container Detector of epub zip formats
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/pkg/ZipContainerDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/pkg/ZipContainerDetector.java
index 6faea59bf..ee5a45465 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/pkg/ZipContainerDetector.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/pkg/ZipContainerDetector.java
@@ -95,6 +95,11 @@ public class ZipContainerDetector implements Detector {
         return MediaType.APPLICATION_ZIP;
     }
 
+    /**
+     * OpenDocument files, along with EPub files, have a mimetype
+     *  entry in the root of their Zip file. This entry contains the
+     *  mimetype of the overall file, stored as a single string.  
+     */
     private static MediaType detectOpenDocument(ZipFile zip) {
         try {
             ZipArchiveEntry mimetype = zip.getEntry("mimetype");
diff --git a/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java b/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
index 511350845..cbffa9d1b 100644
--- a/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
+++ b/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
@@ -155,6 +155,15 @@ public class TestContainerAwareDetector extends TestCase {
         }
     }
 
+    /**
+     * EPub uses a similar mimetype entry to OpenDocument for storing
+     *  the mimetype within the parent zip file
+     */
+    public void testDetectEPub() throws Exception {
+       assertTypeByData("testEPUB.epub", "application/epub+zip");
+       assertTypeByData("testiBooks.ibooks", "application/x-ibooks+zip");
+    }
+
     public void testDetectODF() throws Exception {
         assertTypeByData("testODFwithOOo3.odt", "application/vnd.oasis.opendocument.text");
         assertTypeByData("testOpenOffice2.odf", "application/vnd.oasis.opendocument.formula");
diff --git a/tika-parsers/src/test/resources/test-documents/testiBooks.ibooks b/tika-parsers/src/test/resources/test-documents/testiBooks.ibooks
new file mode 100644
index 000000000..ec4ae5a22
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testiBooks.ibooks differ

Commit:
c95bbb37774c3b09bbac0746e6116ee139cc42c8
Nick Burch
nick@apache.org
2012-01-23 16:08:10 +0000
TIKA-845 Correct the conversion of XML tags to multi-valued metadata values, and avoid duplicating existing values
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/xml/AbstractMetadataHandler.java b/tika-parsers/src/main/java/org/apache/tika/parser/xml/AbstractMetadataHandler.java
index 30491f5cd..598649094 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/xml/AbstractMetadataHandler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/xml/AbstractMetadataHandler.java
@@ -16,6 +16,9 @@
  */
 package org.apache.tika.parser.xml;
 
+import java.util.Arrays;
+import java.util.List;
+
 import org.apache.tika.metadata.Metadata;
 import org.xml.sax.helpers.DefaultHandler;
 
@@ -44,11 +47,23 @@ class AbstractMetadataHandler extends DefaultHandler {
      */
     protected void addMetadata(String value) {
         if (value != null && value.length() > 0) {
-            String previous = metadata.get(name);
-            if (previous != null && previous.length() > 0) {
-                value = previous + ", " + value;
+            if (metadata.isMultiValued(name)) {
+                // Add the value, assuming it's not already there
+                List<String> previous = Arrays.asList(metadata.getValues(name));
+                if (!previous.contains(value)) {
+                    metadata.add(name, value);
+                }
+            } else {
+                // Set the value, assuming it's not already there
+                String previous = metadata.get(name);
+                if (previous != null && previous.length() > 0) {
+                    if (!previous.equals(value)) {
+                        metadata.add(name, value);
+                    }
+                } else {
+                    metadata.set(name, value);
+                }
             }
-            metadata.set(name, value);
         }
     }
 
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/xml/DcXMLParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/xml/DcXMLParserTest.java
index 7bec323cc..ccd0c2d61 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/xml/DcXMLParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/xml/DcXMLParserTest.java
@@ -40,9 +40,17 @@ public class DcXMLParserTest extends TestCase {
                     metadata.get(Metadata.CONTENT_TYPE));
             assertEquals("Tika test document", metadata.get(Metadata.TITLE));
             assertEquals("Rida Benjelloun", metadata.get(Metadata.CREATOR));
-            assertEquals(
-                    "Java, XML, XSLT, JDOM, Indexation",
-                    metadata.get(Metadata.SUBJECT));
+            
+            // The file contains 5 dc:subject tags, which come through as
+            //  a multi-valued Tika Metadata entry in file order
+            assertEquals(true, metadata.isMultiValued(Metadata.SUBJECT));
+            assertEquals(5,      metadata.getValues(Metadata.SUBJECT).length);
+            assertEquals("Java", metadata.getValues(Metadata.SUBJECT)[0]);
+            assertEquals("XML",  metadata.getValues(Metadata.SUBJECT)[1]);
+            assertEquals("XSLT", metadata.getValues(Metadata.SUBJECT)[2]);
+            assertEquals("JDOM", metadata.getValues(Metadata.SUBJECT)[3]);
+            assertEquals("Indexation", metadata.getValues(Metadata.SUBJECT)[4]);
+
             assertEquals(
                     "Framework d\'indexation des documents XML, HTML, PDF etc..",
                     metadata.get(Metadata.DESCRIPTION));

Commit:
92f444695e242cb358a6fb52a70210bdcccc2d66
Nick Burch
nick@apache.org
2012-01-23 15:46:20 +0000
TIKA-844 Add an internal TagBag property type constructor, patch from Ray Gauss
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/Property.java b/tika-core/src/main/java/org/apache/tika/metadata/Property.java
index adf2454c5..6023c4681 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/Property.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/Property.java
@@ -176,6 +176,10 @@ public final class Property implements Comparable<Property> {
     public static Property internalText(String name) {
         return new Property(name, true, ValueType.TEXT);
     }
+    
+    public static Property internalTextBag(String name) {
+        return new Property(name, true, PropertyType.BAG, ValueType.TEXT);
+    }
 
     public static Property internalURI(String name) {
         return new Property(name, true, ValueType.URI);

Commit:
45ac50a852749a90c3da4150f1666251f5f0cf74
Nick Burch
nick@apache.org
2012-01-23 15:45:32 +0000
TIKA-846 Fix indent
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/xml/ElementMetadataHandler.java b/tika-parsers/src/main/java/org/apache/tika/parser/xml/ElementMetadataHandler.java
index a1db68207..48d54dad9 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/xml/ElementMetadataHandler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/xml/ElementMetadataHandler.java
@@ -161,20 +161,19 @@ public class ElementMetadataHandler extends AbstractMetadataHandler {
 
     @Override
     protected void addMetadata(String value) {
-    	if (logger.isTraceEnabled()) {
-    		logger.trace("adding " + name + "=" + value);
-    	}
-    	if (targetProperty != null && targetProperty.getPropertyType() != null &&
-    			targetProperty.getPropertyType() == Property.PropertyType.BAG) {
-		    if (value != null && value.length() > 0) {
-		        String[] previous = metadata.getValues(name);
-		        if (previous == null || !Arrays.asList(previous).contains(value)) {
-		        	metadata.add(name, value);
-		        }
-		    }
-    	} else {
-    		super.addMetadata(value);
-    	}
+        if (logger.isTraceEnabled()) {
+            logger.trace("adding " + name + "=" + value);
+        }
+        if (targetProperty != null && targetProperty.getPropertyType() != null &&
+             targetProperty.getPropertyType() == Property.PropertyType.BAG) {
+            if (value != null && value.length() > 0) {
+                String[] previous = metadata.getValues(name);
+                if (previous == null || !Arrays.asList(previous).contains(value)) {
+                    metadata.add(name, value);
+                }
+            }
+        } else {
+            super.addMetadata(value);
+        }
     }
-
 }

Commit:
c657ecd444505bd924bcf6bd2ed3c4be04f85692
Nick Burch
nick@apache.org
2012-01-23 15:39:11 +0000
TIKA-846 Patch from Ray Gauss to parse RDF Bag Elements to multi-valued metadata
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/xml/ElementMetadataHandler.java b/tika-parsers/src/main/java/org/apache/tika/parser/xml/ElementMetadataHandler.java
index 191ff058f..a1db68207 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/xml/ElementMetadataHandler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/xml/ElementMetadataHandler.java
@@ -16,7 +16,12 @@
  */
 package org.apache.tika.parser.xml;
 
+import java.util.Arrays;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.Property;
 import org.xml.sax.Attributes;
 
 /**
@@ -26,24 +31,80 @@ import org.xml.sax.Attributes;
  * @since Apache Tika 0.10
  */
 public class ElementMetadataHandler extends AbstractMetadataHandler {
+	/**
+	 * Logger for this class
+	 */
+	private static final Log logger = LogFactory
+			.getLog(ElementMetadataHandler.class);
+
+	private static final String LOCAL_NAME_RDF_BAG = "Bag";
+	private static final String LOCAL_NAME_RDF_LI = "li";
+	private static final String URI_RDF = "http://www.w3.org/1999/02/22-rdf-syntax-ns#";
 
     private final String uri;
 
     private final String localName;
 
-    private final StringBuilder buffer = new StringBuilder();
+    private final Metadata metadata;
+
+    private final String name;
+    private Property targetProperty;
+
+    /**
+     * The buffer used to capture characters when inside a bag li element.
+     */
+    private final StringBuilder bufferBagged = new StringBuilder();
+    
+    /**
+     * The buffer used to capture characters inside standard elements.
+     */
+    private final StringBuilder bufferBagless = new StringBuilder();
+    
+    /**
+     * Whether or not the value was found in a standard element structure or inside a bag.
+     */
+    private boolean isBagless = true;
 
     private int matchLevel = 0;
+    private int parentMatchLevel = 0;
 
     public ElementMetadataHandler(
             String uri, String localName, Metadata metadata, String name) {
         super(metadata, name);
         this.uri = uri;
         this.localName = localName;
+        this.metadata = metadata;
+        this.name = name;
+        if (logger.isTraceEnabled()) {
+    		logger.trace("created simple handler for " + this.name);
+    	}
+    }
+
+    public ElementMetadataHandler(
+            String uri, String localName, Metadata metadata, Property targetProperty) {
+    	super(metadata, targetProperty.getName());
+        this.uri = uri;
+        this.localName = localName;
+        this.metadata = metadata;
+        this.targetProperty = targetProperty;
+        this.name = targetProperty.getName();
+        if (logger.isTraceEnabled()) {
+    		logger.trace("created property handler for " + this.name);
+    	}
+    }
+
+    protected boolean isMatchingParentElement(String uri, String localName) {
+        return (uri.equals(this.uri) && localName.equals(this.localName));
     }
 
     protected boolean isMatchingElement(String uri, String localName) {
-        return uri.equals(this.uri) && localName.equals(this.localName);
+    	// match if we're inside the parent element or within some bag element
+        return (uri.equals(this.uri) && localName.equals(this.localName)) ||
+        		(parentMatchLevel > 0 &&
+        				((uri.equals(URI_RDF) && localName.equals(LOCAL_NAME_RDF_BAG)) ||
+        				(uri.equals(URI_RDF) && localName.equals(LOCAL_NAME_RDF_LI))
+        		)
+        );
     }
 
     @Override
@@ -52,23 +113,44 @@ public class ElementMetadataHandler extends AbstractMetadataHandler {
         if (isMatchingElement(uri, localName)) {
             matchLevel++;
         }
+        if (isMatchingParentElement(uri, localName)) {
+            parentMatchLevel++;
+        }
     }
 
     @Override
     public void endElement(String uri, String localName, String name) {
+    	if (isMatchingParentElement(uri, localName)) {
+    		parentMatchLevel--;
+    	}
         if (isMatchingElement(uri, localName)) {
             matchLevel--;
-            if (matchLevel == 0) {
-                addMetadata(buffer.toString().trim());
-                buffer.setLength(0);
+            if (matchLevel == 2) {
+            	// we're inside a bag li element, add the bagged buffer
+                addMetadata(bufferBagged.toString().trim());
+                bufferBagged.setLength(0);
+                isBagless = false;
+            }
+            if (matchLevel == 0 && isBagless) {
+            	String valueBagless = bufferBagless.toString();
+            	if (valueBagless.length() > 0 && !valueBagless.contains(LOCAL_NAME_RDF_BAG)) {
+            		// we're in a standard element, add the bagless buffer
+	                addMetadata(valueBagless.trim());
+	                bufferBagless.setLength(0);
+            	}
+            	isBagless = true;
             }
         }
     }
 
     @Override
     public void characters(char[] ch, int start, int length) {
-        if (matchLevel > 0) {
-            buffer.append(ch, start, length);
+    	// We need to append to both buffers since we don't if we're inside a bag until we're done
+        if (parentMatchLevel > 0 && matchLevel > 2) {
+            bufferBagged.append(ch, start, length);
+        }
+        if (parentMatchLevel > 0 && matchLevel > 0) {
+            bufferBagless.append(ch, start, length);
         }
     }
 
@@ -77,4 +159,22 @@ public class ElementMetadataHandler extends AbstractMetadataHandler {
         characters(ch, start, length);
     }
 
+    @Override
+    protected void addMetadata(String value) {
+    	if (logger.isTraceEnabled()) {
+    		logger.trace("adding " + name + "=" + value);
+    	}
+    	if (targetProperty != null && targetProperty.getPropertyType() != null &&
+    			targetProperty.getPropertyType() == Property.PropertyType.BAG) {
+		    if (value != null && value.length() > 0) {
+		        String[] previous = metadata.getValues(name);
+		        if (previous == null || !Arrays.asList(previous).contains(value)) {
+		        	metadata.add(name, value);
+		        }
+		    }
+    	} else {
+    		super.addMetadata(value);
+    	}
+    }
+
 }

Commit:
f6adfbda369a376d4d03c1c76d14f4736ef6e28c
Nick Burch
nick@apache.org
2012-01-20 17:05:06 +0000
TIKA-843 Switch dates without times to noon UTC
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java b/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
index 83f909592..f623143b3 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
@@ -68,9 +68,9 @@ public class Metadata implements CreativeCommons, DublinCore, Geographic, HttpHe
         createDateFormat("yyyy-MM-dd' 'HH:mm:ss'Z'", "UTC"), // UTC/Zulu
         createDateFormat("yyyy-MM-dd' 'HH:mm:ssZ", null),    // With timezone
         createDateFormat("yyyy-MM-dd' 'HH:mm:ss", null),     // Without timezone
-        // Date without time, set to Midnight UTC
-        createDateFormat("yyyy-MM-dd", "UTC"), // Normal date format
-        createDateFormat("yyyy:MM:dd", "UTC"), // Image (IPTC/EXIF) format
+        // Date without time, set to Midday UTC
+        createDateFormat("yyyy-MM-dd", "GMT-12:00"), // Normal date format
+        createDateFormat("yyyy:MM:dd", "GMT-12:00"), // Image (IPTC/EXIF) format
     };
 
     private static DateFormat createDateFormat(String format, String timezone) {
diff --git a/tika-core/src/test/java/org/apache/tika/metadata/TestMetadata.java b/tika-core/src/test/java/org/apache/tika/metadata/TestMetadata.java
index 3199fcff3..1a4941450 100644
--- a/tika-core/src/test/java/org/apache/tika/metadata/TestMetadata.java
+++ b/tika-core/src/test/java/org/apache/tika/metadata/TestMetadata.java
@@ -253,6 +253,7 @@ public class TestMetadata extends TestCase {
      */
     public void testGetSetDate() {
         Metadata meta = new Metadata();
+        long hour = 60 * 60 * 1000; 
         
         // Isn't initially set, will get null back
         assertEquals(null, meta.get(Metadata.CREATION_DATE));
@@ -309,12 +310,12 @@ public class TestMetadata extends TestCase {
         meta.set(Metadata.CREATION_DATE, "1969-12-31T12:00:01-12:00");
         assertEquals(1000, meta.getDate(Metadata.CREATION_DATE).getTime());
         
-        // Dates without times
+        // Dates without times, come in at midday UTC
         meta.set(Metadata.CREATION_DATE, "1970-01-01");
-        assertEquals(0, meta.getDate(Metadata.CREATION_DATE).getTime());
+        assertEquals(12*hour, meta.getDate(Metadata.CREATION_DATE).getTime());
         
         meta.set(Metadata.CREATION_DATE, "1970:01:01");
-        assertEquals(0, meta.getDate(Metadata.CREATION_DATE).getTime());
+        assertEquals(12*hour, meta.getDate(Metadata.CREATION_DATE).getTime());
     }
     
     /**

Commit:
83eb5b81bca849bf512b84425cd6900c9921b251
Nick Burch
nick@apache.org
2012-01-20 17:01:12 +0000
TIKA-843 Metadata support for dates without times (treated as midnight UTC)
diff --git a/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java b/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
index be9454faf..83f909592 100644
--- a/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
+++ b/tika-core/src/main/java/org/apache/tika/metadata/Metadata.java
@@ -68,6 +68,9 @@ public class Metadata implements CreativeCommons, DublinCore, Geographic, HttpHe
         createDateFormat("yyyy-MM-dd' 'HH:mm:ss'Z'", "UTC"), // UTC/Zulu
         createDateFormat("yyyy-MM-dd' 'HH:mm:ssZ", null),    // With timezone
         createDateFormat("yyyy-MM-dd' 'HH:mm:ss", null),     // Without timezone
+        // Date without time, set to Midnight UTC
+        createDateFormat("yyyy-MM-dd", "UTC"), // Normal date format
+        createDateFormat("yyyy:MM:dd", "UTC"), // Image (IPTC/EXIF) format
     };
 
     private static DateFormat createDateFormat(String format, String timezone) {
diff --git a/tika-core/src/test/java/org/apache/tika/metadata/TestMetadata.java b/tika-core/src/test/java/org/apache/tika/metadata/TestMetadata.java
index 74d5a3f5a..3199fcff3 100644
--- a/tika-core/src/test/java/org/apache/tika/metadata/TestMetadata.java
+++ b/tika-core/src/test/java/org/apache/tika/metadata/TestMetadata.java
@@ -308,6 +308,13 @@ public class TestMetadata extends TestCase {
         
         meta.set(Metadata.CREATION_DATE, "1969-12-31T12:00:01-12:00");
         assertEquals(1000, meta.getDate(Metadata.CREATION_DATE).getTime());
+        
+        // Dates without times
+        meta.set(Metadata.CREATION_DATE, "1970-01-01");
+        assertEquals(0, meta.getDate(Metadata.CREATION_DATE).getTime());
+        
+        meta.set(Metadata.CREATION_DATE, "1970:01:01");
+        assertEquals(0, meta.getDate(Metadata.CREATION_DATE).getTime());
     }
     
     /**

Commit:
a2555c65cf806b7ff47a33c579b33ff7aaf8f3ae
Nick Burch
nick@apache.org
2012-01-20 15:56:05 +0000
TIKA-507 FontBox powered .afm font metrics parser, patch from Fernando Arreola
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/font/AdobeFontMetricParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/font/AdobeFontMetricParser.java
new file mode 100644
index 000000000..29f26348f
--- /dev/null
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/font/AdobeFontMetricParser.java
@@ -0,0 +1,134 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.parser.font;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.util.Collections;
+import java.util.List;
+import java.util.Set;
+
+import org.apache.fontbox.afm.AFMParser;
+import org.apache.fontbox.afm.FontMetric;
+import org.apache.tika.exception.TikaException;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.metadata.Property;
+import org.apache.tika.mime.MediaType;
+import org.apache.tika.parser.AbstractParser;
+import org.apache.tika.parser.ParseContext;
+import org.apache.tika.sax.XHTMLContentHandler;
+import org.xml.sax.ContentHandler;
+import org.xml.sax.SAXException;
+
+/**
+ * Parser for AFM Font Files
+ */
+public class AdobeFontMetricParser extends AbstractParser { 
+    /** Serial version UID */
+    private static final long serialVersionUID = -4820306522217196835L;
+
+    private static final MediaType AFM_TYPE =
+         MediaType.application( "x-font-adobe-metric" );
+
+    private static final Set<MediaType> SUPPORTED_TYPES = Collections.singleton(AFM_TYPE);
+        
+    public Set<MediaType> getSupportedTypes( ParseContext context ) { 
+       return SUPPORTED_TYPES;
+    }
+
+    public void parse(InputStream stream, ContentHandler handler,
+                      Metadata metadata, ParseContext context)
+                      throws IOException, SAXException, TikaException { 
+       FontMetric fontMetrics;
+       AFMParser  parser      = new AFMParser( stream );
+
+       // Have FontBox process the file
+       parser.parse();
+       fontMetrics = parser.getResult();
+
+       // Get the comments in the file to display in xhtml
+       List<String> comments = fontMetrics.getComments();
+
+       // Get the creation date
+       extractCreationDate( metadata, comments );
+
+       metadata.set( Metadata.CONTENT_TYPE, AFM_TYPE.toString() );
+       metadata.set( Metadata.TITLE, fontMetrics.getFullName() );
+
+       // Add metadata associated with the font type
+       addMetadataByString( metadata, "AvgCharacterWidth", Float.toString( fontMetrics.getAverageCharacterWidth() ) );
+       addMetadataByString( metadata, "DocVersion", Float.toString( fontMetrics.getAFMVersion() ) );
+       addMetadataByString( metadata, "FontName", fontMetrics.getFontName() );
+       addMetadataByString( metadata, "FontFullName", fontMetrics.getFullName() );
+       addMetadataByString( metadata, "FontFamilyName", fontMetrics.getFamilyName() );
+       addMetadataByString( metadata, "FontVersion", fontMetrics.getFontVersion() );
+       addMetadataByString( metadata, "FontWeight", fontMetrics.getWeight() );
+       addMetadataByString( metadata, "FontNotice", fontMetrics.getNotice() );
+       addMetadataByString( metadata, "FontUnderlineThickness", Float.toString( fontMetrics.getUnderlineThickness() ) );
+
+       // Output the remaining comments as text
+       XHTMLContentHandler xhtml = new XHTMLContentHandler( handler, metadata );
+       xhtml.startDocument();
+
+       // Display the comments
+       if (comments.size() > 0) {
+          xhtml.element( "h1", "Comments" );
+          xhtml.startElement("div", "class", "comments");
+          for (String comment : comments) {
+              xhtml.element( "p", comment );
+          }
+          xhtml.endElement("div");
+       }
+
+       xhtml.endDocument();
+    }
+
+    private void addMetadataByString( Metadata metadata, String name, String value ) { 
+       // Add metadata if an appropriate value is passed 
+       if (value != null) { 
+          metadata.add( name, value );
+       }
+    }
+
+    private void addMetadataByProperty( Metadata metadata, Property property, String value ) { 
+       // Add metadata if an appropriate value is passed 
+       if (value != null) 
+       {
+          metadata.set( property, value );
+       }
+    }
+
+
+    private void extractCreationDate( Metadata metadata, List<String> comments ) {
+       String   date = null;
+
+       for (String value : comments) {
+          // Look for the creation date
+          if( value.matches( ".*Creation\\sDate.*" ) ) {
+             date = value.substring( value.indexOf( ":" ) + 2 );
+             comments.remove( value );
+
+             break;
+          }
+       }
+
+       // If appropriate date then store as metadata
+       if( date != null ) {
+          addMetadataByProperty( metadata, Metadata.CREATION_DATE, date );
+       }
+    }
+}
diff --git a/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.parser.Parser b/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.parser.Parser
index e3ca9be01..c1090aecd 100644
--- a/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.parser.Parser
+++ b/tika-parsers/src/main/resources/META-INF/services/org.apache.tika.parser.Parser
@@ -19,6 +19,7 @@ org.apache.tika.parser.audio.MidiParser
 org.apache.tika.parser.dwg.DWGParser
 org.apache.tika.parser.epub.EpubParser
 org.apache.tika.parser.feed.FeedParser
+org.apache.tika.parser.font.AdobeFontMetricParser
 org.apache.tika.parser.font.TrueTypeParser
 org.apache.tika.parser.html.HtmlParser
 org.apache.tika.parser.image.ImageParser
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/font/AdobeFontMetricParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/font/AdobeFontMetricParserTest.java
new file mode 100644
index 000000000..a8150094d
--- /dev/null
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/font/AdobeFontMetricParserTest.java
@@ -0,0 +1,66 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.parser.font;
+
+import junit.framework.TestCase;
+
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.parser.AutoDetectParser;
+import org.apache.tika.parser.ParseContext;
+import org.apache.tika.parser.Parser;
+import org.apache.tika.sax.BodyContentHandler;
+import org.xml.sax.ContentHandler;
+import org.apache.tika.io.TikaInputStream;
+
+/**
+ * Test case for parsing afm files.
+ */
+public class AdobeFontMetricParserTest extends TestCase {
+    public void testAdobeFontMetricParsing() throws Exception {
+        Parser parser = new AutoDetectParser(); // Should auto-detect!
+        ContentHandler handler = new BodyContentHandler();
+        Metadata metadata = new Metadata();
+        ParseContext context = new ParseContext();
+        TikaInputStream stream = TikaInputStream.get(
+                AdobeFontMetricParserTest.class.getResource(
+                        "/test-documents/testAFM.afm"));
+
+        try {
+            parser.parse(stream, handler, metadata, context);
+        } finally {
+            stream.close();
+        }
+
+        assertEquals("application/x-font-adobe-metric", metadata.get(Metadata.CONTENT_TYPE));
+        assertEquals("TestFullName", metadata.get(Metadata.TITLE));
+        assertEquals("Fri Jul 15 17:50:51 2011", metadata.get(Metadata.CREATION_DATE));
+        
+        assertEquals("TestFontName", metadata.get("FontName"));
+        assertEquals("TestFullName", metadata.get("FontFullName"));
+        assertEquals("TestSymbol",   metadata.get("FontFamilyName"));
+        
+        assertEquals("Medium",  metadata.get("FontWeight"));
+        assertEquals("001.008", metadata.get("FontVersion"));
+
+        String content = handler.toString();
+
+        // Test that the comments got extracted
+        assertTrue(content.contains("Comments"));
+        assertTrue(content.contains("This is a comment in a sample file"));
+        assertTrue(content.contains("UniqueID 12345"));
+    }
+}
diff --git a/tika-parsers/src/test/resources/test-documents/testAFM.afm b/tika-parsers/src/test/resources/test-documents/testAFM.afm
index 5c3e780ab..8890a128b 100644
--- a/tika-parsers/src/test/resources/test-documents/testAFM.afm
+++ b/tika-parsers/src/test/resources/test-documents/testAFM.afm
@@ -38,7 +38,7 @@ StdHW 91
 
 StdVW 86
 
-StartCharMetrics 190
+StartCharMetrics 2
 
 C 32 ; WX 250 ; N space ; B 0 0 0 0 ;
 

Commit:
80d36ebce4db6b3a15d853b12646c9db40b6cd42
Nick Burch
nick@apache.org
2012-01-18 14:27:08 +0000
TIKA-841 User supplied parsers should be prefered over built in ones in DefaultParser
diff --git a/tika-core/src/main/java/org/apache/tika/parser/DefaultParser.java b/tika-core/src/main/java/org/apache/tika/parser/DefaultParser.java
index e893b0c7a..098f087ae 100644
--- a/tika-core/src/main/java/org/apache/tika/parser/DefaultParser.java
+++ b/tika-core/src/main/java/org/apache/tika/parser/DefaultParser.java
@@ -16,6 +16,11 @@
  */
 package org.apache.tika.parser;
 
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.Comparator;
+import java.util.List;
+
 import javax.imageio.spi.ServiceRegistry;
 
 import org.apache.tika.config.ServiceLoader;
@@ -28,12 +33,40 @@ import org.apache.tika.mime.MediaTypeRegistry;
  * @since Apache Tika 0.8
  */
 public class DefaultParser extends CompositeParser {
-
     /** Serial version UID */
     private static final long serialVersionUID = 3612324825403757520L;
 
+    private static List<Parser> getDefaultParsers(ServiceLoader loader) {
+        // Find all the Parsers available as services
+        List<Parser> svcParsers = loader.loadServiceProviders(Parser.class);
+        List<Parser> parsers = new ArrayList<Parser>(svcParsers.size());
+
+        // Sort the list by classname, rather than discovery order 
+        Collections.sort(svcParsers, new Comparator<Parser>() {
+           public int compare(Parser p1, Parser p2) {
+              return p1.getClass().getName().compareTo(
+                   p2.getClass().getName());
+           }
+        });
+        
+        // CompositeParser takes the last parser for any given mime type, so put the 
+        // TikaParsers first so that non-Tika (user supplied) parsers can take presidence
+        for (Parser p : svcParsers) {
+           if (p.getClass().getName().startsWith("org.apache.tika")) {
+              parsers.add(p);
+           }
+        }
+        for (Parser p : svcParsers) {
+           if (!p.getClass().getName().startsWith("org.apache.tika")) {
+              parsers.add(p);
+           }
+        }
+        
+        return parsers;
+    }
+    
     private DefaultParser(MediaTypeRegistry registry, ServiceLoader loader) {
-        super(registry, loader.loadServiceProviders(Parser.class));
+        super(registry, getDefaultParsers(loader));
     }
 
     public DefaultParser(MediaTypeRegistry registry, ClassLoader loader) {

Commit:
36bbcfca96f67edb19bcd63d6c3f96dbf47e7041
Nick Burch
nick@apache.org
2012-01-16 10:40:32 +0000
TIKA-805 Improved .pptx XSLF extraction, patch from Yegor Kozlov
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XSLFPowerPointExtractorDecorator.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XSLFPowerPointExtractorDecorator.java
index 2aeb96bfb..338ca82ee 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XSLFPowerPointExtractorDecorator.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XSLFPowerPointExtractorDecorator.java
@@ -29,11 +29,20 @@ import org.apache.poi.openxml4j.opc.TargetMode;
 import org.apache.poi.xslf.XSLFSlideShow;
 import org.apache.poi.xslf.extractor.XSLFPowerPointExtractor;
 import org.apache.poi.xslf.usermodel.DrawingParagraph;
+import org.apache.poi.xslf.usermodel.Placeholder;
 import org.apache.poi.xslf.usermodel.XMLSlideShow;
+import org.apache.poi.xslf.usermodel.XSLFComments;
 import org.apache.poi.xslf.usermodel.XSLFCommonSlideData;
+import org.apache.poi.xslf.usermodel.XSLFGroupShape;
 import org.apache.poi.xslf.usermodel.XSLFRelation;
+import org.apache.poi.xslf.usermodel.XSLFShape;
+import org.apache.poi.xslf.usermodel.XSLFSheet;
 import org.apache.poi.xslf.usermodel.XSLFSlide;
 import org.apache.poi.xslf.usermodel.XSLFSlideMaster;
+import org.apache.poi.xslf.usermodel.XSLFTable;
+import org.apache.poi.xslf.usermodel.XSLFTableCell;
+import org.apache.poi.xslf.usermodel.XSLFTableRow;
+import org.apache.poi.xslf.usermodel.XSLFTextShape;
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.sax.XHTMLContentHandler;
@@ -52,68 +61,63 @@ public class XSLFPowerPointExtractorDecorator extends AbstractOOXMLExtractor {
     /**
      * @see org.apache.poi.xslf.extractor.XSLFPowerPointExtractor#getText()
      */
-    @Override
-    protected void buildXHTML(XHTMLContentHandler xhtml) throws SAXException,
-            XmlException, IOException {
+    protected void buildXHTML(XHTMLContentHandler xhtml) throws SAXException, IOException {
         XMLSlideShow slideShow = (XMLSlideShow) extractor.getDocument();
-        XSLFSlideShow rawSlideShow = null;
-        try {
-           rawSlideShow = slideShow._getXSLFSlideShow(); // TODO Avoid this in future
-        } catch(Exception e) {
-           throw new IOException(e.getMessage()); // Shouldn't happen
-        }
 
         XSLFSlide[] slides = slideShow.getSlides();
         for (XSLFSlide slide : slides) {
-           // Find the ID, until we ditch the raw slideshow
-           CTSlideIdListEntry slideId = null;
-           for(CTSlideIdListEntry id : rawSlideShow.getSlideReferences().getSldIdList()) {
-              if(rawSlideShow.getSlidePart(id).getPartName().equals(slide.getPackagePart().getPartName())) {
-                 slideId = id;
-              }
-           }
-           if(slideId == null) {
-              // This shouldn't normally happen
-              continue;
-           }
-           
-            XSLFSlideMaster master = slide.getSlideMaster();
-            CTNotesSlide notes = rawSlideShow.getNotes(slideId);
-            CTCommentList comments = rawSlideShow.getSlideComments(slideId);
+            // slide
+            extractContent(slide.getShapes(), false, xhtml);
+
+            // slide layout which is the master sheet for this slide
+            XSLFSheet slideLayout = slide.getMasterSheet();
+            extractContent(slideLayout.getShapes(), true, xhtml);
 
-            // TODO In POI 3.8 beta 5, improve how we get this
-            xhtml.startElement("div");
-            XSLFCommonSlideData common = new XSLFCommonSlideData(slide.getXmlObject().getCSld());
-            extractShapeContent(common, xhtml);
+            // slide master which is the master sheet for all text layouts
+            XSLFSheet slideMaster = slideLayout.getMasterSheet();
+            extractContent(slideMaster.getShapes(), true, xhtml);
+
+            // notes (if present)
+            XSLFSheet slideNotes = slide.getNotes();
+            if (slideNotes != null) {
+                extractContent(slideNotes.getShapes(), false, xhtml);
+
+                // master sheet for this notes
+                XSLFSheet notesMaster = slideNotes.getMasterSheet();
+                extractContent(notesMaster.getShapes(), true, xhtml);
+            }
 
-            // If there are comments, extract them
+            // comments (if present)
+            XSLFComments comments = slide.getComments();
             if (comments != null) {
-                for (CTComment comment : comments.getCmArray()) {
+                for (CTComment comment : comments.getCTCommentsList().getCmList()) {
                     xhtml.element("p", comment.getText());
                 }
             }
-            
-            // Get text from the master slide
-            // TODO: re-enable this once we fix TIKA-712
-            /*
-            if(master != null) {
-               // TODO In POI 3.8 beta 5, improve how we get this
-               extractShapeContent(new XSLFCommonSlideData(master.getXmlObject().getCSld()), xhtml);
-            }
-            */
-
-            if (notes != null) {
-               // TODO In POI 3.8 beta 5, improve how we get this
-                extractShapeContent(new XSLFCommonSlideData(notes.getCSld()), xhtml);
-            }
-            xhtml.endElement("div");
         }
     }
 
-    private void extractShapeContent(XSLFCommonSlideData data, XHTMLContentHandler xhtml)
+    private void extractContent(XSLFShape[] shapes, boolean skipPlaceholders, XHTMLContentHandler xhtml)
             throws SAXException {
-        for (DrawingParagraph p : data.getText()) {
-            xhtml.element("p", p.getText().toString());
+        for (XSLFShape sh : shapes) {
+            if (sh instanceof XSLFTextShape) {
+                XSLFTextShape txt = (XSLFTextShape) sh;
+                Placeholder ph = txt.getTextType();
+                if (skipPlaceholders && ph != null) {
+                    continue;
+                }
+                xhtml.element("p", txt.getText());
+            } else if (sh instanceof XSLFGroupShape){
+                // recurse into groups of shapes
+                XSLFGroupShape group = (XSLFGroupShape)sh;
+                extractContent(group.getShapes(), skipPlaceholders, xhtml);
+            } else if (sh instanceof XSLFTable) {
+                XSLFTable tbl = (XSLFTable)sh;
+                for(XSLFTableRow row : tbl){
+                    List<XSLFTableCell> cells = row.getCells();
+                    extractContent(cells.toArray(new XSLFTableCell[cells.size()]), skipPlaceholders, xhtml);
+                }
+            }
         }
     }
     

Commit:
36986261cdfade8c8c33a417f20638467e83e660
Nick Burch
nick@apache.org
2012-01-13 15:01:54 +0000
TIKA-840 Update the OOXML parsers, so that rather than hard coding the content type, the file specific one is feteched and set
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/AbstractOOXMLExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/AbstractOOXMLExtractor.java
index 8070537fc..8bc031374 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/AbstractOOXMLExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/AbstractOOXMLExtractor.java
@@ -64,11 +64,8 @@ public abstract class AbstractOOXMLExtractor implements OOXMLExtractor {
 
     private final EmbeddedDocumentExtractor embeddedExtractor;
 
-    private final String type;
-
-    public AbstractOOXMLExtractor(ParseContext context, POIXMLTextExtractor extractor, String type) {
+    public AbstractOOXMLExtractor(ParseContext context, POIXMLTextExtractor extractor) {
         this.extractor = extractor;
-        this.type = type;
 
         EmbeddedDocumentExtractor ex = context.get(EmbeddedDocumentExtractor.class);
 
@@ -91,7 +88,7 @@ public abstract class AbstractOOXMLExtractor implements OOXMLExtractor {
      * @see org.apache.tika.parser.microsoft.ooxml.OOXMLExtractor#getMetadataExtractor()
      */
     public MetadataExtractor getMetadataExtractor() {
-        return new MetadataExtractor(extractor, type);
+        return new MetadataExtractor(extractor);
     }
 
     /**
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java
index fb3dc1f92..4114dd0ce 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java
@@ -44,16 +44,11 @@ public class MetadataExtractor {
 
     private final POIXMLTextExtractor extractor;
 
-    private final String type;
-
-    public MetadataExtractor(POIXMLTextExtractor extractor, String type) {
+    public MetadataExtractor(POIXMLTextExtractor extractor) {
         this.extractor = extractor;
-        this.type = type;
     }
 
     public void extract(Metadata metadata) throws TikaException {
-        addProperty(metadata, Metadata.CONTENT_TYPE, type);
-        
         if (extractor.getDocument() != null ||
               (extractor instanceof XSSFEventBasedExcelExtractor && 
                extractor.getPackage() != null)) {
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/OOXMLExtractorFactory.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/OOXMLExtractorFactory.java
index 18ef14f68..87a14ff53 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/OOXMLExtractorFactory.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/OOXMLExtractorFactory.java
@@ -35,7 +35,10 @@ import org.apache.tika.exception.TikaException;
 import org.apache.tika.io.CloseShieldInputStream;
 import org.apache.tika.io.TikaInputStream;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.mime.MediaType;
+import org.apache.tika.parser.EmptyParser;
 import org.apache.tika.parser.ParseContext;
+import org.apache.tika.parser.pkg.ZipContainerDetector;
 import org.apache.tika.sax.EndDocumentShieldingContentHandler;
 import org.apache.xmlbeans.XmlException;
 import org.xml.sax.ContentHandler;
@@ -56,21 +59,31 @@ public class OOXMLExtractorFactory {
         
         try {
             OOXMLExtractor extractor;
+            OPCPackage pkg;
 
-            POIXMLTextExtractor poiExtractor;
+            // Open the OPCPackage for the file
             TikaInputStream tis = TikaInputStream.cast(stream);
             if (tis != null && tis.getOpenContainer() instanceof OPCPackage) {
-                poiExtractor = ExtractorFactory.createExtractor(
-                        (OPCPackage) tis.getOpenContainer());
+                pkg = (OPCPackage) tis.getOpenContainer();
             } else if (tis != null && tis.hasFile()) {
-                poiExtractor = (POIXMLTextExtractor)
-                        ExtractorFactory.createExtractor(tis.getFile());
+                pkg = OPCPackage.open( tis.getFile().getPath() );
             } else {
                 InputStream shield = new CloseShieldInputStream(stream);
-                poiExtractor = (POIXMLTextExtractor)
-                        ExtractorFactory.createExtractor(shield);
+                pkg = OPCPackage.open(shield); 
             }
+            
+            // Get the type, and ensure it's one we handle
+            MediaType type = ZipContainerDetector.detectOfficeOpenXML(pkg);
+            if (type != null && OOXMLParser.UNSUPPORTED_OOXML_TYPES.contains(type)) {
+               // Not a supported type, delegate to Empty Parser 
+               EmptyParser.INSTANCE.parse(stream, baseHandler, metadata, context);
+               return;
+            }
+            metadata.set(Metadata.CONTENT_TYPE, type.toString());
 
+            // Have the appropriate OOXML text extractor picked
+            POIXMLTextExtractor poiExtractor = ExtractorFactory.createExtractor(pkg);
+            
             POIXMLDocument document = poiExtractor.getDocument();
             if (poiExtractor instanceof XSSFEventBasedExcelExtractor) {
                extractor = new XSSFExcelExtractorDecorator(
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParser.java
index 8d4aae04a..2acfd16aa 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParser.java
@@ -27,7 +27,6 @@ import org.apache.tika.exception.TikaException;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.parser.AbstractParser;
-import org.apache.tika.parser.EmptyParser;
 import org.apache.tika.parser.ParseContext;
 import org.xml.sax.ContentHandler;
 import org.xml.sax.SAXException;
@@ -40,7 +39,7 @@ public class OOXMLParser extends AbstractParser {
     /** Serial version UID */
     private static final long serialVersionUID = 6535995710857776481L;
    
-    private static final Set<MediaType> SUPPORTED_TYPES =
+    protected static final Set<MediaType> SUPPORTED_TYPES =
         Collections.unmodifiableSet(new HashSet<MediaType>(Arrays.asList(
                 MediaType.application("x-tika-ooxml"),
                 MediaType.application("vnd.openxmlformats-officedocument.presentationml.presentation"),
@@ -65,7 +64,7 @@ public class OOXMLParser extends AbstractParser {
      * This list is used to decline certain formats that are not yet supported
      *  by Tika and/or POI.
      */
-    private static final Set<MediaType> UNSUPPORTED_OOXML_TYPES = 
+    protected static final Set<MediaType> UNSUPPORTED_OOXML_TYPES = 
        Collections.unmodifiableSet(new HashSet<MediaType>(Arrays.asList(
                 MediaType.application("vnd.ms-excel.sheet.binary.macroenabled.12"),
                 MediaType.application("vnd.ms-xpsdocument")
@@ -79,14 +78,6 @@ public class OOXMLParser extends AbstractParser {
             InputStream stream, ContentHandler handler,
             Metadata metadata, ParseContext context)
             throws IOException, SAXException, TikaException {
-        // Is this an OOXML derived type that we can't help with?
-        String type = metadata.get(Metadata.CONTENT_TYPE);
-        if (type != null && UNSUPPORTED_OOXML_TYPES.contains(MediaType.parse(type))) {
-           // Not a supported type, delegate to Empty Parser 
-           EmptyParser.INSTANCE.parse(stream, handler, metadata, context);
-           return;
-        }
-
         // Have the OOXML file processed
         OOXMLExtractorFactory.parse(stream, handler, metadata, context);
     }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/POIXMLTextExtractorDecorator.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/POIXMLTextExtractorDecorator.java
index e5644e3c6..375adf5d4 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/POIXMLTextExtractorDecorator.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/POIXMLTextExtractorDecorator.java
@@ -28,7 +28,7 @@ import org.xml.sax.SAXException;
 public class POIXMLTextExtractorDecorator extends AbstractOOXMLExtractor {
 
     public POIXMLTextExtractorDecorator(ParseContext context, POIXMLTextExtractor extractor) {
-        super(context, extractor, null);
+        super(context, extractor);
     }
 
     @Override
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XSLFPowerPointExtractorDecorator.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XSLFPowerPointExtractorDecorator.java
index 22d6edb1e..2aeb96bfb 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XSLFPowerPointExtractorDecorator.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XSLFPowerPointExtractorDecorator.java
@@ -45,12 +45,8 @@ import org.openxmlformats.schemas.presentationml.x2006.main.CTSlideIdListEntry;
 import org.xml.sax.SAXException;
 
 public class XSLFPowerPointExtractorDecorator extends AbstractOOXMLExtractor {
-    // TODO Have this detected rather than hard coded
-    //private static final String TYPE = "application/vnd.openxmlformats-officedocument.presentationml.presentation";
-    private static final String TYPE = null;
-
     public XSLFPowerPointExtractorDecorator(ParseContext context, XSLFPowerPointExtractor extractor) {
-        super(context, extractor, TYPE);
+        super(context, extractor);
     }
 
     /**
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XSSFExcelExtractorDecorator.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XSSFExcelExtractorDecorator.java
index 2e09cd8ca..928333318 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XSSFExcelExtractorDecorator.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XSSFExcelExtractorDecorator.java
@@ -66,12 +66,9 @@ public class XSSFExcelExtractorDecorator extends AbstractOOXMLExtractor {
     private final List<PackagePart> sheetParts = new ArrayList<PackagePart>();
     private final List<Boolean> sheetProtected = new ArrayList<Boolean>();
     
-    // TODO Have this detected rather than hard coded
-    private static final String TYPE = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet";
-
     public XSSFExcelExtractorDecorator(
             ParseContext context, XSSFEventBasedExcelExtractor extractor, Locale locale) {
-        super(context, extractor, TYPE);
+        super(context, extractor);
 
         this.extractor = extractor;
         extractor.setFormulasNotResults(false);
@@ -350,7 +347,7 @@ public class XSSFExcelExtractorDecorator extends AbstractOOXMLExtractor {
 
     @Override
     public MetadataExtractor getMetadataExtractor() {
-        return new MetadataExtractor(extractor, TYPE) {
+        return new MetadataExtractor(extractor) {
             @Override
             public void extract(Metadata metadata) throws TikaException {
                 super.extract(metadata);
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XWPFWordExtractorDecorator.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XWPFWordExtractorDecorator.java
index 1df107a38..fe1b80b8a 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XWPFWordExtractorDecorator.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XWPFWordExtractorDecorator.java
@@ -24,7 +24,22 @@ import org.apache.poi.openxml4j.opc.PackagePart;
 import org.apache.poi.xwpf.extractor.XWPFWordExtractor;
 import org.apache.poi.xwpf.model.XWPFCommentsDecorator;
 import org.apache.poi.xwpf.model.XWPFHeaderFooterPolicy;
-import org.apache.poi.xwpf.usermodel.*;
+import org.apache.poi.xwpf.usermodel.BodyType;
+import org.apache.poi.xwpf.usermodel.IBody;
+import org.apache.poi.xwpf.usermodel.IBodyElement;
+import org.apache.poi.xwpf.usermodel.XWPFDocument;
+import org.apache.poi.xwpf.usermodel.XWPFHeaderFooter;
+import org.apache.poi.xwpf.usermodel.XWPFHyperlink;
+import org.apache.poi.xwpf.usermodel.XWPFHyperlinkRun;
+import org.apache.poi.xwpf.usermodel.XWPFParagraph;
+import org.apache.poi.xwpf.usermodel.XWPFPicture;
+import org.apache.poi.xwpf.usermodel.XWPFPictureData;
+import org.apache.poi.xwpf.usermodel.XWPFRun;
+import org.apache.poi.xwpf.usermodel.XWPFStyle;
+import org.apache.poi.xwpf.usermodel.XWPFStyles;
+import org.apache.poi.xwpf.usermodel.XWPFTable;
+import org.apache.poi.xwpf.usermodel.XWPFTableCell;
+import org.apache.poi.xwpf.usermodel.XWPFTableRow;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.parser.microsoft.WordExtractor;
 import org.apache.tika.parser.microsoft.WordExtractor.TagAndStyle;
@@ -40,8 +55,7 @@ public class XWPFWordExtractorDecorator extends AbstractOOXMLExtractor {
     private XWPFStyles styles;
 
     public XWPFWordExtractorDecorator(ParseContext context, XWPFWordExtractor extractor) {
-        // TODO Have the type detected rather than hard coded
-        super(context, extractor, "application/vnd.openxmlformats-officedocument.wordprocessingml.document");
+        super(context, extractor);
         
         document = (XWPFDocument) extractor.getDocument();
         styles = document.getStyles();
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
index 25aaf16e7..075ee1c54 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
@@ -749,10 +749,9 @@ public class OOXMLParserTest extends TikaTest {
           input.close();
        }
 
-       // When detection / type is fixed, re-enable this
-//       assertEquals(
-//             "application/vnd.openxmlformats-officedocument.presentationml.presentation", 
-//             metadata.get(Metadata.CONTENT_TYPE));
+       assertEquals(
+             "application/vnd.openxmlformats-officedocument.presentationml.presentation", 
+             metadata.get(Metadata.CONTENT_TYPE));
        assertEquals("JOUVIN ETIENNE",       metadata.get(Metadata.AUTHOR));
        assertEquals("EJ04325S",             metadata.get(Metadata.LAST_AUTHOR));
        assertEquals("2011-08-22T13:30:53Z", metadata.get(Metadata.DATE));

Commit:
f28f380415ca1aecc70dd8b9c57a2d18a8176d55
Nick Burch
nick@apache.org
2012-01-13 15:00:01 +0000
TIKA-840 Expose the logic for detecting the type of an OOXML file from an open container
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/pkg/ZipContainerDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/pkg/ZipContainerDetector.java
index 1c3f1378f..6faea59bf 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/pkg/ZipContainerDetector.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/pkg/ZipContainerDetector.java
@@ -95,7 +95,7 @@ public class ZipContainerDetector implements Detector {
         return MediaType.APPLICATION_ZIP;
     }
 
-    private MediaType detectOpenDocument(ZipFile zip) {
+    private static MediaType detectOpenDocument(ZipFile zip) {
         try {
             ZipArchiveEntry mimetype = zip.getEntry("mimetype");
             if (mimetype != null) {
@@ -113,7 +113,7 @@ public class ZipContainerDetector implements Detector {
         }
     }
 
-    private MediaType detectOfficeOpenXML(ZipFile zip, TikaInputStream stream) {
+    private static MediaType detectOfficeOpenXML(ZipFile zip, TikaInputStream stream) {
         try {
             if (zip.getEntry("_rels/.rels") != null
                     || zip.getEntry("[Content_Types].xml") != null) {
@@ -121,27 +121,8 @@ public class ZipContainerDetector implements Detector {
                 OPCPackage pkg = OPCPackage.open(stream.getFile().getPath(), PackageAccess.READ);
                 stream.setOpenContainer(pkg);
 
-                PackageRelationshipCollection core = 
-                    pkg.getRelationshipsByType(ExtractorFactory.CORE_DOCUMENT_REL);
-                if (core.size() != 1) {
-                    // Invalid OOXML Package received
-                    return null;
-                }
-
-                // Get the type of the core document part
-                PackagePart corePart = pkg.getPart(core.getRelationship(0));
-                String coreType = corePart.getContentType();
-
-                // Turn that into the type of the overall document
-                String docType = coreType.substring(0, coreType.lastIndexOf('.'));
-
-                // The Macro Enabled formats are a little special
-                if(docType.toLowerCase().endsWith("macroenabled")) {
-                    docType = docType.toLowerCase() + ".12";
-                }
-
-                // Build the MediaType object and return
-                return MediaType.parse(docType);
+                // Detect based on the open OPC Package
+                return detectOfficeOpenXML(pkg);
             } else {
                 return null;
             }
@@ -153,8 +134,35 @@ public class ZipContainerDetector implements Detector {
             return null;
         }
     }
+    /**
+     * Detects the type of an OfficeOpenXML (OOXML) file from
+     *  opened Package 
+     */
+    public static MediaType detectOfficeOpenXML(OPCPackage pkg) {
+        PackageRelationshipCollection core = 
+           pkg.getRelationshipsByType(ExtractorFactory.CORE_DOCUMENT_REL);
+        if (core.size() != 1) {
+            // Invalid OOXML Package received
+            return null;
+        }
 
-    private MediaType detectIWork(ZipFile zip) {
+        // Get the type of the core document part
+        PackagePart corePart = pkg.getPart(core.getRelationship(0));
+        String coreType = corePart.getContentType();
+
+        // Turn that into the type of the overall document
+        String docType = coreType.substring(0, coreType.lastIndexOf('.'));
+
+        // The Macro Enabled formats are a little special
+        if(docType.toLowerCase().endsWith("macroenabled")) {
+            docType = docType.toLowerCase() + ".12";
+        }
+
+        // Build the MediaType object and return
+        return MediaType.parse(docType);
+    }
+
+    private static MediaType detectIWork(ZipFile zip) {
         if (zip.getEntry(IWorkPackageParser.IWORK_COMMON_ENTRY) != null) {
             // Locate the appropriate index file entry, and reads from that
             // the root element of the document. That is used to the identify
@@ -172,5 +180,4 @@ public class ZipContainerDetector implements Detector {
             return null;
         }
     }
-
 }
\ No newline at end of file

Commit:
0c52b66e9dd568cd9af1529cd1b0fa0819c53e9d
Nick Burch
nick@apache.org
2012-01-12 14:58:18 +0000
TIKA-695 Support some more OOXML custom property types, and expand the unit test coverage
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java
index c3947472c..fb3dc1f92 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java
@@ -143,12 +143,61 @@ public class MetadataExtractor {
           if (property.isSetLpwstr()) {
              val = property.getLpwstr(); 
           }
-          else if (property.isSetFiletime()) {
-             date = property.getFiletime().getTime(); 
+          else if (property.isSetLpstr()) {
+             val = property.getLpstr(); 
           }
           else if (property.isSetDate()) {
              date = property.getDate().getTime(); 
           }
+          else if (property.isSetFiletime()) {
+             date = property.getFiletime().getTime(); 
+          }
+
+          else if (property.isSetBool()) {
+             val = Boolean.toString( property.getBool() );
+          }
+
+          // Integers
+          else if (property.isSetI1()) {
+             val = Integer.toString(property.getI1()); 
+          }
+          else if (property.isSetI2()) {
+             val = Integer.toString(property.getI2()); 
+          }
+          else if (property.isSetI4()) {
+             val = Integer.toString(property.getI4()); 
+          }
+          else if (property.isSetI8()) {
+             val = Long.toString(property.getI8()); 
+          }
+          else if (property.isSetInt()) {
+             val = Integer.toString( property.getInt() ); 
+          }
+
+          // Unsigned Integers
+          else if (property.isSetUi1()) {
+             val = Integer.toString(property.getUi1()); 
+          }
+          else if (property.isSetUi2()) {
+             val = Integer.toString(property.getUi2()); 
+          }
+          else if (property.isSetUi4()) {
+             val = Long.toString(property.getUi4()); 
+          }
+          else if (property.isSetUi8()) {
+             val = property.getUi8().toString(); 
+          }
+          else if (property.isSetUint()) {
+             val = Long.toString(property.getUint()); 
+          }
+
+          // Reals
+          else if (property.isSetR4()) {
+             val = Float.toString( property.getR4() ); 
+          }
+          else if (property.isSetR8()) {
+             val = Double.toString( property.getR8() ); 
+          }
           else if (property.isSetDecimal()) {
              BigDecimal d = property.getDecimal();
              if (d == null) {
@@ -157,19 +206,25 @@ public class MetadataExtractor {
                 val = d.toPlainString();
              }
           }
-          else if (property.isSetBool()) {
-             val = Boolean.toString( property.getBool() );
+
+          else if (property.isSetArray()) {
+             // TODO Fetch the array values and output
           }
-          else if (property.isSetInt()) {
-             val = Integer.toString( property.getInt() ); 
+          else if (property.isSetVector()) {
+             // TODO Fetch the vector values and output
           }
-          else if (property.isSetLpstr()) {
-             val = property.getLpstr(); 
+
+          else if (property.isSetBlob() || property.isSetOblob()) {
+             // TODO Decode, if possible
           }
-          else if (property.isSetI4()) {
-             /* Int4 */ 
-             val = Integer.toString(property.getI4()); 
+          else if (property.isSetStream() || property.isSetOstream() ||
+                   property.isSetVstream()) {
+             // TODO Decode, if possible
           }
+          else if (property.isSetStorage() || property.isSetOstorage()) {
+             // TODO Decode, if possible
+          }
+          
           else {
              // This type isn't currently supported yet, skip the property
           }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XSLFPowerPointExtractorDecorator.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XSLFPowerPointExtractorDecorator.java
index 3e14c966a..22d6edb1e 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XSLFPowerPointExtractorDecorator.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XSLFPowerPointExtractorDecorator.java
@@ -45,9 +45,12 @@ import org.openxmlformats.schemas.presentationml.x2006.main.CTSlideIdListEntry;
 import org.xml.sax.SAXException;
 
 public class XSLFPowerPointExtractorDecorator extends AbstractOOXMLExtractor {
+    // TODO Have this detected rather than hard coded
+    //private static final String TYPE = "application/vnd.openxmlformats-officedocument.presentationml.presentation";
+    private static final String TYPE = null;
 
     public XSLFPowerPointExtractorDecorator(ParseContext context, XSLFPowerPointExtractor extractor) {
-        super(context, extractor, null);
+        super(context, extractor, TYPE);
     }
 
     /**
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XSSFExcelExtractorDecorator.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XSSFExcelExtractorDecorator.java
index dd9f02caa..2e09cd8ca 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XSSFExcelExtractorDecorator.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XSSFExcelExtractorDecorator.java
@@ -65,6 +65,8 @@ public class XSSFExcelExtractorDecorator extends AbstractOOXMLExtractor {
     private final DataFormatter formatter;
     private final List<PackagePart> sheetParts = new ArrayList<PackagePart>();
     private final List<Boolean> sheetProtected = new ArrayList<Boolean>();
+    
+    // TODO Have this detected rather than hard coded
     private static final String TYPE = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet";
 
     public XSSFExcelExtractorDecorator(
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XWPFWordExtractorDecorator.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XWPFWordExtractorDecorator.java
index 734a1c8b5..1df107a38 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XWPFWordExtractorDecorator.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XWPFWordExtractorDecorator.java
@@ -40,6 +40,7 @@ public class XWPFWordExtractorDecorator extends AbstractOOXMLExtractor {
     private XWPFStyles styles;
 
     public XWPFWordExtractorDecorator(ParseContext context, XWPFWordExtractor extractor) {
+        // TODO Have the type detected rather than hard coded
         super(context, extractor, "application/vnd.openxmlformats-officedocument.wordprocessingml.document");
         
         document = (XWPFDocument) extractor.getDocument();
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
index 1d4f37a57..25aaf16e7 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
@@ -699,4 +699,72 @@ public class OOXMLParserTest extends TikaTest {
        assertEquals("2010-12-30T22:00:00Z", metadata.get("custom:MyCustomDate"));
        assertEquals("2010-12-29T22:00:00Z", metadata.get("custom:myCustomSecondDate"));
     }
+    public void testWordCustomProperties() throws Exception {
+       InputStream input = OOXMLParserTest.class.getResourceAsStream(
+             "/test-documents/testWORD_custom_props.docx");
+       Metadata metadata = new Metadata();
+
+       try {
+          ContentHandler handler = new BodyContentHandler(-1);
+          ParseContext context = new ParseContext();
+          context.set(Locale.class, Locale.US);
+          new OOXMLParser().parse(input, handler, metadata, context);
+       } finally {
+          input.close();
+       }
+
+       assertEquals(
+             "application/vnd.openxmlformats-officedocument.wordprocessingml.document", 
+             metadata.get(Metadata.CONTENT_TYPE));
+       assertEquals("EJ04325S",             metadata.get(Metadata.AUTHOR));
+       assertEquals("Etienne Jouvin",       metadata.get(Metadata.LAST_AUTHOR));
+       assertEquals("2011-07-29T16:52:00Z", metadata.get(Metadata.DATE));
+       assertEquals("2011-07-29T16:52:00Z", metadata.get(Metadata.CREATION_DATE));
+       assertEquals("2012-01-03T22:14:00Z", metadata.get(Metadata.LAST_MODIFIED));
+       assertEquals("Microsoft Office Word",metadata.get(Metadata.APPLICATION_NAME));
+       assertEquals("1",                    metadata.get(Metadata.PAGE_COUNT));
+       assertEquals("2",                    metadata.get(Metadata.WORD_COUNT));
+       assertEquals("My Title",             metadata.get(Metadata.TITLE));
+       assertEquals("My Keyword",           metadata.get(Metadata.KEYWORDS));
+       assertEquals("Normal.dotm",          metadata.get(Metadata.TEMPLATE));
+       assertEquals("My subject",           metadata.get(Metadata.SUBJECT));
+       assertEquals("EDF-DIT",              metadata.get(Metadata.PUBLISHER));
+       assertEquals("true",                 metadata.get("custom:myCustomBoolean"));
+       assertEquals("3",                    metadata.get("custom:myCustomNumber"));
+       assertEquals("MyStringValue",        metadata.get("custom:MyCustomString"));
+       assertEquals("2010-12-30T23:00:00Z", metadata.get("custom:MyCustomDate"));
+       assertEquals("2010-12-29T22:00:00Z", metadata.get("custom:myCustomSecondDate"));
+    }
+    public void testPowerPointCustomProperties() throws Exception {
+       InputStream input = OOXMLParserTest.class.getResourceAsStream(
+             "/test-documents/testPPT_custom_props.pptx");
+       Metadata metadata = new Metadata();
+
+       try {
+          ContentHandler handler = new BodyContentHandler(-1);
+          ParseContext context = new ParseContext();
+          context.set(Locale.class, Locale.US);
+          new OOXMLParser().parse(input, handler, metadata, context);
+       } finally {
+          input.close();
+       }
+
+       // When detection / type is fixed, re-enable this
+//       assertEquals(
+//             "application/vnd.openxmlformats-officedocument.presentationml.presentation", 
+//             metadata.get(Metadata.CONTENT_TYPE));
+       assertEquals("JOUVIN ETIENNE",       metadata.get(Metadata.AUTHOR));
+       assertEquals("EJ04325S",             metadata.get(Metadata.LAST_AUTHOR));
+       assertEquals("2011-08-22T13:30:53Z", metadata.get(Metadata.DATE));
+       assertEquals("2011-08-22T13:30:53Z", metadata.get(Metadata.CREATION_DATE));
+       assertEquals("2011-08-22T13:32:49Z", metadata.get(Metadata.LAST_MODIFIED));
+       assertEquals("1",                    metadata.get(Metadata.SLIDE_COUNT));
+       assertEquals("3",                    metadata.get(Metadata.WORD_COUNT));
+       assertEquals("Test extraction properties pptx", metadata.get(Metadata.TITLE));
+       assertEquals("true",                 metadata.get("custom:myCustomBoolean"));
+       assertEquals("3",                    metadata.get("custom:myCustomNumber"));
+       assertEquals("MyStringValue",        metadata.get("custom:MyCustomString"));
+       assertEquals("2010-12-30T22:00:00Z", metadata.get("custom:MyCustomDate"));
+       assertEquals("2010-12-29T22:00:00Z", metadata.get("custom:myCustomSecondDate"));
+    }
 }

Commit:
4b51beae8e08e82458792a63dd867319cb40e1e4
Nick Burch
nick@apache.org
2012-01-11 16:00:12 +0000
TIKA-695 Support for Custom OOXML properties, plus start on tests for it
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java
index adefd9a26..c3947472c 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/MetadataExtractor.java
@@ -16,10 +16,12 @@
  */
 package org.apache.tika.parser.microsoft.ooxml;
 
+import java.math.BigDecimal;
 import java.util.Date;
 
 import org.apache.poi.POIXMLTextExtractor;
 import org.apache.poi.POIXMLProperties.CoreProperties;
+import org.apache.poi.POIXMLProperties.CustomProperties;
 import org.apache.poi.POIXMLProperties.ExtendedProperties;
 import org.apache.poi.openxml4j.opc.internal.PackagePropertiesPart;
 import org.apache.poi.openxml4j.util.Nullable;
@@ -28,6 +30,7 @@ import org.apache.tika.exception.TikaException;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.metadata.PagedText;
 import org.apache.tika.metadata.Property;
+import org.openxmlformats.schemas.officeDocument.x2006.customProperties.CTProperty;
 import org.openxmlformats.schemas.officeDocument.x2006.extendedProperties.CTProperties;
 
 /**
@@ -56,6 +59,7 @@ public class MetadataExtractor {
                extractor.getPackage() != null)) {
             extractMetadata(extractor.getCoreProperties(), metadata);
             extractMetadata(extractor.getExtendedProperties(), metadata);
+            extractMetadata(extractor.getCustomProperties(), metadata);
         }
     }
 
@@ -127,6 +131,59 @@ public class MetadataExtractor {
         addProperty(metadata, Metadata.WORD_COUNT, propsHolder.getWords());
     }
 
+    private void extractMetadata(CustomProperties properties,
+          Metadata metadata) {
+       org.openxmlformats.schemas.officeDocument.x2006.customProperties.CTProperties
+           props = properties.getUnderlyingProperties();
+
+       for(CTProperty property : props.getPropertyList()) {
+          String val = null;
+          Date date = null;
+
+          if (property.isSetLpwstr()) {
+             val = property.getLpwstr(); 
+          }
+          else if (property.isSetFiletime()) {
+             date = property.getFiletime().getTime(); 
+          }
+          else if (property.isSetDate()) {
+             date = property.getDate().getTime(); 
+          }
+          else if (property.isSetDecimal()) {
+             BigDecimal d = property.getDecimal();
+             if (d == null) {
+                val = null;
+             } else {
+                val = d.toPlainString();
+             }
+          }
+          else if (property.isSetBool()) {
+             val = Boolean.toString( property.getBool() );
+          }
+          else if (property.isSetInt()) {
+             val = Integer.toString( property.getInt() ); 
+          }
+          else if (property.isSetLpstr()) {
+             val = property.getLpstr(); 
+          }
+          else if (property.isSetI4()) {
+             /* Int4 */ 
+             val = Integer.toString(property.getI4()); 
+          }
+          else {
+             // This type isn't currently supported yet, skip the property
+          }
+          
+          String propName = "custom:" + property.getName();
+          if (date != null) {
+             Property tikaProp = Property.externalDate(propName);
+             metadata.set(tikaProp, date);
+          } else if (val != null) {
+             metadata.set(propName, val);
+          }
+       }
+    }
+    
     private void addProperty(Metadata metadata, Property property, Nullable<Date> value) {
         if (value.getValue() != null) {
             metadata.set(property, value.getValue());
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
index 478a8ab8c..1d4f37a57 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
@@ -667,4 +667,36 @@ public class OOXMLParserTest extends TikaTest {
         assertContains("Here is some red word Art", content);
     }
 
+    /**
+     * Ensures that custom OOXML properties are extracted
+     */
+    public void testExcelCustomProperties() throws Exception {
+       InputStream input = OOXMLParserTest.class.getResourceAsStream(
+             "/test-documents/testEXCEL_custom_props.xlsx");
+       Metadata metadata = new Metadata();
+       
+       try {
+          ContentHandler handler = new BodyContentHandler(-1);
+          ParseContext context = new ParseContext();
+          context.set(Locale.class, Locale.US);
+          new OOXMLParser().parse(input, handler, metadata, context);
+       } finally {
+          input.close();
+       }
+       
+       assertEquals(
+             "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", 
+             metadata.get(Metadata.CONTENT_TYPE));
+       assertEquals(null,                   metadata.get(Metadata.AUTHOR));
+       assertEquals(null,                   metadata.get(Metadata.LAST_AUTHOR));
+       assertEquals("2006-09-12T15:06:44Z", metadata.get(Metadata.DATE));
+       assertEquals("2006-09-12T15:06:44Z", metadata.get(Metadata.CREATION_DATE));
+       assertEquals("2011-08-22T14:24:38Z", metadata.get(Metadata.LAST_MODIFIED));
+       assertEquals("Microsoft Excel",      metadata.get(Metadata.APPLICATION_NAME));
+       assertEquals("true",                 metadata.get("custom:myCustomBoolean"));
+       assertEquals("3",                    metadata.get("custom:myCustomNumber"));
+       assertEquals("MyStringValue",        metadata.get("custom:MyCustomString"));
+       assertEquals("2010-12-30T22:00:00Z", metadata.get("custom:MyCustomDate"));
+       assertEquals("2010-12-29T22:00:00Z", metadata.get("custom:myCustomSecondDate"));
+    }
 }

Commit:
022f18cecf52a0d653d5cba800ae1d6d3c2c294b
Nick Burch
nick@apache.org
2012-01-11 15:36:23 +0000
TIKA-695 Add unit tests for XLS/DOC/PPT custom properties extraction
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ExcelParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ExcelParserTest.java
index 9a7b2a190..d4371a020 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ExcelParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ExcelParserTest.java
@@ -21,7 +21,6 @@ import java.util.Locale;
 
 import junit.framework.TestCase;
 
-import org.apache.tika.config.TikaConfig;
 import org.apache.tika.detect.DefaultDetector;
 import org.apache.tika.detect.Detector;
 import org.apache.tika.metadata.Metadata;
@@ -261,4 +260,34 @@ public class ExcelParserTest extends TestCase {
           input.close();
        }
     }
+    
+    /**
+     * Ensures that custom OLE2 (HPSF) properties are extracted
+     */
+    public void testCustomProperties() throws Exception {
+       InputStream input = ExcelParserTest.class.getResourceAsStream(
+             "/test-documents/testEXCEL_custom_props.xls");
+       Metadata metadata = new Metadata();
+       
+       try {
+          ContentHandler handler = new BodyContentHandler(-1);
+          ParseContext context = new ParseContext();
+          context.set(Locale.class, Locale.US);
+          new OfficeParser().parse(input, handler, metadata, context);
+       } finally {
+          input.close();
+       }
+       
+       assertEquals("application/vnd.ms-excel", metadata.get(Metadata.CONTENT_TYPE));
+       assertEquals("",                     metadata.get(Metadata.AUTHOR));
+       assertEquals("",                     metadata.get(Metadata.LAST_AUTHOR));
+       assertEquals("2011-08-22T13:45:54Z", metadata.get(Metadata.LAST_SAVED));
+       assertEquals("2006-09-12T15:06:44Z", metadata.get(Metadata.CREATION_DATE));
+       assertEquals("Microsoft Excel",      metadata.get(Metadata.APPLICATION_NAME));
+       assertEquals("true",                 metadata.get("custom:myCustomBoolean"));
+       assertEquals("3",                    metadata.get("custom:myCustomNumber"));
+       assertEquals("MyStringValue",        metadata.get("custom:MyCustomString"));
+       assertEquals("2010-12-30T22:00:00Z", metadata.get("custom:MyCustomDate"));
+       assertEquals("2010-12-29T22:00:00Z", metadata.get("custom:myCustomSecondDate"));
+    }
 }
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PowerPointParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PowerPointParserTest.java
index 6ca34a055..0e565ebcd 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PowerPointParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PowerPointParserTest.java
@@ -17,6 +17,7 @@
 package org.apache.tika.parser.microsoft;
 
 import java.io.InputStream;
+import java.util.Locale;
 
 import org.apache.tika.TikaTest;
 import org.apache.tika.metadata.Metadata;
@@ -178,4 +179,35 @@ public class PowerPointParserTest extends TikaTest {
     }
     */
 
+    /**
+     * Ensures that custom OLE2 (HPSF) properties are extracted
+     */
+    public void testCustomProperties() throws Exception {
+       InputStream input = PowerPointParserTest.class.getResourceAsStream(
+             "/test-documents/testPPT_custom_props.ppt");
+       Metadata metadata = new Metadata();
+       
+       try {
+          ContentHandler handler = new BodyContentHandler(-1);
+          ParseContext context = new ParseContext();
+          context.set(Locale.class, Locale.US);
+          new OfficeParser().parse(input, handler, metadata, context);
+       } finally {
+          input.close();
+       }
+       
+       assertEquals("application/vnd.ms-powerpoint", metadata.get(Metadata.CONTENT_TYPE));
+       assertEquals("JOUVIN ETIENNE",       metadata.get(Metadata.AUTHOR));
+       assertEquals("EJ04325S",             metadata.get(Metadata.LAST_AUTHOR));
+       assertEquals("2011-08-22T13:32:58Z", metadata.get(Metadata.LAST_SAVED));
+       assertEquals("2011-08-22T13:30:53Z", metadata.get(Metadata.CREATION_DATE));
+       assertEquals("1",                    metadata.get(Metadata.SLIDE_COUNT));
+       assertEquals("3",                    metadata.get(Metadata.WORD_COUNT));
+       assertEquals("Test extraction properties pptx", metadata.get(Metadata.TITLE));
+       assertEquals("true",                 metadata.get("custom:myCustomBoolean"));
+       assertEquals("3",                    metadata.get("custom:myCustomNumber"));
+       assertEquals("MyStringValue",        metadata.get("custom:MyCustomString"));
+       assertEquals("2010-12-30T22:00:00Z", metadata.get("custom:MyCustomDate"));
+       assertEquals("2010-12-29T22:00:00Z", metadata.get("custom:myCustomSecondDate"));
+    }
 }
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/WordParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/WordParserTest.java
index 63bcc0f31..528ff403d 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/WordParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/WordParserTest.java
@@ -18,6 +18,7 @@ package org.apache.tika.parser.microsoft;
 
 import java.io.InputStream;
 import java.io.StringWriter;
+import java.util.Locale;
 
 import javax.xml.transform.OutputKeys;
 import javax.xml.transform.sax.SAXTransformerFactory;
@@ -251,5 +252,39 @@ public class WordParserTest extends TikaTest {
         assertContains("And then some Gothic text:", content);
         assertContains("\uD800\uDF32\uD800\uDF3f\uD800\uDF44\uD800\uDF39\uD800\uDF43\uD800\uDF3A", content);
     }
-
+    
+    /**
+     * Ensures that custom OLE2 (HPSF) properties are extracted
+     */
+    public void testCustomProperties() throws Exception {
+       InputStream input = WordParserTest.class.getResourceAsStream(
+             "/test-documents/testWORD_custom_props.doc");
+       Metadata metadata = new Metadata();
+       
+       try {
+          ContentHandler handler = new BodyContentHandler(-1);
+          ParseContext context = new ParseContext();
+          context.set(Locale.class, Locale.US);
+          new OfficeParser().parse(input, handler, metadata, context);
+       } finally {
+          input.close();
+       }
+       
+       assertEquals("application/msword",   metadata.get(Metadata.CONTENT_TYPE));
+       assertEquals("EJ04325S",             metadata.get(Metadata.AUTHOR));
+       assertEquals("Etienne Jouvin",       metadata.get(Metadata.LAST_AUTHOR));
+       assertEquals("2012-01-03T22:14:00Z", metadata.get(Metadata.LAST_SAVED));
+       assertEquals("2010-10-05T09:03:00Z", metadata.get(Metadata.CREATION_DATE));
+       assertEquals("Microsoft Office Word",metadata.get(Metadata.APPLICATION_NAME));
+       assertEquals("1",                    metadata.get(Metadata.PAGE_COUNT));
+       assertEquals("2",                    metadata.get(Metadata.WORD_COUNT));
+       assertEquals("My Title",             metadata.get(Metadata.TITLE));
+       assertEquals("My Keyword",           metadata.get(Metadata.KEYWORDS));
+       assertEquals("Normal.dotm",          metadata.get(Metadata.TEMPLATE));
+       assertEquals("My Comments",          metadata.get(Metadata.COMMENTS));
+       assertEquals("My subject",           metadata.get(Metadata.SUBJECT));
+       assertEquals("EDF-DIT",              metadata.get(Metadata.COMPANY));
+       assertEquals("MyStringValue",        metadata.get("custom:MyCustomString"));
+       assertEquals("2010-12-30T23:00:00Z", metadata.get("custom:MyCustomDate"));
+    }
 }

Commit:
ed4a05526afff4edf4eeea0eb0b9682fefaef310
Nick Burch
nick@apache.org
2012-01-11 15:11:32 +0000
TIKA-695 Sample office files with custom properties
diff --git a/tika-parsers/src/test/resources/test-documents/testEXCEL_custom_props.xls b/tika-parsers/src/test/resources/test-documents/testEXCEL_custom_props.xls
new file mode 100644
index 000000000..6284f9fd7
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testEXCEL_custom_props.xls differ
diff --git a/tika-parsers/src/test/resources/test-documents/testEXCEL_custom_props.xlsx b/tika-parsers/src/test/resources/test-documents/testEXCEL_custom_props.xlsx
new file mode 100644
index 000000000..24eb0d550
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testEXCEL_custom_props.xlsx differ
diff --git a/tika-parsers/src/test/resources/test-documents/testPPT_custom_props.ppt b/tika-parsers/src/test/resources/test-documents/testPPT_custom_props.ppt
new file mode 100644
index 000000000..82dd1e2e3
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testPPT_custom_props.ppt differ
diff --git a/tika-parsers/src/test/resources/test-documents/testPPT_custom_props.pptx b/tika-parsers/src/test/resources/test-documents/testPPT_custom_props.pptx
new file mode 100644
index 000000000..091fa0afc
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testPPT_custom_props.pptx differ
diff --git a/tika-parsers/src/test/resources/test-documents/testWORD_custom_props.doc b/tika-parsers/src/test/resources/test-documents/testWORD_custom_props.doc
new file mode 100644
index 000000000..9a46d0f21
--- /dev/null
+++ b/tika-parsers/src/test/resources/test-documents/testWORD_custom_props.doc
@@ -0,0 +1,3 @@
+
+Document content
+
diff --git a/tika-parsers/src/test/resources/test-documents/testWORD_custom_props.docx b/tika-parsers/src/test/resources/test-documents/testWORD_custom_props.docx
new file mode 100644
index 000000000..3e434a284
--- /dev/null
+++ b/tika-parsers/src/test/resources/test-documents/testWORD_custom_props.docx
@@ -0,0 +1 @@
+Document content

Commit:
0f54339112fdc6c887d2f9e05d0826b1c7462873
Nick Burch
nick@apache.org
2012-01-10 15:28:55 +0000
TIKA-793 follow-on: MP3 files can have more than one comment, as long as the language+description pair is unique, so support capturing multiple comments
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/CompositeTagHandler.java b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/CompositeTagHandler.java
index 7e389152f..a4d778438 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/CompositeTagHandler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/CompositeTagHandler.java
@@ -16,6 +16,9 @@
  */
 package org.apache.tika.parser.mp3;
 
+import java.util.Collections;
+import java.util.List;
+
 /**
  * Takes an array of {@link ID3Tags} in preference order, and when asked for
  * a given tag, will return it from the first {@link ID3Tags} that has it.
@@ -82,13 +85,14 @@ public class CompositeTagHandler implements ID3Tags {
         return null;
     }
 
-    public String getComment() {
+    public List<ID3Comment> getComments() {
         for (ID3Tags tag : tags) {
-            if (tag.getComment() != null) {
-                return tag.getComment();
+            List<ID3Comment> comments = tag.getComments();
+            if (comments != null && comments.size() > 0) {
+                return comments;
             }
         }
-        return null;
+        return Collections.emptyList();
     }
 
     public String getGenre() {
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3Tags.java b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3Tags.java
index 62438aa44..074235d98 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3Tags.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3Tags.java
@@ -16,6 +16,8 @@
  */
 package org.apache.tika.parser.mp3;
 
+import java.util.List;
+
 
 /**
  * Interface that defines the common interface for ID3 tag parsers,
@@ -176,7 +178,12 @@ public interface ID3Tags {
     
     String getComposer();
 
-    String getComment();
+    /**
+     * Retrieves the comments, if any.
+     * Files may have more than one comment, but normally only 
+     *  one with any language/description pair.
+     */
+    List<ID3Comment> getComments();
 
     String getGenre();
 
@@ -184,4 +191,47 @@ public interface ID3Tags {
 
     String getTrackNumber();
 
+    /**
+     * Represents a comments in ID3 (especially ID3 v2), where are 
+     *  made up of several parts
+     */
+    public static class ID3Comment {
+        private String language;
+        private String description;
+        private String text;
+        
+        /**
+         * Creates an ID3 v1 style comment tag
+         */
+        public ID3Comment(String id3v1Text) {
+           this.text = id3v1Text;
+        }
+        /**
+         * Creates an ID3 v2 style comment tag
+         */
+        public ID3Comment(String language, String description, String text) {
+            this.language = language;
+            this.description = description;
+            this.text = text;
+        }
+
+        /**
+         * Gets the language, if present
+         */
+        public String getLanguage() {
+           return language;
+        }
+        /**
+         * Gets the description, if present
+         */
+        public String getDescription() {
+           return description;
+        }
+        /**
+         * Gets the text, if present
+         */
+        public String getText() {
+           return text;
+        }
+    }
 }
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v1Handler.java b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v1Handler.java
index e265636e9..5cf603cf2 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v1Handler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v1Handler.java
@@ -19,6 +19,8 @@ package org.apache.tika.parser.mp3;
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.UnsupportedEncodingException;
+import java.util.Arrays;
+import java.util.List;
 
 import org.apache.tika.exception.TikaException;
 import org.xml.sax.ContentHandler;
@@ -35,7 +37,7 @@ public class ID3v1Handler implements ID3Tags {
     private String artist;
     private String album;
     private String year;
-    private String comment;
+    private ID3Comment comment;
     private String genre;
     private String trackNumber;
 
@@ -60,7 +62,9 @@ public class ID3v1Handler implements ID3Tags {
             artist = getString(tagData, 33, 63);
             album = getString(tagData, 63, 93);
             year = getString(tagData, 93, 97);
-            comment = getString(tagData, 97, 127);
+            
+            String commentStr = getString(tagData, 97, 127);
+            comment = new ID3Comment(commentStr);
 
             int genreID = (int) tagData[127] & 0xff; // unsigned byte
             genre = GENRES[Math.min(genreID, GENRES.length - 1)];
@@ -96,8 +100,8 @@ public class ID3v1Handler implements ID3Tags {
         return year;
     }
 
-    public String getComment() {
-        return comment;
+    public List<ID3Comment> getComments() {
+       return Arrays.asList(new ID3Comment[] {comment});
     }
 
     public String getGenre() {
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v22Handler.java b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v22Handler.java
index 46341adbf..f6ca0ee51 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v22Handler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v22Handler.java
@@ -17,6 +17,8 @@
 package org.apache.tika.parser.mp3;
 
 import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
 
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.parser.mp3.ID3v2Frame.RawTag;
@@ -35,9 +37,9 @@ public class ID3v22Handler implements ID3Tags {
     private String album;
     private String year;
     private String composer;
-    private String comment;
     private String genre;
     private String trackNumber;
+    private List<ID3Comment> comments = new ArrayList<ID3Comment>();
 
     public ID3v22Handler(ID3v2Frame frame)
             throws IOException, SAXException, TikaException {
@@ -55,7 +57,7 @@ public class ID3v22Handler implements ID3Tags {
             } else if (tag.name.equals("TCM")) {
                 composer = getTagString(tag.data, 0, tag.data.length); 
             } else if (tag.name.equals("COM")) {
-                comment = getCommentString(tag.data, 0, tag.data.length); 
+                comments.add( getComment(tag.data, 0, tag.data.length) ); 
             } else if (tag.name.equals("TRK")) {
                 trackNumber = getTagString(tag.data, 0, tag.data.length); 
             } else if (tag.name.equals("TCO")) {
@@ -67,8 +69,8 @@ public class ID3v22Handler implements ID3Tags {
     private String getTagString(byte[] data, int offset, int length) {
         return ID3v2Frame.getTagString(data, offset, length);
     }
-    private String getCommentString(byte[] data, int offset, int length) {
-        return ID3v2Frame.getCommentString(data, offset, length);
+    private ID3Comment getComment(byte[] data, int offset, int length) {
+        return ID3v2Frame.getComment(data, offset, length);
     }
     
     protected static String extractGenre(String rawGenre) {
@@ -115,8 +117,8 @@ public class ID3v22Handler implements ID3Tags {
         return composer;
     }
 
-    public String getComment() {
-        return comment;
+    public List<ID3Comment> getComments() {
+        return comments;
     }
 
     public String getGenre() {
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v23Handler.java b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v23Handler.java
index 72c0b9f22..daee47e34 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v23Handler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v23Handler.java
@@ -17,6 +17,8 @@
 package org.apache.tika.parser.mp3;
 
 import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
 
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.parser.mp3.ID3v2Frame.RawTag;
@@ -35,9 +37,9 @@ public class ID3v23Handler implements ID3Tags {
     private String album;
     private String year;
     private String composer;
-    private String comment;
     private String genre;
     private String trackNumber;
+    private List<ID3Comment> comments = new ArrayList<ID3Comment>();
 
     public ID3v23Handler(ID3v2Frame frame)
             throws IOException, SAXException, TikaException {
@@ -55,7 +57,7 @@ public class ID3v23Handler implements ID3Tags {
             } else if (tag.name.equals("TCOM")) {
                 composer = getTagString(tag.data, 0, tag.data.length); 
             } else if (tag.name.equals("COMM")) {
-                comment = getCommentString(tag.data, 0, tag.data.length); 
+                comments.add( getComment(tag.data, 0, tag.data.length) ); 
             } else if (tag.name.equals("TRCK")) {
                 trackNumber = getTagString(tag.data, 0, tag.data.length); 
             } else if (tag.name.equals("TCON")) {
@@ -67,8 +69,8 @@ public class ID3v23Handler implements ID3Tags {
     private String getTagString(byte[] data, int offset, int length) {
         return ID3v2Frame.getTagString(data, offset, length);
     }
-    private String getCommentString(byte[] data, int offset, int length) {
-       return ID3v2Frame.getCommentString(data, offset, length);
+    private ID3Comment getComment(byte[] data, int offset, int length) {
+       return ID3v2Frame.getComment(data, offset, length);
     }
 
     public boolean getTagsPresent() {
@@ -95,8 +97,8 @@ public class ID3v23Handler implements ID3Tags {
         return composer;
     }
 
-    public String getComment() {
-        return comment;
+    public List<ID3Comment> getComments() {
+        return comments;
     }
 
     public String getGenre() {
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v24Handler.java b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v24Handler.java
index dda81bda6..33d4a0145 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v24Handler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v24Handler.java
@@ -17,6 +17,8 @@
 package org.apache.tika.parser.mp3;
 
 import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
 
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.parser.mp3.ID3v2Frame.RawTag;
@@ -36,9 +38,9 @@ public class ID3v24Handler implements ID3Tags {
     private String album;
     private String year;
     private String composer;
-    private String comment;
     private String genre;
     private String trackNumber;
+    private List<ID3Comment> comments = new ArrayList<ID3Comment>();
 
     public ID3v24Handler(ID3v2Frame frame)
             throws IOException, SAXException, TikaException {
@@ -60,7 +62,7 @@ public class ID3v24Handler implements ID3Tags {
             } else if (tag.name.equals("TCOM")) {
                 composer = getTagString(tag.data, 0, tag.data.length); 
             } else if (tag.name.equals("COMM")) {
-                comment = getCommentString(tag.data, 0, tag.data.length); 
+                comments.add( getComment(tag.data, 0, tag.data.length) ); 
             } else if (tag.name.equals("TRCK")) {
                 trackNumber = getTagString(tag.data, 0, tag.data.length); 
             } else if (tag.name.equals("TCON")) {
@@ -72,8 +74,8 @@ public class ID3v24Handler implements ID3Tags {
     private String getTagString(byte[] data, int offset, int length) {
         return ID3v2Frame.getTagString(data, offset, length);
     }
-    private String getCommentString(byte[] data, int offset, int length) {
-        return ID3v2Frame.getCommentString(data, offset, length);
+    private ID3Comment getComment(byte[] data, int offset, int length) {
+        return ID3v2Frame.getComment(data, offset, length);
     }
 
     public boolean getTagsPresent() {
@@ -100,8 +102,8 @@ public class ID3v24Handler implements ID3Tags {
         return composer;
     }
 
-    public String getComment() {
-        return comment;
+    public List<ID3Comment> getComments() {
+        return comments;
     }
 
     public String getGenre() {
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v2Frame.java b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v2Frame.java
index d790741a5..0175756d8 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v2Frame.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v2Frame.java
@@ -21,6 +21,8 @@ import java.io.InputStream;
 import java.io.UnsupportedEncodingException;
 import java.util.Iterator;
 
+import org.apache.tika.parser.mp3.ID3Tags.ID3Comment;
+
 /**
  * A frame of ID3v2 data, which is then passed to a handler to 
  * be turned into useful data.
@@ -234,16 +236,17 @@ public class ID3v2Frame implements MP3Frame {
         }
     }
     /**
-     * Returns the comment string, in the form [LANG]: [Desc]\n[Text]
+     * Builds up the ID3 comment, by parsing and extracting
+     *  the comment string parts from the given data. 
      */
-    protected static String getCommentString(byte[] data, int offset, int length) {
+    protected static ID3Comment getComment(byte[] data, int offset, int length) {
        // Comments must have an encoding
        int encodingFlag = data[offset];
        if (encodingFlag >= 0 && encodingFlag < encodings.length) {
           // Good, valid flag
        } else {
           // Invalid string
-          return "";
+          return null;
        }
        
        TextEncoding encoding = encodings[encodingFlag];
@@ -285,11 +288,7 @@ public class ID3v2Frame implements MP3Frame {
           }
           
           // Return
-          if (description == null || description.length() == 0) {
-             return lang + " - " + text;
-          } else {
-             return lang + " - " + description + "\n" + text;
-          }
+          return new ID3Comment(lang, description, text);
        } catch (UnsupportedEncodingException e) {
           throw new RuntimeException(
                   "Core encoding " + encoding.encoding + " is not available", e);
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/Mp3Parser.java b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/Mp3Parser.java
index 78a22ad7f..91493d6f9 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/Mp3Parser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/Mp3Parser.java
@@ -29,6 +29,7 @@ import org.apache.tika.metadata.XMPDM;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.parser.AbstractParser;
 import org.apache.tika.parser.ParseContext;
+import org.apache.tika.parser.mp3.ID3Tags.ID3Comment;
 import org.apache.tika.sax.XHTMLContentHandler;
 import org.xml.sax.ContentHandler;
 import org.xml.sax.SAXException;
@@ -77,7 +78,27 @@ public class Mp3Parser extends AbstractParser {
            metadata.set(XMPDM.ALBUM, tag.getAlbum());
            metadata.set(XMPDM.RELEASE_DATE, tag.getYear());
            metadata.set(XMPDM.GENRE, tag.getGenre());
-           metadata.set(XMPDM.LOG_COMMENT, tag.getComment());
+           
+           List<String> comments = new ArrayList<String>();
+           for (ID3Comment comment : tag.getComments()) {
+              StringBuffer cmt = new StringBuffer();
+              if (comment.getLanguage() != null) {
+                 cmt.append(comment.getLanguage());
+                 cmt.append(" - ");
+              }
+              if (comment.getDescription() != null) {
+                 cmt.append(comment.getDescription());
+                 if (comment.getText() != null) {
+                    cmt.append("\n");
+                 }
+              }
+              if (comment.getText() != null) {
+                 cmt.append(comment.getText());
+              }
+              
+              comments.add(cmt.toString());
+              metadata.add(XMPDM.LOG_COMMENT.getName(), cmt.toString());
+           }
 
            xhtml.element("h1", tag.getTitle());
            xhtml.element("p", tag.getArtist());
@@ -90,8 +111,10 @@ public class Mp3Parser extends AbstractParser {
                 xhtml.element("p", tag.getAlbum());
             }
             xhtml.element("p", tag.getYear());
-            xhtml.element("p", tag.getComment());
             xhtml.element("p", tag.getGenre());
+            for (String comment : comments) {
+               xhtml.element("p", comment);
+            }
         }
         if (audioAndTags.audio != null) {
             metadata.set("samplerate", String.valueOf(audioAndTags.audio.getSampleRate()));

Commit:
fa076c5ddf7d6685fb491a6cfe531c4eeb91f542
Jukka Zitting
jukka@apache.org
2012-01-03 18:10:47 +0000
TIKA-375: EmptyParser Singleton should be final
diff --git a/tika-core/pom.xml b/tika-core/pom.xml
index e230b455c..bce215c5f 100644
--- a/tika-core/pom.xml
+++ b/tika-core/pom.xml
@@ -94,6 +94,7 @@
               <excludes>
                 <exlude>org/apache/tika/metadata/Property$PropertyType</exlude>
                 <exlude>org/apache/tika/metadata/Property$ValueType</exlude>
+                <exlude>org/apache/tika/parser/EmptyParser</exlude>
               </excludes>
               <comparisonArtifacts>
                 <comparisonArtifact>
diff --git a/tika-core/src/main/java/org/apache/tika/parser/EmptyParser.java b/tika-core/src/main/java/org/apache/tika/parser/EmptyParser.java
index eed73cd01..3ca418846 100644
--- a/tika-core/src/main/java/org/apache/tika/parser/EmptyParser.java
+++ b/tika-core/src/main/java/org/apache/tika/parser/EmptyParser.java
@@ -41,7 +41,7 @@ public class EmptyParser extends AbstractParser {
     /**
      * Singleton instance of this class.
      */
-    public static EmptyParser INSTANCE = new EmptyParser();
+    public static final EmptyParser INSTANCE = new EmptyParser();
 
     public Set<MediaType> getSupportedTypes(ParseContext context) {
         return Collections.emptySet();

Commit:
e303705a4beab60fe4dad27f29621939fe2f0d0a
Nick Burch
nick@apache.org
2012-01-03 05:23:39 +0000
Patch from Fabian Lange from TIKA-837 - Make inner classes static where possible
diff --git a/tika-core/src/main/java/org/apache/tika/language/LanguageProfile.java b/tika-core/src/main/java/org/apache/tika/language/LanguageProfile.java
index 44541430e..3b01a587d 100644
--- a/tika-core/src/main/java/org/apache/tika/language/LanguageProfile.java
+++ b/tika-core/src/main/java/org/apache/tika/language/LanguageProfile.java
@@ -44,7 +44,7 @@ public class LanguageProfile {
      */
     private long count = 0;
 
-    private class Counter {
+    private static class Counter {
         private long count = 0;
         public String toString() {
             return Long.toString(count);
diff --git a/tika-core/src/main/java/org/apache/tika/language/LanguageProfilerBuilder.java b/tika-core/src/main/java/org/apache/tika/language/LanguageProfilerBuilder.java
index 82e8610b9..0508388eb 100644
--- a/tika-core/src/main/java/org/apache/tika/language/LanguageProfilerBuilder.java
+++ b/tika-core/src/main/java/org/apache/tika/language/LanguageProfilerBuilder.java
@@ -552,7 +552,7 @@ public class LanguageProfilerBuilder {
     /**
      * Inner class that describes a NGram
      */
-    class NGramEntry implements Comparable<NGramEntry> {
+    static class NGramEntry implements Comparable<NGramEntry> {
 
         /** The NGRamProfile this NGram is related to */
         private LanguageProfilerBuilder profile = null;
@@ -682,7 +682,7 @@ public class LanguageProfilerBuilder {
 
     }
 
-    private class QuickStringBuffer implements CharSequence {
+    private static class QuickStringBuffer implements CharSequence {
 
         private char value[];
 
diff --git a/tika-core/src/main/java/org/apache/tika/mime/MimeType.java b/tika-core/src/main/java/org/apache/tika/mime/MimeType.java
index 2d10ffbc0..97bd0ae9f 100644
--- a/tika-core/src/main/java/org/apache/tika/mime/MimeType.java
+++ b/tika-core/src/main/java/org/apache/tika/mime/MimeType.java
@@ -221,7 +221,7 @@ public final class MimeType implements Comparable<MimeType>, Serializable {
      * Defines a RootXML description. RootXML is made of a localName and/or a
      * namespaceURI.
      */
-    class RootXML implements Serializable {
+    static class RootXML implements Serializable {
 
         /**
          * Serial version UID.
diff --git a/tika-core/src/main/java/org/apache/tika/mime/Patterns.java b/tika-core/src/main/java/org/apache/tika/mime/Patterns.java
index 412056661..212f5e6db 100644
--- a/tika-core/src/main/java/org/apache/tika/mime/Patterns.java
+++ b/tika-core/src/main/java/org/apache/tika/mime/Patterns.java
@@ -56,7 +56,7 @@ class Patterns implements Serializable {
     private final SortedMap<String, MimeType> globs =
         new TreeMap<String, MimeType>(new LengthComparator());
 
-    private final class LengthComparator
+    private static final class LengthComparator
             implements Comparator<String>, Serializable {
 
         /**
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XSSFExcelExtractorDecorator.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XSSFExcelExtractorDecorator.java
index ae98cfd53..dd9f02caa 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XSSFExcelExtractorDecorator.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XSSFExcelExtractorDecorator.java
@@ -174,7 +174,7 @@ public class XSSFExcelExtractorDecorator extends AbstractOOXMLExtractor {
     /**
      * Turns formatted sheet events into HTML
      */
-    protected class SheetTextAsHTML implements SheetContentsHandler {
+    protected static class SheetTextAsHTML implements SheetContentsHandler {
        private XHTMLContentHandler xhtml;
        private CommentsTable comments;
        private List<String> headers;
@@ -235,7 +235,7 @@ public class XSSFExcelExtractorDecorator extends AbstractOOXMLExtractor {
      * Allows access to headers/footers from raw xml strings
      */
     private static HeaderFooterHelper hfHelper = new HeaderFooterHelper();
-    protected class HeaderFooterFromString implements HeaderFooter {
+    protected static class HeaderFooterFromString implements HeaderFooter {
       private String text;
       protected HeaderFooterFromString(String text) {
          this.text = text;
@@ -260,7 +260,7 @@ public class XSSFExcelExtractorDecorator extends AbstractOOXMLExtractor {
      * Captures information on interesting tags, whilst
      *  delegating the main work to the formatting handler
      */
-    protected class XSSFSheetInterestingPartsCapturer implements ContentHandler {
+    protected static class XSSFSheetInterestingPartsCapturer implements ContentHandler {
       private ContentHandler delegate;
       private boolean hasProtection = false;
       
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/odf/OpenDocumentContentParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/odf/OpenDocumentContentParser.java
index 6cd0c20c8..d62fc9b89 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/odf/OpenDocumentContentParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/odf/OpenDocumentContentParser.java
@@ -23,6 +23,7 @@ import java.io.InputStream;
 import java.util.BitSet;
 import java.util.Collections;
 import java.util.HashMap;
+import java.util.Map;
 import java.util.Set;
 import java.util.Stack;
 
@@ -54,7 +55,154 @@ import org.xml.sax.helpers.DefaultHandler;
  */
 public class OpenDocumentContentParser extends AbstractParser {
 
-    public static final String TEXT_NS =
+    private static final class OpenDocumentElementMappingContentHandler extends
+			ElementMappingContentHandler {
+		private final ContentHandler handler;
+		private final BitSet textNodeStack = new BitSet();
+		private int nodeDepth = 0;
+		private int completelyFiltered = 0;
+		private Stack<String> headingStack = new Stack<String>();
+
+		private OpenDocumentElementMappingContentHandler(ContentHandler handler,
+				Map<QName, TargetElement> mappings) {
+			super(handler, mappings);
+			this.handler = handler;
+		}
+
+		@Override
+		public void characters(char[] ch, int start, int length)
+		        throws SAXException {
+		    // only forward content of tags from text:-namespace
+		    if (completelyFiltered == 0 && nodeDepth > 0
+		            && textNodeStack.get(nodeDepth - 1)) {
+		        super.characters(ch,start,length);
+		    }
+		}
+
+		// helper for checking tags which need complete filtering
+		// (with sub-tags)
+		private boolean needsCompleteFiltering(
+		        String namespaceURI, String localName) {
+		    if (TEXT_NS.equals(namespaceURI)) {
+		        return localName.endsWith("-template")
+		            || localName.endsWith("-style");
+		    } else if (TABLE_NS.equals(namespaceURI)) {
+		        return "covered-table-cell".equals(localName);
+		    } else {
+		        return false;
+		    }
+		}
+
+		// map the heading level to <hX> HTML tags
+		private String getXHTMLHeaderTagName(Attributes atts) {
+		    String depthStr = atts.getValue(TEXT_NS, "outline-level");
+		    if (depthStr == null) {
+		        return "h1";
+		    }
+
+		    int depth = Integer.parseInt(depthStr);
+		    if (depth >= 6) {
+		        return "h6";
+		    } else if (depth <= 1) {
+		        return "h1";
+		    } else {
+		        return "h" + depth;
+		    }
+		}
+
+		/**
+		 * Check if a node is a text node
+		 */
+		private boolean isTextNode(String namespaceURI, String localName) {
+		    if (TEXT_NS.equals(namespaceURI) && !localName.equals("page-number") && !localName.equals("page-count")) {
+		        return true;
+		    }
+		    if (SVG_NS.equals(namespaceURI)) {
+		        return "title".equals(localName) ||
+		                "desc".equals(localName);
+		    }
+		    return false;
+		}
+
+		@Override
+		public void startElement(
+		        String namespaceURI, String localName, String qName,
+		        Attributes atts) throws SAXException {
+		    // keep track of current node type. If it is a text node,
+		    // a bit at the current depth ist set in textNodeStack.
+		    // characters() checks the top bit to determine, if the
+		    // actual node is a text node to print out nodeDepth contains
+		    // the depth of the current node and also marks top of stack.
+		    assert nodeDepth >= 0;
+
+		    textNodeStack.set(nodeDepth++, 
+		            isTextNode(namespaceURI, localName));
+		    // filter *all* content of some tags
+		    assert completelyFiltered >= 0;
+
+		    if (needsCompleteFiltering(namespaceURI, localName)) {
+		        completelyFiltered++;
+		    }
+		    // call next handler if no filtering
+		    if (completelyFiltered == 0) {
+		        // special handling of text:h, that are directly passed
+		        // to incoming handler
+		        if (TEXT_NS.equals(namespaceURI) && "h".equals(localName)) {
+		            final String el = headingStack.push(getXHTMLHeaderTagName(atts));
+		            handler.startElement(XHTMLContentHandler.XHTML, el, el, EMPTY_ATTRIBUTES);
+		        } else {
+		            super.startElement(
+		                    namespaceURI, localName, qName, atts);
+		        }
+		    }
+		}
+
+		@Override
+		public void endElement(
+		        String namespaceURI, String localName, String qName)
+		        throws SAXException {
+		    // call next handler if no filtering
+		    if (completelyFiltered == 0) {
+		        // special handling of text:h, that are directly passed
+		        // to incoming handler
+		        if (TEXT_NS.equals(namespaceURI) && "h".equals(localName)) {
+		            final String el = headingStack.pop();
+		            handler.endElement(XHTMLContentHandler.XHTML, el, el);
+		        } else {
+		            super.endElement(namespaceURI,localName,qName);
+		        }
+
+		        // special handling of tabulators
+		        if (TEXT_NS.equals(namespaceURI)
+		                && ("tab-stop".equals(localName)
+		                        || "tab".equals(localName))) {
+		            this.characters(TAB, 0, TAB.length);
+		        }
+		    }
+
+		    // revert filter for *all* content of some tags
+		    if (needsCompleteFiltering(namespaceURI,localName)) {
+		        completelyFiltered--;
+		    }
+		    assert completelyFiltered >= 0;
+
+		    // reduce current node depth
+		    nodeDepth--;
+		    assert nodeDepth >= 0;
+		}
+
+		@Override
+		public void startPrefixMapping(String prefix, String uri) {
+		    // remove prefix mappings as they should not occur in XHTML
+		}
+
+		@Override
+		public void endPrefixMapping(String prefix) {
+		    // remove prefix mappings as they should not occur in XHTML
+		}
+	}
+
+	public static final String TEXT_NS =
         "urn:oasis:names:tc:opendocument:xmlns:text:1.0";
 
     public static final String TABLE_NS =
@@ -187,149 +335,7 @@ public class OpenDocumentContentParser extends AbstractParser {
             Metadata metadata, ParseContext context)
             throws IOException, SAXException, TikaException {
 
-        DefaultHandler dh = new ElementMappingContentHandler(handler, MAPPINGS) {
-
-            private final BitSet textNodeStack = new BitSet();
-
-            private int nodeDepth = 0;
-
-            private int completelyFiltered = 0;
-
-            private Stack<String> headingStack = new Stack<String>();
-
-            @Override
-            public void characters(char[] ch, int start, int length)
-                    throws SAXException {
-                // only forward content of tags from text:-namespace
-                if (completelyFiltered == 0 && nodeDepth > 0
-                        && textNodeStack.get(nodeDepth - 1)) {
-                    super.characters(ch,start,length);
-                }
-            }
-
-            // helper for checking tags which need complete filtering
-            // (with sub-tags)
-            private boolean needsCompleteFiltering(
-                    String namespaceURI, String localName) {
-                if (TEXT_NS.equals(namespaceURI)) {
-                    return localName.endsWith("-template")
-                        || localName.endsWith("-style");
-                } else if (TABLE_NS.equals(namespaceURI)) {
-                    return "covered-table-cell".equals(localName);
-                } else {
-                    return false;
-                }
-            }
-
-            // map the heading level to <hX> HTML tags
-            private String getXHTMLHeaderTagName(Attributes atts) {
-                String depthStr = atts.getValue(TEXT_NS, "outline-level");
-                if (depthStr == null) {
-                    return "h1";
-                }
-
-                int depth = Integer.parseInt(depthStr);
-                if (depth >= 6) {
-                    return "h6";
-                } else if (depth <= 1) {
-                    return "h1";
-                } else {
-                    return "h" + depth;
-                }
-            }
-
-            /**
-             * Check if a node is a text node
-             */
-            private boolean isTextNode(String namespaceURI, String localName) {
-                if (TEXT_NS.equals(namespaceURI) && !localName.equals("page-number") && !localName.equals("page-count")) {
-                    return true;
-                }
-                if (SVG_NS.equals(namespaceURI)) {
-                    return "title".equals(localName) ||
-                            "desc".equals(localName);
-                }
-                return false;
-            }
-
-            @Override
-            public void startElement(
-                    String namespaceURI, String localName, String qName,
-                    Attributes atts) throws SAXException {
-                // keep track of current node type. If it is a text node,
-                // a bit at the current depth ist set in textNodeStack.
-                // characters() checks the top bit to determine, if the
-                // actual node is a text node to print out nodeDepth contains
-                // the depth of the current node and also marks top of stack.
-                assert nodeDepth >= 0;
-
-                textNodeStack.set(nodeDepth++, 
-                        isTextNode(namespaceURI, localName));
-                // filter *all* content of some tags
-                assert completelyFiltered >= 0;
-
-                if (needsCompleteFiltering(namespaceURI, localName)) {
-                    completelyFiltered++;
-                }
-                // call next handler if no filtering
-                if (completelyFiltered == 0) {
-                    // special handling of text:h, that are directly passed
-                    // to incoming handler
-                    if (TEXT_NS.equals(namespaceURI) && "h".equals(localName)) {
-                        final String el = headingStack.push(getXHTMLHeaderTagName(atts));
-                        handler.startElement(XHTMLContentHandler.XHTML, el, el, EMPTY_ATTRIBUTES);
-                    } else {
-                        super.startElement(
-                                namespaceURI, localName, qName, atts);
-                    }
-                }
-            }
-
-            @Override
-            public void endElement(
-                    String namespaceURI, String localName, String qName)
-                    throws SAXException {
-                // call next handler if no filtering
-                if (completelyFiltered == 0) {
-                    // special handling of text:h, that are directly passed
-                    // to incoming handler
-                    if (TEXT_NS.equals(namespaceURI) && "h".equals(localName)) {
-                        final String el = headingStack.pop();
-                        handler.endElement(XHTMLContentHandler.XHTML, el, el);
-                    } else {
-                        super.endElement(namespaceURI,localName,qName);
-                    }
-
-                    // special handling of tabulators
-                    if (TEXT_NS.equals(namespaceURI)
-                            && ("tab-stop".equals(localName)
-                                    || "tab".equals(localName))) {
-                        this.characters(TAB, 0, TAB.length);
-                    }
-                }
-
-                // revert filter for *all* content of some tags
-                if (needsCompleteFiltering(namespaceURI,localName)) {
-                    completelyFiltered--;
-                }
-                assert completelyFiltered >= 0;
-
-                // reduce current node depth
-                nodeDepth--;
-                assert nodeDepth >= 0;
-            }
-
-            @Override
-            public void startPrefixMapping(String prefix, String uri) {
-                // remove prefix mappings as they should not occur in XHTML
-            }
-
-            @Override
-            public void endPrefixMapping(String prefix) {
-                // remove prefix mappings as they should not occur in XHTML
-            }
-
-        };
+        DefaultHandler dh = new OpenDocumentElementMappingContentHandler(handler, MAPPINGS);
 
         try {
             SAXParserFactory factory = SAXParserFactory.newInstance();
@@ -354,3 +360,4 @@ public class OpenDocumentContentParser extends AbstractParser {
     }
 
 }
+	
\ No newline at end of file

Commit:
83a8a97e02d1ac479bbea6770732e4ea9d8fcf7f
Nick Burch
nick@apache.org
2012-01-03 05:19:33 +0000
TIKA-826 For an OOXML type we can't handle, use EmptyParser for valid, empty xml
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParser.java
index 935a935fc..8d4aae04a 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParser.java
@@ -27,6 +27,7 @@ import org.apache.tika.exception.TikaException;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.mime.MediaType;
 import org.apache.tika.parser.AbstractParser;
+import org.apache.tika.parser.EmptyParser;
 import org.apache.tika.parser.ParseContext;
 import org.xml.sax.ContentHandler;
 import org.xml.sax.SAXException;
@@ -81,6 +82,8 @@ public class OOXMLParser extends AbstractParser {
         // Is this an OOXML derived type that we can't help with?
         String type = metadata.get(Metadata.CONTENT_TYPE);
         if (type != null && UNSUPPORTED_OOXML_TYPES.contains(MediaType.parse(type))) {
+           // Not a supported type, delegate to Empty Parser 
+           EmptyParser.INSTANCE.parse(stream, handler, metadata, context);
            return;
         }
 

Commit:
9e22f46f2403b89dbc8454cefb8b83881f437419
Nick Burch
nick@apache.org
2012-01-03 05:12:47 +0000
TIKA-826 We don't currently support .xps or .xlsb files (which are OOXML based), so ensure we don't explicitly claim them, and have the OOXML parser decline if it gets them on the basis of the parent type
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 2c96313bb..d497b7838 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -1372,6 +1372,7 @@
   </mime-type>
   <mime-type type="application/vnd.ms-xpsdocument">
     <glob pattern="*.xps"/>
+    <sub-class-of type="application/x-tika-ooxml"/>
   </mime-type>
   <mime-type type="application/vnd.mseq">
     <glob pattern="*.mseq"/>
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java
index 91dd41771..005c14935 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java
@@ -70,8 +70,7 @@ public class OfficeParser extends AbstractParser {
                     POIFSDocumentType.VISIO.type,
                     // Works isn't supported
                     POIFSDocumentType.XLR.type, // but Works 7.0 Spreadsheet is
-                    POIFSDocumentType.OUTLOOK.type,
-                    MediaType.application("vnd.ms-excel.sheet.binary.macroenabled.12")
+                    POIFSDocumentType.OUTLOOK.type
                     )));
 
     public enum POIFSDocumentType {
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParser.java
index c5bdb50d0..935a935fc 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParser.java
@@ -57,6 +57,18 @@ public class OOXMLParser extends AbstractParser {
                 MediaType.application("vnd.ms-word.document.macroenabled.12"),
                 MediaType.application("vnd.openxmlformats-officedocument.wordprocessingml.template"),
                 MediaType.application("vnd.ms-word.template.macroenabled.12"))));
+    
+    /**
+     * We claim to support all OOXML files, but we actually don't support a small
+     *  number of them.
+     * This list is used to decline certain formats that are not yet supported
+     *  by Tika and/or POI.
+     */
+    private static final Set<MediaType> UNSUPPORTED_OOXML_TYPES = 
+       Collections.unmodifiableSet(new HashSet<MediaType>(Arrays.asList(
+                MediaType.application("vnd.ms-excel.sheet.binary.macroenabled.12"),
+                MediaType.application("vnd.ms-xpsdocument")
+       )));
 
     public Set<MediaType> getSupportedTypes(ParseContext context) {
         return SUPPORTED_TYPES;
@@ -66,7 +78,13 @@ public class OOXMLParser extends AbstractParser {
             InputStream stream, ContentHandler handler,
             Metadata metadata, ParseContext context)
             throws IOException, SAXException, TikaException {
+        // Is this an OOXML derived type that we can't help with?
+        String type = metadata.get(Metadata.CONTENT_TYPE);
+        if (type != null && UNSUPPORTED_OOXML_TYPES.contains(MediaType.parse(type))) {
+           return;
+        }
+
+        // Have the OOXML file processed
         OOXMLExtractorFactory.parse(stream, handler, metadata, context);
     }
-
 }
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ExcelParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ExcelParserTest.java
index 790fac64e..9a7b2a190 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ExcelParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ExcelParserTest.java
@@ -21,8 +21,14 @@ import java.util.Locale;
 
 import junit.framework.TestCase;
 
+import org.apache.tika.config.TikaConfig;
+import org.apache.tika.detect.DefaultDetector;
+import org.apache.tika.detect.Detector;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.mime.MediaType;
+import org.apache.tika.parser.AutoDetectParser;
 import org.apache.tika.parser.ParseContext;
+import org.apache.tika.parser.microsoft.ooxml.OOXMLParser;
 import org.apache.tika.sax.BodyContentHandler;
 import org.xml.sax.ContentHandler;
 
@@ -211,4 +217,48 @@ public class ExcelParserTest extends TestCase {
         }
     }
 
+    /**
+     * We don't currently support the .xlsb file format 
+     *  (an OOXML container with binary blobs), but we 
+     *  shouldn't break on these files either (TIKA-826)  
+     */
+    public void testExcelXLSB() throws Exception {
+       Detector detector = new DefaultDetector();
+       AutoDetectParser parser = new AutoDetectParser();
+       
+       InputStream input = ExcelParserTest.class.getResourceAsStream(
+             "/test-documents/testEXCEL.xlsb");
+       Metadata m = new Metadata();
+       m.add(Metadata.RESOURCE_NAME_KEY, "excel.xlsb");
+       
+       // Should be detected correctly
+       MediaType type = null;
+       try {
+          type = detector.detect(input, m);
+          assertEquals("application/vnd.ms-excel.sheet.binary.macroenabled.12", type.toString());
+       } finally {
+          input.close();
+       }
+       
+       // OfficeParser won't handle it
+       assertEquals(false, (new OfficeParser()).getSupportedTypes(new ParseContext()).contains(type));
+       
+       // OOXMLParser won't handle it
+       assertEquals(false, (new OOXMLParser()).getSupportedTypes(new ParseContext()).contains(type));
+       
+       // AutoDetectParser doesn't break on it
+       input = ExcelParserTest.class.getResourceAsStream("/test-documents/testEXCEL.xlsb");
+
+       try {
+          ContentHandler handler = new BodyContentHandler(-1);
+          ParseContext context = new ParseContext();
+          context.set(Locale.class, Locale.US);
+          parser.parse(input, handler, m, context);
+
+          String content = handler.toString();
+          assertEquals("", content);
+       } finally {
+          input.close();
+       }
+    }
 }

Commit:
52d51b91d4b288db5887d592826abbbec5cd6db5
Chris Mattmann
mattmann@apache.org
2012-01-03 04:20:04 +0000
- apply patch from TIKA-824 contributed by Markus Jelsma
diff --git a/CHANGES.txt b/CHANGES.txt
index 65f5627d2..0d1688cbd 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -4,6 +4,9 @@ Apache Tika Change Log
 Release 1.1 - Current Development
 ---------------------------------
 
+ * Link Extraction: The rel attribute is now extracted from 
+   links per the LinkConteHandler. (TIKA-824)
+
  * MP3: Fixed handling of UTF-16 (two byte) ID3v2 tags (previously
    the last character in a UTF-16 tag could be corrupted) (TIKA-793)
 
diff --git a/tika-core/src/main/java/org/apache/tika/sax/Link.java b/tika-core/src/main/java/org/apache/tika/sax/Link.java
index 749059559..00cf2238e 100644
--- a/tika-core/src/main/java/org/apache/tika/sax/Link.java
+++ b/tika-core/src/main/java/org/apache/tika/sax/Link.java
@@ -26,11 +26,22 @@ public class Link {
 
     private final String text;
 
+    private final String rel;
+
     public Link(String type, String uri, String title, String text) {
         this.type = type;
         this.uri = uri;
         this.title = title;
         this.text = text;
+        this.rel = "";
+    }
+
+    public Link(String type, String uri, String title, String text, String rel) {
+        this.type = type;
+        this.uri = uri;
+        this.title = title;
+        this.text = text;
+        this.rel = rel;
     }
 
     public boolean isAnchor() {
@@ -57,6 +68,10 @@ public class Link {
         return text;
     }
 
+    public String getRel() {
+      return rel;
+    }
+
     public String toString() {
         StringBuilder builder = new StringBuilder();
         if (isImage()) {
@@ -80,6 +95,10 @@ public class Link {
                 builder.append("\" title=\"");
                 builder.append(title);
             }
+            if (rel != null && rel.length() > 0) {
+                builder.append("\" rel=\"");
+                builder.append(rel);
+            }
             builder.append("\">");
             builder.append(text);
             builder.append("</");
diff --git a/tika-core/src/main/java/org/apache/tika/sax/LinkBuilder.java b/tika-core/src/main/java/org/apache/tika/sax/LinkBuilder.java
index 7ad655d98..a1c0b1aa8 100644
--- a/tika-core/src/main/java/org/apache/tika/sax/LinkBuilder.java
+++ b/tika-core/src/main/java/org/apache/tika/sax/LinkBuilder.java
@@ -24,6 +24,8 @@ class LinkBuilder {
 
     private String title = "";
 
+    private String rel = "";
+
     private final StringBuilder text = new StringBuilder();
 
     public LinkBuilder(String type) {
@@ -46,12 +48,20 @@ class LinkBuilder {
         }
     }
 
+    public void setRel(String rel) {
+        if (rel != null) {
+            this.rel = rel;
+        } else {
+            this.rel = "";
+        }
+    }
+
     public void characters(char[] ch, int offset, int length) {
         text.append(ch, offset, length);
     }
 
     public Link getLink() {
-        return new Link(type, uri, title, text.toString());
+        return new Link(type, uri, title, text.toString(), rel);
     }
 
 }
diff --git a/tika-core/src/main/java/org/apache/tika/sax/LinkContentHandler.java b/tika-core/src/main/java/org/apache/tika/sax/LinkContentHandler.java
index 16fc72c78..b7b4691a3 100644
--- a/tika-core/src/main/java/org/apache/tika/sax/LinkContentHandler.java
+++ b/tika-core/src/main/java/org/apache/tika/sax/LinkContentHandler.java
@@ -62,11 +62,13 @@ public class LinkContentHandler extends DefaultHandler {
                 LinkBuilder builder = new LinkBuilder("a");
                 builder.setURI(attributes.getValue("", "href"));
                 builder.setTitle(attributes.getValue("", "title"));
+                builder.setRel(attributes.getValue("", "rel"));
                 builderStack.addFirst(builder);
             } else if ("img".equals(local)) {
                 LinkBuilder builder = new LinkBuilder("img");
                 builder.setURI(attributes.getValue("", "src"));
                 builder.setTitle(attributes.getValue("", "title"));
+                builder.setRel(attributes.getValue("", "rel"));
                 builderStack.addFirst(builder);
 
                 String alt = attributes.getValue("", "alt");

Commit:
f6001f7cababf5dad2bdf063c839b5314eff2628
Nick Burch
nick@apache.org
2011-12-29 09:14:11 +0000
Add TIKA-793 to the changelog
diff --git a/CHANGES.txt b/CHANGES.txt
index 0cd53fcad..65f5627d2 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -4,6 +4,9 @@ Apache Tika Change Log
 Release 1.1 - Current Development
 ---------------------------------
 
+ * MP3: Fixed handling of UTF-16 (two byte) ID3v2 tags (previously
+   the last character in a UTF-16 tag could be corrupted) (TIKA-793)
+
  * Performance: Loading of the default media type registry is now
    significantly faster. (TIKA-780)
 

Commit:
3bdf69a7d2e119aa722a097d81a99fd63d76be78
Nick Burch
nick@apache.org
2011-12-29 09:11:28 +0000
TIKA-793 Correctly handle the COM/COMM tag in MP3s, which is in a different form - encoding+language+desc+text
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v22Handler.java b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v22Handler.java
index a4c64f044..46341adbf 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v22Handler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v22Handler.java
@@ -55,7 +55,7 @@ public class ID3v22Handler implements ID3Tags {
             } else if (tag.name.equals("TCM")) {
                 composer = getTagString(tag.data, 0, tag.data.length); 
             } else if (tag.name.equals("COM")) {
-                comment = getTagString(tag.data, 0, tag.data.length); 
+                comment = getCommentString(tag.data, 0, tag.data.length); 
             } else if (tag.name.equals("TRK")) {
                 trackNumber = getTagString(tag.data, 0, tag.data.length); 
             } else if (tag.name.equals("TCO")) {
@@ -67,6 +67,9 @@ public class ID3v22Handler implements ID3Tags {
     private String getTagString(byte[] data, int offset, int length) {
         return ID3v2Frame.getTagString(data, offset, length);
     }
+    private String getCommentString(byte[] data, int offset, int length) {
+        return ID3v2Frame.getCommentString(data, offset, length);
+    }
     
     protected static String extractGenre(String rawGenre) {
        int open = rawGenre.indexOf("(");
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v23Handler.java b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v23Handler.java
index 7509a8412..72c0b9f22 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v23Handler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v23Handler.java
@@ -55,7 +55,7 @@ public class ID3v23Handler implements ID3Tags {
             } else if (tag.name.equals("TCOM")) {
                 composer = getTagString(tag.data, 0, tag.data.length); 
             } else if (tag.name.equals("COMM")) {
-                comment = getTagString(tag.data, 0, tag.data.length); 
+                comment = getCommentString(tag.data, 0, tag.data.length); 
             } else if (tag.name.equals("TRCK")) {
                 trackNumber = getTagString(tag.data, 0, tag.data.length); 
             } else if (tag.name.equals("TCON")) {
@@ -65,9 +65,10 @@ public class ID3v23Handler implements ID3Tags {
     }
 
     private String getTagString(byte[] data, int offset, int length) {
-        String str = ID3v2Frame.getTagString(data, offset, length);
-        // Handle embedded nulls
-        return str.replace((char)0, '\n');
+        return ID3v2Frame.getTagString(data, offset, length);
+    }
+    private String getCommentString(byte[] data, int offset, int length) {
+       return ID3v2Frame.getCommentString(data, offset, length);
     }
 
     public boolean getTagsPresent() {
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v24Handler.java b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v24Handler.java
index 575ed7b31..dda81bda6 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v24Handler.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v24Handler.java
@@ -60,7 +60,7 @@ public class ID3v24Handler implements ID3Tags {
             } else if (tag.name.equals("TCOM")) {
                 composer = getTagString(tag.data, 0, tag.data.length); 
             } else if (tag.name.equals("COMM")) {
-                comment = getTagString(tag.data, 0, tag.data.length); 
+                comment = getCommentString(tag.data, 0, tag.data.length); 
             } else if (tag.name.equals("TRCK")) {
                 trackNumber = getTagString(tag.data, 0, tag.data.length); 
             } else if (tag.name.equals("TCON")) {
@@ -72,6 +72,9 @@ public class ID3v24Handler implements ID3Tags {
     private String getTagString(byte[] data, int offset, int length) {
         return ID3v2Frame.getTagString(data, offset, length);
     }
+    private String getCommentString(byte[] data, int offset, int length) {
+        return ID3v2Frame.getCommentString(data, offset, length);
+    }
 
     public boolean getTagsPresent() {
         return true;
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v2Frame.java b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v2Frame.java
index 68c9c57f5..d790741a5 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v2Frame.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v2Frame.java
@@ -175,6 +175,21 @@ public class ID3v2Frame implements MP3Frame {
 
         return b;
     }
+    
+    protected static class TextEncoding {
+       public final boolean doubleByte;
+       public final String encoding;
+       private TextEncoding(String encoding, boolean doubleByte) {
+          this.doubleByte = doubleByte;
+          this.encoding = encoding;
+       }
+    }
+    protected static final TextEncoding[] encodings = new TextEncoding[] {
+          new TextEncoding("ISO-8859-1", false),
+          new TextEncoding("UTF-16", true), // With BOM
+          new TextEncoding("UTF-16BE", true), // Without BOM
+          new TextEncoding("UTF-8", false)
+    };
 
     /**
      * Returns the (possibly null padded) String at the given offset and
@@ -191,31 +206,19 @@ public class ID3v2Frame implements MP3Frame {
 
         // Does it have an encoding flag?
         // Detect by the first byte being sub 0x20
-        boolean doubleByte = false;
-        String encoding = "ISO8859_1";
+        TextEncoding encoding = encodings[0];
         byte maybeEncodingFlag = data[offset];
-        if (maybeEncodingFlag == 0 || maybeEncodingFlag == 1 ||
-              maybeEncodingFlag == 2 || maybeEncodingFlag == 3) {
+        if (maybeEncodingFlag >= 0 && maybeEncodingFlag < encodings.length) {
             offset++;
             actualLength--;
-            if (maybeEncodingFlag == 1) {
-                // With BOM
-                encoding = "UTF-16";
-                doubleByte = true;
-            } else if (maybeEncodingFlag == 2) {
-                // Without BOM
-                encoding = "UTF-16BE";
-                doubleByte = true;
-            } else if (maybeEncodingFlag == 3) {
-                encoding = "UTF8";
-            }
+            encoding = encodings[maybeEncodingFlag];
         }
         
         // Trim off null termination / padding (as present) 
-        while (doubleByte && actualLength >= 2 && data[offset+actualLength-1] == 0 && data[offset+actualLength-2] == 0) {
+        while (encoding.doubleByte && actualLength >= 2 && data[offset+actualLength-1] == 0 && data[offset+actualLength-2] == 0) {
            actualLength -= 2;
         } 
-        while (!doubleByte && actualLength >= 1 && data[offset+actualLength-1] == 0) {
+        while (!encoding.doubleByte && actualLength >= 1 && data[offset+actualLength-1] == 0) {
            actualLength--;
         }
         if (actualLength == 0) {
@@ -224,12 +227,74 @@ public class ID3v2Frame implements MP3Frame {
 
         try {
             // Build the base string
-            return new String(data, offset, actualLength, encoding);
+            return new String(data, offset, actualLength, encoding.encoding);
         } catch (UnsupportedEncodingException e) {
             throw new RuntimeException(
-                    "Core encoding " + encoding + " is not available", e);
+                    "Core encoding " + encoding.encoding + " is not available", e);
         }
     }
+    /**
+     * Returns the comment string, in the form [LANG]: [Desc]\n[Text]
+     */
+    protected static String getCommentString(byte[] data, int offset, int length) {
+       // Comments must have an encoding
+       int encodingFlag = data[offset];
+       if (encodingFlag >= 0 && encodingFlag < encodings.length) {
+          // Good, valid flag
+       } else {
+          // Invalid string
+          return "";
+       }
+       
+       TextEncoding encoding = encodings[encodingFlag];
+       
+       // First is a 3 byte language
+       String lang = getString(data, offset+1, 3);
+       
+       // After that we have [Desc]\0(\0)[Text]
+       int descStart = offset+4;
+       int textStart = -1;
+       String description = null;
+       String text = null;
+       
+       // Find where the description ends
+       try {
+          for (int i=descStart; i<offset+length; i++) {
+             if (encoding.doubleByte && data[i]==0 && data[i+1] == 0) {
+                // Handle LE vs BE on low byte text
+                if (i+2 < offset+length && data[i+1] == 0 && data[i+2] == 0) {
+                   i++;
+                }
+                textStart = i+2;
+                description = new String(data, descStart, i-descStart, encoding.encoding);
+                break;
+             }
+             if (!encoding.doubleByte && data[i]==0) {
+                textStart = i+1;
+                description = new String(data, descStart, i-descStart, encoding.encoding);
+                break;
+             }
+          }
+          
+          // Did we find the end?
+          if (textStart > -1) {
+             text = new String(data, textStart, offset+length-textStart, encoding.encoding);
+          } else {
+             // Assume everything is the text
+             text = new String(data, descStart, offset+length-descStart, encoding.encoding);
+          }
+          
+          // Return
+          if (description == null || description.length() == 0) {
+             return lang + " - " + text;
+          } else {
+             return lang + " - " + description + "\n" + text;
+          }
+       } catch (UnsupportedEncodingException e) {
+          throw new RuntimeException(
+                  "Core encoding " + encoding.encoding + " is not available", e);
+       }
+    }
 
     /**
      * Returns the String at the given
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/mp3/Mp3ParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/mp3/Mp3ParserTest.java
index 56949692d..41484f2b8 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/mp3/Mp3ParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/mp3/Mp3ParserTest.java
@@ -109,7 +109,7 @@ public class Mp3ParserTest extends TestCase {
         assertEquals(null, metadata.get(XMPDM.COMPOSER));
         assertEquals("2008", metadata.get(XMPDM.RELEASE_DATE));
         assertEquals("Rock", metadata.get(XMPDM.GENRE));
-        assertEquals("XXXID3v1 Comment\nTest Comment", metadata.get(XMPDM.LOG_COMMENT.getName()));
+        assertEquals("XXX - ID3v1 Comment\nTest Comment", metadata.get(XMPDM.LOG_COMMENT.getName()));
         assertEquals("1", metadata.get(XMPDM.TRACK_NUMBER));
         
         assertEquals("44100", metadata.get(XMPDM.AUDIO_SAMPLE_RATE));
@@ -208,8 +208,10 @@ public class Mp3ParserTest extends TestCase {
        assertEquals("Test Artist \u2468\u2460", metadata.get(XMPDM.ARTIST));
        assertEquals("Test Album \u2460\u2468", metadata.get(XMPDM.ALBUM));
 
-       // TODO Fix comments
-//       assertEquals("Comment Desc - This is a comment", metadata.get(XMPDM.LOG_COMMENT));
+       assertEquals(
+             "Eng - Comment Desc\nThis is a \u1357\u2468\u2460 Comment", 
+             metadata.get(XMPDM.LOG_COMMENT)
+       );
        
        assertEquals("MPEG 3 Layer III Version 1", metadata.get("version"));
        assertEquals("44100", metadata.get("samplerate"));

Commit:
554605b284b0c4ac32b8cdda512700d780915a8d
Nick Burch
nick@apache.org
2011-12-29 07:17:07 +0000
TIKA-793 Unit test for i18n MP3 tags (excluding comments)
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v2Frame.java b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v2Frame.java
index c11670ef1..68c9c57f5 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v2Frame.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v2Frame.java
@@ -192,7 +192,7 @@ public class ID3v2Frame implements MP3Frame {
         // Does it have an encoding flag?
         // Detect by the first byte being sub 0x20
         boolean doubleByte = false;
-        String encoding = "ISO-8859-1";
+        String encoding = "ISO8859_1";
         byte maybeEncodingFlag = data[offset];
         if (maybeEncodingFlag == 0 || maybeEncodingFlag == 1 ||
               maybeEncodingFlag == 2 || maybeEncodingFlag == 3) {
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/mp3/Mp3ParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/mp3/Mp3ParserTest.java
index ef7698f76..56949692d 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/mp3/Mp3ParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/mp3/Mp3ParserTest.java
@@ -185,6 +185,38 @@ public class Mp3ParserTest extends TestCase {
         assertEquals("2", metadata.get("channels"));
     }
     
+    /**
+     * Tests that a file with characters not in the ISO 8859-1
+     *  range is correctly handled
+     */
+    public void testMp3ParsingID3i18n() throws Exception {
+       Parser parser = new AutoDetectParser(); // Should auto-detect!
+       ContentHandler handler = new BodyContentHandler();
+       Metadata metadata = new Metadata();
+
+       InputStream stream = Mp3ParserTest.class.getResourceAsStream(
+               "/test-documents/testMP3i18n.mp3");
+       try {
+           parser.parse(stream, handler, metadata, new ParseContext());
+       } finally {
+           stream.close();
+       }
+
+       assertEquals("audio/mpeg", metadata.get(Metadata.CONTENT_TYPE));
+       assertEquals("Une chason en Fran\u00e7ais", metadata.get(Metadata.TITLE));
+       assertEquals("Test Artist \u2468\u2460", metadata.get(Metadata.AUTHOR));
+       assertEquals("Test Artist \u2468\u2460", metadata.get(XMPDM.ARTIST));
+       assertEquals("Test Album \u2460\u2468", metadata.get(XMPDM.ALBUM));
+
+       // TODO Fix comments
+//       assertEquals("Comment Desc - This is a comment", metadata.get(XMPDM.LOG_COMMENT));
+       
+       assertEquals("MPEG 3 Layer III Version 1", metadata.get("version"));
+       assertEquals("44100", metadata.get("samplerate"));
+       assertEquals("2", metadata.get("channels"));
+   }
+    
+    
     /**
      * Tests that a file with both lyrics and
      *  ID3v2 tags gets both extracted correctly

Commit:
5a1ebc75ec867a1d7d204239054e27198b88e2ce
Nick Burch
nick@apache.org
2011-12-29 06:59:08 +0000
TIKA-831 Start on a test for the ForkParser with a parser exception that isn't serializable (currently not working so disabled)
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/fork/ForkParserIntegrationTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/fork/ForkParserIntegrationTest.java
index 83ec4930e..b2b61af8a 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/fork/ForkParserIntegrationTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/fork/ForkParserIntegrationTest.java
@@ -26,7 +26,6 @@ import java.util.Set;
 import junit.framework.TestCase;
 
 import org.apache.tika.Tika;
-import org.apache.tika.config.TikaConfig;
 import org.apache.tika.detect.Detector;
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.fork.ForkParser;
@@ -99,16 +98,43 @@ public class ForkParserIntegrationTest extends TestCase {
         }
     }
     
+    /**
+     * This error isn't serializable on the server, so can't be sent back
+     *  to the Fork Client once it has occured
+     */
+    static class WontBeSerializedError extends RuntimeException {
+       private static final long serialVersionUID = 1L;
+
+       WontBeSerializedError(String message) {
+          super(message);
+       }
+
+       private void writeObject(java.io.ObjectOutputStream out) {
+          RuntimeException e = new RuntimeException("Bang!");
+          boolean found = false;
+          for (StackTraceElement ste : e.getStackTrace()) {
+             if (ste.getClassName().equals(ForkParser.class.getName())) {
+                found = true;
+             }
+          }
+          if (!found) {
+             throw e;
+          }
+       }
+    }
+    
     static class BrokenParser implements Parser {
         private static final long serialVersionUID = 995871497930817839L;
-        public Error e = new AnError("Simulated fail"); 
+        public Error err = new AnError("Simulated fail");
+        public RuntimeException re = null;
         
         public Set<MediaType> getSupportedTypes(ParseContext context) {
             return new HashSet<MediaType>(Arrays.asList(MediaType.TEXT_PLAIN));
         }
 
         public void parse(InputStream stream, ContentHandler handler, Metadata metadata, ParseContext context) throws IOException, SAXException, TikaException {
-            throw e;
+            if (re != null) throw re;
+            throw err;
         }
     }
     
@@ -120,14 +146,31 @@ public class ForkParserIntegrationTest extends TestCase {
         BrokenParser brokenParser = new BrokenParser();
         Parser parser = new ForkParser(ForkParser.class.getClassLoader(), brokenParser);
         InputStream stream = getClass().getResourceAsStream("/test-documents/testTXT.txt");
+        
+        // With a serializable error, we'll get that back
         try {
             ContentHandler output = new BodyContentHandler();
             ParseContext context = new ParseContext();
             parser.parse(stream, output, new Metadata(), context);
             fail("Expected TikaException caused by Error");
         } catch (TikaException e) {
-            assertEquals(brokenParser.e, e.getCause());
+            assertEquals(brokenParser.err, e.getCause());
         }
+        
+        // With a non serializable one, we'll get something else
+        // TODO Fix this test
+        brokenParser = new BrokenParser();
+        brokenParser.re= new WontBeSerializedError("Can't Serialize");
+        parser = new ForkParser(ForkParser.class.getClassLoader(), brokenParser);
+//        try {
+//           ContentHandler output = new BodyContentHandler();
+//           ParseContext context = new ParseContext();
+//           parser.parse(stream, output, new Metadata(), context);
+//           fail("Expected TikaException caused by Error");
+//       } catch (TikaException e) {
+//           assertEquals(TikaException.class, e.getCause().getClass());
+//           assertEquals("Bang!", e.getCause().getMessage());
+//       }
     }
     
     /**

Commit:
bc075703823e7250a7ad7db93ef58712133920f2
Nick Burch
nick@apache.org
2011-12-29 06:35:02 +0000
TIKA-830 Improved error message in the ForkParser if we are unable to serialize the parse objects
diff --git a/tika-core/src/main/java/org/apache/tika/fork/ForkClient.java b/tika-core/src/main/java/org/apache/tika/fork/ForkClient.java
index 77ae72b59..7b8a67bc1 100644
--- a/tika-core/src/main/java/org/apache/tika/fork/ForkClient.java
+++ b/tika-core/src/main/java/org/apache/tika/fork/ForkClient.java
@@ -22,6 +22,7 @@ import java.io.File;
 import java.io.FileOutputStream;
 import java.io.IOException;
 import java.io.InputStream;
+import java.io.NotSerializableException;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
@@ -29,6 +30,7 @@ import java.util.jar.JarEntry;
 import java.util.jar.JarOutputStream;
 import java.util.zip.ZipEntry;
 
+import org.apache.tika.exception.TikaException;
 import org.apache.tika.io.IOExceptionWithCause;
 import org.apache.tika.io.IOUtils;
 import org.xml.sax.ContentHandler;
@@ -50,7 +52,7 @@ class ForkClient {
     private final InputStream error;
 
     public ForkClient(ClassLoader loader, Object object, String java)
-            throws IOException {
+            throws IOException, TikaException {
         boolean ok = false;
         try {
             this.loader = loader;
@@ -100,7 +102,7 @@ class ForkClient {
 
 
     public synchronized Throwable call(String method, Object... args)
-            throws IOException {
+            throws IOException, TikaException {
         List<ForkResource> r = new ArrayList<ForkResource>(resources);
         output.writeByte(ForkServer.CALL);
         output.writeUTF(method);
@@ -119,7 +121,7 @@ class ForkClient {
      * @throws IOException if the object could not be serialized
      */
     private void sendObject(Object object, List<ForkResource> resources)
-            throws IOException {
+            throws IOException, TikaException {
         int n = resources.size();
         if (object instanceof InputStream) {
             resources.add(new InputStreamResource((InputStream) object));
@@ -132,7 +134,14 @@ class ForkClient {
             object = new ClassLoaderProxy(n);
         }
 
-        ForkObjectInputStream.sendObject(object, output);
+        try {
+           ForkObjectInputStream.sendObject(object, output);
+        } catch(NotSerializableException nse) {
+           // Build a more friendly error message for this
+           throw new TikaException(
+                 "Unable to serialize " + object.getClass().getSimpleName() +
+                 " to pass to the Forked Parser", nse);
+        }
 
         waitForResponse(resources);
     }
diff --git a/tika-core/src/main/java/org/apache/tika/fork/ForkParser.java b/tika-core/src/main/java/org/apache/tika/fork/ForkParser.java
index 8c91a892d..338842f76 100644
--- a/tika-core/src/main/java/org/apache/tika/fork/ForkParser.java
+++ b/tika-core/src/main/java/org/apache/tika/fork/ForkParser.java
@@ -130,7 +130,12 @@ public class ForkParser extends AbstractParser {
         try {
             t = client.call("parse", stream, handler, metadata, context);
             alive = true;
+        } catch (TikaException te) {
+            // Problem occurred on our side
+            alive = true;
+            throw te;
         } catch (IOException e) {
+            // Problem occurred on the other side
             throw new TikaException(
                     "Failed to communicate with a forked parser process."
                     + " The process has most likely crashed due to some error"
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/fork/ForkParserIntegrationTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/fork/ForkParserIntegrationTest.java
index bb7e981b2..83ec4930e 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/fork/ForkParserIntegrationTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/fork/ForkParserIntegrationTest.java
@@ -18,6 +18,7 @@ package org.apache.tika.parser.fork;
 
 import java.io.IOException;
 import java.io.InputStream;
+import java.io.NotSerializableException;
 import java.util.Arrays;
 import java.util.HashSet;
 import java.util.Set;
@@ -26,6 +27,7 @@ import junit.framework.TestCase;
 
 import org.apache.tika.Tika;
 import org.apache.tika.config.TikaConfig;
+import org.apache.tika.detect.Detector;
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.fork.ForkParser;
 import org.apache.tika.metadata.Metadata;
@@ -127,6 +129,38 @@ public class ForkParserIntegrationTest extends TestCase {
             assertEquals(brokenParser.e, e.getCause());
         }
     }
+    
+    /**
+     * If we supply a non serializable object on the ParseContext,
+     *  check we get a helpful exception back
+     */
+    public void testParserHandlingOfNonSerializable() throws Exception {
+       ForkParser parser = new ForkParser(
+             ForkParserIntegrationTest.class.getClassLoader(),
+             tika.getParser());
+       
+       ParseContext context = new ParseContext();
+       context.set(Detector.class, new Detector() {
+          public MediaType detect(InputStream input, Metadata metadata) {
+             return MediaType.OCTET_STREAM;
+          }
+       });
+
+       try {
+          ContentHandler output = new BodyContentHandler();
+          InputStream stream = ForkParserIntegrationTest.class.getResourceAsStream(
+              "/test-documents/testTXT.txt");
+          parser.parse(stream, output, new Metadata(), context);
+          fail("Should have blown up with a non serializable ParseContext");
+       } catch(TikaException e) {
+          // Check the right details
+          assertNotNull(e.getCause());
+          assertEquals(NotSerializableException.class, e.getCause().getClass());
+          assertEquals("Unable to serialize ParseContext to pass to the Forked Parser", e.getMessage());
+       } finally {
+          parser.close();
+       }
+    }
 
     /**
      * TIKA-808 - Ensure that parsing of our test PDFs work under

Commit:
b20beb604d191010793eded2398cba985312ca6a
Nick Burch
nick@apache.org
2011-12-28 05:31:10 +0000
TIKA-833 Mark some more Excel formatting tests as passing (with tweaks to match what actually gets stored)
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ExcelParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ExcelParserTest.java
index d95b3cf8d..790fac64e 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ExcelParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ExcelParserTest.java
@@ -107,24 +107,25 @@ public class ExcelParserTest extends TestCase {
             // Date Format: d-mmm-yy
             assertTrue(content.contains("17-May-07"));
 
+            // Date Format: m/d/yy
+            assertTrue(content.contains("10/3/09"));
+            
+            // Date/Time Format: m/d/yy h:mm
+            assertTrue(content.contains("1/19/08 4:35"));
+
+            
             // Below assertions represent outstanding formatting issues to be addressed
             // they are included to allow the issues to be progressed with the Apache POI
             // team - See TIKA-103.
 
             /*************************************************************************
-            // Date Format: m/d/yy
-            assertTrue(content.contains("03/10/2009"));
-
-            // Date/Time Format
-            assertTrue(content.contains("19/01/2008 04:35"));
-
             // Custom Number (0 "dollars and" .00 "cents")
             assertTrue(content.contains("19 dollars and .99 cents"));
 
             // Custom Number ("At" h:mm AM/PM "on" dddd mmmm d"," yyyy)
             assertTrue(content.contains("At 4:20 AM on Thursday May 17, 2007"));
 
-            // Fraction (2.5): # ?/?
+            // Fraction (2.5): # ?/?  (TODO Coming in POI 3.8 beta 6)
             assertTrue(content.contains("2 1 / 2"));
             **************************************************************************/
 

Commit:
a739ddde294161f50b42858f64ba06f9b9e33cfe
Nick Burch
nick@apache.org
2011-12-27 03:15:17 +0000
TIKA-793 Sample MP3 with UTF-16 text in the comments (others are all ISO8859-1 text)
diff --git a/tika-parsers/src/test/resources/test-documents/testMP3i18n.mp3 b/tika-parsers/src/test/resources/test-documents/testMP3i18n.mp3
new file mode 100644
index 000000000..0f253704e
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testMP3i18n.mp3 differ

Commit:
b93fc6f1b3e16e8f76dadb4d7a94a782879fe3ef
Nick Burch
nick@apache.org
2011-12-27 03:00:53 +0000
TIKA-793 Correct the null termination stripping in the ID3 tag code, when dealing with double byte encoded strings
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v2Frame.java b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v2Frame.java
index a126572c0..c11670ef1 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v2Frame.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/mp3/ID3v2Frame.java
@@ -182,15 +182,16 @@ public class ID3v2Frame implements MP3Frame {
      */
     protected static String getTagString(byte[] data, int offset, int length) {
         int actualLength = length;
-        while (actualLength > 0 && data[actualLength-1] == 0) {
-            actualLength--;
-        }
         if (actualLength == 0) {
             return "";
         }
+        if (actualLength == 1 && data[offset] == 0) {
+            return "";
+        }
 
         // Does it have an encoding flag?
         // Detect by the first byte being sub 0x20
+        boolean doubleByte = false;
         String encoding = "ISO-8859-1";
         byte maybeEncodingFlag = data[offset];
         if (maybeEncodingFlag == 0 || maybeEncodingFlag == 1 ||
@@ -200,15 +201,29 @@ public class ID3v2Frame implements MP3Frame {
             if (maybeEncodingFlag == 1) {
                 // With BOM
                 encoding = "UTF-16";
+                doubleByte = true;
             } else if (maybeEncodingFlag == 2) {
                 // Without BOM
                 encoding = "UTF-16BE";
+                doubleByte = true;
             } else if (maybeEncodingFlag == 3) {
                 encoding = "UTF8";
             }
         }
+        
+        // Trim off null termination / padding (as present) 
+        while (doubleByte && actualLength >= 2 && data[offset+actualLength-1] == 0 && data[offset+actualLength-2] == 0) {
+           actualLength -= 2;
+        } 
+        while (!doubleByte && actualLength >= 1 && data[offset+actualLength-1] == 0) {
+           actualLength--;
+        }
+        if (actualLength == 0) {
+           return "";
+        }
 
         try {
+            // Build the base string
             return new String(data, offset, actualLength, encoding);
         } catch (UnsupportedEncodingException e) {
             throw new RuntimeException(

Commit:
e2720e4736b830873d0abce69f3bd3e3798e527a
Nick Burch
nick@apache.org
2011-12-27 02:45:14 +0000
TIKA-831 Fix test warnings, and enable the last test (needs to not use the Tika facade)
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/fork/ForkParserIntegrationTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/fork/ForkParserIntegrationTest.java
index 865295e74..bb7e981b2 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/fork/ForkParserIntegrationTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/fork/ForkParserIntegrationTest.java
@@ -71,8 +71,8 @@ public class ForkParserIntegrationTest extends TestCase {
      * This error has a message and an equals() implementation as to be able 
      * to match it against the serialized version of itself.
      */
-    @SuppressWarnings("serial")
     static class AnError extends Error {
+        private static final long serialVersionUID = -6197267350768803348L;
         private String message;
         AnError(String message) {
             super(message);
@@ -98,7 +98,9 @@ public class ForkParserIntegrationTest extends TestCase {
     }
     
     static class BrokenParser implements Parser {
+        private static final long serialVersionUID = 995871497930817839L;
         public Error e = new AnError("Simulated fail"); 
+        
         public Set<MediaType> getSupportedTypes(ParseContext context) {
             return new HashSet<MediaType>(Arrays.asList(MediaType.TEXT_PLAIN));
         }
@@ -111,15 +113,15 @@ public class ForkParserIntegrationTest extends TestCase {
     /**
      * TIKA-831 Parsers throwing errors should be caught and
      *  properly reported
-     * TODO Disabled, pending a fix for the not serialized exception
      */
-    public void DISABLEDtestParsingErrorInForkedParserShouldBeReported() throws Exception {
+    public void testParsingErrorInForkedParserShouldBeReported() throws Exception {
         BrokenParser brokenParser = new BrokenParser();
         Parser parser = new ForkParser(ForkParser.class.getClassLoader(), brokenParser);
-        Tika forkedTika = new Tika(TikaConfig.getDefaultConfig().getDetector(), parser);
         InputStream stream = getClass().getResourceAsStream("/test-documents/testTXT.txt");
         try {
-            forkedTika.parseToString(stream);
+            ContentHandler output = new BodyContentHandler();
+            ParseContext context = new ParseContext();
+            parser.parse(stream, output, new Metadata(), context);
             fail("Expected TikaException caused by Error");
         } catch (TikaException e) {
             assertEquals(brokenParser.e, e.getCause());

Commit:
a90b827bcbed21bb8a149cebdfdd483b3a20d7fe
Nick Burch
nick@apache.org
2011-12-27 02:44:28 +0000
TIKA-827 Handle sending non serializable exceptions back from the ForkServer
diff --git a/tika-core/src/main/java/org/apache/tika/fork/ForkServer.java b/tika-core/src/main/java/org/apache/tika/fork/ForkServer.java
index 96049e91a..baeae203d 100644
--- a/tika-core/src/main/java/org/apache/tika/fork/ForkServer.java
+++ b/tika-core/src/main/java/org/apache/tika/fork/ForkServer.java
@@ -21,6 +21,7 @@ import java.io.DataInputStream;
 import java.io.DataOutputStream;
 import java.io.IOException;
 import java.io.InputStream;
+import java.io.NotSerializableException;
 import java.io.OutputStream;
 import java.lang.reflect.InvocationTargetException;
 import java.lang.reflect.Method;
@@ -29,6 +30,8 @@ import java.util.zip.CheckedInputStream;
 import java.util.zip.CheckedOutputStream;
 import java.util.zip.Checksum;
 
+import org.apache.tika.exception.TikaException;
+
 class ForkServer implements Runnable, Checksum {
 
     public static final byte ERROR = -1;
@@ -137,7 +140,17 @@ class ForkServer implements Runnable, Checksum {
             output.write(DONE);
         } catch (InvocationTargetException e) {
             output.write(ERROR);
-            ForkObjectInputStream.sendObject(e.getCause(), output);
+            
+            // Try to send the underlying Exception itself
+            Throwable toSend = e.getCause();
+            try {
+               ForkObjectInputStream.sendObject(toSend, output);
+            } catch (NotSerializableException nse) {
+               // Need to build a serializable version of it
+               TikaException te = new TikaException( toSend.getMessage() );
+               te.setStackTrace( toSend.getStackTrace() );
+               ForkObjectInputStream.sendObject(te, output);
+            }
         }
     }
 

Commit:
915be4f4fb999a79ea1f3f90b3a2637ea086ae26
Nick Burch
nick@apache.org
2011-12-26 12:51:47 +0000
TIKA-831 Fix the data type when comparing errors from the forked server, and add some more Forked unit tests (one disabled) - patch originally from Jerome Lacoste
diff --git a/tika-core/src/main/java/org/apache/tika/fork/ForkClient.java b/tika-core/src/main/java/org/apache/tika/fork/ForkClient.java
index 0980ed5f8..77ae72b59 100644
--- a/tika-core/src/main/java/org/apache/tika/fork/ForkClient.java
+++ b/tika-core/src/main/java/org/apache/tika/fork/ForkClient.java
@@ -172,7 +172,7 @@ class ForkClient {
                 ForkResource resource =
                     resources.get(input.readUnsignedByte());
                 resource.process(input, output);
-            } else if (type == ForkServer.ERROR) {
+            } else if ((byte) type == ForkServer.ERROR) {
                 try {
                     return (Throwable) ForkObjectInputStream.readObject(
                             input, loader);
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/fork/ForkParserIntegrationTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/fork/ForkParserIntegrationTest.java
index a99573994..865295e74 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/fork/ForkParserIntegrationTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/fork/ForkParserIntegrationTest.java
@@ -16,28 +16,38 @@
  */
 package org.apache.tika.parser.fork;
 
+import java.io.IOException;
 import java.io.InputStream;
+import java.util.Arrays;
+import java.util.HashSet;
+import java.util.Set;
 
 import junit.framework.TestCase;
 
 import org.apache.tika.Tika;
+import org.apache.tika.config.TikaConfig;
+import org.apache.tika.exception.TikaException;
 import org.apache.tika.fork.ForkParser;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.mime.MediaType;
 import org.apache.tika.parser.ParseContext;
+import org.apache.tika.parser.Parser;
 import org.apache.tika.sax.BodyContentHandler;
 import org.xml.sax.ContentHandler;
+import org.xml.sax.SAXException;
 
 /**
  * Test that the ForkParser correctly behaves when
  *  wired in to the regular Parsers and their test data
  */
 public class ForkParserIntegrationTest extends TestCase {
-
+//    private TikaConfig tika = TikaConfig.getDefaultConfig();
+    private Tika tika = new Tika(); // TODO Use TikaConfig instead, when it works
+    
     /**
      * Simple text parsing
      */
     public void testForkedTextParsing() throws Exception {
-        Tika tika = new Tika();
         ForkParser parser = new ForkParser(
                 ForkParserIntegrationTest.class.getClassLoader(),
                 tika.getParser());
@@ -57,12 +67,70 @@ public class ForkParserIntegrationTest extends TestCase {
        }
     }
    
+    /**
+     * This error has a message and an equals() implementation as to be able 
+     * to match it against the serialized version of itself.
+     */
+    @SuppressWarnings("serial")
+    static class AnError extends Error {
+        private String message;
+        AnError(String message) {
+            super(message);
+            this.message = message;
+        }
+
+        @Override
+        public boolean equals(Object o) {
+            if (this == o) return true;
+            if (o == null || getClass() != o.getClass()) return false;
+
+            AnError anError = (AnError) o;
+
+            if (!message.equals(anError.message)) return false;
+
+            return true;
+        }
+
+        @Override
+        public int hashCode() {
+            return message.hashCode();
+        }
+    }
+    
+    static class BrokenParser implements Parser {
+        public Error e = new AnError("Simulated fail"); 
+        public Set<MediaType> getSupportedTypes(ParseContext context) {
+            return new HashSet<MediaType>(Arrays.asList(MediaType.TEXT_PLAIN));
+        }
+
+        public void parse(InputStream stream, ContentHandler handler, Metadata metadata, ParseContext context) throws IOException, SAXException, TikaException {
+            throw e;
+        }
+    }
+    
+    /**
+     * TIKA-831 Parsers throwing errors should be caught and
+     *  properly reported
+     * TODO Disabled, pending a fix for the not serialized exception
+     */
+    public void DISABLEDtestParsingErrorInForkedParserShouldBeReported() throws Exception {
+        BrokenParser brokenParser = new BrokenParser();
+        Parser parser = new ForkParser(ForkParser.class.getClassLoader(), brokenParser);
+        Tika forkedTika = new Tika(TikaConfig.getDefaultConfig().getDetector(), parser);
+        InputStream stream = getClass().getResourceAsStream("/test-documents/testTXT.txt");
+        try {
+            forkedTika.parseToString(stream);
+            fail("Expected TikaException caused by Error");
+        } catch (TikaException e) {
+            assertEquals(brokenParser.e, e.getCause());
+        }
+    }
+
     /**
      * TIKA-808 - Ensure that parsing of our test PDFs work under
      * the Fork Parser, to ensure that complex parsing behaves
      */
     public void testForkedPDFParsing() throws Exception {
-        Tika tika = new Tika();
         ForkParser parser = new ForkParser(
                 ForkParserIntegrationTest.class.getClassLoader(),
                 tika.getParser());
@@ -82,5 +150,4 @@ public class ForkParserIntegrationTest extends TestCase {
             parser.close();
         }
     }
-
 }

Commit:
dd8480f92b6a7750cb65ce2eb95c9d2fe8b9b988
Nick Burch
nick@apache.org
2011-12-26 04:04:54 +0000
TIKA-829 Validate inputs to the ForkParser constructor (must not be another ForkParser) and TikaInputStream get (must not be null) - patch from Jerome Lacoste
diff --git a/tika-core/src/main/java/org/apache/tika/fork/ForkParser.java b/tika-core/src/main/java/org/apache/tika/fork/ForkParser.java
index b8d1adc82..8c91a892d 100644
--- a/tika-core/src/main/java/org/apache/tika/fork/ForkParser.java
+++ b/tika-core/src/main/java/org/apache/tika/fork/ForkParser.java
@@ -52,7 +52,14 @@ public class ForkParser extends AbstractParser {
     private final Queue<ForkClient> pool =
         new LinkedList<ForkClient>();
 
+    /**
+     * @param loader The ClassLoader to use 
+     * @param parser the parser to delegate to. This one cannot be another ForkParser
+     */
     public ForkParser(ClassLoader loader, Parser parser) {
+        if (parser instanceof ForkParser) {
+            throw new IllegalArgumentException("The underlying parser of a ForkParser should not be a ForkParser, but a specific implementation.");
+        }
         this.loader = loader;
         this.parser = parser;
     }
@@ -112,6 +119,10 @@ public class ForkParser extends AbstractParser {
             InputStream stream, ContentHandler handler,
             Metadata metadata, ParseContext context)
             throws IOException, SAXException, TikaException {
+        if (stream == null) {
+            throw new NullPointerException("null stream");
+        }
+
         Throwable t;
 
         boolean alive = false;
diff --git a/tika-core/src/main/java/org/apache/tika/io/TikaInputStream.java b/tika-core/src/main/java/org/apache/tika/io/TikaInputStream.java
index 1f064aabe..a254908ff 100644
--- a/tika-core/src/main/java/org/apache/tika/io/TikaInputStream.java
+++ b/tika-core/src/main/java/org/apache/tika/io/TikaInputStream.java
@@ -105,6 +105,9 @@ public class TikaInputStream extends TaggedInputStream {
      */
     public static TikaInputStream get(
             InputStream stream, TemporaryResources tmp) {
+        if (stream == null) {
+            throw new NullPointerException("The Stream must not be null");
+        }
         if (stream instanceof TikaInputStream) {
             return (TikaInputStream) stream;
         } else {

Commit:
0ee593533742bbb6feda9c4f0591163cf22bef20
Jukka Zitting
jukka@apache.org
2011-12-23 23:33:19 +0000
TIKA-808: Fork Parser doesn't work for PDF files
diff --git a/tika-parent/pom.xml b/tika-parent/pom.xml
index 5702653fc..1fe698741 100644
--- a/tika-parent/pom.xml
+++ b/tika-parent/pom.xml
@@ -294,7 +294,7 @@
             <artifactId>maven-surefire-plugin</artifactId>
             <configuration>
               <excludes>
-                <exclude>**/ForkParserTest.java</exclude>
+                <exclude>**/ForkParser*Test.java</exclude>
               </excludes>
             </configuration>
           </plugin>
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/fork/ForkParserIntegrationTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/fork/ForkParserIntegrationTest.java
index 1d06c7cfe..a99573994 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/fork/ForkParserIntegrationTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/fork/ForkParserIntegrationTest.java
@@ -20,6 +20,7 @@ import java.io.InputStream;
 
 import junit.framework.TestCase;
 
+import org.apache.tika.Tika;
 import org.apache.tika.fork.ForkParser;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.parser.ParseContext;
@@ -31,24 +32,26 @@ import org.xml.sax.ContentHandler;
  *  wired in to the regular Parsers and their test data
  */
 public class ForkParserIntegrationTest extends TestCase {
+
     /**
      * Simple text parsing
-     * TODO Fix this test so it passes
      */
-    public void DISABLEDtestForkedTextParsing() throws Exception {
-       final ForkParser parser = new ForkParser(
-             ForkParserIntegrationTest.class.getClassLoader(),
-             new ForkParser());
+    public void testForkedTextParsing() throws Exception {
+        Tika tika = new Tika();
+        ForkParser parser = new ForkParser(
+                ForkParserIntegrationTest.class.getClassLoader(),
+                tika.getParser());
 
        try {
           ContentHandler output = new BodyContentHandler();
-          InputStream stream = ForkParserIntegrationTest.class.getResourceAsStream("testTXT.txt");
+          InputStream stream = ForkParserIntegrationTest.class.getResourceAsStream(
+                  "/test-documents/testTXT.txt");
           ParseContext context = new ParseContext();
           parser.parse(stream, output, new Metadata(), context);
 
           String content = output.toString();
           assertTrue(content.contains("Test d'indexation"));
-          assertTrue(content.contains("http://www.apache.org/"));
+          assertTrue(content.contains("http://www.apache.org"));
        } finally {
           parser.close();
        }
@@ -56,31 +59,28 @@ public class ForkParserIntegrationTest extends TestCase {
    
     /**
      * TIKA-808 - Ensure that parsing of our test PDFs work under
-     *  the Fork Parser, to ensure that complex parsing behaves
-     * TODO Fix this test so it passes
+     * the Fork Parser, to ensure that complex parsing behaves
      */
-    public void DISABLEDtestForkedPDFParsing() throws Exception {
-       final ForkParser parser = new ForkParser(
-             ForkParserIntegrationTest.class.getClassLoader(),
-             new ForkParser());
-       
-       try {
-          ContentHandler output = new BodyContentHandler();
-          InputStream stream = ForkParserIntegrationTest.class.getResourceAsStream("testPDF.pdf");
-          ParseContext context = new ParseContext();
-          parser.parse(stream, output, new Metadata(), context);
-          
-          String content = output.toString();
-          assertTrue(content.contains("Apache Tika"));
-          assertTrue(content.contains("Tika - Content Analysis Toolkit"));
-          assertTrue(content.contains("incubator"));
-          assertTrue(content.contains("Apache Software Foundation"));
-      } finally {
-          parser.close();
-      }
-    }
-    
-    public void testDUMMY() {
-       // To avoid warnings about no tests while others are disabled
+    public void testForkedPDFParsing() throws Exception {
+        Tika tika = new Tika();
+        ForkParser parser = new ForkParser(
+                ForkParserIntegrationTest.class.getClassLoader(),
+                tika.getParser());
+        try {
+            ContentHandler output = new BodyContentHandler();
+            InputStream stream = ForkParserIntegrationTest.class.getResourceAsStream(
+                    "/test-documents/testPDF.pdf");
+            ParseContext context = new ParseContext();
+            parser.parse(stream, output, new Metadata(), context);
+
+            String content = output.toString();
+            assertTrue(content.contains("Apache Tika"));
+            assertTrue(content.contains("Tika - Content Analysis Toolkit"));
+            assertTrue(content.contains("incubator"));
+            assertTrue(content.contains("Apache Software Foundation"));
+        } finally {
+            parser.close();
+        }
     }
+
 }

Commit:
486d767688ce4c93c9e90ede0b27459cebfa5233
Jukka Zitting
jukka@apache.org
2011-12-23 23:30:07 +0000
TIKA-808: Fork Parser doesn't work for PDF files
diff --git a/tika-core/src/main/java/org/apache/tika/fork/ForkClient.java b/tika-core/src/main/java/org/apache/tika/fork/ForkClient.java
index 9aabd5766..0980ed5f8 100644
--- a/tika-core/src/main/java/org/apache/tika/fork/ForkClient.java
+++ b/tika-core/src/main/java/org/apache/tika/fork/ForkClient.java
@@ -246,8 +246,10 @@ class ForkClient {
             Class<?>[] bootstrap = {
                     ForkServer.class, ForkObjectInputStream.class,
                     ForkProxy.class, ClassLoaderProxy.class,
-                    MemoryURLConnection.class, MemoryURLStreamHandler.class,
-                    MemoryURLStreamHandlerFactory.class
+                    MemoryURLConnection.class,
+                    MemoryURLStreamHandler.class,
+                    MemoryURLStreamHandlerFactory.class,
+                    MemoryURLStreamRecord.class
             };
             ClassLoader loader = ForkServer.class.getClassLoader();
             for (Class<?> klass : bootstrap) {
diff --git a/tika-core/src/main/java/org/apache/tika/fork/MemoryURLStreamHandler.java b/tika-core/src/main/java/org/apache/tika/fork/MemoryURLStreamHandler.java
index 27366a9c6..8c1572707 100644
--- a/tika-core/src/main/java/org/apache/tika/fork/MemoryURLStreamHandler.java
+++ b/tika-core/src/main/java/org/apache/tika/fork/MemoryURLStreamHandler.java
@@ -31,19 +31,15 @@ class MemoryURLStreamHandler extends URLStreamHandler {
 
     private static final AtomicInteger counter = new AtomicInteger();
 
-    private static class Record {
-        public WeakReference<URL> url;
-        public byte[] data;
-    }
-
-    private static final List<Record> records = new LinkedList<Record>();
+    private static final List<MemoryURLStreamRecord> records =
+        new LinkedList<MemoryURLStreamRecord>();
 
     public static URL createURL(byte[] data) {
         try {
             int i = counter.incrementAndGet();
             URL url =  new URL("tika-in-memory", "localhost", "/" + i);
 
-            Record record = new Record();
+            MemoryURLStreamRecord record = new MemoryURLStreamRecord();
             record.url = new WeakReference<URL>(url);
             record.data = data;
             records.add(record);
@@ -56,9 +52,9 @@ class MemoryURLStreamHandler extends URLStreamHandler {
 
     @Override
     protected URLConnection openConnection(URL u) throws IOException {
-        Iterator<Record> iterator = records.iterator();
+        Iterator<MemoryURLStreamRecord> iterator = records.iterator();
         while (iterator.hasNext()) {
-            Record record = iterator.next();
+            MemoryURLStreamRecord record = iterator.next();
             URL url = record.url.get();
             if (url == null) {
                 iterator.remove();
diff --git a/tika-core/src/main/java/org/apache/tika/fork/MemoryURLStreamRecord.java b/tika-core/src/main/java/org/apache/tika/fork/MemoryURLStreamRecord.java
new file mode 100644
index 000000000..8d1a50954
--- /dev/null
+++ b/tika-core/src/main/java/org/apache/tika/fork/MemoryURLStreamRecord.java
@@ -0,0 +1,27 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.fork;
+
+import java.lang.ref.WeakReference;
+import java.net.URL;
+
+class MemoryURLStreamRecord {
+
+    public WeakReference<URL> url;
+    public byte[] data;
+
+}
\ No newline at end of file

Commit:
edb6775bf356eaaf656730589cc3340a15b602ea
Jukka Zitting
jukka@apache.org
2011-12-23 22:50:28 +0000
TIKA-828: TaggedIOException can be passed non Serializable objects
diff --git a/tika-core/src/main/java/org/apache/tika/io/TaggedInputStream.java b/tika-core/src/main/java/org/apache/tika/io/TaggedInputStream.java
index f63e6118e..a5810a3fd 100644
--- a/tika-core/src/main/java/org/apache/tika/io/TaggedInputStream.java
+++ b/tika-core/src/main/java/org/apache/tika/io/TaggedInputStream.java
@@ -18,6 +18,8 @@ package org.apache.tika.io;
 
  import java.io.IOException;
 import java.io.InputStream;
+import java.io.Serializable;
+import java.util.UUID;
 
 /**
  * An input stream decorator that tags potential exceptions so that the
@@ -58,6 +60,11 @@ import java.io.InputStream;
  */
 public class TaggedInputStream extends ProxyInputStream {
 
+    /**
+     * The unique (serializable) tag of this stream.
+     */
+    private final Serializable tag = UUID.randomUUID();
+
     /**
      * Creates a tagging decorator for the given input stream.
      *
@@ -90,7 +97,7 @@ public class TaggedInputStream extends ProxyInputStream {
     public boolean isCauseOf(IOException exception) {
         if (exception instanceof TaggedIOException) {
             TaggedIOException tagged = (TaggedIOException) exception;
-            return this == tagged.getTag();
+            return tag.equals(tagged.getTag());
         } else {
             return false;
         }
@@ -109,7 +116,7 @@ public class TaggedInputStream extends ProxyInputStream {
     public void throwIfCauseOf(Exception exception) throws IOException {
         if (exception instanceof TaggedIOException) {
             TaggedIOException tagged = (TaggedIOException) exception;
-            if (this == tagged.getTag()) {
+            if (tag.equals(tagged.getTag())) {
                 throw tagged.getCause();
             }
         }
@@ -123,10 +130,10 @@ public class TaggedInputStream extends ProxyInputStream {
      */
     @Override
     protected void handleIOException(IOException e) throws IOException {
-        throw new TaggedIOException(e, this);
+        throw new TaggedIOException(e, tag);
     }
 
     public String toString() {
-        return "Tika Tagged InputStream wrapping " + in.toString(); 
+        return "Tika Tagged InputStream wrapping " + in;
     }
 }
diff --git a/tika-core/src/test/java/org/apache/tika/io/TaggedInputStreamTest.java b/tika-core/src/test/java/org/apache/tika/io/TaggedInputStreamTest.java
new file mode 100644
index 000000000..36e0e8366
--- /dev/null
+++ b/tika-core/src/test/java/org/apache/tika/io/TaggedInputStreamTest.java
@@ -0,0 +1,55 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.io;
+
+import org.junit.Test;
+
+import java.io.ByteArrayOutputStream;
+import java.io.IOException;
+import java.io.ObjectOutputStream;
+
+import static org.junit.Assert.fail;
+
+public class TaggedInputStreamTest {
+
+    @Test
+    public void createdIOExceptionIsSerializable() {
+        try {
+            new TaggedInputStream(null).handleIOException(new IOException("Dummy"));
+        } catch (IOException e) {
+            assertCanSerialize(e);
+        }
+    }
+
+    private static void assertCanSerialize(Object e) {
+        ByteArrayOutputStream out = new ByteArrayOutputStream();
+        ObjectOutputStream oos = null;
+        try {
+            oos = new ObjectOutputStream(out);
+            oos.writeObject(e);
+        } catch (IOException e1) {
+            fail(e1.getMessage());
+        } finally {
+            if (oos != null)
+                try {
+                    oos.close();
+                } catch (IOException ignore) {
+                }
+        }
+    }
+
+}
\ No newline at end of file

Commit:
57a99d012bc43d04ded8e7d88e056680542b405f
Antoni Mylka
amylka@apache.org
2011-12-21 11:58:55 +0000
TIKA-823 support for detecting StarOffice types, both in MimeTypes and POIFSContainerDetector
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index c252265a4..2c96313bb 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -1885,18 +1885,42 @@
   <mime-type type="application/vnd.sss-dtf"/>
   <mime-type type="application/vnd.sss-ntf"/>
   <mime-type type="application/vnd.stardivision.calc">
+    <sub-class-of type="application/x-tika-msoffice"/>
+    <magic priority="50">
+      <match value="0xd0cf11e0a1b11ae1" type="string" offset="0:8">
+         <match value="StarCalc" type="string" offset="2048:2207" />
+      </match>
+    </magic>
     <glob pattern="*.sdc"/>
   </mime-type>
   <mime-type type="application/vnd.stardivision.draw">
+    <sub-class-of type="application/x-tika-msoffice"/>
+    <magic priority="50">
+      <match value="0xd0cf11e0a1b11ae1" type="string" offset="0:8">
+         <match value="StarDraw" type="string" offset="2048:2207" />
+      </match>
+    </magic>
     <glob pattern="*.sda"/>
   </mime-type>
   <mime-type type="application/vnd.stardivision.impress">
+    <sub-class-of type="application/x-tika-msoffice"/>
+    <magic priority="50">
+      <match value="0xd0cf11e0a1b11ae1" type="string" offset="0:8">
+         <match value="StarImpress" type="string" offset="2048:2207" />
+      </match>
+    </magic>
     <glob pattern="*.sdd"/>
   </mime-type>
   <mime-type type="application/vnd.stardivision.math">
     <glob pattern="*.smf"/>
   </mime-type>
   <mime-type type="application/vnd.stardivision.writer">
+    <sub-class-of type="application/x-tika-msoffice"/>
+    <magic priority="50">
+      <match value="0xd0cf11e0a1b11ae1" type="string" offset="0:8">
+         <match value="StarWriter" type="string" offset="2048:2207" />
+      </match>
+    </magic>
     <glob pattern="*.sdw"/>
   </mime-type>
   <mime-type type="application/x-staroffice-template">
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java
index 1c20e9417..91dd41771 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java
@@ -117,7 +117,7 @@ public class OfficeParser extends AbstractParser {
             for (Entry entry : node) {
                 names.add(entry.getName());
             }
-            MediaType type = POIFSContainerDetector.detect(names);
+            MediaType type = POIFSContainerDetector.detect(names, node);
             for (POIFSDocumentType poifsType : values()) {
                if (type.equals(poifsType.type)) {
                   return poifsType;
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java
index d5dbbe6c0..fc65e5eb3 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java
@@ -26,10 +26,14 @@ import java.util.HashSet;
 import java.util.Set;
 import java.util.regex.Pattern;
 
+import org.apache.poi.poifs.filesystem.DirectoryEntry;
 import org.apache.poi.poifs.filesystem.DirectoryNode;
+import org.apache.poi.poifs.filesystem.DocumentInputStream;
+import org.apache.poi.poifs.filesystem.DocumentNode;
 import org.apache.poi.poifs.filesystem.Entry;
 import org.apache.poi.poifs.filesystem.NPOIFSFileSystem;
 import org.apache.tika.detect.Detector;
+import org.apache.tika.io.IOUtils;
 import org.apache.tika.io.TikaInputStream;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.mime.MediaType;
@@ -44,6 +48,16 @@ public class POIFSContainerDetector implements Detector {
 
     /** Serial version UID */
     private static final long serialVersionUID = -3028021741663605293L;
+    
+    /** An ASCII String "StarImpress" */
+    private static final byte [] STAR_IMPRESS = new byte [] {
+        0x53, 0x74, 0x61, 0x72, 0x49, 0x6d, 0x70, 0x72, 0x65, 0x73, 0x73
+    };
+    
+    /** An ASCII String "StarDraw" */
+    private static final byte [] STAR_DRAW = new byte [] {
+        0x53, 0x74, 0x61, 0x72, 0x44, 0x72, 0x61, 0x77
+    };
 
     /** The OLE base file format */
     public static final MediaType OLE = application("x-tika-msoffice");
@@ -80,6 +94,18 @@ public class POIFSContainerDetector implements Detector {
     
     /** Microsoft Project */
     public static final MediaType MPP = application("vnd.ms-project");
+    
+    /** StarOffice Calc */
+    public static final MediaType SDC = application("vnd.stardivision.calc");
+    
+    /** StarOffice Draw */
+    public static final MediaType SDA = application("vnd.stardivision.draw");
+    
+    /** StarOffice Impress */
+    public static final MediaType SDD = application("vnd.stardivision.impress");
+    
+    /** StarOffice Writer */
+    public static final MediaType SDW = application("vnd.stardivision.writer");
 
     /** Regexp for matching the MPP Project Data stream */
     private static final Pattern mppDataMatch = Pattern.compile("\\s\\s\\s\\d+");
@@ -127,16 +153,59 @@ public class POIFSContainerDetector implements Detector {
         }
         
         // Detect based on the names (as available)
-        return detect(names);
+        if (tis != null && 
+            tis.getOpenContainer() != null && 
+            tis.getOpenContainer() instanceof NPOIFSFileSystem) {
+            return detect(names, ((NPOIFSFileSystem)tis.getOpenContainer()).getRoot());
+        } else {
+            return detect(names, null);
+        }
     }
-    
+
     /**
-     * Internal detection of the specific kind of OLE2 document, based on the 
-     *  names of the top level streams within the file.
+     * Internal detection of the specific kind of OLE2 document, based on the
+     * names of the top level streams within the file.
+     * 
+     * @deprecated Use {@link #detect(Set, DirectoryEntry)} and pass the root
+     *             entry of the filesystem whose type is to be detected, as a
+     *             second argument.
      */
     protected static MediaType detect(Set<String> names) {
+        return detect(names, null);
+    }
+    
+    /**
+     * Internal detection of the specific kind of OLE2 document, based on the
+     * names of the top-level streams within the file. In some cases the
+     * detection may need access to the root {@link DirectoryEntry} of that file
+     * for best results. The entry can be given as a second, optional argument.
+     * 
+     * @param names
+     * @param root
+     * @return
+     */
+    protected static MediaType detect(Set<String> names, DirectoryEntry root) {
         if (names != null) {
-            if (names.contains("WksSSWorkBook")) {
+            if (names.contains("StarCalcDocument")) {
+                // Star Office Calc
+                return SDC;
+            } else if (names.contains("StarWriterDocument")) {
+                return SDW;
+            } else if (names.contains("StarDrawDocument3")) {
+                if (root == null) {
+                    /*
+                     * This is either StarOfficeDraw or StarOfficeImpress, we have
+                     * to consult the CompObj to distinguish them, if this method is
+                     * called in "legacy mode", without the root, just return
+                     * x-tika-msoffice. The one-argument method is only for backward
+                     * compatibility, if someone calls old API he/she can get the
+                     * old result.
+                     */
+                    return OLE;
+                } else {
+                    return processStarDrawOrImpress(root);
+                }
+            } else if (names.contains("WksSSWorkBook")) {
                 // This check has to be before names.contains("Workbook")
                 // Works 7.0 spreadsheet files contain both
                 // we want to avoid classifying this as Excel
@@ -165,8 +234,8 @@ public class POIFSContainerDetector implements Detector {
             } else if (names.contains("\u0001Ole10Native")) {
                 return OLE10_NATIVE;
             } else if (names.contains("MatOST")) {
-            	// this occurs on older Works Word Processor files (versions 3.0 and 4.0)
-            	return WPS;
+                // this occurs on older Works Word Processor files (versions 3.0 and 4.0)
+                return WPS;
             } else if (names.contains("CONTENTS") && names.contains("SPELLING")) {
                // Newer Works files
                return WPS;
@@ -207,6 +276,58 @@ public class POIFSContainerDetector implements Detector {
         return OLE;
     }
 
+    private static MediaType processStarDrawOrImpress(DirectoryEntry root) {
+        try {
+            Entry e = root.getEntry("\u0001CompObj");
+            if (e != null && e.isDocumentEntry()) {
+                DocumentNode dn = (DocumentNode)e;
+                DocumentInputStream stream = new DocumentInputStream(dn);
+                byte [] bytes = IOUtils.toByteArray(stream);
+                /*
+                 * This array contains a string with a normal ASCII name of the
+                 * application used to create this file. We want to search for that
+                 * name.
+                 */
+                if ( arrayContains(bytes, STAR_DRAW) ) {
+                    return SDA;
+                } else if (arrayContains(bytes, STAR_IMPRESS)) {
+                    return SDD;
+                }
+            } 
+        } catch (Exception e) {
+            /*
+             * "root.getEntry" can throw FileNotFoundException. The code inside
+             * "if" can throw IOExceptions. Theoretically. Practically no
+             * exceptions will likely ever appear.
+             * 
+             * Swallow all of them. If any occur, we just assume that we can't
+             * distinguish between Draw and Impress and return something safe:
+             * x-tika-msoffice
+             */
+        }
+        return OLE;
+    }
+    
+    // poor man's search for byte arrays, replace with some library call if
+    // you know one without adding new dependencies
+    private static boolean arrayContains(byte [] larger, byte [] smaller) {
+        int largerCounter = 0;
+        int smallerCounter = 0;
+        while (largerCounter < larger.length) {
+            if (larger[largerCounter] == smaller[smallerCounter]) {
+                largerCounter++;
+                smallerCounter++;
+                if (smallerCounter == smaller.length) {
+                    return true;
+                }
+            } else {
+                largerCounter = largerCounter - smallerCounter + 1;
+                smallerCounter=0;
+            }
+        }
+        return false;
+    }
+
     private static Set<String> getTopLevelNames(TikaInputStream stream)
             throws IOException {
         // Force the document stream to a (possibly temporary) file
diff --git a/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java b/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
index 13a6e46bb..511350845 100644
--- a/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
+++ b/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
@@ -41,6 +41,10 @@ public class TestContainerAwareDetector extends TestCase {
     private void assertTypeByNameAndData(String file, String type) throws Exception {
        assertTypeByNameAndData(file, file, type);
     }
+    private void assertType(String file, String byData, String byNameAndData) throws Exception {
+       assertTypeByData(file, byData);
+       assertTypeByNameAndData(file, byNameAndData);
+    }
     private void assertTypeByNameAndData(String dataFile, String name, String type) throws Exception {
        TikaInputStream stream = TikaInputStream.get(
                TestContainerAwareDetector.class.getResource(
@@ -71,8 +75,8 @@ public class TestContainerAwareDetector extends TestCase {
         assertTypeByData("testWORKS.wps", "application/vnd.ms-works");
         assertTypeByData("testWORKS2000.wps", "application/vnd.ms-works");
         // older Works Word Processor files can't be recognized
-    	// they were created with Works Word Processor 7.0 (hence the text inside)
-    	// and exported to the older formats with the "Save As" feature
+        // they were created with Works Word Processor 7.0 (hence the text inside)
+        // and exported to the older formats with the "Save As" feature
         assertTypeByData("testWORKSWordProcessor3.0.wps","application/vnd.ms-works");
         assertTypeByData("testWORKSWordProcessor4.0.wps","application/vnd.ms-works");
         assertTypeByData("testWORKSSpreadsheet7.0.xlr", "application/x-tika-msworks-spreadsheet");
@@ -99,6 +103,42 @@ public class TestContainerAwareDetector extends TestCase {
         assertTypeByNameAndData("testEXCEL.xls", "notPDF.pdf",  "application/vnd.ms-excel");
         assertTypeByNameAndData("testEXCEL.xls", "notPNG.png",  "application/vnd.ms-excel");
     }
+    
+    /**
+     * There is no way to distinguish "proper" StarOffice files from templates.
+     * All templates have the same extension but their actual type depends on
+     * the magic. Our current MimeTypes class doesn't allow us to use the same
+     * glob pattern in more than one mimetype.
+     * 
+     * @throws Exception
+     */
+    public void testDetectStarOfficeFiles() throws Exception {
+        assertType("testStarOffice-5.2-calc.sdc",
+                "application/vnd.stardivision.calc",
+                "application/vnd.stardivision.calc");
+        assertType("testVORCalcTemplate.vor",
+                "application/vnd.stardivision.calc",
+                "application/vnd.stardivision.calc");
+        assertType("testStarOffice-5.2-draw.sda",
+                "application/vnd.stardivision.draw",
+                "application/vnd.stardivision.draw");
+        assertType("testVORDrawTemplate.vor",
+                "application/vnd.stardivision.draw",
+                "application/vnd.stardivision.draw");
+        assertType("testStarOffice-5.2-impress.sdd",
+                "application/vnd.stardivision.impress",
+                "application/vnd.stardivision.impress");
+        assertType("testVORImpressTemplate.vor",
+                "application/vnd.stardivision.impress",
+                "application/vnd.stardivision.impress");
+        assertType("testStarOffice-5.2-writer.sdw",
+                "application/vnd.stardivision.writer",
+                "application/vnd.stardivision.writer");
+        assertType("testVORWriterTemplate.vor",
+                "application/vnd.stardivision.writer",
+                "application/vnd.stardivision.writer");
+
+    }
 
     public void testOpenContainer() throws Exception {
         TikaInputStream stream = TikaInputStream.get(
diff --git a/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java b/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
index 947ff53ce..6cbd17109 100644
--- a/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
+++ b/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
@@ -110,16 +110,6 @@ public class TestMimeTypes extends TestCase {
         assertTypeByName("application/vnd.ms-powerpoint.presentation.macroenabled.12", "x.pptm");
         assertTypeByName("application/vnd.ms-powerpoint.template.macroenabled.12", "x.potm");
         assertTypeByName("application/vnd.ms-powerpoint.slideshow.macroenabled.12", "x.ppsm");
-
-        assertTypeByName("application/x-staroffice-template", "x.vor");
-        assertTypeByData("application/x-tika-msoffice", "testVORCalcTemplate.vor");
-        assertTypeByData("application/x-tika-msoffice", "testVORDrawTemplate.vor");
-        assertTypeByData("application/x-tika-msoffice", "testVORImpressTemplate.vor");
-        assertTypeByData("application/x-tika-msoffice", "testVORWriterTemplate.vor");
-        assertTypeByNameAndData("application/x-staroffice-template", "testVORCalcTemplate.vor");
-        assertTypeByNameAndData("application/x-staroffice-template", "testVORDrawTemplate.vor");
-        assertTypeByNameAndData("application/x-staroffice-template", "testVORImpressTemplate.vor");
-        assertTypeByNameAndData("application/x-staroffice-template", "testVORWriterTemplate.vor");
     }
 
     /**
@@ -159,16 +149,52 @@ public class TestMimeTypes extends TestCase {
      * @throws Exception
      */
     public void testWorksSpreadsheetDetection() throws Exception {
-    	assertTypeDetection("testWORKSSpreadsheet7.0.xlr",
-    			// with name-only, everything should be all right 
-    			"application/x-tika-msworks-spreadsheet",
-    			// this is possible due to MimeTypes guessing the type
-    	        // based on the WksSSWorkBook near the beginning of the
-    	        // file
-    			"application/x-tika-msworks-spreadsheet",
-    			// this is right, the magic-based detection works, there is
-    	        // no need for the name-based detection to refine it
-    			"application/x-tika-msworks-spreadsheet");
+        assertTypeDetection("testWORKSSpreadsheet7.0.xlr",
+                // with name-only, everything should be all right 
+                "application/x-tika-msworks-spreadsheet",
+                // this is possible due to MimeTypes guessing the type
+                // based on the WksSSWorkBook near the beginning of the
+                // file
+                "application/x-tika-msworks-spreadsheet",
+                // this is right, the magic-based detection works, there is
+                // no need for the name-based detection to refine it
+                "application/x-tika-msworks-spreadsheet");
+    }
+    
+    public void testStarOfficeDetection() throws Exception {
+        assertTypeDetection("testVORCalcTemplate.vor",
+                "application/x-staroffice-template",
+                "application/vnd.stardivision.calc",
+                "application/vnd.stardivision.calc");
+        assertTypeDetection("testVORDrawTemplate.vor",
+                "application/x-staroffice-template",
+                "application/vnd.stardivision.draw",
+                "application/vnd.stardivision.draw");
+        assertTypeDetection("testVORImpressTemplate.vor",
+                "application/x-staroffice-template",
+                "application/vnd.stardivision.impress",
+                "application/vnd.stardivision.impress");
+        assertTypeDetection("testVORWriterTemplate.vor",
+                "application/x-staroffice-template",
+                "application/vnd.stardivision.writer",
+                "application/vnd.stardivision.writer");
+        
+        assertTypeDetection("testStarOffice-5.2-calc.sdc",
+                "application/vnd.stardivision.calc",
+                "application/vnd.stardivision.calc",
+                "application/vnd.stardivision.calc");
+        assertTypeDetection("testStarOffice-5.2-draw.sda",
+                "application/vnd.stardivision.draw",
+                "application/vnd.stardivision.draw",
+                "application/vnd.stardivision.draw");
+        assertTypeDetection("testStarOffice-5.2-impress.sdd",
+                "application/vnd.stardivision.impress",
+                "application/vnd.stardivision.impress",
+                "application/vnd.stardivision.impress");
+        assertTypeDetection("testStarOffice-5.2-writer.sdw",
+                "application/vnd.stardivision.writer",
+                "application/vnd.stardivision.writer",
+                "application/vnd.stardivision.writer");
     }
     
     /**
@@ -178,21 +204,21 @@ public class TestMimeTypes extends TestCase {
      * @throws Exception
      */
     public void testOldWorksWordProcessorDetection() throws Exception {
-    	assertTypeDetection(
-    			"testWORKSWordProcessor3.0.wps",
-    			// .wps is just like any other works extension
-    			"application/vnd.ms-works",
-    			// this is due to MatOST substring
-    			"application/vnd.ms-works",
-    			// magic-based detection works, no need to refine it
-    			"application/vnd.ms-works");
-    	
-    	// files in version 4.0 are no different from those in version 3.0
-    	assertTypeDetection(
-    			"testWORKSWordProcessor4.0.wps",
-    			"application/vnd.ms-works",
-    			"application/vnd.ms-works",
-    			"application/vnd.ms-works");
+        assertTypeDetection(
+                "testWORKSWordProcessor3.0.wps",
+                // .wps is just like any other works extension
+                "application/vnd.ms-works",
+                // this is due to MatOST substring
+                "application/vnd.ms-works",
+                // magic-based detection works, no need to refine it
+                "application/vnd.ms-works");
+        
+        // files in version 4.0 are no different from those in version 3.0
+        assertTypeDetection(
+                "testWORKSWordProcessor4.0.wps",
+                "application/vnd.ms-works",
+                "application/vnd.ms-works",
+                "application/vnd.ms-works");
     }
     
     /**
@@ -596,14 +622,14 @@ public class TestMimeTypes extends TestCase {
     }
     
     private void assertTypeDetection(String filename, String byName, String byData, 
-    		String byNameAndData) throws IOException {
-    	assertTypeByName(byName, filename);
-    	assertTypeByData(byData, filename);
-    	assertTypeByNameAndData(byNameAndData, filename);
+            String byNameAndData) throws IOException {
+        assertTypeByName(byName, filename);
+        assertTypeByData(byData, filename);
+        assertTypeByNameAndData(byNameAndData, filename);
     }
     
     private void assertTypeByNameAndData(String expected, String filename)
-	    throws IOException {
+        throws IOException {
        assertEquals(expected, getTypeByNameAndData(filename).toString());
     }
     private MediaType getTypeByNameAndData(String filename) throws IOException {
diff --git a/tika-parsers/src/test/resources/test-documents/testStarOffice-5.2-calc.sdc b/tika-parsers/src/test/resources/test-documents/testStarOffice-5.2-calc.sdc
new file mode 100644
index 000000000..6390f5094
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testStarOffice-5.2-calc.sdc differ
diff --git a/tika-parsers/src/test/resources/test-documents/testStarOffice-5.2-draw.sda b/tika-parsers/src/test/resources/test-documents/testStarOffice-5.2-draw.sda
new file mode 100644
index 000000000..dc69b4ac0
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testStarOffice-5.2-draw.sda differ
diff --git a/tika-parsers/src/test/resources/test-documents/testStarOffice-5.2-impress.sdd b/tika-parsers/src/test/resources/test-documents/testStarOffice-5.2-impress.sdd
new file mode 100644
index 000000000..eed858415
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testStarOffice-5.2-impress.sdd differ
diff --git a/tika-parsers/src/test/resources/test-documents/testStarOffice-5.2-writer.sdw b/tika-parsers/src/test/resources/test-documents/testStarOffice-5.2-writer.sdw
new file mode 100644
index 000000000..49b0c7028
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testStarOffice-5.2-writer.sdw differ

Commit:
48b28a6d31c3afb741ffa5ace4c0c4738101b539
Nick Burch
nick@apache.org
2011-12-21 03:03:17 +0000
TIKA-822 - Handle quoted parameters on media types
diff --git a/tika-core/src/main/java/org/apache/tika/mime/MediaType.java b/tika-core/src/main/java/org/apache/tika/mime/MediaType.java
index bca232b31..b1116e7eb 100644
--- a/tika-core/src/main/java/org/apache/tika/mime/MediaType.java
+++ b/tika-core/src/main/java/org/apache/tika/mime/MediaType.java
@@ -17,10 +17,8 @@
 package org.apache.tika.mime;
 
 import java.io.Serializable;
-import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
-import java.util.List;
 import java.util.Locale;
 import java.util.Map;
 import java.util.SortedMap;
@@ -163,6 +161,9 @@ public final class MediaType implements Comparable<MediaType>, Serializable {
             return Collections.<String, String>emptyMap();
         }
 
+        // Extracts k1=v1, k2=v2 from mime/type; k1=v1; k2=v2
+        // Note - this logic isn't fully RFC2045 compliant yet, as it
+        //  doesn't fully handle quoted keys or values (eg containing ; or =)
         Map<String, String> parameters = new HashMap<String, String>();
         while (string.length() > 0) {
             String key = string;
@@ -184,11 +185,22 @@ public final class MediaType implements Comparable<MediaType>, Serializable {
 
             key = key.trim();
             if (key.length() > 0) {
-                parameters.put(key, value.trim());
+                parameters.put(key, unquote(value.trim()));
             }
         }
         return parameters;
     }
+    
+    private static String unquote(String s) {
+        if( s.startsWith("\"") && s.endsWith("\"")) {
+            return s.substring(1, s.length() - 1);
+        }
+        if( s.startsWith("'") && s.endsWith("'")) {
+           return s.substring(1, s.length() - 1);
+       }
+
+        return s;
+    }
 
     /**
      * Canonical string representation of this media type.
diff --git a/tika-core/src/test/java/org/apache/tika/mime/MediaTypeTest.java b/tika-core/src/test/java/org/apache/tika/mime/MediaTypeTest.java
index f6194e0bf..3d7161793 100644
--- a/tika-core/src/test/java/org/apache/tika/mime/MediaTypeTest.java
+++ b/tika-core/src/test/java/org/apache/tika/mime/MediaTypeTest.java
@@ -21,6 +21,8 @@ import java.util.Map;
 
 import junit.framework.TestCase;
 
+import static java.util.Collections.singletonMap;
+
 public class MediaTypeTest extends TestCase {
 
     public void testBasics() {
@@ -131,6 +133,28 @@ public class MediaTypeTest extends TestCase {
         assertTrue(gotCharset && gotFoo && gotFoo2);
     }
 
+    /**
+     * Per http://tools.ietf.org/html/rfc2045#section-5.1, charset can be in quotes
+     */
+    public void testParseWithParamsAndQuotedCharset() {
+        // Typical case, with a quoted charset
+        String mimeStringWithParams = "text/html;charset=\"UTF-8\"";
+
+        MediaType type = MediaType.parse(mimeStringWithParams);
+        assertNotNull(type);
+        assertEquals(singletonMap("charset", "UTF-8"), type.getParameters());
+        
+        // Complex case, with various different quoted and un-quoted forms
+        mimeStringWithParams = "text/html;charset=\'UTF-8\';test=\"true\";unquoted=here";
+
+        type = MediaType.parse(mimeStringWithParams);
+        assertNotNull(type);
+        assertEquals(3, type.getParameters().size());
+        assertEquals("UTF-8", type.getParameters().get("charset"));
+        assertEquals("true", type.getParameters().get("test"));
+        assertEquals("here", type.getParameters().get("unquoted"));
+    }
+
     /**
      * @since TIKA-121
      */

Commit:
e3a183120a7638ccd2093f62a47730e9636ec047
Antoni Mylka
amylka@apache.org
2011-12-20 21:16:36 +0000
TIKA-812 Clarified the javadoc of the test method I introduced with ver2 of my patch. In ver2 I added a magic which allows pure MimeTypes to detect works-spreadsheet files, but forgot to update the javadoc for the text method. It was untrue. Now it's OK.
diff --git a/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java b/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
index 4546402c3..947ff53ce 100644
--- a/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
+++ b/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
@@ -153,17 +153,12 @@ public class TestMimeTypes extends TestCase {
     /**
      * Files generated by Works 7.0 Spreadsheet application use the OLE2
      * structure and resemble Excel files (they contain a "Workbook"). They are
-     * not Excel though. The {@link POIFSContainerDetector} can detect them
-     * properly. With plain {@link MimeTypes} they are detected as Excel,
-     * because of the "Workbook" string. It's a problem we discussed in TIKA-806
-     * and agreed that we live with that. The policy is that container-based
-     * detection should trump magic-based detection. It's implemented in
-     * {@link DefaultDetector} (TIKA-786) and users who don't want to use to
-     * {@link DefaultDetector} should be aware of it.
+     * not Excel though. They are distinguished from Excel files with an
+     * additional top-level entry in below the root of the POI filesystem.
      * 
      * @throws Exception
      */
-    public void testWorks70Detection() throws Exception {
+    public void testWorksSpreadsheetDetection() throws Exception {
     	assertTypeDetection("testWORKSSpreadsheet7.0.xlr",
     			// with name-only, everything should be all right 
     			"application/x-tika-msworks-spreadsheet",

Commit:
75d487d306d75995484f1d010ab7e712dd2026eb
Antoni Mylka
amylka@apache.org
2011-12-20 15:55:48 +0000
TIKA-821 Added support for detection of old MS Works Word Processor files
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 01cdcdb60..c252265a4 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -1355,6 +1355,11 @@
   </mime-type>
 
   <mime-type type="application/vnd.ms-works">
+    <magic priority="50">
+      <match value="0xd0cf11e0a1b11ae1" type="string" offset="0:8">
+         <match value="M\x00a\x00t\x00O\x00S\x00T" type="string" offset="1152:4096" />
+      </match>
+    </magic>
     <glob pattern="*.wps"/>
     <glob pattern="*.wks"/>
     <glob pattern="*.wcm"/>
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java
index 2340875eb..d5dbbe6c0 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java
@@ -164,6 +164,9 @@ public class POIFSContainerDetector implements Detector {
                 return VSD;
             } else if (names.contains("\u0001Ole10Native")) {
                 return OLE10_NATIVE;
+            } else if (names.contains("MatOST")) {
+            	// this occurs on older Works Word Processor files (versions 3.0 and 4.0)
+            	return WPS;
             } else if (names.contains("CONTENTS") && names.contains("SPELLING")) {
                // Newer Works files
                return WPS;
diff --git a/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java b/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
index 19b54c5f1..13a6e46bb 100644
--- a/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
+++ b/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
@@ -70,6 +70,11 @@ public class TestContainerAwareDetector extends TestCase {
         assertTypeByData("testPUBLISHER.pub", "application/x-mspublisher");
         assertTypeByData("testWORKS.wps", "application/vnd.ms-works");
         assertTypeByData("testWORKS2000.wps", "application/vnd.ms-works");
+        // older Works Word Processor files can't be recognized
+    	// they were created with Works Word Processor 7.0 (hence the text inside)
+    	// and exported to the older formats with the "Save As" feature
+        assertTypeByData("testWORKSWordProcessor3.0.wps","application/vnd.ms-works");
+        assertTypeByData("testWORKSWordProcessor4.0.wps","application/vnd.ms-works");
         assertTypeByData("testWORKSSpreadsheet7.0.xlr", "application/x-tika-msworks-spreadsheet");
         assertTypeByData("testPROJECT2003.mpp", "application/vnd.ms-project");
         assertTypeByData("testPROJECT2007.mpp", "application/vnd.ms-project");
@@ -79,6 +84,7 @@ public class TestContainerAwareDetector extends TestCase {
         assertTypeByData("testQUATTRO.qpw", "application/x-quattro-pro");
         assertTypeByData("testQUATTRO.wb3", "application/x-quattro-pro");
         
+        
         // With the filename and data
         assertTypeByNameAndData("testEXCEL.xls", "application/vnd.ms-excel");
         assertTypeByNameAndData("testWORD.doc", "application/msword");
diff --git a/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java b/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
index b525a90b7..4546402c3 100644
--- a/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
+++ b/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
@@ -164,19 +164,40 @@ public class TestMimeTypes extends TestCase {
      * @throws Exception
      */
     public void testWorks70Detection() throws Exception {
-        // this is possible due to MimeTypes guessing the type
-        // based on the WksSSWorkBook near the beginning of the
-        // file
-        assertTypeByData("application/x-tika-msworks-spreadsheet",
-                "testWORKSSpreadsheet7.0.xlr");
-        
-        // this is right, we made x-xlr a subtype of vnd.ms-excel
-        assertTypeByNameAndData("application/x-tika-msworks-spreadsheet",
-                "testWORKSSpreadsheet7.0.xlr");
-        
-        // with name-only, everything should be all right
-        assertTypeByName("application/x-tika-msworks-spreadsheet", 
-                "testWORKSSpreadsheet7.0.xlr");
+    	assertTypeDetection("testWORKSSpreadsheet7.0.xlr",
+    			// with name-only, everything should be all right 
+    			"application/x-tika-msworks-spreadsheet",
+    			// this is possible due to MimeTypes guessing the type
+    	        // based on the WksSSWorkBook near the beginning of the
+    	        // file
+    			"application/x-tika-msworks-spreadsheet",
+    			// this is right, the magic-based detection works, there is
+    	        // no need for the name-based detection to refine it
+    			"application/x-tika-msworks-spreadsheet");
+    }
+    
+    /**
+     * Files generated by Works Word Processor versions 3.0 and 4.0 use the
+     * OLE2 structure. They don't resemble Word though.
+     * 
+     * @throws Exception
+     */
+    public void testOldWorksWordProcessorDetection() throws Exception {
+    	assertTypeDetection(
+    			"testWORKSWordProcessor3.0.wps",
+    			// .wps is just like any other works extension
+    			"application/vnd.ms-works",
+    			// this is due to MatOST substring
+    			"application/vnd.ms-works",
+    			// magic-based detection works, no need to refine it
+    			"application/vnd.ms-works");
+    	
+    	// files in version 4.0 are no different from those in version 3.0
+    	assertTypeDetection(
+    			"testWORKSWordProcessor4.0.wps",
+    			"application/vnd.ms-works",
+    			"application/vnd.ms-works",
+    			"application/vnd.ms-works");
     }
     
     /**
@@ -579,6 +600,13 @@ public class TestMimeTypes extends TestCase {
        }
     }
     
+    private void assertTypeDetection(String filename, String byName, String byData, 
+    		String byNameAndData) throws IOException {
+    	assertTypeByName(byName, filename);
+    	assertTypeByData(byData, filename);
+    	assertTypeByNameAndData(byNameAndData, filename);
+    }
+    
     private void assertTypeByNameAndData(String expected, String filename)
 	    throws IOException {
        assertEquals(expected, getTypeByNameAndData(filename).toString());
diff --git a/tika-parsers/src/test/resources/test-documents/testWORKSWordProcessor3.0.wps b/tika-parsers/src/test/resources/test-documents/testWORKSWordProcessor3.0.wps
new file mode 100644
index 000000000..4324affe2
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testWORKSWordProcessor3.0.wps differ
diff --git a/tika-parsers/src/test/resources/test-documents/testWORKSWordProcessor4.0.wps b/tika-parsers/src/test/resources/test-documents/testWORKSWordProcessor4.0.wps
new file mode 100644
index 000000000..3e28e47b8
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testWORKSWordProcessor4.0.wps differ

Commit:
3d6dbb3e6e567eac8191e408b3de47413301da94
Nick Burch
nick@apache.org
2011-12-20 06:44:38 +0000
TIKA-816 The Excel (XLS) Parser should format numeric formula cell values, and handle string formula cell values
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ExcelExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ExcelExtractor.java
index bb8314c53..1fa83a0e3 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ExcelExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ExcelExtractor.java
@@ -51,6 +51,7 @@ import org.apache.poi.hssf.record.NumberRecord;
 import org.apache.poi.hssf.record.RKRecord;
 import org.apache.poi.hssf.record.Record;
 import org.apache.poi.hssf.record.SSTRecord;
+import org.apache.poi.hssf.record.StringRecord;
 import org.apache.poi.hssf.record.TextObjectRecord;
 import org.apache.poi.hssf.record.chart.SeriesTextRecord;
 import org.apache.poi.hssf.record.common.UnicodeString;
@@ -181,6 +182,7 @@ public class ExcelExtractor extends AbstractPOIFSExtractor {
         private Exception exception = null;
 
         private SSTRecord sstRecord;
+        private FormulaRecord stringFormulaRecord;
         
         private short previousSid;
 
@@ -274,6 +276,7 @@ public class ExcelExtractor extends AbstractPOIFSExtractor {
                 hssfRequest.addListener(formatListener, LabelSSTRecord.sid);
                 hssfRequest.addListener(formatListener, NumberRecord.sid);
                 hssfRequest.addListener(formatListener, RKRecord.sid);
+                hssfRequest.addListener(formatListener, StringRecord.sid);
                 hssfRequest.addListener(formatListener, HyperlinkRecord.sid);
                 hssfRequest.addListener(formatListener, TextObjectRecord.sid);
                 hssfRequest.addListener(formatListener, SeriesTextRecord.sid);
@@ -375,7 +378,22 @@ public class ExcelExtractor extends AbstractPOIFSExtractor {
 
             case FormulaRecord.sid: // Cell value from a formula
                 FormulaRecord formula = (FormulaRecord) record;
-                addCell(record, new NumberCell(formula.getValue(), format));
+                if (formula.hasCachedResultString()) {
+                   // The String itself should be the next record
+                   stringFormulaRecord = formula;
+                } else {
+                   addTextCell(record, formatListener.formatNumberDateCell(formula));
+                }
+                break;
+                
+            case StringRecord.sid:
+                if (previousSid == FormulaRecord.sid) {
+                   // Cached string value of a string formula
+                   StringRecord sr = (StringRecord) record;
+                   addTextCell(stringFormulaRecord, sr.getString());
+                } else {
+                   // Some other string not associated with a cell, skip
+                }
                 break;
 
             case LabelRecord.sid: // strings stored directly in the cell
@@ -435,6 +453,10 @@ public class ExcelExtractor extends AbstractPOIFSExtractor {
             }
 
             previousSid = record.getSid();
+            
+            if (stringFormulaRecord != record) {
+               stringFormulaRecord = null;
+            }
         }
 
         private void processExtraText() throws SAXException {

Commit:
03e6113c9ea555bf93b9ce064a2c0d1cd8073cc5
Nick Burch
nick@apache.org
2011-12-20 06:22:10 +0000
TIKA-705 / TIKA-757 - Simplify the OOXML related parts code, following POI upgrade
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/AbstractOOXMLExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/AbstractOOXMLExtractor.java
index d93010548..8070537fc 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/AbstractOOXMLExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/AbstractOOXMLExtractor.java
@@ -18,8 +18,6 @@ package org.apache.tika.parser.microsoft.ooxml;
 
 import java.io.FileNotFoundException;
 import java.io.IOException;
-import java.net.URI;
-import java.net.URISyntaxException;
 import java.util.List;
 
 import org.apache.poi.POIXMLDocument;
@@ -27,7 +25,6 @@ import org.apache.poi.POIXMLTextExtractor;
 import org.apache.poi.openxml4j.exceptions.InvalidFormatException;
 import org.apache.poi.openxml4j.opc.PackagePart;
 import org.apache.poi.openxml4j.opc.PackageRelationship;
-import org.apache.poi.openxml4j.opc.PackagingURIHelper;
 import org.apache.poi.openxml4j.opc.TargetMode;
 import org.apache.poi.poifs.filesystem.DirectoryNode;
 import org.apache.poi.poifs.filesystem.Ole10Native;
@@ -121,21 +118,7 @@ public abstract class AbstractOOXMLExtractor implements OOXMLExtractor {
             for (PackagePart source : getMainDocumentParts()) {
                 for (PackageRelationship rel : source.getRelationships()) {
                     if (rel.getTargetMode() == TargetMode.INTERNAL) {
-                        // TODO Simply this when on POI 3.8 beta 5
-                        URI uri = rel.getTargetURI();
-                        if(uri.getFragment() != null) {
-                           // TODO Workaround for TIKA-705 needed until 3.8 beta 5
-                           try {
-                              String u = uri.toString();
-                              uri = new URI(u.substring(0, u.indexOf('#')));
-                           } catch(URISyntaxException e) {
-                              throw new TikaException("Broken OOXML file", e);
-                           }
-                        }
-                        PackagePart target = rel.getPackage().getPart(
-                                PackagingURIHelper.createPartName(uri));
-                        // TODO Simpler version in POI 3.8 beta 5
-                        // PackagePart target = source.getRelatedPart(rel);
+                        PackagePart target = source.getRelatedPart(rel);
 
                         String type = rel.getRelationshipType();
                         if (RELATION_OLE_OBJECT.equals(type)

Commit:
b21fa6a110ccf987e1c46980b0d7db5d869bedfe
Nick Burch
nick@apache.org
2011-12-20 06:15:29 +0000
TIKA-757 Tidy the OLE10Native extractor code now that POI has been upgraded
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/AbstractPOIFSExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/AbstractPOIFSExtractor.java
index 764ea2ce2..9707ae592 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/AbstractPOIFSExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/AbstractPOIFSExtractor.java
@@ -16,16 +16,15 @@
  */
 package org.apache.tika.parser.microsoft;
 
-import java.io.ByteArrayOutputStream;
 import java.io.IOException;
 
 import org.apache.poi.poifs.filesystem.DirectoryEntry;
+import org.apache.poi.poifs.filesystem.DirectoryNode;
 import org.apache.poi.poifs.filesystem.DocumentEntry;
 import org.apache.poi.poifs.filesystem.DocumentInputStream;
 import org.apache.poi.poifs.filesystem.Entry;
 import org.apache.poi.poifs.filesystem.Ole10Native;
 import org.apache.poi.poifs.filesystem.Ole10NativeException;
-import org.apache.poi.util.IOUtils;
 import org.apache.tika.exception.TikaException;
 import org.apache.tika.extractor.EmbeddedDocumentExtractor;
 import org.apache.tika.extractor.ParsingEmbeddedDocumentExtractor;
@@ -107,24 +106,16 @@ abstract class AbstractPOIFSExtractor {
 
         try {
             if (type == POIFSDocumentType.OLE10_NATIVE) {
-                Entry entry = dir.getEntry(Ole10Native.OLE10_NATIVE);
-                ByteArrayOutputStream bos = new ByteArrayOutputStream();
-
-                // TODO: once we upgrade to POI 3.8 beta 5
-                // we can avoid this full copy/serialize by
-                // passing the DirectoryNode instead:
-                IOUtils.copy(new DocumentInputStream((DocumentEntry) entry), bos);
-                byte[] data = bos.toByteArray();
-
                 try {
-                    // Maybe unwrap OLE10Native record:
-                    Ole10Native ole = new Ole10Native(data, 0);
-                    data = ole.getDataBuffer();
+                    // Try to un-wrap the OLE10Native record:
+                    Ole10Native ole = Ole10Native.createFromEmbeddedOleObject((DirectoryNode)dir);
                     metadata.set(Metadata.RESOURCE_NAME_KEY, dir.getName() + '/' + ole.getLabel());
+                    
+                    byte[] data = ole.getDataBuffer();
+                    embedded = TikaInputStream.get(data);
                 } catch (Ole10NativeException ex) {
-                    // Not an OLE10Native record
+                    // Not a valid OLE10Native record, skip it
                 }
-                embedded = TikaInputStream.get(data);
             } else {
                 metadata.set(Metadata.CONTENT_TYPE, type.getType().toString());
                 metadata.set(Metadata.RESOURCE_NAME_KEY, dir.getName() + '.' + type.getExtension());

Commit:
ac13e8e051494a19d5a311fbbe8a5210fd7196e1
Nick Burch
nick@apache.org
2011-12-20 06:08:15 +0000
TIKA-757 Tidy the Word Extractor picture locating code
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/WordExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/WordExtractor.java
index 9ff57352d..bd3aeb86d 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/WordExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/WordExtractor.java
@@ -535,15 +535,10 @@ public class WordExtractor extends AbstractPOIFSExtractor {
           picturesTable = doc.getPicturesTable();
           all = picturesTable.getAllPictures();
           
-          // Compute the Offset-Picture lookup
+          // Build the Offset-Picture lookup map
           lookup = new HashMap<Integer, Picture>();
           for(Picture p : all) {
-             // TODO Make this nicer when POI 3.7 is out
-             String name = p.suggestFullFileName();
-             if(name.indexOf('.') > -1)
-                name = name.substring(0, name.indexOf('.'));
-             int offset = Integer.parseInt(name, 16);
-             lookup.put(offset, p);
+             lookup.put(p.getStartOffset(), p);
           }
           
           // Work out which Pictures aren't referenced by

Commit:
ce78a8197fd7275dfcfbf3f36c914fd04c37cbb6
Nick Burch
nick@apache.org
2011-12-20 06:04:51 +0000
TIKA-757 Tidy Excel extractor code after POI upgrade
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ExcelExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ExcelExtractor.java
index ccf2b688a..bb8314c53 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ExcelExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ExcelExtractor.java
@@ -28,9 +28,7 @@ import java.util.SortedMap;
 import java.util.TreeMap;
 
 import org.apache.poi.ddf.EscherBSERecord;
-import org.apache.poi.ddf.EscherBitmapBlip;
 import org.apache.poi.ddf.EscherBlipRecord;
-import org.apache.poi.ddf.EscherMetafileBlip;
 import org.apache.poi.ddf.EscherRecord;
 import org.apache.poi.hssf.eventusermodel.FormatTrackingHSSFListener;
 import org.apache.poi.hssf.eventusermodel.HSSFEventFactory;
@@ -56,6 +54,7 @@ import org.apache.poi.hssf.record.SSTRecord;
 import org.apache.poi.hssf.record.TextObjectRecord;
 import org.apache.poi.hssf.record.chart.SeriesTextRecord;
 import org.apache.poi.hssf.record.common.UnicodeString;
+import org.apache.poi.hssf.usermodel.HSSFPictureData;
 import org.apache.poi.poifs.filesystem.DirectoryEntry;
 import org.apache.poi.poifs.filesystem.DirectoryNode;
 import org.apache.poi.poifs.filesystem.DocumentInputStream;
@@ -550,37 +549,9 @@ public class ExcelExtractor extends AbstractPOIFSExtractor {
               if (escherRecord instanceof EscherBSERecord) {
                  EscherBlipRecord blip = ((EscherBSERecord) escherRecord).getBlipRecord();
                  if (blip != null) {
-                    // TODO When we have upgraded POI, we can use this code instead
-                    //HSSFPictureData picture = new HSSFPictureData(blip);
-                    //String mimeType = picture.getMimeType();
-                    //TikaInputStream stream = TikaInputStream.get(picture.getData());
-                    
-                    // This code is cut'n'paste from a newer version of POI
-                    String mimeType = "";
-                    switch (blip.getRecordId()) {
-                    case EscherMetafileBlip.RECORD_ID_WMF:
-                       mimeType =  "image/x-wmf";
-                       break;
-                    case EscherMetafileBlip.RECORD_ID_EMF:
-                       mimeType =  "image/x-emf";
-                       break;
-                    case EscherMetafileBlip.RECORD_ID_PICT:
-                       mimeType =  "image/x-pict";
-                       break;
-                    case EscherBitmapBlip.RECORD_ID_PNG:
-                       mimeType =  "image/png";
-                       break;
-                    case EscherBitmapBlip.RECORD_ID_JPEG:
-                       mimeType =  "image/jpeg";
-                       break;
-                    case EscherBitmapBlip.RECORD_ID_DIB:
-                       mimeType =  "image/bmp";
-                       break;
-                    default:
-                       mimeType =  "image/unknown";
-                       break;
-                    }
-                    TikaInputStream stream = TikaInputStream.get(blip.getPicturedata());
+                    HSSFPictureData picture = new HSSFPictureData(blip);
+                    String mimeType = picture.getMimeType();
+                    TikaInputStream stream = TikaInputStream.get(picture.getData());
                     
                     // Handle the embeded resource
                     extractor.handleEmbeddedResource(

Commit:
60711a9496a6387c125f8138b3b34a799a3f4c94
Nick Burch
nick@apache.org
2011-12-20 05:59:57 +0000
TIKA-700 Upgrade to POI 3.8 beta 5
diff --git a/tika-parsers/pom.xml b/tika-parsers/pom.xml
index 14f31aa55..ba8df5684 100644
--- a/tika-parsers/pom.xml
+++ b/tika-parsers/pom.xml
@@ -35,7 +35,7 @@
   <url>http://tika.apache.org/</url>
 
   <properties>
-    <poi.version>3.8-beta4</poi.version>
+    <poi.version>3.8-beta5</poi.version>
     <codec.version>1.5</codec.version> <!-- NOTE: sync with POI -->
     <mime4j.version>0.7</mime4j.version>
   </properties>
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XSLFPowerPointExtractorDecorator.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XSLFPowerPointExtractorDecorator.java
index 193f6ff2c..3e14c966a 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XSLFPowerPointExtractorDecorator.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/ooxml/XSLFPowerPointExtractorDecorator.java
@@ -78,7 +78,7 @@ public class XSLFPowerPointExtractorDecorator extends AbstractOOXMLExtractor {
               continue;
            }
            
-            XSLFSlideMaster master = slide.getMasterSheet();
+            XSLFSlideMaster master = slide.getSlideMaster();
             CTNotesSlide notes = rawSlideShow.getNotes(slideId);
             CTCommentList comments = rawSlideShow.getSlideComments(slideId);
 
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/POIContainerExtractionTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/POIContainerExtractionTest.java
index 5b41b2dad..dae50c2de 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/POIContainerExtractionTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/POIContainerExtractionTest.java
@@ -169,23 +169,23 @@ public class POIContainerExtractionTest extends AbstractPOIContainerExtractionTe
        
        // Filenames are a bit iffy...
        // Should really be 3*embedded pictures then 3*icons then embedded docs
-       assertEquals("image1", handler.filenames.get(0));
+       assertEquals("image1.emf", handler.filenames.get(0));
        assertEquals("image4.png", handler.filenames.get(1));
        assertEquals("image5.jpg", handler.filenames.get(2));
        assertEquals("image6.png", handler.filenames.get(3));
-       assertEquals("image2", handler.filenames.get(4));
-       assertEquals("image3", handler.filenames.get(5));
+       assertEquals("image2.emf", handler.filenames.get(4));
+       assertEquals("image3.emf", handler.filenames.get(5));
        assertEquals(null, handler.filenames.get(6));
        assertEquals("_1345471035.ppt", handler.filenames.get(7));
        assertEquals("_1345470949.xls", handler.filenames.get(8));
        
        // But we do know their types
-       assertEquals(MediaType.parse("image/unknown"), handler.mediaTypes.get(0)); // Icon of embedded office doc?
+       assertEquals(TYPE_EMF, handler.mediaTypes.get(0)); // Icon of embedded office doc?
        assertEquals(TYPE_PNG, handler.mediaTypes.get(1)); // Embedded image - logo
        assertEquals(TYPE_JPG, handler.mediaTypes.get(2)); // Embedded image - safe
        assertEquals(TYPE_PNG, handler.mediaTypes.get(3)); // Embedded image - try
-       assertEquals(MediaType.parse("image/unknown"), handler.mediaTypes.get(4)); // Icon of embedded office doc?
-       assertEquals(MediaType.parse("image/unknown"), handler.mediaTypes.get(5)); // Icon of embedded office doc?
+       assertEquals(TYPE_EMF, handler.mediaTypes.get(4)); // Icon of embedded office doc?
+       assertEquals(TYPE_EMF, handler.mediaTypes.get(5)); // Icon of embedded office doc?
        assertEquals(TYPE_DOCX, handler.mediaTypes.get(6)); // Embedded office doc
        assertEquals(TYPE_PPT, handler.mediaTypes.get(7)); // Embedded office doc
        assertEquals(TYPE_XLS, handler.mediaTypes.get(8)); // Embedded office doc
@@ -197,12 +197,12 @@ public class POIContainerExtractionTest extends AbstractPOIContainerExtractionTe
        assertEquals(13, handler.mediaTypes.size());
        
        // We don't know their filenames, except for doc images + docx
-       assertEquals("image1", handler.filenames.get(0));
+       assertEquals("image1.emf", handler.filenames.get(0));
        assertEquals("image4.png", handler.filenames.get(1));
        assertEquals("image5.jpg", handler.filenames.get(2));
        assertEquals("image6.png", handler.filenames.get(3));
-       assertEquals("image2", handler.filenames.get(4));
-       assertEquals("image3", handler.filenames.get(5));
+       assertEquals("image2.emf", handler.filenames.get(4));
+       assertEquals("image3.emf", handler.filenames.get(5));
        assertEquals(null, handler.filenames.get(6));
        assertEquals("image2.png", handler.filenames.get(7));
        assertEquals("image3.jpeg", handler.filenames.get(8));
@@ -211,12 +211,12 @@ public class POIContainerExtractionTest extends AbstractPOIContainerExtractionTe
           assertNull(handler.filenames.get(i));
        }
        // But we do know their types
-       assertEquals(MediaType.parse("image/unknown"), handler.mediaTypes.get(0)); // Icon of embedded office doc?
+       assertEquals(TYPE_EMF, handler.mediaTypes.get(0)); // Icon of embedded office doc
        assertEquals(TYPE_PNG, handler.mediaTypes.get(1)); // Embedded image - logo
        assertEquals(TYPE_JPG, handler.mediaTypes.get(2)); // Embedded image - safe
        assertEquals(TYPE_PNG, handler.mediaTypes.get(3)); // Embedded image - try
-       assertEquals(MediaType.parse("image/unknown"), handler.mediaTypes.get(4)); // Icon of embedded office doc?
-       assertEquals(MediaType.parse("image/unknown"), handler.mediaTypes.get(5)); // Icon of embedded office doc?
+       assertEquals(TYPE_EMF, handler.mediaTypes.get(4)); // Icon of embedded office doc
+       assertEquals(TYPE_EMF, handler.mediaTypes.get(5)); // Icon of embedded office doc
        assertEquals(TYPE_DOCX, handler.mediaTypes.get(6)); // Embedded office doc
        assertEquals(TYPE_PNG, handler.mediaTypes.get(7));  //    PNG inside .docx
        assertEquals(TYPE_JPG, handler.mediaTypes.get(8));  //    JPG inside .docx

Commit:
853fea00ee10fc660470643162e430a5be555560
Antoni Mylka
amylka@apache.org
2011-12-19 11:36:33 +0000
TIKA-814 MimeTypes detects plain text based on a larger sample of bytes.
diff --git a/tika-core/src/main/java/org/apache/tika/detect/TextDetector.java b/tika-core/src/main/java/org/apache/tika/detect/TextDetector.java
index 74b7339db..31a1fa509 100644
--- a/tika-core/src/main/java/org/apache/tika/detect/TextDetector.java
+++ b/tika-core/src/main/java/org/apache/tika/detect/TextDetector.java
@@ -45,7 +45,7 @@ public class TextDetector implements Detector {
      * The number of bytes from the beginning of the document stream
      * to test for control bytes.
      */
-    private static final int NUMBER_OF_BYTES_TO_TEST = 512;
+    private static final int DEFAULT_NUMBER_OF_BYTES_TO_TEST = 512;
 
     /**
      * Lookup table for all the ASCII/ISO-Latin/UTF-8/etc. control bytes
@@ -81,6 +81,24 @@ public class TextDetector implements Detector {
         IS_CONTROL_BYTE[0x1B] = false; // escape
     }
 
+    private final int bytesToTest;
+    
+    /**
+     * Constructs a {@link TextDetector} which will look at the default number
+     * of bytes from the beginning of the document.
+     */
+    public TextDetector() {
+        this(DEFAULT_NUMBER_OF_BYTES_TO_TEST);
+    }
+
+    /**
+     * Constructs a {@link TextDetector} which will look at a given number of
+     * bytes from the beginning of the document.
+     */
+    public TextDetector(int bytesToTest) {
+        this.bytesToTest = bytesToTest;
+    }
+    
     /**
      * Looks at the beginning of the document input stream to determine
      * whether the document is text or not.
@@ -96,13 +114,13 @@ public class TextDetector implements Detector {
             return MediaType.OCTET_STREAM;
         }
 
-        input.mark(NUMBER_OF_BYTES_TO_TEST);
+        input.mark(bytesToTest);
         try {
             int chars = 0;
             int controls = 0;
             int asciis = 0;
             int ch = input.read();
-            while (ch != -1 && chars < NUMBER_OF_BYTES_TO_TEST) {
+            while (ch != -1 && chars < bytesToTest) {
                 if (ch < IS_CONTROL_BYTE.length && IS_CONTROL_BYTE[ch]) {
                     controls++;
                 } else if (ch < 127) {
diff --git a/tika-core/src/main/java/org/apache/tika/mime/MimeTypes.java b/tika-core/src/main/java/org/apache/tika/mime/MimeTypes.java
index 91d25e03f..cb7beb1ad 100644
--- a/tika-core/src/main/java/org/apache/tika/mime/MimeTypes.java
+++ b/tika-core/src/main/java/org/apache/tika/mime/MimeTypes.java
@@ -210,7 +210,7 @@ public final class MimeTypes implements Detector, Serializable {
 
         // Finally, assume plain text if no control bytes are found
         try {
-            TextDetector detector = new TextDetector();
+            TextDetector detector = new TextDetector(getMinLength());
             ByteArrayInputStream stream = new ByteArrayInputStream(data);
             return forName(detector.detect(stream, new Metadata()).toString());
         } catch (Exception e) {

Commit:
4bd426e403e806d1add41284de577431fe555a6e
Antoni Mylka
amylka@apache.org
2011-12-19 11:27:06 +0000
TIKA-813 Support for detection of Apple "bplist" files (Binary Property List) and webarchive files - a special case of bplists.
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index c4cb18ef8..01cdcdb60 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -2256,6 +2256,17 @@
     </magic>
     <glob pattern="*.torrent"/>
   </mime-type>
+  
+  <mime-type type="application/x-bplist">
+    <!-- The priority is 60, as .webarchive files often contain 
+         (X)HTML content. The bplist magic must trump the XHTML 
+         magics further within the file. This must also be 
+         independent of the internal ordering of patterns within 
+         MimeTypes -->
+    <magic priority="60">
+      <match value="bplist" type="string" offset="0"/>
+    </magic>
+  </mime-type>
 
   <mime-type type="application/x-bzip">
     <magic priority="40">
@@ -2814,6 +2825,10 @@
   <mime-type type="application/x-wais-source">
     <glob pattern="*.src"/>
   </mime-type>
+  <mime-type type="application/x-webarchive">
+    <sub-class-of type="application/x-bplist"/>
+    <glob pattern="*.webarchive"/>
+  </mime-type>
   <mime-type type="application/x-x509-ca-cert">
     <glob pattern="*.der"/>
     <glob pattern="*.crt"/>
diff --git a/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java b/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
index 0ea5609a8..b525a90b7 100644
--- a/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
+++ b/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
@@ -529,6 +529,12 @@ public class TestMimeTypes extends TestCase {
         assertType("application/x-msaccess", "testACCESS.mdb");
         assertType("application/x-font-ttf", "testTrueType.ttf");
     }
+    
+    public void testWebArchiveDetection() throws Exception {
+        assertTypeByName("application/x-webarchive","x.webarchive");
+        assertTypeByData("application/x-bplist","testWEBARCHIVE.webarchive");
+        assertTypeByNameAndData("application/x-webarchive", "testWEBARCHIVE.webarchive");
+    }
 
     private void assertType(String expected, String filename) throws Exception {
         InputStream stream = TestMimeTypes.class.getResourceAsStream(
diff --git a/tika-parsers/src/test/resources/test-documents/testWEBARCHIVE.webarchive b/tika-parsers/src/test/resources/test-documents/testWEBARCHIVE.webarchive
new file mode 100644
index 000000000..b78643a2f
--- /dev/null
+++ b/tika-parsers/src/test/resources/test-documents/testWEBARCHIVE.webarchive
@@ -0,0 +1,646 @@
+bplist00_WebMainResource_WebSubresources	
+_WebResourceData_WebResourceMIMEType_WebResourceTextEncodingName_WebResourceFrameName^WebResourceURLOP<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><!--
+  Licensed to the Apache Software Foundation (ASF) under one
+  or more contributor license agreements.  See the NOTICE file
+  distributed with this work for additional information
+  regarding copyright ownership.  The ASF licenses this file
+  to you under the Apache License, Version 2.0 (the
+  "License"); you may not use this file except in compliance
+  with the License.  You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+ 
+  Unless required by applicable law or agreed to in writing,
+  software distributed under the License is distributed on an
+  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+  KIND, either express or implied.  See the License for the
+  specific language governing permissions and limitations
+  under the License.
+--><html xmlns="http://www.w3.org/1999/xhtml"><head>
+    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
+    <title>Apache Tika - Apache Tika</title>
+    <style type="text/css" media="all">
+      @import url("./css/site.css");
+    </style>
+    <link rel="icon" type="image/png" href="./tikaNoText16.png">
+    <script type="text/javascript">
+      function selectProvider(form) {
+        provider = form.elements['searchProvider'].value;
+        if (provider == "any") {
+          if (Math.random() > 0.5) {
+            provider = "lucid";
+          } else {
+            provider = "sl";
+          }
+        }
+        if (provider == "lucid") {
+          form.action = "http://search.lucidimagination.com/p:tika";
+        } else if (provider == "sl") {
+          form.action = "http://search-lucene.com/tika";
+        }
+        days = 90;
+        date = new Date();
+        date.setTime(date.getTime() + (days * 24 * 60 * 60 * 1000));
+        expires = "; expires=" + date.toGMTString();
+        document.cookie = "searchProvider=" + provider + expires + "; path=/";
+      }
+      function initProvider() {
+        if (document.cookie.length>0) {
+          cStart=document.cookie.indexOf("searchProvider=");
+          if (cStart!=-1) {
+            cStart=cStart + "searchProvider=".length;
+            cEnd=document.cookie.indexOf(";", cStart);
+            if (cEnd==-1) {
+              cEnd=document.cookie.length;
+            }
+            provider = unescape(document.cookie.substring(cStart,cEnd));
+            document.forms['searchform'].elements['searchProvider'].value = provider;
+          }
+        }
+        document.forms['searchform'].elements['q'].focus();
+      }
+    </script>
+  </head>
+  <body onload="initProvider();">
+    <div id="body">
+      <div id="banner">
+        <a href="http://tika.apache.org" id="bannerLeft" title="Apache Tika"><img src="http://tika.apache.org/tika.png" alt="Apache Tika" width="292" height="100"></a>
+        <a href="http://www.apache.org/" id="bannerRight" title="The Apache Software Foundation"><img src="http://tika.apache.org/asf-logo.gif" alt="The Apache Software Foundation" width="387" height="100"></a>
+      </div>
+      <div id="content">
+        <!-- Licensed to the Apache Software Foundation (ASF) under one or more --><!-- contributor license agreements.  See the NOTICE file distributed with --><!-- this work for additional information regarding copyright ownership. --><!-- The ASF licenses this file to You under the Apache License, Version 2.0 --><!-- (the "License"); you may not use this file except in compliance with --><!-- the License.  You may obtain a copy of the License at --><!--  --><!-- http://www.apache.org/licenses/LICENSE-2.0 --><!--  --><!-- Unless required by applicable law or agreed to in writing, software --><!-- distributed under the License is distributed on an "AS IS" BASIS, --><!-- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. --><!-- See the License for the specific language governing permissions and --><!-- limitations under the License. --><div class="section"><h2>Apache Tika - a content analysis toolkit<a name="Apache_Tika_-_a_content_analysis_toolkit"></a></h2><p>The Apache Tika toolkit detects and extracts metadata and structured text content from various documents using existing parser libraries. You can find the latest release on the <a href="./download.html">download page</a>. See the <a href="./0.10/gettingstarted.html">Getting Started</a> guide for instructions on how to start using Tika.</p><p>Tika is a project of the <a class="externalLink" href="http://www.apache.org/">Apache Software Foundation</a>, and was formerly a subproject of <a class="externalLink" href="http://lucene.apache.org/">Apache Lucene</a>.</p></div><div class="section"><h2>Latest News<a name="Latest_News"></a></h2><dl><dt>7 November 2011: Apache Tika Release</dt><dd> Apache Tika 1.0 has been released, just in time for ApacheCon NA 2011! The 1.0 release of Tika removes all deprecated pre 1.0 API methods, makes several OSGi and Configuration improvements, and improves parsing in RTF, Word and PDF files. Tika no longer ships a retro-translated JDK 1.4 version of the library, so it's time to get on JDK 1.5 or higher to use Tika, so be on the look out. Have a look at the download page for more details. </dd><dt>7-11 November 2011 - Tika at US ApacheCon</dt><dd> ApacheCon NA is coming to Vancouver, British Columbia, at the Westin Bayshore, and Chris Mattmann will be giving a <a class="externalLink" href="http://na11.apachecon.com/talks/19391">talk</a> on the forthcoming 1.0 release of Tika as part of the <a class="externalLink" href="http://na11.apachecon.com/talk/by_track/1400">Content Technologies track</a> on Thursday November 10th, 2011. The talk will cover the history of Tika, its genesis, its inception as a top-level project, and where it's headed 1.0 and beyond. Come out and support Tika by attending the talk! </dd><dt>30 September 2011: Apache Tika Release</dt><dd> Apache Tika 0.10 has been released. This release includes new parser support for CHM files, bugfixes to RTF parsing, an improved GUI and more. Please see the download page for more details. </dd><dt>16 February 2011: Apache Tika Release</dt><dd> Apache Tika 0.9 has been released. This release includes several important bugfixes and new features. Please see the download page for more details. </dd><dt>12 November 2010: Apache Tika Release</dt><dd> Apache Tika 0.8 has been released. Please see the download page for more details. This is our first release as a TLP. We're excited!</dd><dt>1-5 November 2010 - Tika at US ApacheCon</dt><dd> ApacheCon NA is coming to Atlanta, Georgia, at the Westin Peachtree, and Tika is being repped as part of the <a class="externalLink" href="http://us.apachecon.com/c/acna2010/schedule/2010/11/05">Lucene and friends track</a> on Friday, November 5th, 2010. Chris Mattmann will give a talk on how Tika is being used at NASA and in the context of other projects in the Apache ecosystem.<p>Friday, Nov. 5th, 2010:</p><ul><li><a class="externalLink" href="http://us.apachecon.com/c/acna2010/sessions/538">Scientific data curation and processing with Apache Tika</a> - Chris Mattmann @ 9:00am</li></ul></dd><dt>April 2010: Tika Graduates to TLP</dt><dd> Apache Tika was voted into TLP status by a resolution submitted to the Apache Board. We are in the process of updating the site and moving things around. If you notice anything out of place, let us know.</dd><dt>April 2010: Apache Tika Release</dt><dd> Apache Tika 0.7 has been released. Please see the download page for more details.</dd><dt>January 2010: Apache Tika Release</dt><dd> Apache Tika 0.6 has been released. Please see the download page for more details.</dd><dt>November 2009: Apache Tika Release</dt><dd> Apache Tika 0.5 has been released. Please see the download page for more details.</dd><dt>14 August 2009 - Lucene at US ApacheCon</dt><dd> ApacheCon US is once again in the Bay Area and Lucene is coming along for the ride! The Lucene community has planned two full days of talks, plus a meetup and the usual bevy of training. With a well-balanced mix of first time and veteran ApacheCon speakers, the <a class="externalLink" href="http://www.us.apachecon.com/c/acus2009/schedule#lucene">Lucene track</a> at ApacheCon US promises to have something for everyone. Be sure not to miss:<p>Training:</p><ul><li><a class="externalLink" href="http://www.us.apachecon.com/c/acus2009/sessions/437">Lucene Boot Camp</a> - A two day training session, Nov. 2nd &amp; 3rd</li><li><a class="externalLink" href="http://www.us.apachecon.com/c/acus2009/sessions/375">Solr Day</a> - A one day training session, Nov. 2nd</li></ul><p>Thursday, Nov. 5th:</p><ul><li><a class="externalLink" href="http://www.us.apachecon.com/c/acus2009/sessions/428">Introduction to the Lucene Ecosystem</a> - Grant Ingersoll @ 9:00</li><li><a class="externalLink" href="http://www.us.apachecon.com/c/acus2009/sessions/461">Lucene Basics and New Features</a> - Michael Busch @ 10:00</li><li><a class="externalLink" href="http://www.us.apachecon.com/c/acus2009/sessions/331">Apache Solr: Out of the Box</a> - Chris Hostetter @ 14:00</li><li><a class="externalLink" href="http://www.us.apachecon.com/c/acus2009/sessions/427">Introduction to Nutch</a> - Andrzej Bialecki @ 15:00</li><li><a class="externalLink" href="http://www.us.apachecon.com/c/acus2009/sessions/430">Lucene and Solr Performance Tuning</a> - Mark Miller @ 16:30</li></ul><p>Friday, Nov. 6th:</p><ul><li><a class="externalLink" href="http://www.us.apachecon.com/c/acus2009/sessions/332">Implementing an Information Retrieval Framework for an Organizational Repository</a> - Sithu D Sudarsan @ 9:00</li><li><a class="externalLink" href="http://www.us.apachecon.com/c/acus2009/sessions/333">Apache Mahout - Going from raw data to Information</a> - Isabel Drost @ 10:00</li><li><a class="externalLink" href="http://www.us.apachecon.com/c/acus2009/sessions/334">MIME Magic with Apache Tika</a> - Jukka Zitting @ 11:30</li><li><a class="externalLink" href="http://www.us.apachecon.com/c/acus2009/sessions/335">Building Intelligent Search Applications with the Lucene Ecosystem</a> - Ted Dunning @ 14:00</li><li><a class="externalLink" href="http://www.us.apachecon.com/c/acus2009/sessions/462">Realtime Search</a> - Jason Rutherglen @ 15:00</li></ul></dd><dt>July 2009: Apache Tika Release</dt><dd> Apache Tika 0.4 has been released. Please see the download page for more details.</dd><dt>March 2009: Apache Tika Release</dt><dd> Apache Tika 0.3 has been released. Please see the download page for more details.</dd><dt>February 2009: Lucene at ApacheCon Europe 2009 in Amsterdam</dt><dd> Lucene will be extremely well represented at <a class="externalLink" href="http://www.eu.apachecon.com/c/aceu2009/">ApacheCon EU 2009</a> in Amsterdam, Netherlands this March 23-27, 2009:<ul><li><a class="externalLink" href="http://eu.apachecon.com/c/aceu2009/sessions/197">Lucene Boot Camp</a> - A two day training session, March 23 &amp; 24th</li><li><a class="externalLink" href="http://eu.apachecon.com/c/aceu2009/sessions/201">Solr Boot Camp</a> - A one day training session, March 24th</li><li><a class="externalLink" href="http://eu.apachecon.com/c/aceu2009/sessions/136">Introducing Apache Mahout</a> - Grant Ingersoll. March 25th @ 10:30</li><li><a class="externalLink" href="http://eu.apachecon.com/c/aceu2009/sessions/137">Lucene/Solr Case Studies</a> - Erik Hatcher. March 25th @ 11:30</li><li><a class="externalLink" href="http://eu.apachecon.com/c/aceu2009/sessions/138">Advanced Indexing Techniques with Apache Lucene</a> - Michael Busch. March 25th @ 14:00</li><li><a class="externalLink" href="http://eu.apachecon.com/c/aceu2009/sessions/251">Apache Solr - A Case Study</a> - Uri Boness. March 26th @ 17:30</li><li><a class="externalLink" href="http://eu.apachecon.com/c/aceu2009/sessions/250">Best of breed - httpd, forrest, solr and droids</a> - Thorsten Scherler. March 27th @ 17:30</li><li><a class="externalLink" href="http://eu.apachecon.com/c/aceu2009/sessions/165">Apache Droids - an intelligent standalone robot framework</a> - Thorsten Scherler. March 26th @ 15:00</li></ul></dd><dt>December 2008: Apache Tika Release</dt><dd> Apache Tika 0.2 has been released. Please see the download page for more details.</dd><dt>November 2008: User mailing list created</dt><dd> A new mailing list, tika-user@lucene.apache.org, has been created for discussion about the use of the Tika toolkit. You can subscribe this mailing list by sending a message to tika-user-subscribe@lucene.apache.org.</dd><dt>October 2008: Tika graduates to a Lucene subproject</dt><dd> Tika has graduated form the Incubator to become a subproject of Apache Lucene. The project infrastructure will be migrated from incubator.apache.org to lucene.apache.org.</dd><dt>October 2008: Apache Tika status report</dt><dd> Dave Meikle was just voted in as a new committer.<p>Paolo Mottadelli will present Tika at ApacheCon US.</p><p>Tika 0.2 should be released soon.</p><p>Usage documentation has been added to the website.</p></dd><dt>July 2008: Apache Tika status report</dt><dd> Tika community remains relatively small, with just a handful of active members<p>Work towards Tika 0.2 continues, Chris Mattman has volunteered to be the release manager</p></dd><dt>April 2008: Apache Tika status report</dt><dd> Niall Pemberton joined the project as a committer and PPMC member<p>The number of issues reported by external contributors is growing gradually.</p><p>There was a Fast Feather Talk on Tika in ApacheCon EU 2008</p><p>We have good contacts especially with Apache POI and PDFBox</p><p>We are working towards Tika 0.2</p><p>Metadata handling improvements are being discussed</p></dd><dt>January 2008: Apache Tika status report</dt><dd> No new committers since the last report, activity has been moderate but steady, leading to the 0.1 release.<p>Tika 0.1 (incubating) has just been released.</p><p>Chris Mattmann intends to use that release in Nutch, That's good progress towards Tika's goal of providing data extraction functionality to other projects.</p><p>A new Tika logo was created by Google Highly Open Participation student, hasn't been integrated yet.</p></dd><dt>December 27th, 2007: Tika 0.1-incubating Released!</dt><dd> Tika has made its first official release, titled 0.1-incubating. See the <a class="externalLink" href="http://www.apache.org/dist/incubator/tika/CHANGES-0.1-incubating.txt">CHANGES.txt</a> file for more information on the list of updates in this initial release. Thanks to all who contributed! You can download the official source tarball <a class="externalLink" href="http://www.apache.org/dyn/closer.cgi/incubator/tika">here</a>.</dd><dt>October 8th, 2007: Welcome Keith Bennett!</dt><dd> The Tika PPMC has <a class="externalLink" href="http://www.nabble.com/Please-welcome-Keith-Bennett-as-a-Tika-committer%21-tf4586151.html#a13107428">elected</a> Keith Bennett as our new committer. Welcome!</dd><dt>March 22nd, 2007: Apache Tika project started</dt><dd> The Apache Tika project was formally started when the <a class="externalLink" href="http://wiki.apache.org/incubator/TikaProposal">Tika proposal</a> was <a class="externalLink" href="http://mail-archives.apache.org/mod_mbox/incubator-general/200703.mbox/%3c510143ac0703221130p4341aa78vd6608c13ffc95a82@mail.gmail.com%3e">accepted</a> by the <a class="externalLink" href="http://incubator.apache.org/">Apache Incubator PMC</a>. </dd></dl></div>
+      </div>
+      <div id="sidebar">
+        <div id="navigation">
+                    <h5>Apache Tika</h5>
+            <ul>
+              
+    <li class="none">
+              <strong>Introduction</strong>
+        </li>
+              
+    <li class="none">
+                    <a href="download.html">Download</a>
+          </li>
+              
+    <li class="none">
+                    <a href="mail-lists.html">Mailing Lists</a>
+          </li>
+              
+    <li class="none">
+                    <a href="http://wiki.apache.org/tika/" class="externalLink">Tika Wiki</a>
+          </li>
+              
+    <li class="none">
+                    <a href="https://issues.apache.org/jira/browse/TIKA" class="externalLink">Issue Tracker</a>
+          </li>
+          </ul>
+              <h5>Documentation</h5>
+            <ul>
+              
+          
+                    
+                  
+                  
+                  
+                  
+                  
+              
+        <li class="expanded">
+                    <a href="1.0/index.html">Apache Tika 1.0</a>
+                  <ul>
+                  
+    <li class="none">
+                    <a href="1.0/gettingstarted.html">Getting Started</a>
+          </li>
+                  
+    <li class="none">
+                    <a href="1.0/formats.html">Supported Formats</a>
+          </li>
+                  
+    <li class="none">
+                    <a href="1.0/parser.html">Parser API</a>
+          </li>
+                  
+    <li class="none">
+                    <a href="1.0/parser_guide.html">Parser 5min Quick Start Guide</a>
+          </li>
+                  
+    <li class="none">
+                    <a href="1.0/detection.html">Content and Language Detection</a>
+          </li>
+                  
+    <li class="none">
+                    <a href="1.0/api/">API Documentation</a>
+          </li>
+              </ul>
+        </li>
+              
+                
+                    
+                  
+                  
+                  
+                  
+                  
+              
+        <li class="collapsed">
+                    <a href="0.10/index.html">Apache Tika 0.10</a>
+                </li>
+              
+                
+                    
+                  
+                  
+                  
+                  
+                  
+              
+        <li class="collapsed">
+                    <a href="0.9/index.html">Apache Tika 0.9</a>
+                </li>
+              
+                
+                    
+                  
+                  
+                  
+                  
+                  
+              
+        <li class="collapsed">
+                    <a href="0.8/index.html">Apache Tika 0.8</a>
+                </li>
+          </ul>
+              <h5>The Apache Software Foundation</h5>
+            <ul>
+              
+    <li class="none">
+                    <a href="http://www.apache.org/foundation/" class="externalLink">About</a>
+          </li>
+              
+    <li class="none">
+                    <a href="http://www.apache.org/licenses/" class="externalLink">License</a>
+          </li>
+              
+    <li class="none">
+                    <a href="http://www.apache.org/security/" class="externalLink">Security</a>
+          </li>
+              
+    <li class="none">
+                    <a href="http://www.apache.org/foundation/sponsorship.html" class="externalLink">Sponsorship</a>
+          </li>
+              
+    <li class="none">
+                    <a href="http://www.apache.org/foundation/thanks.html" class="externalLink">Thanks</a>
+          </li>
+          </ul>
+      
+          <div id="search">
+            <h5>Search with Apache Solr</h5>
+            <form action="http://search.lucidimagination.com/p:tika" method="get" id="searchform">
+              <input type="text" id="query" name="q">
+              <select name="searchProvider" id="searchProvider">
+                <option value="any">provider</option>
+                <option value="lucid">Lucid Find</option>
+                <option value="sl">Search-Lucene</option>
+              </select>
+              <input type="submit" id="submit" value="Search" name="Search" onclick="selectProvider(this.form)">
+            </form>
+          </div>
+
+          <div id="bookpromo">
+            <h5>Books about Tika</h5>
+            <p>
+              <a href="http://manning.com/mattmann/" title="Tika in Action"><img src="./mattmann_cover150.jpg" width="150" height="186"></a>
+            </p>
+          </div>
+        </div>
+      </div>
+      <div id="footer">
+        <p>
+          Copyright  2011
+          <a href="http://www.apache.org/">The Apache Software Foundation</a>.
+          Site powered by <a href="http://maven.apache.org/">Apache Maven</a>. 
+          Search powered by
+          <a href="http://www.lucidimagination.com">Lucid Imagination</a>
+          and <a href="http://sematext.com">Sematext</a>.
+          <br>
+          Apache Tika, Tika, Apache, the Apache feather logo, and the Apache
+          Tika project logo are trademarks of The Apache Software Foundation.
+        </p>
+      </div>
+    </div>
+  
+
+</body></html>Ytext/htmlUUTF-8P_http://tika.apache.org/$_WebResourceResponseO/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+body {
+    font-family: serif;
+    font-size: 13pt;
+    background-color: #eee;
+    margin: 0;
+    padding: 0;
+}
+
+#body {
+    width: 800px;
+    height: 100%;
+    margin: 20px auto;
+    left: auto;
+    right: auto;
+    background-color: white;
+    padding: 20px;
+    border: 1px solid #CCC;
+    -moz-border-radius: 15px;
+    border-radius: 15px;
+    -moz-box-shadow: 1ex 1ex 1ex #666;
+    -webkit-box-shadow: 1ex 1ex 1ex #666;
+    box-shadow: 5px 5px 5px #666;
+}
+
+#banner {
+    height: 100px;
+    padding-bottom: 1em;
+    border-bottom: 1px solid #eee;
+}
+
+#bannerLeft {
+    float: left;
+}
+
+#bannerRight {
+    float: right;
+}
+
+#content {
+    width: 600px;
+    float: left;
+    line-height: 1.3em;
+}
+
+#navigation {
+    width: 180px;
+    float: right;
+    font-size: 12px;
+}
+
+#navigation h5 {
+    font-size: 12px;
+    margin-bottom: 1ex;
+}
+
+#navigation ul {
+    margin: 0;
+    padding: 0;
+}
+
+#navigation li {
+    list-style-type: none;
+    list-style-position: inside;
+}
+
+#navigation li ul {
+    margin-left: 20px;
+}
+
+#navigation li.expanded {
+    list-style-type: disc;
+}
+
+#navigation li.collapsed {
+    list-style-type: circle;
+}
+
+#navigation strong {
+    font-weight: normal;
+}
+
+#navigation a {
+    text-decoration: none;
+}
+
+#navigation form {
+    text-align: right;
+}
+
+#query {
+    width: 100%;
+    border: 1px solid #eee;
+}
+
+#searchProvider, #submit {
+    width: 48%;
+}
+
+#bookpromo p {
+    text-align: center;
+}
+
+#footer {
+    clear: both;
+    border-top: 1px solid #eee;
+    font-size: 8pt;
+    color: gray;
+    text-align: center;
+}
+
+h1, h2, h3, h4, h5, h6 {
+    font-family: sans-serif;
+    color: #900;
+}
+
+li {
+    margin-top: 2px;
+}
+
+a:link {
+    color: #36a;
+}
+a:visited  {
+    color:#47a;
+}
+a:active, a:hover {
+    color:#69c;
+}
+a.externalLink {
+    background: url(../images/external.png) right center no-repeat;
+    padding-right: 18px;
+}
+
+img {
+    border: 0;
+}
+
+pre {
+    border: 1px solid #ccc;
+    background-color: #eee;
+    padding: 1ex;
+    overflow: auto;
+}
+
+/* From maven-theme.css */
+
+table.bodyTable th {
+  color: white;
+  background-color: #bbb;
+  text-align: left;
+  font-weight: bold;
+}
+
+table.bodyTable th, table.bodyTable td {
+  font-size: 1em;
+}
+
+table.bodyTable tr.a {
+  background-color: #ddd;
+}
+
+table.bodyTable tr.b {
+  background-color: #eee;
+}
+
+dt {
+  color: #900;
+  font-weight: bold;
+}
+dd {
+  margin-bottom: 1ex;
+}
+
+.errormark, .warningmark, .donemark, .infomark {
+  background: url(../images/icon_error_sml.gif) no-repeat;
+}
+
+.warningmark {
+  background-image: url(../images/icon_warning_sml.gif);
+}
+
+.donemark {
+  background-image: url(../images/icon_success_sml.gif);
+}
+
+.infomark {
+  background-image: url(../images/icon_info_sml.gif);
+}
+
+/* From maven-base.css */
+
+table {
+  padding:0px;
+  width: 100%;
+  margin-left: -2px;
+  margin-right: -2px;
+}
+acronym {
+  cursor: help;
+  border-bottom: 1px dotted #feb;
+}
+table.bodyTable th, table.bodyTable td {
+  padding: 2px 4px 2px 4px;
+  vertical-align: top;
+}
+
+Xtext/css_#http://tika.apache.org/css/site.cssObplist00noX$versionX$objectsY$archiverT$top ""()012NOPQRSTUVWXYZ[\]^_`abcdhiU$null	
+ !R$6S$10R$2R$7R$3S$11R$8V$classR$4R$9R$0R$5R$1  ! #$%&[NS.relativeWNS.base _#http://tika.apache.org/css/site.css*+,-Z$classnameX$classesUNSURL./UNSURLXNSObject#A63456BWNS.keysZNS.objects789:;<=>?@A	
+CDEFGHIJKLMTVaryVServerZConnection]Last-Modified\Content-Type]Accept-RangesTDate_Content-Encoding^Content-LengthZKeep-AliveTEtag_Accept-Encoding_:Apache/2.3.15-dev (Unix) mod_ssl/2.3.15-dev OpenSSL/1.0.0cZKeep-Alive_Sun, 31 Oct 2010 21:50:22 GMTXtext/cssUbytes_Tue, 13 Dec 2011 18:55:14 GMTTgzipT1418_timeout=5, max=100_"d1b503-eaa-493f0adabe380-gzip"*+ef_NSMutableDictionaryeg/\NSDictionary*+jk_NSHTTPURLResponselm/_NSHTTPURLResponse]NSURLResponse_NSKeyedArchiverpq_WebResourceResponse    # - 2 7 \ b }                               	"(+1:CELT_amoqsuwy{}.kv!%25:NRft             r              OPNG
+
+   IHDR      	   &   gAMA  7   tEXtSoftware Adobe ImageReadyqe<   PLTEuuu  P   tRNS @*   PIDATxb`&& @P6#@` X 2 d@ A3 (  * t    IENDB`Yimage/png_*http://tika.apache.org/images/external.pngOVbplist00fgX$versionX$objectsY$archiverT$top "()012JKLMNOPQRSTUVWXYZ[\`aU$null	
+ !R$6S$10R$2R$7R$3S$11R$8V$classR$4R$9R$0R$5R$1  #$%&[NS.relativeWNS.base _*http://tika.apache.org/images/external.png*+,-Z$classnameX$classesUNSURL./UNSURLXNSObject#A%3456@WNS.keysZNS.objects789:;<=>?	
+ABCDEFGHIVServerZConnection\Content-Type]Last-Modified]Accept-RangesTDate^Content-LengthZKeep-AliveTEtag_:Apache/2.3.15-dev (Unix) mod_ssl/2.3.15-dev OpenSSL/1.0.0cZKeep-AliveYimage/png_Tue, 24 Aug 2010 12:56:41 GMTUbytes_Tue, 13 Dec 2011 18:55:14 GMTS230_timeout=5, max=100_"8a3e79-e6-48e914bdcb440"*+]^_NSMutableDictionary]_/\NSDictionary*+bc_NSHTTPURLResponsede/_NSHTTPURLResponse]NSURLResponse_NSKeyedArchiverhi_WebResourceResponse    # - 2 7 X ^ y |                              %+.4=FHOWbdnprtvxz|~8CMms'5GJ`             j              bOVPNG
+
+   IHDR  $   d   /M4   sBIT|d   	pHYs  0  0?   tEXtSoftware www.inkscape.org<   BtEXtTitle generated by pstoedit version:3.45 from Z:/asf_logo_1999.eps]    IDATxw|\W7};}F3*$N!	F,bvi?/^,!$!8qdF8ZWW#i$c{ssC@D@cf 2s!8h*03ly  f\2_ZW	dG 2,p1iWx
+>-"Z`S<jg> "@c48j ='C0" 0" Qf.H"Xf#<^Yf@E9#{ s1:X!2- #$1f lY@,l\~0`  ^ H 1F>Ze9E 4^0sb]BI a}~baP`%>*Y 0s#"GB,"0sG;@c(c0p{ h" L[ybQy |]6 yB&93Ma99"('kr &QH }*7YC~flGo: } 4Y<qa|O+SyL2d<Kyt;8c,mJgM#H[HL@D E^
+@VF =t`.W,
+@Nfbau<m(FXg%+_{]sw!2Ff=%OF>E0r@ea`Swn#K<QG,>1NYQBg~k/omo1 4Y	$Y^3[Qc[=e,iyJX,Xy,J6oJ)/k)$-OZ]TW2FL'Jcog*B{ z-y H"N]IZ6	<y"JXFDY+h* Z<#,wRW." qfNAd^ j,_'vq|Y^J!
+?,<i)N Q-&YiZ(1a8**oe][9g-|`d;=!8M4e^nfI`
+M6jPvHm	f%6{+2"XSwV`m!Ywybd)8ae=I[kR1k>e9jUUW9U+V=Vxg#<=#1*r\^g3Ya`r(l@jb%tk;e&c [K dng*)`d='#sdJ'-Z*sBGx0`|ceC5	!N ZWEy	 x=W6o|-e]"CC;o?U5?}mwydQW)/Vb*[^338$[UCqd C Xliwm7s;l-e%Hr xt@"LQYI'a>7kM]z^cYmu=6t2M^N
+_\]^Y\]fc|T!	 Z131XgMRbODuTp<#I@.CK=!Y\/))DE (cP^Ap[kxF9#s][1a y}_wMjGr??7"@3LYdR&61aqb|d ! |2:Ww{YOGAPl!PI7h%KpDhEC|
+b4C?@ZQu$ ^YOM9{|A:p7^{O'Fou?Pr2	H13MdjG
+;L|q	JLrc v/w:r"A=6!W 6<W0 7|M5a`6=>F#i:eV05`:1}Fbe#&c[zLGIG6QH4(X$*d>b)OQ(,9,DT&DT)h{v,#DOZ	}Rmy'Z~5Xto=3r9Ca)?|t&wt?6$Rci0!<`d)R	us" ` pZ}189V^d]	P'?CKi3O#F^ /^7,%zg8+SA}j!vFLUvr(lt.EXaYI= ePP+!v6-m~,E.
+YzeB3}2X+[W`
+gjcCW{|`fcKy5g0R3hry6:FLeKEl@ *9:_T*?0ShN:TdIzfs,|@g ,lS1fI+Ee:0a`7t(U~f> hr/|fE,9Z.Dd9Se%pH|6w;Or8^O;3>MY 8%!3ofoYQsp;smC5L w#!y9TfyoA>lmt@`!f>I|Qh&=-E.Kba:R}q+> 9i>p\ee%@7yaTW,s"L/,Zkb1wgj=
+g)'6]
+_Y3b{omsY\w~g/y~[9'quU_OzaNHUu2e!YB/G8mb-#NSHe18bQb8mXb\Wa=n --zy3/xk9W4Cd}25'<2Ms:Qs_tCYQMtoOJ?sMEpH:w]xwf3w?3  HJ&Sp{jpp0]]S g#3HWdXq%0sr\`~"r$M	 "4a7V5<m>Nf){p/Amtl.3E0 1yzLTlTbUTX;/h??pp~#JH;?'q'XE 8	<xw~y?fBmB8 Uq0=qHB6iK}S1a'\2sm6[7`f"G=tb`ID
+b!HM'?Sl{2>g.)0,<I> f+:GyFhetm'x2pvWdu4o78k39yu/r	8DceSO2CJHYbsi&3nN<V@*,E^BK	u\/T0HJhodBLrRa"a=Z{cD%?2D,	sZv+],Bd;<
+`DT!xARP"Zi2OL9e=+ecj* Xx&"+nl+cW7;bVQ8r,
+[<sWusm{j9<mj\q}?g{`'TvDe<&\2 %LL'F1!:F+Q<BpJ)CJA)xNR,pw7fZ"1@xi*h5d]DN0fMYXOm3DlnSbbVpw;S7@:FTct<72Et<'(uZ~vh.b$5Ev @[-9FTn[s*Te>
+!-GIINl64F7M1MJ&\e#LF_Srxx@W/ ]j,#Yh*#Y02s14m]9cV_cb~fp .'MdO'b4<\"*|n<bG%9RD>vn Uau&;ZUnrt@yAi`q'&ZS0xjDe>(5{5$FN%Ws7x6p$CSBvg]1Jr0%UDj\^h=7(DOeJod4+ee0(wPZ?Oa#g!#)wY.mO`QUxb>.BQhIy|k^*JIx.rW>H".<"oYu?H1Ouue>
+t([gU*r"zaGF_([lyZ]oW'vhhSc4{QwD<4wVhV<cs@a`q(&oq@W=jLF:IB72|5Sv `'<Z/v4^!8a*HQX'}f['}R|}
+o~qHiHQ7<"??rPWzMBC3)#v[H!8'w6#c{i"+2vnr;l},T	R=)y!d>/Vu!O4eM"1v<'r&ay^ID#MBo3!!A, 1Ub l%g$Qd-bCf^x-yX-K=n!N-(v(Qe}!^LV"z^o_o_W}#vdH#z#E{C84i 9Sp;u~`h99vf'KdKiMl@}(q:-!ViQ*b19I")05* HD
+3  XoY,c&"zr&#L"jTR14R!b9B	@?/0B 3I"`+pd.UUBQ,C,UvPV|!~ |V!#$':DQc^$z9O(,
+[R=D<j.l3l:>3,Z7|te_M_}kYE#f1@*y- 'R\>LQT^ys-{*@@F939v5?=|Dti Od+ yDtt~\8>Lr	`UB anoo4M]D.(anAJf3p&	Eq&
+A*1qjd: AXWAlf-f63~b\k0)[LYT[;!&1%07d2}V6=)Y' \oZs\=>Az<9+@J	U%Iz%A~c?v+CT=z##jCh8&{Wq-Vw'XXQH|CX$W-f0UID^,= 1l;^L=O~%$YW SCTW)`!#vQ=
+ s2e R=sbIs_}|M>|NU=_hZVDUK5BXJ
+Y#x}U43#Hn%UOL`(R^GQZZ;j"'hp^-srWz~?|;m{ddSa#,noXsD `R1IWa$9MD;d]M(=F
+;)iQK!(4(5/!d4	 !FqH3GT?;ZskMk_/4z2(6<D
+uf(!Cw Ui[k*g
+8?y{YC#[;88`Np1Htb*$"I sdn"d?~Ady0Gu(.DtB8f!6q>|2%	V@(It31o1BA]g~$
+0}rH\QBn#a$QClm}u=[PA)P	P&HALy	=f	ot1]6;4\sd 2BCrfb?!=eqy
+nL%r%,TfBKCvMHa2ObAH^;Ao1Q^4"a(Uo
+P}j$3~ 5. neBLAL6z|$<yHjCPk?	g,C,D30G~`gc2
+BPFDuvzv}/I#vV%XL$a7IE.5tJ~{{fu\.6RhT[5FUF
+Jez<ecqw;qJO9b|PNe1:*'o'sI8C/ZtxB4K'mAPG8x%>Kbl=Ny7M^F)9L'~]B>L,ZFe4CdGjk[+y*|x1f`x4L<9p09yr`= aG(W+k\~9#	#TGrT!/9lX"6W35)&-a	$JUP<>-fp,$tEMRi0$[H>p0s6Qipp$T&4Hp&w0e:+;pU#rN#(<Z7R+]\1C[dNl	Kx!    IDAT:5[_?h-P+Ode!iyTBq)h%;{
+ g4sU,,8P^VU%,_$A""k\!4Ot0Hq&!G!Q` DP"cT)PS+FW:,7cg!U'eUo|!6,:s?W{,S	q=LKEDw#6Q"8MAV|` C$/iUy658@b#ZN(49dk~m%,CZ6B[:*'CjD	K&/j=6.-Gu vC\nh tU8]4`S!%'*G*"1R|x1?[8#7eJ]- xXGGG'v!#qgC;7wm]FDu2mXcP#AXay&u :f>m 3$?'-s	Ti=
+Bo]BLORkV{052O5{ ]Hx_Iip)0s2mQ #GyD..G_ws|{9RJir`?bx]B>m3~ +&5q{aF\#`8^:U2.k|G \FD3$ChB]t"bu_Y >.CX |p47%tQ  [K:f|V!gMnY HDfOD @ K/e.iYUh{5#ZE9Ly(%89B0]AIG>I2FB.pq@|cmH#BF~VcN +]~,MD[m	"JJb8 o^J \GD{lCpW+*Eu|LKxa#jm.XcW`q4O A2e* DOs{nzg{r7!x_5</''v"?<7RaBui0xo~xgvs}V]{xEaU|rN
+^W \p=c:>> !5qz9Fi"bco3a#.LOJbsBR4)Ya-?nU@^a=|CB,q\$iH(^ o8S7`+lJE&e`>e0PvBC
+w7y;?A<Ku-u\$fBy	K8XI3Ie9,noYJiw#U&?hEUS()u0V#sMyHT&/9j  )2IU52n'a 0
+JW#=F}39O|UF)B6oGx1 &Yxj`GF[k+QkOd57eeswE<T
+:Af%A*p: JS" _E47?c?@a{c]E9xaYdIJi^my{?.1J@{ dYl\1"Ju	(U#y5;XD|pE [N	`2]RHBpEY]>LDA){,l_'W`MlOD(F<x]G	9&MIBC*b	ru9'aP?7IZuUjK3IxYGX';PYxu"{?|_n1daa,V xZ
+wZr A8w2 D87JeCrtQ*4i
+{3]WG*|4!f r	"]?y6Vh1J&%U,iRx\(B8VbH& L<C7IIG0q d6
+w(5*aEq48~w7_>)q _
+:UdL'2YBsfhc4FDwB!m	K8QixR\0O.tl{CGn6z;eY(!$2(B	,(a9UPkF.EJ;\Wu8:2[MpWh6PcBtp+A*x
+5wd=O}=ETIg4^)l,`  }('Np}{1 D[I):w}vU#y5<h)0 P9<Bnr[|yGV*e5NHP)_ P,mH6ig{U!*$42ps~R,78|8/7xk!6A~u" Y'1a'%|4K?YtmU#:v!FIhXN.;dg2'HIG#C]'np}Tf,dpHMogs9/ZK3#_b1ZNur@0!o?
+B
+Z {5#BZh\c,#{[F rFiHh;2u=-f$&8qCksAu802Nd?B.a	K\[	aSorBDdT/KCf^v 9o~7/zal](yEAEDP'zj"JpTp,%*.J"M<21(r PZ%WU(zGV@jgS<zvk%F2o3llc9F<]v-@Xed'KxMTH4?`ox I q
+GZ@8z!k/r]wvwGDYe*
+P$iTP#cqr#Md8R|(H#eJs\FUYTq.JGN{Cg?I o`B"zMLc pS)c)ob AD /a		e{ E~*g%myL"*g1f_sBw++Qe$9R9'2@r&%Ai8ZB":P<_8gqc E_lR
+SknAmCwf
++T^BJZ\&|_})Q:k 	"n\k %"
+,a	$fOLD1 yCT*l[}8Hs&a&Q(\JEpHc4!7R^{J@	0sPc5zXEHGXyAi:a=Z[ljgT#1Z4t07@p Cp!;11 mc{`,m4C\_/_b:PXM~<:R!9eJ};W5anW@RQ?.hqW	CYOGFtrhsw3CcCC6_Hc;_fLuCXdhf%H1r(<MSg8Wh7ftSHC3y&k%Y	* i= wP??+' @P]94^S,}ir q	rtiB;
+mJ>q+($a&QsQc(FG~z/%T2*oyleTqwa(0{ %@Q9[-9O&2,Bciemct+bj9E$`w3R~U! "F"( dh	" l|uIfd 4NHV5W~H&HC7M,H '
+$3NTH0W8%(Bw~
+G434r8zSu5)S?Gz0he^:`	J=ov(6[ ,7?[II!`1O"6Ap:vn{~ -  K#FYtGL#f~ &{ w6B >k1?_q8O2R`~)`={~#-pWd C3'P)AN$Fq%HC=,yq5nLCJ4)>R)uf,pej}Yk+5.0HhcVPupx\p:rhy>8SYKaopqlp2~b7e.HC!lGQfwHAkJU"q	 :c]u8!y6  iD!C1b[CZ|T=E4|E=$yF>%w0qjG.5M
+FbHq#7D)n}1?j*dJor\[W]_*<~`Z*$.W_H.N\Vx*p6(}k|=89 a`PCu!s6Vsv~({"&>9xHw@w -6J+7 ~;OpA wuM_,JU;r
+V
+IRaF	8%F7ZX2G1M;Zq|LLqr66wq6`poa8{$F[iqrW:}z\XbD{"T5rnVS1tR=v}Ngf1d9d"@K8Ai `@l/BE!Ahp9IlphYn.'u?fz8bHeUYrOBd<xSp INr,V|8LhzHCf=jiyr#	BOd=v6sQC]wAuC{UY?'c< ro,}E;n"p+ tS %_ E' }x.2"% m#J1^O`-y"'OysFn DA}79ejEl=|sua:#{ylF[ B=/s?vO*YcepN`,a	_A7. |KFwX01 p] 7U 6CPbG&,;,?-jAygRY ^emy@n{7R Tr$V;AfmU//q !#KTpNL^lXm>x(fyg?c9c%ATncL^?#DamD= 0i |SO!T|B"~pj?Tj-J{x_$'mzVj{*T%~= @I:mq_Tk `C6qgK!dW=)eX9{GFytb<z,;w_7Z![@{}k-BM (*cC;gum0-eN:Jj^>	v"K:VBh\Y7Z*m~ ~1' b'K2#U )z:7 G(4TnxwJ	 2VS62D~Jc<fhrli8&wWqJPs_&vmjm BF
+oTg+G-zF_2U,<`p"b<E_~\PpwsVWCz fla1n08^q	qZ5oB /$se; KbbVY?o-UD9 h{m1}NrH-3#7k9}c=c{/]q4NK(C,HSVCrHSk Y;rX?<#?_=fd}juF9vc}cpR40RIPZTvV:`2x~NO53
+OdWJ. @X63+:0%{hO@3|@Cg"z!e J)oM|[ %WV[1>=+mSl|`NI.L1:x`o6Bu]}<fSTU]_}/GG7^:gg/s^&%tok Ikoym,lWM!BF
+PyUFx ~ N[ojf_"|<".u F- dLCf{nT!Y4Y_(V6jc]i/TB  \$F pn9k1!9!&suo~'xM|s_wd2uo?1..8msh:F"RVU/f51~K{Nwmu
+V*uf= l`Eb3O\x|Jm4H[2ZuwN3[g_1`eZz<-oW>wXEp
+Csv^&lc"gtB$HA \q/!gG[ciwuZv697v0c\+xs=0f2xJmC][ZUjvn]{)v==\cO@9*X8Y#Vqk4<z7RW#/o}iiH&*0I;"?\<KZJU EtqD{  IDAT, >HN.Q AI-TRewo3]yO9<>:4xLfpe^n|p6bYCmZE[6jy_&Zmj+u38,cOPwy?Gj5\i.T8Udczfjs{!bi%I):qYIP< Ju.$p!7 M;!^MVL>"Z@:xhY\~4TQ~8iz|'<8(U3	-lP(=z{E[oxl
+^bW\	IMNew96z?|SO=0sTOH \BDW,.SDtB%kjy6A
+!B3WR8]!_ G||'8DtFy 9$ jeeN"jXM 3%@t5Gkh 18:Be+:[f)'9R} |q3-Vom=hZ@UT:Bt+D  NDNO\V/+$Y,gZ!{5Dwm>]uT8"wJkP>y]F:!nm;&if6?^{42))zdfr#,#WeV.f)#Qxz{?iJpbA"=b l^C\q9dcNT!Y0%TU*J*]N`CVpjkOWr_6{arD;dw|?;(mk_6L` m5%q+ m]av ocizU6io|B2.u dY/G7kCVB=?&T]U;0>.X=s^+WU'?|.RFW^_<V~;DW<tHQDhK^%s^I&	{ %vUzPUm../7}AOwHi>Y|Z;>lR\W(]-{}8wq(PX_q W%,U"FFkF; +NwC4[K
+nhWbDT1Jqq$'eR.8Jbb(:
+n *.4h89~~5UoUW{spa<_Y/F8@N]V6]fo]-hlR<GyiKWX^9xX=[t?t`9~yt\R}@ut>Fv5b(-+(Wc'"B#i#sGq
+]^V^^a{6n^LuhG<wU[>:eHu&Wk{exMM[UqU`v/K,C_+~+/39TX#t?m3Voh5A0mfbHXwkS2tx:,~CvexZ@[!\
+,jH'|'yg_z0vV<JMiT>\jTT,WVAv_XRs%#",%S4h5"r~[0E<leyz`NUfS0w	:f=`)c>}CD `V"r;\x`!*`V"+we(~q` B,#;	2z, [Fz O"T	D!sff9:JuE b~H3zo @u"'}c?e"Q7lx~a8fg5g'[ytI6o?j@CEyi{{v'lcWu,?`(ys1T-hMH^iB\hO"2KCs4cncyX0slRUm]El1Oh/#)!B@4HgrfnPDiX998LU'`nU 7w1B1.Zq'4tY;kUV~LrhqIg~\q{s5,e{pkGb{Ce1-@g~zJFbQ~jWhC#Wv+"k=J
+E;e2;(UmwWF)sdCP rCw!Gex9VF]
+IUoP!:VUOTT&Ugjx|m}-=ze/<[QYyG_ly`;oIQl41+J+2X</M:e
+lGKY0ut4h^F\WG7g`t p\#SXrY`Y:/{aPBlF2rY#I[<sFdIi|Tl iGvbJ.9+Uad2G7#eFs]9>qhJx2V2*$yl`q7SRZZwX'5K}7(-+;|cvoN:.u~6b7tBItCF_"I5~N=lL!%!iNWFHB @Y3z8)#]Cg#+"Og'~z;;S=fa^dQQT9eFb "oc.qf`pL"5+u"F`/ou#{=vWvoB&'#27OTz]\ U].";DJ"v))"\sf=	3VVDja7O=@HmNv!2)9gvC@/8
+3%XtFKKKk}O Gn%r*GDR_h[bYO1N?{{{c8AU#"^T#v0Fx! jO=j w#0sm>@dvP\jPd`(7;:MQEtpR_43Q'_/oL -xyZ4U3ioXHxj9I1TL5z~G
+(DSGT{]l7	2	.<l/ S$fv=suKB^!G7#16. ffGZe}!uyG )=YlO/l"2<^dBC/CUH$hbpT@Dz%,^W1GEdX"i$}tpnK"G9i#$+'"NzM_eBGIu{]BBJ5f>x.H[IH:<D`km6,?l@e~i<|Ofb/F_D5!Wnm[gXJ"_"#"b^"r~%A0>PU^Us0R(/( e{wbNa5"WU}Fb|"SUo0&H{1+LY]2U|("0o<r~(m8&siaT"c$T/"WTgvvX7KiS9W}a?qc	,XyHNxg8r#f8Rl	ge$~N<oXHx{U]	_RnJh=p~9E8Sl),<i[6$W)XLa&/mi,X8+@@ml&)`:Tu/$:U2"j>_+VyPwIYb}vI%/]{GKL<|G D^~G>U5	alNIBJEvP Nv'`0>D6"g.Ty wR;C(	[;[E5	WL5ucza6F6tt+<Xt8xAfXdK5cdw KO3BJ"FBo:jlI$6dbk:tQ,3/%u!}MRNW<^vZ0KLJGRk!;T/%V&2(zHy{f}yGk;k+M(pL)eJHIx' hx1T)$"Ed*e "PADnW2#0-"z]10ID5Y2"a[;[SDh*"17W]8ZDN8ens3Ezlg=z=H{0Joo1cz]Y7x0DD.`;B>q^^9}R}K[i)yR;S1bl2C9m*JE%<:RMb%}f&_c"3wGx+@#0S=JkTua=,gjD,LQXnxw`W HX3UuLM;Sd]Wt'GkUM>0u7sPsV2Qu    IENDB`Yimage/png_http://tika.apache.org/tika.pngOObplist00fgX$versionX$objectsY$archiverT$top "()012JKLMNOPQRSTUVWXYZ[\`aU$null	
+ !R$6S$10R$2R$7R$3S$11R$8V$classR$4R$9R$0R$5R$1  #$%&[NS.relativeWNS.base _http://tika.apache.org/tika.png*+,-Z$classnameX$classesUNSURL./UNSURLXNSObject#Aq3456@WNS.keysZNS.objects789:;<=>?	
+ABCDEFGHIVServerZConnection\Content-Type]Last-Modified]Accept-RangesTDate^Content-LengthZKeep-AliveTEtag_:Apache/2.3.15-dev (Unix) mod_ssl/2.3.15-dev OpenSSL/1.0.0cZKeep-AliveYimage/png_Sun, 31 Oct 2010 21:50:23 GMTUbytes_Tue, 13 Dec 2011 18:55:14 GMTU22216_timeout=5, max=99_"d1b54d-56c8-493f0adbb25c0"*+]^_NSMutableDictionary]_/\NSDictionaryV*+bc_NSHTTPURLResponsede/_NSHTTPURLResponse]NSURLResponse_NSKeyedArchiverhi_WebResourceResponse    # - 2 7 X ^ y |                               #)2;=DLWYcegikmoqsu-8Bbh .@CY             j              [ !"#OGIF87ad  ~fff 3olJff3OEfffO f 3{7O3 3 fffPPPf3333fN@EYf/X T J Tfff fuf3ff 3Jmv dfff   VPEO VNjEHf|~cv3fdlifIvt33gt|tA{F|{7-}L"Bjx OKVE0*P jOV]~ff33{M
+V JqYOCLVAMY
+U Q Pw{}Hm~_!trlT=GQx|N\n{8QuNNNlUHiNy/f3fQ,    d   H*\#JH3j CI(S\0cI8s@
+JH*]PJJXj`Kb] 9m-)  3faaf#KLB9", 
+ $ XX 3TH4<Dy^~6@_?N('8"0E{@x;3L/8FH@\~yGBS^_EBlX@N0	P,@-x\pXaET@U@EW@sp QbP DM9 y$(#qT0:Y=1@=v1		YIe[>ffp=
+d|vqB 2Q'gPpgQJdo|)^p[rFHRc*k?6r5kY9 |ZP_(&1NyV! CkhHNV=0&KB,H7Z\YA
+%iH\of "6(U:@*`.|A8EPAYi
+k/6{R",o>xm(F6? QKF!=nO iZZ2v<r-a6r 	Pqd.>qt}	V `Hu&'+wM .N9x A. PDd:u>wtyY}|W9V$;aD ~|d,oC0p  /12&!  5h^N!S+ CYc@6 t@,7D|}`|60>AK3!%v$Q]ZF?gxY'g`ya0@@
+`x4KNWvjH
+\cooABy:D M @pS6iD~X@P`.0j]>y	@ 
+ODi2.?ei}g" 0/"Nc4NkC2JVR^Dxe.`yE	HPiC&6IE W63j+8b(<*Rw.< :@Mg"`MlW8k(bV	3< V" .axn}ukB:fQ"V'MTHW2H|<k  k#]RAq r?Tn$j!cg~5IxSoFPJUUf2RCri&`	Fz1j/E	b 3!M(#GJLsA10C5/,yLx/]
+>nJdyvSY]/1s0ERB>BHaTl@"IgD>m'EEw-$^2s i GxD^H<*D jZMl30TR~%WN%|8;! l'GmAkCD6#DX!%D	* D<y'D&rhxl2YqR>CE,)WP ,m:Yyb7 -AF$@ } 	feK
+hp@ h&q`8<:-(p?j	
+Alp-5
+V	Qk.kmdbrN&4p Y>s7y9n'vje8!nq-+1WSZyI$*]G&FyE?M*NK 	m2!'-iAN2p\c7PKsxT!.W3 4!5XALxM<BEo")n`	f6%'I^vJZhk"O	(7(N-W ~/ d%W[yx?p%	lRG /OT[##;5i ?5 %`\E` @@ ` ?7Q	7}:eyKc1}pO1pR ^	 &mZ-2-GdWRr]%W n n\T\0D37  v`R  }FychlbU.qx(XWEygsB+pME.` [4<WMBSEdJwdB\v%\.5UE0't? ,|8 agUVQwy+jpa"dHopL8(p{% Yb+2siWZ("8 (X!fd~lg$g(yGG!: 50O1&Gr$gI6$\@JtYOp(PX| 8>`6\-V\g@2|4<F&p!sLCrp >uJS(SvBz8UC${f9(A4eI7pya'.}.-*451#M(y{tW!pC: YW &me^2W&_iN/#ivy:|p A 7QP7QQtsbh(RRiVPQD 2R^Q8J dTd{0M$602KDJUSy LL+L Ap7@PIg%pA" )yV8U  V4i  4 [ R%Jh
+O%r=/]0apHp a|  FltVD7Q1:l7WRa	r4Yhh 0%#A4^s0 3Zi/7@v|M L``Rs1Di.vZnT[<gU!( S0@[M|? MjXci sgZbC94ExZIt$+Bx%G@+1&!*h=r
+P3R?KW<. M%!9\r%Bc M vP9Iv61}or1~ji,OOdZOhTgM fj3]~x NQkGRGpjRfPY0O` JO0D%K##jZC |]v  > ,!i}*TqAG *   {xh O*:3 z(P K0J6S0KVy2	[ ; 3 \6
+1+q7.	Y5
+B w:!\:!,9l<'L-l[#0<>,	19|$k[q7o&lS! HY[RQQ<T_iP!MQh<Gpg-Wf{rtlvoi%xh+[vQMUGSxiu#(.b4+LlTuV:kB&zAI](y!8$ak(BB"!L#U(! ,$gZHM7Ct[&wScBwVgvU&{&	HT<Gip~d(!l]MaI]Uk%BAV1HMw.U8yl|<H -A	nuI{fpFgM}p|y\\&Be(,VQF\1Gi$.oZU`px<]tVK;M)).Kc2.w]H^QTgm<tz-GegMn=u-M~Qg]pl L5- yx<l(o4lfi=C{Zm\=M<=$JeXg-]=shBk$]_]xq0PV~f >%.x<h=!f(7oTRWdxE,UK~t	9=M3.)\J4W>&w\Xpmk= '6^MQ.nN{1om>-MeM	UBG>E~DbFWrBcVn^SpRM=D!MRjv(xUMLYN"1nn>ok .mn>@7^=AN ]bym\Bt1t&.%w.!6+dM9 6g}x
+njuwM1J?${-6%R9tPHdH%Tcq_NL}~.?/R->/w{tQ)N^q|! >C 95&]vz:_?`(la:.hVB\L(*
+R~(|(Csg 1@Dp >QD-^QF=~RH%MDRJ-]SL5mSN=}TPEETRM>UTU^UV]~Vl ;Yimage/gif_#http://tika.apache.org/asf-logo.gifORbplist00fgX$versionX$objectsY$archiverT$top "()012JKLMNOPQRSTUVWXYZ[\`aU$null	
+ !R$6S$10R$2R$7R$3S$11R$8V$classR$4R$9R$0R$5R$1  #$%&[NS.relativeWNS.base _#http://tika.apache.org/asf-logo.gif*+,-Z$classnameX$classesUNSURL./UNSURLXNSObject#A|B 3456@WNS.keysZNS.objects789:;<=>?	
+ABCDEFGHIVServerZConnection\Content-Type]Last-Modified]Accept-RangesTDate^Content-LengthZKeep-AliveTEtag_:Apache/2.3.15-dev (Unix) mod_ssl/2.3.15-dev OpenSSL/1.0.0cZKeep-AliveYimage/gif_Sun, 31 Oct 2010 21:50:23 GMTUbytes_Tue, 13 Dec 2011 18:55:14 GMTT6338_timeout=5, max=99_"d1b54c-18c2-493f0adbb25c0"*+]^_NSMutableDictionary]_/\NSDictionary*+bc_NSHTTPURLResponsede/_NSHTTPURLResponse]NSURLResponse_NSKeyedArchiverhi_WebResourceResponse    # - 2 7 X ^ y |                              
+$'-6?AHP[]gikmoqsuwy1<Ffl#1CF\             j              ^%&'(OJ JFIF   d d   Ducky     Y   Adobe d                      	
+            	 
+ o! 1AQ"aq2	#BR3$bC4%
+rS&cD5Ts6'E7FdU()8GHVe*9:IJWXYZftugvwhijxyz i !1AQa"q2#BR	3br$Csc%4S5&DTdEU'
+()*6789:FGHIJVWXYZefghijtuvwxyz   ? .c%v"WzWzWr OY6u  ?1 >? .[z*=^s=^s=^s=^s=^s*yS<W3B,?CKOb2Wb+zWzWz/ g_([L Z iO7rs=^s=^<C1]DSxEWmmRA6s:zz9Iz^zD$ 3</O zz\JE{W{W{V l  ~pc1V}P]) ~]^Uz^zH0,by0b1ax^WL#(,OYd;+_us1uU*U5Nl$I
+HlLZ##$BqjUHJN4QfQ"$sfDI|.'Va"s9
+8~BQZL 7*GzWz>H gYO =^1^z^z^': Erd ~UTGJWjaU ;oXYDsepA=^|zW?23eBhK%^FG5tFHw+1nSAISNo)L:xj0(G5+=<AIn4X }X(m;kCKQa}'PO&m=c&zjVe|c1<Uxd &'KMFisjwm+ZR N[w "h*wHB1(Z@"1]u3Z4ZO-%TuKcr<'"*|zWz>I _Y}S WdWeQv`M\< 5V#c{RFTnf
+=svW+=^zEn=VBwXa' &M X	? -ttG'&|3u]XQ
+YKZ_UM5DZJ@5U;mu]g6*R5jfvzIQH>t~>:s&a9cYz LRV3
+8p?A<.nf&$K@m+ |U2waaUP _p\60|jL^)LM]GR)a1 m8I	^@qD'C)r} aUiX,H,rHm7B8\I<
+	 :-_(~%j2,M|P)v_8?<;SGTkuf"xug9jwnU;(Fo'&$E7*qJj^zD$3  2Wb(WQ
+JAYZLQ4jeo;Wx`p=t#thaJ):2 2F
+IffuoY^]?ltg /q><aO"p+]YE#(kz}nH0#	
+JJ>4@W VnM9W*BP3=+)sN}ozwa&)
+.N8}6"Ay1~TI<x-$zv=Vm~B@(##f4A+qEzTAmqbS1p?R0lhp:xi&bnl5<'Rnw}Z$O&M_	bj*:c4l7
+Z;Y6>;AJ?*>
+eBzU.d1Na58;nL.S-5-TpDhY#vHT	Pse3 l$D|kfJI:{QtjCnOX<PF\FD4$HPGryZS?#/+x<t#RJ,Emb,/w5,HBRqJ$Ow-F1 (Zzg'Ei3%RT4mU]T"	Qs{yi8"@B|;6d/4A$SeC,]\i~3M>T|4
++8[_~,*Q8S=54VWT<*{	l:T2!P*-N\K,Nn3|VmAzcC:o5nIz) }$69;:LhwUUTMT(Ve 'VyQO9!@NQFt>+F{xGU`_NQ^sUZ=^M?o*x^ |=^g V9>#;_
+ f@ 'MrW2&z8!-u$34KGfuNnnKkp|'zT	Cp8l.~"T!Me,SQMK=CH%$
+,m#+}np}zAuO HKlc)KpAKIX|M"uU0ep6q]L |(![6lH9fN%Di3g>zQ(pp*dzgQmk u;pN>tGI7fp	R &h OZ<$gj7L pJhz:&0LBRdAF>T ,m$/3<13=wZoX!5VTTVY^&=DkV@7SV<$?'z;
+U{H~]3=\m TyGT5{u"?W*B$@A%8l-ZP
+F'ew{8WJU	j1i[::E_"bXeZ)KUD$jU4UsUkv}eeh@BIQ@F%pF((bv"1Q 5xf1P"t]Z+4vX m<$6>dU:Vg >]FzzA]Jj\')P`)mLeV=DYk%:j'r%!6BshuIFRI3'gTQamn:DLa(^:W=Ec WIYX1(f>CPf3lQ@f/,M]sU6l),.RkNv8W6dKz<s}}>c_9*AWN$%X*Y756qSCT#<H'fvL&%ln;z"uvLF9D8fz$;JGra$Es.p=#I5z=^Ooo ?WK]sFc#7k!_| U|sY[Stz+*? PQc	?SJj  7 FTEG_2B8NtZ7G,RQU$lvM6/6{B*
+d_{|l	 R	y%W4z|n&1JII0e!3qa,#7mm,co8t^zshj\[=BTxEba cj/_W Ju#b>1>.3AV`*CuX 6R\vm;bj"Di+8;8S3.\s
+lie\NbGAm	+O6d]:D#La@{Mffz4ge)C Y2Fc$PcYK@SS;vx35f`vu*$3JdbT|6	<"#0`v 4U&	hZ+3RKURvE5GL%OhWU`%)r%J)RKoa	PW\).U: #`$E7ZXXNUq'/CZ-w9	7nb~gJ$N=j7G*#@AUw%fXj-e6rOSW`N(jc#&i*)BW( @*mg0M'O:A$	$pCVbZStgjyX	5l@I
+d}V{-<Wr8F	$%#D(lxrXB|)b@j?;yG0tK]ru_W2\MJ,t:ZLu8h4B"dU$e}#zJ^a+RRV81Dr{@5W>zD$ 3uO?z_=.c%v"W2O*7afM*F'ZE7;6#fM)^#<vVoo3Y:IfU"4U D~],P\8&Z.J9"l$sw`4}+Y'S]g+( , lj68lxPU_Wvy>O}\{O:GEAg\ *h:vu*z^^k<#,YQU-E)Vv@chv-mc/80gIJ5iugPljCOWKmV*#l/ P@VR5w5$z>;es7rTa*H :fwIEngLO`b)QORPC;1}\'5<\ZF57hU4g*\Ns-tPJ}b&<hSTDu\?_g9l[xtXz,eQGcPaCt5~Q@8`FxPwst_0I' uu7pnTy>B!MX|:!'vx^U P%'iyB7tJ\ 
+V `
+Tvea[f%H;&Bq"LK8n9-_H'UaO_S[ 8ai`pq=40t0@ IVfm[6L;YuTp?]xSdCiZk$z)L4*IJk!P0vWfeGHTGg`>Tk/%m iU pq&DL3|&ed~Ld#9)+)i-|/&Uf!t0vi%_MaRz5 Sz_SC=b39sxDP02
+	{#.bu"A'+w^IHPNDu}0\>rpe]r=ZO?o*x__z_=.c%v"W9tY"za4
+ R(3^.(jm{.Z*Sbi;{awPRG JA?_9J(83>rn9bRmR4We=mb-,M^z@g8ZKET	QB8dN^xhR1UUmI'1y+q	G	xH-}[/m4zrBzt",WRt
+11JsRr @g"n'HIV;)_gVW9+A|%(Vt^N	kgOH4<k+.>(`8*AWU`e~*-g+B
+xaa.^;u>Z2Td u@yg:p;"!iUpmo{/|Rzoj1Pb;G-^Q]4oNdFJzV$QYzZ>tXX"]d{eM)'l6Xrhg ]8zOQimZJ<>`7;p\f*)LV^%UpH!h"<Usl)N0qG7R-BIJ@1(=~26L>RnGPkKWc9%)=!oN3ev0"@;0'=BU:emt+KcqW(aA&)GkU%TOUpNz6%/Vr%fa&UX
+5-'YK*gb{0R}D9(`}L~J~0wsqS24j!A~RfJR&DuxWO~do8|64K@9&bE;sU$#If  ?WO]sO|NG>p8*569OF$`Kl893YmdvXgyaq~Py	(\iN
+u[Pu?WE{<%OQ6N3yYW$NkfgFCY^qwv:1u}:}&v]r}&n`JlAjdkp@ ZJB11h{7z`	S~KnZO
+=Lg{:sI2JLFA=TUaM48,nWD\!PfF;"d;jjZB[t)0RHIO$~%K O4tCpdYn16{Z>-_VJb:\Kd u1l4xzI1
+	3Q70_3y|on5uw@F)MM$f7Fj" H+_x1Pv$ZQC+T571z.'*>X>o]$Y*g '}z2ML;|_O>&0VCxXJQ6[m6GCnZ**Ef1GD@ {g8uET]=gQj/CIIjguUrlrhH&wq<-= dP6h85**   ~ U1\/.K"RVrVbTJLJB
+/lO9(	m!  diY	:MxxQ'	*pkk g^+1J,YM=FU'.1LpHkw8-$"F~5YljSBBITEoI]M`:U$#Ifzz\JE{W{W{V l  ~pc1V}P]) ~]^UzMVR*G=[k;9z#b?55~7L 3O-czQ3rmD#[O'X1S(;pj4pS`0 nJuMr6'Em9?|`2P=u=ZB#Tp4>+=mfCL%3m(	im(^#tmJ(T$9@rV00\v*(Gj\^}	 V_>
+?Hq)O*S2"(	kpJ\fg96!d7D^'-"U)fBhKws1#YH8Q'L7</O zz|JE{W{W{V l  ~pc1V}P]) ~]^Uz@&S:U
+<'$`)[9EO$	fPxXPD(iHSA>PTgfzd6TL:8bUT;O32 8@|&YU-'	Q>}JK/;=bccf*Q8dR-{KK7j8-Py~/ v6 zh	pA}O0HUPe$UBBkQ bp5_D8	gK)fln^~)
+:b^	'$~sE>cqii_JV7F^_h+Z[4Dm95?97f?hj7U}Xtn~rN\6L$tPUQLRFnCH 6|'wq*)EoaxU=MiW<Po+Ac<EJzD$7Tzz\JE{W{W{V l  ~pc1V}P]) ~]^UzTv~*8+ac^'Pi&p
+h|Z&nGIPgq >i)QVaR|Qf_h32VF l?:7m6	
+i)E?e3=>+W$44xQE AcE"Vj^Z<OF9yPn$TR WE)sn`F:c]i*fTL=5+{x#h)j@hwBpqP$6I'
+PRzq1 WxmF(ImdjdeyI]NR^Z;H-? {t4B?]IpW*0wLT!`e"Rgh(('#l
+/+S6bm
+b'X6bE~E	
+ASICYKM;JK{APN(;=rc  = A8ed}8sU$'Ifx] s+zJ/"s2F1JiS,pSt<U7m/[eJ4-@	8Lc(=qv( T)+LOZ).Uo1me!*P$y&$H+.`x.)Zj(Id	Tu*`vnH8LvdO]&U*CE8]7Umy/'K34gN'AK7K GZ iO7rsMlf6|ZEu0%DMmEEe6=Ezr^Zl5=<DeTR(`&aNcphTQgN;Et@AKIi
+3GI_E&SyZ\P&ea9lYJQ&;MA{rjL[QJm Lt;0{C@:	dyPM;*Xi)j=KDHW	@:79=#``z{/~3Lc<4n	!jYTmHTw"qNA{MYso"`2SOI[by;E	#7b7 H0GAiqa$<eRZ*Oa7hp
+ls}}^d ~\14qWG^,jEfp[	h8
+	n>H oY|=^i	:d|GtT30<fjt!M{@b JR8og6Tw[E@8%#h*_Rxf3JBI.#.54kA-qs!du l9@ZS%Z "8B%%o3Po
+ *j _%}4|p-{ <\JAJ;``&}FLC?Sn!WSF))&kuqn%0y
+2n j 0p5'W&u\s'^c1
+k#?H{
+zWiV^ydxn^#g 0hBE @'4q	?
+^Ox4rib2oDi*HB"J_"F |B =KgU t	;7O8:y"@?8X4NU~San1]{%b&D~rhZ`0;	5R.|E
+GD0N%Jqx\b#i	$=*vdf!\nl@(GOI?dA$&zIGuK-`dj6lP/=y8[JdqCNz\w^e\(Li,$0g'M}=	)x5%#If   2Wb+zNr2YQ2KOv}7kKNiZRvb}8oOUdy]#X>]$me#m#O5:Rd<0!%|f]>}=W#.2>AWzP~x13'X5y-4;U],&qfdGF	I$$ 0[~
++:O?7eO[E3bgP@C{s-
+BG+>cw!jmm" 8*kX0i3D:|E3+8,&Ezxw)nvQS~1E\N_]<FEVW+XnzrtP0>A1hhi{QjU 6]ZPL$:xEfa{g]u	ZK8vyQ#g#SrREcW.uK@f/ZPH<$V!y&|iTID~@ =?	,31eRIDn0h.Pa( `+TkoR3QH
+mOAOOq%#lQ%#(G~ Zxx-%a\vJ,RH<8TL\X0mH0\[k)BIQ`U8%DPLm[x8RnU-6	S@j,TRA
+ ET KX1;Tc9s.Ny,F3w%F_
+\&GFF<vLrO:=S WdW{W`x"^ :&p8f(6 ?|=-Q*T{N6Oh4Eu9F}>gKa5&tE%ED=[\ d,A1A{4%(N:JG_zOqO*<FZY)R{n)dd:
+a.R-Y!@4"G
+9f>.aUsJ&%MAd:[ceVj0$QsfP\PJpG}qP>y;uW)dh%_xjj<q,9HvPCxtK7hCkP$	XU |5W[1u'Q[*S0([	"J,`6n..y+RqfCu7a9Sp *:aTtQzO+j'DdV:0>P,?x\7D$ @7B {/	O3.L=h07	s-GNWC2eJ!&/;j@?g##a)R%Da1'o	AzQUSdZAR:z?-v2}}-o}~"J(D#z	br%bQGbGp)jJZ?
+n;mN0qqA^gG-.ajVMkKBX|yH)N[w0-x6u&SWM|k s!I[
+|P5JYgg.6	yvG2R5IHo{dT~,H OY|=^s=^vn/m)nQR8GU/ xj=,!3v3g`5t$uC1+2Z;v%REp8[qK>^X3j-z@+Ab}a^S[ ,3 Z`RU
+,|)H]QsMyZZ&"BO)3OKo/R=f&*MK@ErV}]k+P^I0}Z^iL3orSpJPG]zg 1R9GJ3bWhg\rS!1h+tguFP~{<6J>eI##LldFea:h)RVlNFAJ?a~]JZPzhv,u.#E5s&ITbK|iYvFt]t:jxQ @fjzO#W,SE]i:JrC;yTM@ms}W( QkpJwjJp?/A1*w1AmFt?3A=3I-5m$mte`Y%M,G AL`J* Qk}h95v[FGG*
+fZdSg?PA&2vnH*:Q?zG[8O~Vw8fAu&AWtiV24--le~[)<y`e%)4ufNkr(VIHvv4heNb}gzZY'" CPx$`@XM6\M{9[$$:8o=AZ)y'Ie>azzJE{W{Tj{=vosx}m{o/
+O
+K=sFM^qQl> |tGsd!8Uhg~P-RZ 8Ecw0PcVbL\
+Pb9.EZI+)JnYLh2:hy"]#"@j+@x=vWgNz8f)v	"b.!H  7:YPGNofH-[JM}f YRzIiuDr8TY5@2B*H1KW-[D4$bJva8{B$ >mg(MlQHh$!$ VX{E\Li T+W}:oxwLz{iRbDxkfV?*da1.>yzvahkAl%&38j<(-*zfJ]>&oVfV,|K[&d6.w_x4}ET= }C=fMWWa#a+#fBkUV$wu)GP{qnZrP-iz_s\uz0,sef	Rau,:u(/2@ ]e(t-H
+%CT#DG'`ESf?SWM7M4N:!>4>m  t-@oHcM2Cy|?LS(~5~'8 )y'Ie>'e$=^1^:
+B=E=,7`Ibyd#e00F>Uq
+ -D/Um9\owi2nMd6ka|8^6%$J&ti{y+aDHHj5(RD]XGj/MYbQ:|nJj^fxe(nr;'	+xAn OJeDRpQ}ySejZ6EA[ZvX?J=+W3-.cZBkh[q2%iVxy"Lq:* %x{h)>v~r}y?O0u8 @JCR(>}+>i;
+t8tU$=bF
+K	Y16 !zT@j;8R7/delZ|r1UyPU+H$ {h;qs[p>;s z>T1Lh;(` 122avFM0\2T}\|< bzW=
+7,\f,<y08EUeUCyK9mI{/.NhIP$   
+2GGnO(e0Rz&&@^"6uuRJCh<M;jC>RN[N~$z[s< '5<
+3W8/W&utzz\JE{U~G$zz,O6BQC==MgWXYMvZ[fdEcj^g0 u=@h([gTrQ2E:wsFO
+q(yQ9%;t 's.[`ivs9Gi2$h&a&^!Q	/38gI"*eX?/[lMsm+
+qxB{y	c94WLG%83`j P,1k!n68mvlQ14|1:: \2jE<pX1IO c?SGJWOWikh%sc%+?q
+<'P]z57X9ds (jnP[/FO=^S-qD1vbL=^5_pT+g/*p/41[Bb?wU!zRQL<f0G PO
+AyL16B,N=EeA!Mx[|+SZM'3 un]c`{}<D~*%Ru0:7g6&R/+H*"SpW|;iW&uxv WI|zF	z{qJPz_6m{ ulG],=#b/ ?Ok2OU ^ aW? :6}C 3I Jk365  ?^~5xi?W{}\ '* pC {{ >_ JkgwJ Y)GUQ#TQaG0jh@kfeZPV!vb@i))D@mY_ +\>.R/ aq mrAt_~k WW '=^G6ob 1t:c8vW	D/# ^z]Hko?T@t]o6?+bz6-|E Wx'Y2E1(qM0-@1	L//+7=^Y] C}|T_tU:y{ <z z^ O=^{ <nyu z^ O=^W~s <z/}\zW 8Wt x>|yZimage/jpeg_,http://tika.apache.org/mattmann_cover150.jpgO^bplist00fgX$versionX$objectsY$archiverT$top "()012JKLMNOPQRSTUVWXYZ[\`aU$null	
+ !R$6S$10R$2R$7R$3S$11R$8V$classR$4R$9R$0R$5R$1  #$%&[NS.relativeWNS.base _,http://tika.apache.org/mattmann_cover150.jpg*+,-Z$classnameX$classesUNSURL./UNSURLXNSObject#A3456@WNS.keysZNS.objects789:;<=>?	
+ABCDEFGHIVServerZConnection\Content-Type]Last-Modified]Accept-RangesTDate^Content-LengthZKeep-AliveTEtag_:Apache/2.3.15-dev (Unix) mod_ssl/2.3.15-dev OpenSSL/1.0.0cZKeep-AliveZimage/jpeg_Tue, 24 Aug 2010 14:15:18 GMTUbytes_Tue, 13 Dec 2011 18:55:14 GMTU19086_timeout=5, max=100_"c22e47-4a8e-48e9265046980"*+]^_NSMutableDictionary]_/\NSDictionaryJ*+bc_NSHTTPURLResponsede/_NSHTTPURLResponse]NSURLResponse_NSKeyedArchiverhi_WebResourceResponse    # - 2 7 X ^ y |                              '-06?HJQYdfprtvxz|~:EPpv/=ORh             j              j            1   <   N   d           Qg  Qq  Qw  Qx  Q  Q  Q  Q  `e  `n  `  e=  eF  f/  f9  ff  j  j                  i  r . . .>             )             2
\ No newline at end of file

Commit:
50437f30e0a6c6969be162dc1e768ab061e67dac
Antoni Mylka
amylka@apache.org
2011-12-19 11:15:56 +0000
TIKA-812 Support for detection of MS Works 7.0 Spreadsheet files
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 72c464ea2..c4cb18ef8 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -2777,6 +2777,17 @@
     <_comment>OLE10 Native Embedded Document</_comment>
   </mime-type>
 
+  <mime-type type="application/x-tika-msworks-spreadsheet">
+    <glob pattern="*.xlr"/>
+    <sub-class-of type="application/vnd.ms-excel"/>
+    <!-- this has to be highter than the Excel match -->
+    <magic priority="60">
+      <match value="0xd0cf11e0a1b11ae1" type="string" offset="0:8">
+         <match value="W\x00k\x00s\x00S\x00S\x00W\x00o\x00r\x00k\x00B\x00o\x00o\x00k" type="string" offset="1152:4096" />
+      </match>
+    </magic>
+  </mime-type>
+
   <!-- =================================================================== -->
   <!-- Office Open XML file formats                                        -->
   <!-- http://www.ecma-international.org/publications/standards/Ecma-376.htm -->
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java
index 368595fa3..1c20e9417 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java
@@ -69,6 +69,7 @@ public class OfficeParser extends AbstractParser {
                     POIFSDocumentType.PROJECT.type,
                     POIFSDocumentType.VISIO.type,
                     // Works isn't supported
+                    POIFSDocumentType.XLR.type, // but Works 7.0 Spreadsheet is
                     POIFSDocumentType.OUTLOOK.type,
                     MediaType.application("vnd.ms-excel.sheet.binary.macroenabled.12")
                     )));
@@ -84,6 +85,7 @@ public class OfficeParser extends AbstractParser {
         PROJECT("mpp", MediaType.application("vnd.ms-project")),
         VISIO("vsd", MediaType.application("vnd.visio")),
         WORKS("wps", MediaType.application("vnd.ms-works")),
+        XLR("xlr", MediaType.application("x-tika-msworks-spreadsheet")),
         OUTLOOK("msg", MediaType.application("vnd.ms-outlook"));
 
         private final String extension;
@@ -186,6 +188,7 @@ public class OfficeParser extends AbstractParser {
            new HSLFExtractor(context).parse(root, xhtml);
            break;
         case WORKBOOK:
+        case XLR:
            Locale locale = context.get(Locale.class, Locale.getDefault());
            new ExcelExtractor(context).parse(root, xhtml, locale);
            break;
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java
index 6a6e0137f..2340875eb 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java
@@ -71,6 +71,9 @@ public class POIFSContainerDetector implements Detector {
 
     /** Microsoft Works */
     public static final MediaType WPS = application("vnd.ms-works");
+    
+    /** Microsoft Works Spreadsheet 7.0 */
+    public static final MediaType XLR = application("x-tika-msworks-spreadsheet");
 
     /** Microsoft Outlook */
     public static final MediaType MSG = application("vnd.ms-outlook");
@@ -133,7 +136,12 @@ public class POIFSContainerDetector implements Detector {
      */
     protected static MediaType detect(Set<String> names) {
         if (names != null) {
-            if (names.contains("Workbook")) {
+            if (names.contains("WksSSWorkBook")) {
+                // This check has to be before names.contains("Workbook")
+                // Works 7.0 spreadsheet files contain both
+                // we want to avoid classifying this as Excel
+                return XLR; 
+            } else if (names.contains("Workbook")) {
                 return XLS;
             } else if (names.contains("EncryptedPackage") && 
                     names.contains("EncryptionInfo") &&
diff --git a/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java b/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
index 25626d816..19b54c5f1 100644
--- a/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
+++ b/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
@@ -70,6 +70,7 @@ public class TestContainerAwareDetector extends TestCase {
         assertTypeByData("testPUBLISHER.pub", "application/x-mspublisher");
         assertTypeByData("testWORKS.wps", "application/vnd.ms-works");
         assertTypeByData("testWORKS2000.wps", "application/vnd.ms-works");
+        assertTypeByData("testWORKSSpreadsheet7.0.xlr", "application/x-tika-msworks-spreadsheet");
         assertTypeByData("testPROJECT2003.mpp", "application/vnd.ms-project");
         assertTypeByData("testPROJECT2007.mpp", "application/vnd.ms-project");
 
diff --git a/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java b/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
index c7fc8e6be..0ea5609a8 100644
--- a/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
+++ b/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
@@ -1,5 +1,5 @@
 /*
- * Licensed to the Apache Software Foundation (ASF) under one or more
+* Licensed to the Apache Software Foundation (ASF) under one or more
  * contributor license agreements.  See the NOTICE file distributed with
  * this work for additional information regarding copyright ownership.
  * The ASF licenses this file to You under the Apache License, Version 2.0
@@ -27,7 +27,9 @@ import junit.framework.TestCase;
 
 import org.apache.tika.Tika;
 import org.apache.tika.config.TikaConfig;
+import org.apache.tika.detect.DefaultDetector;
 import org.apache.tika.metadata.Metadata;
+import org.apache.tika.parser.microsoft.POIFSContainerDetector;
 
 /**
  * 
@@ -148,6 +150,35 @@ public class TestMimeTypes extends TestCase {
         assertTypeByNameAndData("application/msword", "testWORD.doc");
     }
     
+    /**
+     * Files generated by Works 7.0 Spreadsheet application use the OLE2
+     * structure and resemble Excel files (they contain a "Workbook"). They are
+     * not Excel though. The {@link POIFSContainerDetector} can detect them
+     * properly. With plain {@link MimeTypes} they are detected as Excel,
+     * because of the "Workbook" string. It's a problem we discussed in TIKA-806
+     * and agreed that we live with that. The policy is that container-based
+     * detection should trump magic-based detection. It's implemented in
+     * {@link DefaultDetector} (TIKA-786) and users who don't want to use to
+     * {@link DefaultDetector} should be aware of it.
+     * 
+     * @throws Exception
+     */
+    public void testWorks70Detection() throws Exception {
+        // this is possible due to MimeTypes guessing the type
+        // based on the WksSSWorkBook near the beginning of the
+        // file
+        assertTypeByData("application/x-tika-msworks-spreadsheet",
+                "testWORKSSpreadsheet7.0.xlr");
+        
+        // this is right, we made x-xlr a subtype of vnd.ms-excel
+        assertTypeByNameAndData("application/x-tika-msworks-spreadsheet",
+                "testWORKSSpreadsheet7.0.xlr");
+        
+        // with name-only, everything should be all right
+        assertTypeByName("application/x-tika-msworks-spreadsheet", 
+                "testWORKSSpreadsheet7.0.xlr");
+    }
+    
     /**
      * Note - detecting container formats by mime magic is very very
      *  iffy, as we can't be sure where things will end up.
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ExcelParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ExcelParserTest.java
index 7e58b5cd4..d95b3cf8d 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ExcelParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ExcelParserTest.java
@@ -192,5 +192,22 @@ public class ExcelParserTest extends TestCase {
             input.close();
         }
     }
+    
+    public void testWorksSpreadsheet70() throws Exception {
+        InputStream input = ExcelParserTest.class.getResourceAsStream(
+                "/test-documents/testWORKSSpreadsheet7.0.xlr");
+        try {
+            Metadata metadata = new Metadata();
+            ContentHandler handler = new BodyContentHandler(-1);
+            ParseContext context = new ParseContext();
+            context.set(Locale.class, Locale.US);
+            new OfficeParser().parse(input, handler, metadata, context);
+
+            String content = handler.toString();
+            assertTrue(content.contains("Microsoft Works"));
+        } finally {
+            input.close();
+        }
+    }
 
 }
diff --git a/tika-parsers/src/test/resources/test-documents/testWORKSSpreadsheet7.0.xlr b/tika-parsers/src/test/resources/test-documents/testWORKSSpreadsheet7.0.xlr
new file mode 100644
index 000000000..d59473353
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testWORKSSpreadsheet7.0.xlr differ

Commit:
4287c50ce36dd48ec9ec99bbd66b73ee594af889
Nick Burch
nick@apache.org
2011-12-13 04:13:53 +0000
TIKA-803 Wrap the outlook message body in a special div
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OutlookExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OutlookExtractor.java
index 63d0653df..18819264d 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OutlookExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OutlookExtractor.java
@@ -182,6 +182,7 @@ public class OutlookExtractor extends AbstractPOIFSExtractor {
            }
            
            boolean doneBody = false;
+           xhtml.startElement("div", "class", "message-body");
            if(htmlChunk != null) {
               byte[] data = null;
               if(htmlChunk instanceof ByteChunk) {
@@ -215,6 +216,7 @@ public class OutlookExtractor extends AbstractPOIFSExtractor {
            if(textChunk != null && !doneBody) {
               xhtml.element("p", ((StringChunk)textChunk).getValue());
            }
+           xhtml.endElement("div");
            
            // Process the attachments
            for (AttachmentChunks attachment : msg.getAttachmentFiles()) {
@@ -245,7 +247,6 @@ public class OutlookExtractor extends AbstractPOIFSExtractor {
                }
 
                xhtml.endElement("div");
-               
            }
         } catch(ChunkNotFoundException e) {
            throw new TikaException("POI MAPIMessage broken - didn't return null on missing chunk", e);

Commit:
50d6e5858d1557c00a42726cbe59cce3453db245
Nick Burch
nick@apache.org
2011-12-12 03:11:15 +0000
TIKA-808 Remove un-used fork test imports
diff --git a/tika-core/src/test/java/org/apache/tika/fork/ForkParserTest.java b/tika-core/src/test/java/org/apache/tika/fork/ForkParserTest.java
index 2cc1a116b..e3a388f06 100644
--- a/tika-core/src/test/java/org/apache/tika/fork/ForkParserTest.java
+++ b/tika-core/src/test/java/org/apache/tika/fork/ForkParserTest.java
@@ -25,12 +25,10 @@ import java.util.concurrent.Semaphore;
 
 import junit.framework.TestCase;
 
-import org.apache.tika.exception.TikaException;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.sax.BodyContentHandler;
 import org.xml.sax.ContentHandler;
-import org.xml.sax.SAXException;
 import org.xml.sax.helpers.DefaultHandler;
 
 public class ForkParserTest extends TestCase {

Commit:
eec596c1b44922b7bd1e177f485338f8e8adf826
Nick Burch
nick@apache.org
2011-12-12 03:07:51 +0000
TIKA-809 Handle embedded files with no file extension
diff --git a/tika-app/src/main/java/org/apache/tika/gui/TikaGUI.java b/tika-app/src/main/java/org/apache/tika/gui/TikaGUI.java
index a8746de6c..87ce1e986 100644
--- a/tika-app/src/main/java/org/apache/tika/gui/TikaGUI.java
+++ b/tika-app/src/main/java/org/apache/tika/gui/TikaGUI.java
@@ -575,7 +575,13 @@ public class TikaGUI extends JFrame
       }
       
       public File requestSave(String embeddedName) throws IOException {
-         String suffix = embeddedName.substring(embeddedName.lastIndexOf('.'));
+         String suffix = ".tika";
+         
+         int splitAt = embeddedName.lastIndexOf('.');
+         if (splitAt > 0) {
+            embeddedName.substring(splitAt);
+         }
+         
          File tmp = File.createTempFile("tika-embedded-", suffix);
          wanted.put(embeddedName, tmp);
          return tmp;

Commit:
f8e572b5a18699ff25f1bf21744662877a3d362f
Nick Burch
nick@apache.org
2011-12-12 02:25:29 +0000
Add disabled tests for TIKA-808 (parser needs fixing so that tests can pass)
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/fork/ForkParserIntegrationTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/fork/ForkParserIntegrationTest.java
new file mode 100644
index 000000000..1d06c7cfe
--- /dev/null
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/fork/ForkParserIntegrationTest.java
@@ -0,0 +1,86 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.parser.fork;
+
+import java.io.InputStream;
+
+import junit.framework.TestCase;
+
+import org.apache.tika.fork.ForkParser;
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.parser.ParseContext;
+import org.apache.tika.sax.BodyContentHandler;
+import org.xml.sax.ContentHandler;
+
+/**
+ * Test that the ForkParser correctly behaves when
+ *  wired in to the regular Parsers and their test data
+ */
+public class ForkParserIntegrationTest extends TestCase {
+    /**
+     * Simple text parsing
+     * TODO Fix this test so it passes
+     */
+    public void DISABLEDtestForkedTextParsing() throws Exception {
+       final ForkParser parser = new ForkParser(
+             ForkParserIntegrationTest.class.getClassLoader(),
+             new ForkParser());
+
+       try {
+          ContentHandler output = new BodyContentHandler();
+          InputStream stream = ForkParserIntegrationTest.class.getResourceAsStream("testTXT.txt");
+          ParseContext context = new ParseContext();
+          parser.parse(stream, output, new Metadata(), context);
+
+          String content = output.toString();
+          assertTrue(content.contains("Test d'indexation"));
+          assertTrue(content.contains("http://www.apache.org/"));
+       } finally {
+          parser.close();
+       }
+    }
+   
+    /**
+     * TIKA-808 - Ensure that parsing of our test PDFs work under
+     *  the Fork Parser, to ensure that complex parsing behaves
+     * TODO Fix this test so it passes
+     */
+    public void DISABLEDtestForkedPDFParsing() throws Exception {
+       final ForkParser parser = new ForkParser(
+             ForkParserIntegrationTest.class.getClassLoader(),
+             new ForkParser());
+       
+       try {
+          ContentHandler output = new BodyContentHandler();
+          InputStream stream = ForkParserIntegrationTest.class.getResourceAsStream("testPDF.pdf");
+          ParseContext context = new ParseContext();
+          parser.parse(stream, output, new Metadata(), context);
+          
+          String content = output.toString();
+          assertTrue(content.contains("Apache Tika"));
+          assertTrue(content.contains("Tika - Content Analysis Toolkit"));
+          assertTrue(content.contains("incubator"));
+          assertTrue(content.contains("Apache Software Foundation"));
+      } finally {
+          parser.close();
+      }
+    }
+    
+    public void testDUMMY() {
+       // To avoid warnings about no tests while others are disabled
+    }
+}

Commit:
b73dccb6bc47d33bdb6f1e51b723c7ef6bf3e1a3
Michael McCandless
mikemccand@apache.org
2011-12-09 18:48:49 +0000
TIKA-801: fixed NPE when filtering Outlook docs with RTF or HTML content
diff --git a/CHANGES.txt b/CHANGES.txt
index ed9055c43..0cd53fcad 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -17,7 +17,6 @@ Release 1.1 - Current Development
    XHTML output, causing NPE when opening some PDFs with the GUI
    (TIKA-778).
 
-
  * RTF: Fixed case where a font change would result in processing
    bytes in the wrong font's charset, producing bogus text output
    (TIKA-777).  Don't output whitespace in ignored group states,
@@ -40,6 +39,9 @@ Release 1.1 - Current Development
  * Microsoft Project (MPP): Filetype detection has been fixed,
    and basic metadata (but no text) is now extracted. (TIKA-789)
 
+ * Outlook: fixed NullPointerException in TikaGUI when messages with
+   embedded RTF or HTML content were filtered (TIKA-801).
+
 Release 1.0 - 11/4/2011
 ---------------------------------
 
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OutlookExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OutlookExtractor.java
index 94dfc0a47..63d0653df 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OutlookExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OutlookExtractor.java
@@ -42,6 +42,7 @@ import org.apache.tika.parser.rtf.RTFParser;
 import org.apache.tika.parser.txt.CharsetDetector;
 import org.apache.tika.parser.txt.CharsetMatch;
 import org.apache.tika.sax.BodyContentHandler;
+import org.apache.tika.sax.EmbeddedContentHandler;
 import org.apache.tika.sax.XHTMLContentHandler;
 import org.xml.sax.SAXException;
 
@@ -189,10 +190,11 @@ public class OutlookExtractor extends AbstractPOIFSExtractor {
                  data = ((StringChunk)htmlChunk).getRawValue();
               }
               if(data != null) {
+                  // nocommit same problem here?
                  HtmlParser htmlParser = new HtmlParser();
                  htmlParser.parse(
                        new ByteArrayInputStream(data),
-                       new BodyContentHandler(xhtml), 
+                       new EmbeddedContentHandler(new BodyContentHandler(xhtml)), 
                        new Metadata(), new ParseContext()
                  );
                  doneBody = true;
@@ -206,8 +208,8 @@ public class OutlookExtractor extends AbstractPOIFSExtractor {
               RTFParser rtfParser = new RTFParser();
               rtfParser.parse(
                               new ByteArrayInputStream(rtf.getData()),
-                              xhtml, new Metadata(), new ParseContext()
-                              );
+                              new EmbeddedContentHandler(new BodyContentHandler(xhtml)),
+                              new Metadata(), new ParseContext());
               doneBody = true;
            }
            if(textChunk != null && !doneBody) {
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/OutlookParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/OutlookParserTest.java
index 7a3edba6c..6d18859bf 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/OutlookParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/OutlookParserTest.java
@@ -170,7 +170,34 @@ public class OutlookParserTest extends TestCase {
         
         // Make sure we don't have nested html docs
         assertEquals(2, content.split("<body>").length);
-        //assertEquals(2, content.split("<\\/body>").length); // TODO Fix
+        assertEquals(2, content.split("<\\/body>").length);
+    }
+
+    public void testOutlookForwarded() throws Exception {
+        Parser parser = new AutoDetectParser();
+        Metadata metadata = new Metadata();
+       
+        // Check the HTML version
+        StringWriter sw = new StringWriter();
+        SAXTransformerFactory factory = (SAXTransformerFactory)
+                 SAXTransformerFactory.newInstance();
+        TransformerHandler handler = factory.newTransformerHandler();
+        handler.getTransformer().setOutputProperty(OutputKeys.METHOD, "xml");
+        handler.getTransformer().setOutputProperty(OutputKeys.INDENT, "yes");
+        handler.setResult(new StreamResult(sw));
+
+        InputStream stream = OutlookParserTest.class.getResourceAsStream(
+               "/test-documents/testMSG_forwarded.msg");
+        try {
+           parser.parse(stream, handler, metadata, new ParseContext());
+        } finally {
+           stream.close();
+        }
+         
+        // Make sure we don't have nested docs
+        String content = sw.toString();
+        assertEquals(2, content.split("<body>").length);
+        assertEquals(2, content.split("<\\/body>").length);
     }
     
     public void testOutlookHTMLfromRTF() throws Exception {
diff --git a/tika-parsers/src/test/resources/test-documents/testMSG_forwarded.msg b/tika-parsers/src/test/resources/test-documents/testMSG_forwarded.msg
new file mode 100644
index 000000000..d74d31a5e
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testMSG_forwarded.msg differ

Commit:
707b8f2157ffcdb6a8e8871baa53258b3b5b9ea7
Nick Burch
nick@apache.org
2011-12-08 05:30:39 +0000
Add TikaCLI help for the -f/--fork option previously added for TIKA-416
diff --git a/tika-app/src/main/java/org/apache/tika/cli/TikaCLI.java b/tika-app/src/main/java/org/apache/tika/cli/TikaCLI.java
index f9d3c2d94..e0e193963 100644
--- a/tika-app/src/main/java/org/apache/tika/cli/TikaCLI.java
+++ b/tika-app/src/main/java/org/apache/tika/cli/TikaCLI.java
@@ -414,6 +414,7 @@ public class TikaCLI {
         out.println();
         out.println("    -g  or --gui           Start the Apache Tika GUI");
         out.println("    -s  or --server        Start the Apache Tika server");
+        out.println("    -f  or --fork          Use Fork Mode for out-of-process extraction");
         out.println();
         out.println("    -x  or --xml           Output XHTML content (default)");
         out.println("    -h  or --html          Output HTML content");

Commit:
7e2393fabca843e0c596eae2a29aebea3a937842
Jukka Zitting
jukka@apache.org
2011-12-06 17:06:45 +0000
TIKA-567: Temporary file leak in TikaInputStream
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
index 3daecd2f5..478a8ab8c 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
@@ -39,18 +39,20 @@ public class OOXMLParserTest extends TikaTest {
 
     private Parser parser = new AutoDetectParser();
 
-   public void testExcel() throws Exception {
-        InputStream input = OOXMLParserTest.class
-                .getResourceAsStream("/test-documents/testEXCEL.xlsx");
-        assertNotNull(input);
+    private InputStream getTestDocument(String name) {
+        return TikaInputStream.get(OOXMLParserTest.class.getResourceAsStream(
+                "/test-documents/" + name));
+    }
 
+    public void testExcel() throws Exception {
         Metadata metadata = new Metadata(); 
         ContentHandler handler = new BodyContentHandler();
         ParseContext context = new ParseContext();
         context.set(Locale.class, Locale.US);
 
+        InputStream input = getTestDocument("testEXCEL.xlsx");
         try {
-            parser.parse(TikaInputStream.get(input), handler, metadata, context);
+            parser.parse(input, handler, metadata, context);
 
             assertEquals(
                     "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
@@ -71,16 +73,14 @@ public class OOXMLParserTest extends TikaTest {
     }
 
     public void testExcelFormats() throws Exception {
-        InputStream input = OOXMLParserTest.class
-                .getResourceAsStream("/test-documents/testEXCEL-formats.xlsx");
-
         Metadata metadata = new Metadata();
         ContentHandler handler = new BodyContentHandler();
         ParseContext context = new ParseContext();
         context.set(Locale.class, Locale.US);
 
+        InputStream input = getTestDocument("testEXCEL-formats.xlsx");
         try {
-            parser.parse(TikaInputStream.get(input), handler, metadata, context);
+            parser.parse(input, handler, metadata, context);
 
             assertEquals(
                     "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
@@ -168,9 +168,6 @@ public class OOXMLParserTest extends TikaTest {
             String extension = extensions[i];
             String filename = "testPPT." + extension;
 
-            InputStream input = OOXMLParserTest.class
-                    .getResourceAsStream("/test-documents/"+filename);
-    
             Parser parser = new AutoDetectParser();
             Metadata metadata = new Metadata();
             // TODO: should auto-detect without the resource name
@@ -178,6 +175,7 @@ public class OOXMLParserTest extends TikaTest {
             ContentHandler handler = new BodyContentHandler();
             ParseContext context = new ParseContext();
     
+            InputStream input = getTestDocument(filename);
             try {
                 parser.parse(input, handler, metadata, context);
     
@@ -225,15 +223,13 @@ public class OOXMLParserTest extends TikaTest {
      * @throws Exception
      */
     public void testWord() throws Exception {
-        InputStream input = OOXMLParserTest.class
-                .getResourceAsStream("/test-documents/testWORD.docx");
-
         Metadata metadata = new Metadata();
         ContentHandler handler = new BodyContentHandler();
         ParseContext context = new ParseContext();
 
+        InputStream input = getTestDocument("testWORD.docx");
         try {
-            parser.parse(TikaInputStream.get(input), handler, metadata, context);
+            parser.parse(input, handler, metadata, context);
             assertEquals(
                     "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                     metadata.get(Metadata.CONTENT_TYPE));
@@ -250,15 +246,13 @@ public class OOXMLParserTest extends TikaTest {
      * @throws Exception
      */
     public void testWordFootnote() throws Exception {
-        InputStream input = OOXMLParserTest.class
-                .getResourceAsStream("/test-documents/footnotes.docx");
-
         Metadata metadata = new Metadata();
         ContentHandler handler = new BodyContentHandler();
         ParseContext context = new ParseContext();
 
+        InputStream input = getTestDocument("footnotes.docx");
         try {
-            parser.parse(TikaInputStream.get(input), handler, metadata, context);
+            parser.parse(input, handler, metadata, context);
             assertEquals(
                     "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                     metadata.get(Metadata.CONTENT_TYPE));
@@ -278,10 +272,7 @@ public class OOXMLParserTest extends TikaTest {
       }
     }
 
-    private XMLResult getXML(String filePath) throws Exception {
-        InputStream input = null;
-        Metadata metadata = new Metadata();
-        
+    private XMLResult getXML(String name) throws Exception {
         StringWriter sw = new StringWriter();
         SAXTransformerFactory factory = (SAXTransformerFactory)
                  SAXTransformerFactory.newInstance();
@@ -291,9 +282,10 @@ public class OOXMLParserTest extends TikaTest {
         handler.setResult(new StreamResult(sw));
 
         // Try with a document containing various tables and formattings
-        input = OOXMLParserTest.class.getResourceAsStream(filePath);
+        InputStream input = getTestDocument(name);
         try {
-            parser.parse(TikaInputStream.get(input), handler, metadata, new ParseContext());
+            Metadata metadata = new Metadata();
+            parser.parse(input, handler, metadata, new ParseContext());
             return new XMLResult(sw.toString(), metadata);
         } finally {
             input.close();
@@ -306,7 +298,7 @@ public class OOXMLParserTest extends TikaTest {
      */
     public void testWordHTML() throws Exception {
 
-      XMLResult result = getXML("/test-documents/testWORD.docx");
+      XMLResult result = getXML("testWORD.docx");
       String xml = result.xml;
       Metadata metadata = result.metadata;
       assertEquals(
@@ -336,7 +328,7 @@ public class OOXMLParserTest extends TikaTest {
       // Paragraphs with other styles
       assertTrue(xml.contains("<p class=\"signature\">This one"));
 
-      result = getXML("/test-documents/testWORD_3imgs.docx");
+      result = getXML("testWORD_3imgs.docx");
       xml = result.xml;
 
       // Images 2-4 (there is no 1!)
@@ -349,7 +341,7 @@ public class OOXMLParserTest extends TikaTest {
 
       // TIKA-692: test document containing multiple
       // character runs within a bold tag:
-      xml = getXML("/test-documents/testWORD_bold_character_runs.docx").xml;
+      xml = getXML("testWORD_bold_character_runs.docx").xml;
 
       // Make sure bold text arrived as single
       // contiguous string even though Word parser
@@ -358,7 +350,7 @@ public class OOXMLParserTest extends TikaTest {
 
       // TIKA-692: test document containing multiple
       // character runs within a bold tag:
-      xml = getXML("/test-documents/testWORD_bold_character_runs2.docx").xml;
+      xml = getXML("testWORD_bold_character_runs2.docx").xml;
             
       // Make sure bold text arrived as single
       // contiguous string even though Word parser
@@ -370,7 +362,6 @@ public class OOXMLParserTest extends TikaTest {
      * Test that we can extract image from docx header
      */
     public void testWordPicturesInHeader() throws Exception {
-        InputStream input = null;
         Metadata metadata = new Metadata();
         ParseContext context = new ParseContext();
 
@@ -383,9 +374,9 @@ public class OOXMLParserTest extends TikaTest {
         handler.setResult(new StreamResult(sw));
 
         // Try with a document containing various tables and formattings
-        input = OOXMLParserTest.class.getResourceAsStream("/test-documents/headerPic.docx");
+        InputStream input = getTestDocument("headerPic.docx");
         try {
-            parser.parse(TikaInputStream.get(input), handler, metadata, context);
+            parser.parse(input, handler, metadata, context);
             String xml = sw.toString();
             assertEquals(
                     "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
@@ -428,14 +419,13 @@ public class OOXMLParserTest extends TikaTest {
      * See TIKA-437.
      */
     public void testProtectedExcelFile() throws Exception {
-        InputStream input = OOXMLParserTest.class
-                .getResourceAsStream("/test-documents/protectedFile.xlsx");
 
         Parser parser = new AutoDetectParser();
         Metadata metadata = new Metadata();
         ContentHandler handler = new BodyContentHandler();
         ParseContext context = new ParseContext();
 
+        InputStream input = getTestDocument("protectedFile.xlsx");
         try {
             parser.parse(input, handler, metadata, context);
 
@@ -462,9 +452,9 @@ public class OOXMLParserTest extends TikaTest {
         ContentHandler handler = new BodyContentHandler();
         ParseContext context = new ParseContext();
 
-        InputStream input = OOXMLParserTest.class.getResourceAsStream("/test-documents/NullHeader.docx");
+        InputStream input = getTestDocument("NullHeader.docx");
         try {
-            parser.parse(TikaInputStream.get(input), handler, metadata, context);
+            parser.parse(input, handler, metadata, context);
             assertFalse(handler.toString().length()==0);
         } finally {
             input.close();

Commit:
7e2326a8050352a38c2d278174877211d1049436
Jukka Zitting
jukka@apache.org
2011-12-06 17:06:32 +0000
TIKA-800: mark/reset not supported from POIFSContainerDetector
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/pkg/PackageExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/pkg/PackageExtractor.java
index 1d5df628c..8c9c63885 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/pkg/PackageExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/pkg/PackageExtractor.java
@@ -33,6 +33,7 @@ import org.apache.tika.exception.TikaException;
 import org.apache.tika.extractor.EmbeddedDocumentExtractor;
 import org.apache.tika.extractor.ParsingEmbeddedDocumentExtractor;
 import org.apache.tika.io.CloseShieldInputStream;
+import org.apache.tika.io.TemporaryResources;
 import org.apache.tika.io.TikaInputStream;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.parser.ParseContext;
@@ -150,9 +151,10 @@ class PackageExtractor {
      * @param xhtml content handler
      * @throws IOException if an IO error occurs
      * @throws SAXException if a SAX error occurs
+     * @throws TikaException if another error occurs
      */
     public void unpack(ArchiveInputStream archive, XHTMLContentHandler xhtml)
-            throws IOException, SAXException {
+            throws IOException, SAXException, TikaException {
         try {
             ArchiveEntry entry = archive.getNextEntry();
             while (entry != null) {
@@ -167,8 +169,13 @@ class PackageExtractor {
                         if (extractor.shouldParseEmbedded(entrydata)) {
                             // For detectors to work, we need a mark/reset supporting
                             //  InputStream, which ArchiveInputStream isn't, so wrap
-                            TikaInputStream stream = TikaInputStream.get(archive);
-                            extractor.parseEmbedded(stream, xhtml, entrydata, true);
+                            TemporaryResources tmp = new TemporaryResources();
+                            try {
+                                TikaInputStream stream = TikaInputStream.get(archive, tmp);
+                                extractor.parseEmbedded(stream, xhtml, entrydata, true);
+                            } finally {
+                                tmp.dispose();
+                            }
                         }
                     } else if (name != null && name.length() > 0) {
                         xhtml.element("p", name);

Commit:
852f14826948a66e23a76f7df41da76e61e7a387
Jukka Zitting
jukka@apache.org
2011-12-06 15:35:17 +0000
TIKA-565: Improved OSGi bundling
diff --git a/tika-parsers/pom.xml b/tika-parsers/pom.xml
index 5bee31742..14f31aa55 100644
--- a/tika-parsers/pom.xml
+++ b/tika-parsers/pom.xml
@@ -215,6 +215,37 @@
         </executions>
       </plugin>
     </plugins>
+
+    <pluginManagement>
+      <plugins>
+        <!-- This plugin's configuration is used to store Eclipse m2e      -->
+        <!-- settings only. It has no influence on the Maven build itself. -->
+        <plugin>
+          <groupId>org.eclipse.m2e</groupId>
+          <artifactId>lifecycle-mapping</artifactId>
+          <version>1.0.0</version>
+          <configuration>
+            <lifecycleMappingMetadata>
+              <pluginExecutions>
+                <pluginExecution>
+                  <pluginExecutionFilter>
+                    <groupId>org.apache.felix</groupId>
+                    <artifactId>maven-scr-plugin</artifactId>
+                    <versionRange>[1.7.2,)</versionRange>
+                    <goals>
+                      <goal>scr</goal>
+                    </goals>
+                  </pluginExecutionFilter>
+                  <action>
+                    <execute/>
+                  </action>
+                </pluginExecution>
+              </pluginExecutions>
+            </lifecycleMappingMetadata>
+          </configuration>
+        </plugin>
+      </plugins>
+    </pluginManagement>
   </build>
 
 </project>

Commit:
374538b413fffbc254dca221e7a56021421e8871
Nick Burch
nick@apache.org
2011-12-06 01:13:23 +0000
TIKA-800 Wrap the ArchiveInputStream in PackageExtractor so that it can be used with Detectors
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/pkg/PackageExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/pkg/PackageExtractor.java
index 2ff323c4f..1d5df628c 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/pkg/PackageExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/pkg/PackageExtractor.java
@@ -33,6 +33,7 @@ import org.apache.tika.exception.TikaException;
 import org.apache.tika.extractor.EmbeddedDocumentExtractor;
 import org.apache.tika.extractor.ParsingEmbeddedDocumentExtractor;
 import org.apache.tika.io.CloseShieldInputStream;
+import org.apache.tika.io.TikaInputStream;
 import org.apache.tika.metadata.Metadata;
 import org.apache.tika.parser.ParseContext;
 import org.apache.tika.sax.XHTMLContentHandler;
@@ -164,7 +165,10 @@ class PackageExtractor {
                             entrydata.set(Metadata.RESOURCE_NAME_KEY, name);
                         }
                         if (extractor.shouldParseEmbedded(entrydata)) {
-                            extractor.parseEmbedded(archive, xhtml, entrydata, true);
+                            // For detectors to work, we need a mark/reset supporting
+                            //  InputStream, which ArchiveInputStream isn't, so wrap
+                            TikaInputStream stream = TikaInputStream.get(archive);
+                            extractor.parseEmbedded(stream, xhtml, entrydata, true);
                         }
                     } else if (name != null && name.length() > 0) {
                         xhtml.element("p", name);

Commit:
82ddc5381b8a2127e66828dd1faa0b469aa354f0
Nick Burch
nick@apache.org
2011-12-05 03:44:42 +0000
TIKA-410 Word Parser support for extracting textbox content (Patch from John Mastarone)
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/WordExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/WordExtractor.java
index b7fa106fc..9ff57352d 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/WordExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/WordExtractor.java
@@ -98,7 +98,11 @@ public class WordExtractor extends AbstractPOIFSExtractor {
         }
 
         // Do everything else
-        for (String paragraph : wordExtractor.getFootnoteText()) {
+        for (String paragraph: wordExtractor.getMainTextboxText()) {
+            xhtml.element("p", paragraph);
+        }
+
+	for (String paragraph : wordExtractor.getFootnoteText()) {
             xhtml.element("p", paragraph);
         }
 
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/WordParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/WordParserTest.java
index 4e3f15e07..63bcc0f31 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/WordParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/WordParserTest.java
@@ -202,8 +202,7 @@ public class WordParserTest extends TikaTest {
         assertContains("This is a footnote.", content);
         assertContains("This is the header text.", content);
         assertContains("This is the footer text.", content);
-        // TODO: WordExtractor misses this
-        //assertContains("Here is a text box", content);
+        assertContains("Here is a text box", content);
         assertContains("Bold", content);
         assertContains("italic", content);
         assertContains("underline", content);

Commit:
513dbdb28e0a3f7311e302646dc64bd2f0f3389d
Nick Burch
nick@apache.org
2011-12-05 00:32:53 +0000
TIKA-798 - EMF and WMF metafiles aren't the same, so split the mimetypes, plus add magic+tests for them (patch from Antoni)
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 57d58fc2c..72c464ea2 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -2365,6 +2365,15 @@
     <glob pattern="*.elc"/>
   </mime-type>
 
+  <mime-type type="application/x-emf">
+    <acronym>EMF</acronym>
+    <_comment>Extended Metafile</_comment>
+    <glob pattern="*.emf"/>
+    <magic priority="50">
+      <match value="0x01000000" type="string" offset="0"/>
+    </magic>
+  </mime-type>
+
   <mime-type type="application/x-font-bdf">
     <glob pattern="*.bdf"/>
   </mime-type>
@@ -2593,12 +2602,14 @@
     <glob pattern="*.m14"/>
   </mime-type>
   <mime-type type="application/x-msmetafile">
-    <alias type="image/x-emf"/>
     <alias type="image/x-wmf"/>
     <acronym>WMF</acronym>
     <_comment>Windows Metafile</_comment>
     <glob pattern="*.wmf"/>
-    <glob pattern="*.emf"/>
+    <magic priority="50">
+      <match value="0xd7cdc69a0000" type="string" offset="0"/>
+      <match value="0x010009000003" type="string" offset="0"/>
+    </magic>
   </mime-type>
   <mime-type type="application/x-msmoney">
     <glob pattern="*.mny"/>
diff --git a/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java b/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
index d54ff1669..c7fc8e6be 100644
--- a/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
+++ b/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
@@ -328,16 +328,17 @@ public class TestMimeTypes extends TestCase {
    }
 
     public void testWmfDetection() throws Exception {
-        // TODO: Need a test wmf file
         assertTypeByName("application/x-msmetafile", "x.wmf");
+        assertTypeByData("application/x-msmetafile", "testWMF.wmf");
         assertTypeByName("application/x-msmetafile", "x.WMF");
-        // TODO: Need a test emf file
-        assertTypeByName("application/x-msmetafile", "x.emf");
-        assertTypeByName("application/x-msmetafile", "x.EMF");
+
+        assertTypeByName("application/x-emf", "x.emf");
+        assertTypeByData("application/x-emf","testEMF.emf");
+        assertTypeByName("application/x-emf", "x.EMF");
         // TODO: Need a test wmz file
         assertTypeByName("application/x-ms-wmz", "x.wmz");
         assertTypeByName("application/x-ms-wmz", "x.WMZ");
-        // TODO: Need a test emf file
+        // TODO: Need a test emz file
         assertTypeByName("application/x-gzip", "x.emz");
         assertTypeByName("application/x-gzip", "x.EMZ");
     }
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/AbstractPOIContainerExtractionTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/AbstractPOIContainerExtractionTest.java
index 8b130659a..258e364b8 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/AbstractPOIContainerExtractionTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/AbstractPOIContainerExtractionTest.java
@@ -47,7 +47,8 @@ public abstract class AbstractPOIContainerExtractionTest extends TestCase {
     public static final MediaType TYPE_JPG = MediaType.image("jpeg");
     public static final MediaType TYPE_GIF = MediaType.image("gif");
     public static final MediaType TYPE_PNG = MediaType.image("png");
-    public static final MediaType TYPE_EMF = MediaType.application("x-msmetafile");
+    public static final MediaType TYPE_EMF = MediaType.application("x-emf");
+    public static final MediaType TYPE_WMF = MediaType.application("x-msmetafile");
 
     protected TrackingHandler process(String filename, ContainerExtractor extractor, boolean recurse) throws Exception {
         TikaInputStream stream = getTestFile(filename);
diff --git a/tika-parsers/src/test/resources/test-documents/testEMF.emf b/tika-parsers/src/test/resources/test-documents/testEMF.emf
new file mode 100644
index 000000000..2314d93d6
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testEMF.emf differ
diff --git a/tika-parsers/src/test/resources/test-documents/testWMF.wmf b/tika-parsers/src/test/resources/test-documents/testWMF.wmf
new file mode 100644
index 000000000..f281df502
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testWMF.wmf differ

Commit:
90d327c0ec329c3c242d374331d04f7acca963fc
Nick Burch
nick@apache.org
2011-12-02 12:17:53 +0000
Patch+Test from Antoni from TIKA-797 - Correct the default PPT extension
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 48fa456d9..57d58fc2c 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -1288,8 +1288,8 @@
          <match value="P\x00o\x00w\x00e\x00r\x00P\x00o\x00i\x00n\x00t\x00 D\x00o\x00c\x00u\x00m\x00e\x00n\x00t" type="string" offset="1152:4096" />
       </match>
     </magic>
-    <glob pattern="*.ppz"/>
     <glob pattern="*.ppt"/>
+    <glob pattern="*.ppz"/>
     <glob pattern="*.pps"/>
     <glob pattern="*.pot"/>
     <glob pattern="*.ppa"/>
diff --git a/tika-core/src/test/java/org/apache/tika/mime/MimeTypesReaderTest.java b/tika-core/src/test/java/org/apache/tika/mime/MimeTypesReaderTest.java
index 900e4fdc4..3f2ac8e39 100644
--- a/tika-core/src/test/java/org/apache/tika/mime/MimeTypesReaderTest.java
+++ b/tika-core/src/test/java/org/apache/tika/mime/MimeTypesReaderTest.java
@@ -162,5 +162,12 @@ public class MimeTypesReaderTest extends TestCase {
           fail(e.getMessage());
        }
     }
+    
+    public void testGetExtensionForPowerPoint() throws Exception {
+        MimeType mt = this.mimeTypes.forName("application/vnd.ms-powerpoint");
+        String ext = mt.getExtension();
+        assertEquals(".ppt",ext);
+        assertEquals(".ppt",mt.getExtensions().get(0));
+    }
 
 }

Commit:
a78309d0739614ded08803b688ba9683bada270a
Nick Burch
nick@apache.org
2011-11-28 13:57:08 +0000
TIKA-790 Remove the duplicated detection code between OfficeParser and POIFSContainerDetector, by following the pattern from TIKA-791 and adding a type for OLE10Native, then pushing the rest of the detection work to POIFSContainerDetector
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index cbfbec8ee..48fa456d9 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -2761,6 +2761,11 @@
     </magic>
   </mime-type>
 
+  <mime-type type="application/x-tika-msoffice-embedded">
+    <sub-class-of type="application/x-tika-msoffice"/>
+    <_comment>OLE10 Native Embedded Document</_comment>
+  </mime-type>
+
   <!-- =================================================================== -->
   <!-- Office Open XML file formats                                        -->
   <!-- http://www.ecma-international.org/publications/standards/Ecma-376.htm -->
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java
index 8afb6cfff..368595fa3 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java
@@ -21,10 +21,8 @@ import java.io.InputStream;
 import java.security.GeneralSecurityException;
 import java.util.Arrays;
 import java.util.Collections;
-import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Locale;
-import java.util.Map;
 import java.util.Set;
 
 import org.apache.poi.hdgf.extractor.VisioTextExtractor;
@@ -77,7 +75,7 @@ public class OfficeParser extends AbstractParser {
 
     public enum POIFSDocumentType {
         WORKBOOK("xls", MediaType.application("vnd.ms-excel")),
-        OLE10_NATIVE("ole", MediaType.application("x-tika-msoffice")),
+        OLE10_NATIVE("ole", MediaType.application("x-tika-msoffice-embedded")),
         WORDDOCUMENT("doc", MediaType.application("msword")),
         UNKNOWN("unknown", MediaType.application("x-tika-msoffice")),
         ENCRYPTED("ole", MediaType.application("x-tika-ooxml-protected")),
@@ -113,39 +111,15 @@ public class OfficeParser extends AbstractParser {
        }
 
         public static POIFSDocumentType detectType(DirectoryEntry node) {
+            Set<String> names = new HashSet<String>();
             for (Entry entry : node) {
-                POIFSDocumentType type = detectType(entry);
-                if (type!=UNKNOWN) {
-                    return type;
-                }
+                names.add(entry.getName());
             }
-            return UNKNOWN;
-        }
-
-        // TODO Avoid this duplication with POIFSContainerDetector (TIKA-790)
-        private final static Map<String,POIFSDocumentType> typeMap = new HashMap<String,POIFSDocumentType>();
-        static {
-            typeMap.put("Workbook", WORKBOOK);
-            typeMap.put("EncryptedPackage", ENCRYPTED);
-            typeMap.put("WordDocument", WORDDOCUMENT);
-            typeMap.put("Quill", PUBLISHER);
-            typeMap.put("PowerPoint Document", POWERPOINT);
-            typeMap.put("VisioDocument", VISIO);
-            typeMap.put("CONTENTS", WORKS);
-            typeMap.put("\u0001Ole10Native", POIFSDocumentType.OLE10_NATIVE);
-            typeMap.put("Props", PROJECT);  // Project 8
-            typeMap.put("Props9", PROJECT); // Project 9, 10, 11
-            typeMap.put("Props12", PROJECT); // Project 12+
-        }
-
-        public static POIFSDocumentType detectType(Entry entry) {
-            String name = entry.getName();
-            POIFSDocumentType type = typeMap.get(name);
-            if (type != null) {
-                return type;
-            }
-            if (entry.getName().startsWith("__substg1.0_")) {
-                return OUTLOOK;
+            MediaType type = POIFSContainerDetector.detect(names);
+            for (POIFSDocumentType poifsType : values()) {
+               if (type.equals(poifsType.type)) {
+                  return poifsType;
+               }
             }
             return UNKNOWN;
         }
@@ -193,71 +167,64 @@ public class OfficeParser extends AbstractParser {
         new SummaryExtractor(metadata).parseSummaries(root);
 
         // Parse remaining document entries
-        boolean outlookExtracted = false;
-        for (Entry entry : root) {
-            POIFSDocumentType type = POIFSDocumentType.detectType(entry);
-
-            if (type!=POIFSDocumentType.UNKNOWN) {
-                setType(metadata, type.getType());
-            }
-
-            switch (type) {
-                case PUBLISHER:
-                    PublisherTextExtractor publisherTextExtractor =
-                        new PublisherTextExtractor(root);
-                    xhtml.element("p", publisherTextExtractor.getText());
-                    break;
-                case WORDDOCUMENT:
-                    new WordExtractor(context).parse(root, xhtml);
-                    break;
-                case POWERPOINT:
-                    new HSLFExtractor(context).parse(root, xhtml);
-                    break;
-                case WORKBOOK:
-                    Locale locale = context.get(Locale.class, Locale.getDefault());
-                    new ExcelExtractor(context).parse(root, xhtml, locale);
-                    break;
-                case PROJECT:
-                    // We currently can't do anything beyond the metadata
-                    break;
-                case VISIO:
-                    VisioTextExtractor visioTextExtractor =
-                        new VisioTextExtractor(root);
-                    for (String text : visioTextExtractor.getAllText()) {
-                        xhtml.element("p", text);
-                    }
-                    break;
-                case OUTLOOK:
-                    if (!outlookExtracted) {
-                        outlookExtracted = true;
-
-                        OutlookExtractor extractor =
-                            new OutlookExtractor(root, context);
-
-                        extractor.parse(xhtml, metadata);
-                    }
-                    break;
-                case ENCRYPTED:
-                    EncryptionInfo info = new EncryptionInfo(root);
-                    Decryptor d = Decryptor.getInstance(info);
+        POIFSDocumentType type = POIFSDocumentType.detectType(root);
 
-                    try {
-                        // TODO Allow the user to specify the password via the ParseContext
-                        if (!d.verifyPassword(Decryptor.DEFAULT_PASSWORD)) {
-                            throw new EncryptedDocumentException();
-                        }
-
-                        // Decrypt the OLE2 stream, and delegate the resulting OOXML
-                        //  file to the regular OOXML parser for normal handling
-                        OOXMLParser parser = new OOXMLParser();
+        if (type!=POIFSDocumentType.UNKNOWN) {
+            setType(metadata, type.getType());
+        }
 
-                        parser.parse(d.getDataStream(root), new EmbeddedContentHandler(
-                                        new BodyContentHandler(xhtml)),
-                                        metadata, context);
-                    } catch (GeneralSecurityException ex) {
-                        throw new EncryptedDocumentException(ex);
-                    }
-            }
+        switch (type) {
+        case PUBLISHER:
+           PublisherTextExtractor publisherTextExtractor =
+              new PublisherTextExtractor(root);
+           xhtml.element("p", publisherTextExtractor.getText());
+           break;
+        case WORDDOCUMENT:
+           new WordExtractor(context).parse(root, xhtml);
+           break;
+        case POWERPOINT:
+           new HSLFExtractor(context).parse(root, xhtml);
+           break;
+        case WORKBOOK:
+           Locale locale = context.get(Locale.class, Locale.getDefault());
+           new ExcelExtractor(context).parse(root, xhtml, locale);
+           break;
+        case PROJECT:
+           // We currently can't do anything beyond the metadata
+           break;
+        case VISIO:
+           VisioTextExtractor visioTextExtractor =
+              new VisioTextExtractor(root);
+           for (String text : visioTextExtractor.getAllText()) {
+              xhtml.element("p", text);
+           }
+           break;
+        case OUTLOOK:
+           OutlookExtractor extractor =
+                 new OutlookExtractor(root, context);
+
+           extractor.parse(xhtml, metadata);
+           break;
+        case ENCRYPTED:
+           EncryptionInfo info = new EncryptionInfo(root);
+           Decryptor d = Decryptor.getInstance(info);
+
+           try {
+              // TODO Allow the user to specify the password via the ParseContext
+              if (!d.verifyPassword(Decryptor.DEFAULT_PASSWORD)) {
+                 throw new EncryptedDocumentException();
+              }
+
+              // Decrypt the OLE2 stream, and delegate the resulting OOXML
+              //  file to the regular OOXML parser for normal handling
+              OOXMLParser parser = new OOXMLParser();
+
+              parser.parse(d.getDataStream(root), new EmbeddedContentHandler(
+                    new BodyContentHandler(xhtml)),
+                    metadata, context);
+           } catch (GeneralSecurityException ex) {
+              throw new EncryptedDocumentException(ex);
+           }
         }
     }
 
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java
index 5a04a7a10..6a6e0137f 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java
@@ -50,6 +50,9 @@ public class POIFSContainerDetector implements Detector {
     
     /** The protected OOXML base file format */
     public static final MediaType OOXML_PROTECTED = application("x-tika-ooxml-protected");
+    
+    /** An OLE10 Native embedded document within another OLE2 document */
+    public static final MediaType OLE10_NATIVE = application("x-tika-msoffice-embedded");
 
     /** Microsoft Excel */
     public static final MediaType XLS = application("vnd.ms-excel");
@@ -119,7 +122,16 @@ public class POIFSContainerDetector implements Detector {
             // Look for known top level entry names to detect the document type
             names = getTopLevelNames(tis);
         }
-
+        
+        // Detect based on the names (as available)
+        return detect(names);
+    }
+    
+    /**
+     * Internal detection of the specific kind of OLE2 document, based on the 
+     *  names of the top level streams within the file.
+     */
+    protected static MediaType detect(Set<String> names) {
         if (names != null) {
             if (names.contains("Workbook")) {
                 return XLS;
@@ -142,6 +154,8 @@ public class POIFSContainerDetector implements Detector {
                 return PPT;
             } else if (names.contains("VisioDocument")) {
                 return VSD;
+            } else if (names.contains("\u0001Ole10Native")) {
+                return OLE10_NATIVE;
             } else if (names.contains("CONTENTS") && names.contains("SPELLING")) {
                // Newer Works files
                return WPS;
@@ -161,8 +175,6 @@ public class POIFSContainerDetector implements Detector {
                      return MPP;
                   }
                }
-            } else if (names.contains("\u0001Ole10Native")) {
-                return OLE;
             } else if (names.contains("PerfectOffice_MAIN")) {
                 if (names.contains("SlideShow")) {
                     return MediaType.application("x-corelpresentations"); // .shw

Commit:
e735a659560602a1372c5aa64b3ee2475f0d1a67
Nick Burch
nick@apache.org
2011-11-28 13:35:29 +0000
TIKA-791 POIFS Container Detector support for encrypted OOXML files, plus tests and new (tika specific) mimetype
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 74a84b986..cbfbec8ee 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -2774,6 +2774,13 @@
     </magic>
   </mime-type>
 
+  <!-- Note - password protected OOXML files are actually stored in -->
+  <!--  an OLE2 (application/x-tika-msoffice) container -->
+  <mime-type type="application/x-tika-ooxml-protected">
+    <sub-class-of type="application/x-tika-ooxml"/>
+    <_comment>Password Protected OOXML File</_comment>
+  </mime-type>
+
   <mime-type type="application/x-ustar">
     <glob pattern="*.ustar"/>
   </mime-type>
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java
index f234780c8..8afb6cfff 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java
@@ -80,7 +80,7 @@ public class OfficeParser extends AbstractParser {
         OLE10_NATIVE("ole", MediaType.application("x-tika-msoffice")),
         WORDDOCUMENT("doc", MediaType.application("msword")),
         UNKNOWN("unknown", MediaType.application("x-tika-msoffice")),
-        ENCRYPTED("ole", MediaType.application("x-tika-msoffice")),
+        ENCRYPTED("ole", MediaType.application("x-tika-ooxml-protected")),
         POWERPOINT("ppt", MediaType.application("vnd.ms-powerpoint")),
         PUBLISHER("pub", MediaType.application("x-mspublisher")),
         PROJECT("mpp", MediaType.application("vnd.ms-project")),
@@ -242,10 +242,13 @@ public class OfficeParser extends AbstractParser {
                     Decryptor d = Decryptor.getInstance(info);
 
                     try {
+                        // TODO Allow the user to specify the password via the ParseContext
                         if (!d.verifyPassword(Decryptor.DEFAULT_PASSWORD)) {
                             throw new EncryptedDocumentException();
                         }
 
+                        // Decrypt the OLE2 stream, and delegate the resulting OOXML
+                        //  file to the regular OOXML parser for normal handling
                         OOXMLParser parser = new OOXMLParser();
 
                         parser.parse(d.getDataStream(root), new EmbeddedContentHandler(
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java
index 4ab5de485..5a04a7a10 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java
@@ -47,6 +47,9 @@ public class POIFSContainerDetector implements Detector {
 
     /** The OLE base file format */
     public static final MediaType OLE = application("x-tika-msoffice");
+    
+    /** The protected OOXML base file format */
+    public static final MediaType OOXML_PROTECTED = application("x-tika-ooxml-protected");
 
     /** Microsoft Excel */
     public static final MediaType XLS = application("vnd.ms-excel");
@@ -120,6 +123,15 @@ public class POIFSContainerDetector implements Detector {
         if (names != null) {
             if (names.contains("Workbook")) {
                 return XLS;
+            } else if (names.contains("EncryptedPackage") && 
+                    names.contains("EncryptionInfo") &&
+                    names.contains("\u0006DataSpaces")) {
+                // This is a protected OOXML document, which is an OLE2 file
+                //  with an Encrypted Stream which holds the OOXML data
+                // Without decrypting the stream, we can't tell what kind of
+                //  OOXML file we have. Return a general OOXML Protected type,
+                //  and hope the name based detection can guess the rest! 
+                return OOXML_PROTECTED;
             } else if (names.contains("EncryptedPackage")) {
                 return OLE;
             } else if (names.contains("WordDocument")) {
diff --git a/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java b/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
index 90d987bc8..25626d816 100644
--- a/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
+++ b/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
@@ -140,6 +140,47 @@ public class TestContainerAwareDetector extends TestCase {
         // With an incorrect filename of a different container type, data trumps filename
         assertTypeByNameAndData("testEXCEL.xlsx", "notOldExcel.xls", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet");
     }
+    
+    /**
+     * Password Protected OLE2 files are fairly straightforward to detect, as they
+     *  have the same structure as regular OLE2 files. (Core streams may be encrypted
+     *  however)
+     */
+    public void testDetectProtectedOLE2() throws Exception {
+        assertTypeByData("testEXCEL_protected_passtika.xls", "application/vnd.ms-excel");
+        assertTypeByData("testWORD_protected_passtika.doc", "application/msword");
+        assertTypeByData("testPPT_protected_passtika.ppt", "application/vnd.ms-powerpoint");
+        assertTypeByNameAndData("testEXCEL_protected_passtika.xls", "application/vnd.ms-excel");
+        assertTypeByNameAndData("testWORD_protected_passtika.doc", "application/msword");
+        assertTypeByNameAndData("testPPT_protected_passtika.ppt", "application/vnd.ms-powerpoint");
+    }
+
+    /**
+     * Password Protected OOXML files are much more tricky beasts to work with.
+     * They have a very different structure to regular OOXML files, and instead
+     *  of being ZIP based they are actually an OLE2 file which contains the
+     *  OOXML structure within an encrypted stream.
+     * This makes detecting them much harder...
+     */
+    public void testDetectProtectedOOXML() throws Exception {
+        // Encrypted Microsoft Office OOXML files have OLE magic but
+        //  special streams, so we can tell they're Protected OOXML
+        assertTypeByData("testEXCEL_protected_passtika.xlsx", 
+                "application/x-tika-ooxml-protected");
+        assertTypeByData("testWORD_protected_passtika.docx", 
+                "application/x-tika-ooxml-protected");
+        assertTypeByData("testPPT_protected_passtika.pptx", 
+                "application/x-tika-ooxml-protected");
+        
+        // At the moment, we can't use the name to specialise
+        // See discussions on TIKA-790 for details
+        assertTypeByNameAndData("testEXCEL_protected_passtika.xlsx", 
+                "application/x-tika-ooxml-protected");
+        assertTypeByNameAndData("testWORD_protected_passtika.docx", 
+                "application/x-tika-ooxml-protected");
+        assertTypeByNameAndData("testPPT_protected_passtika.pptx", 
+                "application/x-tika-ooxml-protected");
+    }
 
     /**
      * Check that temporary files created by Tika are removed after

Commit:
9a937193640ae16173ab98cf2e368ec424f3d71b
Nick Burch
nick@apache.org
2011-11-28 13:05:40 +0000
TIKA-791 Sample protect Microsoft Office documents
diff --git a/tika-parsers/src/test/resources/test-documents/testEXCEL_protected_passtika.xls b/tika-parsers/src/test/resources/test-documents/testEXCEL_protected_passtika.xls
new file mode 100644
index 000000000..8d7e1ec80
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testEXCEL_protected_passtika.xls differ
diff --git a/tika-parsers/src/test/resources/test-documents/testEXCEL_protected_passtika.xlsx b/tika-parsers/src/test/resources/test-documents/testEXCEL_protected_passtika.xlsx
new file mode 100644
index 000000000..deea286c6
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testEXCEL_protected_passtika.xlsx differ
diff --git a/tika-parsers/src/test/resources/test-documents/testPPT_protected_passtika.ppt b/tika-parsers/src/test/resources/test-documents/testPPT_protected_passtika.ppt
new file mode 100644
index 000000000..ae67450f2
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testPPT_protected_passtika.ppt differ
diff --git a/tika-parsers/src/test/resources/test-documents/testPPT_protected_passtika.pptx b/tika-parsers/src/test/resources/test-documents/testPPT_protected_passtika.pptx
new file mode 100644
index 000000000..d24287021
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testPPT_protected_passtika.pptx differ
diff --git a/tika-parsers/src/test/resources/test-documents/testWORD_protected_passtika.doc b/tika-parsers/src/test/resources/test-documents/testWORD_protected_passtika.doc
new file mode 100644
index 000000000..b407783d2
--- /dev/null
+++ b/tika-parsers/src/test/resources/test-documents/testWORD_protected_passtika.doc
@@ -0,0 +1 @@
+
diff --git a/tika-parsers/src/test/resources/test-documents/testWORD_protected_passtika.docx b/tika-parsers/src/test/resources/test-documents/testWORD_protected_passtika.docx
new file mode 100644
index 000000000..9d50a001b

Commit:
96c92f509db1f424147ac0f1b7a5cfcfe6211435
Nick Burch
nick@apache.org
2011-11-28 00:26:28 +0000
TIKA-794 Correct Little16 mime magic logic, and enable the CPIO test now that the detection is correct
diff --git a/tika-core/src/main/java/org/apache/tika/detect/MagicDetector.java b/tika-core/src/main/java/org/apache/tika/detect/MagicDetector.java
index b50d44816..0b1c2cb9d 100644
--- a/tika-core/src/main/java/org/apache/tika/detect/MagicDetector.java
+++ b/tika-core/src/main/java/org/apache/tika/detect/MagicDetector.java
@@ -83,7 +83,7 @@ public class MagicDetector implements Detector {
             decoded = tmpVal.getBytes();
         } else if (type.equals("host16") || type.equals("little16")) {
             int i = Integer.parseInt(tmpVal, radix);
-            decoded = new byte[] { (byte) (i >> 8), (byte) (i & 0x00FF) };
+            decoded = new byte[] { (byte) (i & 0x00FF), (byte) (i >> 8) };
         } else if (type.equals("big16")) {
             int i = Integer.parseInt(tmpVal, radix);
             decoded = new byte[] { (byte) (i >> 8), (byte) (i & 0x00FF) };
diff --git a/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java b/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
index 1a76a3bb4..d54ff1669 100644
--- a/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
+++ b/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
@@ -207,12 +207,12 @@ public class TestMimeTypes extends TestCase {
        // TODO Add an example .deb and .udeb, then check these
        
        // Check the mime magic patterns for them work too
-       assertTypeByData("application/x-archive", "testARofText.ar"); // TODO TIKA-697
-       assertTypeByData("application/x-archive", "testARofSND.ar");  // TODO TIKA-697 
+       assertTypeByData("application/x-archive", "testARofText.ar");
+       assertTypeByData("application/x-archive", "testARofSND.ar"); 
        assertTypeByData("application/zip",    "test-documents.zip");
        assertTypeByData("application/x-gtar",  "test-documents.tar"); // GNU TAR
        assertTypeByData("application/x-gzip", "test-documents.tgz"); // See GZIP, not tar contents of it
-//       assertTypeByData("application/x-cpio", "test-documents.cpio"); // TODO Magic isn't correct?
+       assertTypeByData("application/x-cpio", "test-documents.cpio");
     }
 
     public void testJpegDetection() throws Exception {

Commit:
2d42f07783fa52e1f3064f63e39712698916f2d6
Nick Burch
nick@apache.org
2011-11-27 22:57:18 +0000
TIKA-697 Add mime magic for .deb files, which are base on .ar but have a specific first entry
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 4ed518ca0..74a84b986 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -2313,6 +2313,9 @@
 
   <mime-type type="application/x-debian-package">
     <sub-class-of type="application/x-archive"/>
+    <magic priority="60">
+      <match value="!&lt;arch&gt;\ndebian-binary" type="string" offset="0"/>
+    </magic>
     <glob pattern="*.deb"/>
     <glob pattern="*.udeb"/>
   </mime-type>

Commit:
4885ea7e2eb8a557879a08be9eae85224b718063
Nick Burch
nick@apache.org
2011-11-27 22:51:36 +0000
TIKA-697 Correct mime match for .ar unix archives, add the suggested extra filetypes and aliases, and list .deb as being ar based
diff --git a/tika-core/src/main/java/org/apache/tika/detect/MagicDetector.java b/tika-core/src/main/java/org/apache/tika/detect/MagicDetector.java
index ceb2205ab..b50d44816 100644
--- a/tika-core/src/main/java/org/apache/tika/detect/MagicDetector.java
+++ b/tika-core/src/main/java/org/apache/tika/detect/MagicDetector.java
@@ -126,6 +126,12 @@ public class MagicDetector implements Detector {
                     decoded.write(Integer.parseInt(
                             value.substring(i + 2, i + 4), 16));
                     i += 3;
+                } else if (value.charAt(i + 1) == 'r') {
+                    decoded.write((int)'\r');
+                    i++;
+                } else if (value.charAt(i + 1) == 'n') {
+                   decoded.write((int)'\n');
+                   i++;
                 } else {
                     int j = i + 1;
                     while ((j < i + 4) && (j < value.length())
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 28f720127..4ed518ca0 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -2182,11 +2182,13 @@
   </mime-type>
 
   <mime-type type="application/x-archive">
+    <alias type="application/x-unix-archive"/>
     <magic priority="50">
       <match value="=&lt;ar&gt;" type="string" offset="0"/>
-      <match value="=!&lt;arch&gt;" type="string" offset="0"/>
+      <match value="!&lt;arch&gt;\n" type="string" offset="0"/>
     </magic>
     <glob pattern="*.ar"/>
+    <glob pattern="*.a"/>
   </mime-type>
 
   <mime-type type="application/x-authorware-bin">
@@ -2310,6 +2312,7 @@
   </mime-type>
 
   <mime-type type="application/x-debian-package">
+    <sub-class-of type="application/x-archive"/>
     <glob pattern="*.deb"/>
     <glob pattern="*.udeb"/>
   </mime-type>
diff --git a/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java b/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
index bc52e39ab..1a76a3bb4 100644
--- a/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
+++ b/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
@@ -204,9 +204,11 @@ public class TestMimeTypes extends TestCase {
        assertTypeByName("application/x-gzip", "test.tgz"); // See GZIP, not tar contents of it
        assertTypeByName("application/x-cpio", "test.cpio");
        
+       // TODO Add an example .deb and .udeb, then check these
+       
        // Check the mime magic patterns for them work too
-//       assertTypeByData("application/x-archive", "testARofText.ar"); // TODO TIKA-697
-//       assertTypeByData("application/x-archive", "testARofSND.ar");  // TODO TIKA-697 
+       assertTypeByData("application/x-archive", "testARofText.ar"); // TODO TIKA-697
+       assertTypeByData("application/x-archive", "testARofSND.ar");  // TODO TIKA-697 
        assertTypeByData("application/zip",    "test-documents.zip");
        assertTypeByData("application/x-gtar",  "test-documents.tar"); // GNU TAR
        assertTypeByData("application/x-gzip", "test-documents.tgz"); // See GZIP, not tar contents of it

Commit:
e72a9c4028f3e5d9039e6003c46015752be2282e
Nick Burch
nick@apache.org
2011-11-27 22:21:39 +0000
TIKA-697 Archive formats mimetype tests (not all of which work yet)
diff --git a/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java b/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
index 9c4068c83..bc52e39ab 100644
--- a/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
+++ b/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
@@ -196,6 +196,22 @@ public class TestMimeTypes extends TestCase {
        assertTypeByNameAndData("application/vnd.apple.numbers", "testNumbers.numbers");
        assertTypeByNameAndData("application/vnd.apple.pages", "testPages.pages");
     }
+    
+    public void testArchiveDetection() throws Exception {
+       assertTypeByName("application/x-archive", "test.ar");
+       assertTypeByName("application/zip",    "test.zip");
+       assertTypeByName("application/x-tar",  "test.tar");
+       assertTypeByName("application/x-gzip", "test.tgz"); // See GZIP, not tar contents of it
+       assertTypeByName("application/x-cpio", "test.cpio");
+       
+       // Check the mime magic patterns for them work too
+//       assertTypeByData("application/x-archive", "testARofText.ar"); // TODO TIKA-697
+//       assertTypeByData("application/x-archive", "testARofSND.ar");  // TODO TIKA-697 
+       assertTypeByData("application/zip",    "test-documents.zip");
+       assertTypeByData("application/x-gtar",  "test-documents.tar"); // GNU TAR
+       assertTypeByData("application/x-gzip", "test-documents.tgz"); // See GZIP, not tar contents of it
+//       assertTypeByData("application/x-cpio", "test-documents.cpio"); // TODO Magic isn't correct?
+    }
 
     public void testJpegDetection() throws Exception {
         assertType("image/jpeg", "testJPEG.jpg");

Commit:
31f96edba7e21c85a152c469e0331d0b6e6c71d0
Nick Burch
nick@apache.org
2011-11-27 18:10:01 +0000
TIKA-697 Test CPIO file
diff --git a/tika-parsers/src/test/resources/test-documents/test-documents.cpio b/tika-parsers/src/test/resources/test-documents/test-documents.cpio
new file mode 100644
index 000000000..c13a1cb58
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/test-documents.cpio differ

Commit:
6ef64ddbeff4b23ee25e3d3f51f8a07c49d37c2b
Michael McCandless
mikemccand@apache.org
2011-11-26 19:57:15 +0000
TIKA-778: fix cases where PDFParser produced too many </p> tags
diff --git a/CHANGES.txt b/CHANGES.txt
index 8fba2a176..ed9055c43 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -13,7 +13,10 @@ Release 1.1 - Current Development
    non-duplicated characters were incorrectly removed (TIKA-767).
    Allow controlling whether text tokens should be sorted by their x/y
    position before extracting text (TIKA-612); this is necessary for
-   certain PDFs.
+   certain PDFs.  Fixed cases where too many </p> tags appear in the
+   XHTML output, causing NPE when opening some PDFs with the GUI
+   (TIKA-778).
+
 
  * RTF: Fixed case where a font change would result in processing
    bytes in the wrong font's charset, producing bogus text output
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDF2XHTML.java b/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDF2XHTML.java
index 09f32d3cf..ca1c54377 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDF2XHTML.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDF2XHTML.java
@@ -126,20 +126,19 @@ class PDF2XHTML extends PDFTextStripper {
     protected void startPage(PDPage page) throws IOException {
         try {
             handler.startElement("div", "class", "page");
-            handler.startElement("p");
         } catch (SAXException e) {
             throw new IOExceptionWithCause("Unable to start a page", e);
         }
+        writeParagraphStart();
     }
 
     @Override
     protected void endPage(PDPage page) throws IOException {
 
         try {
+            writeParagraphEnd();
             // TODO: remove once PDFBOX-1143 is fixed:
-            handler.endElement("p");
             if (extractAnnotationText) {
-                boolean foundTextAnnots = false;
                 for(Object o : page.getAnnotations()) {
                     if ((o instanceof PDAnnotation) && PDAnnotationMarkup.SUB_TYPE_FREETEXT.equals(((PDAnnotation) o).getSubtype())) {
                         // It's a text annotation:
@@ -149,11 +148,6 @@ class PDF2XHTML extends PDFTextStripper {
                         String contents = annot.getContents();
                         // TODO: maybe also annot.getRichContents()?
                         if (title != null || subject != null || contents != null) {
-                            if (!foundTextAnnots) {
-                                handler.endElement("p");
-                                foundTextAnnots = true;
-                            }
-
                             handler.startElement("div", "class", "annotation");
 
                             if (title != null) {
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java
index 4d13d1a20..f3631762e 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java
@@ -250,6 +250,26 @@ public class PDFParserTest extends TikaTest {
         content = content.replaceAll("[\\s\u00a0]+"," ");
         assertContains("Here is some text", content);
         assertEquals(-1, content.indexOf("Here is a comment"));
+
+        // TIKA-738: make sure no extra </p> tags
+        String xml = getXML("testAnnotations.pdf").xml;
+        assertEquals(substringCount("<p>", xml),
+                     substringCount("</p>", xml));
+    }
+
+    private static int substringCount(String needle, String haystack) {
+        int upto = -1;
+        int count = 0;
+        while(true) {
+            final int next = haystack.indexOf(needle, upto);
+            if (next == -1) {
+                break;
+            }
+            count++;
+            upto = next+1;
+        }
+
+        return count;
     }
 
     public void testPageNumber() throws Exception {

Commit:
00801cbcc44f7c2e8e8fbc00d8d1b21c687331d3
Nick Burch
nick@apache.org
2011-11-25 15:43:05 +0000
TIKA-789 Add the project type to the OfficeParser mimetype list, and add a note on why Works is missing from the list
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java
index fd4629190..f234780c8 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java
@@ -68,7 +68,9 @@ public class OfficeParser extends AbstractParser {
                     POIFSDocumentType.ENCRYPTED.type,
                     POIFSDocumentType.POWERPOINT.type,
                     POIFSDocumentType.PUBLISHER.type,
+                    POIFSDocumentType.PROJECT.type,
                     POIFSDocumentType.VISIO.type,
+                    // Works isn't supported
                     POIFSDocumentType.OUTLOOK.type,
                     MediaType.application("vnd.ms-excel.sheet.binary.macroenabled.12")
                     )));

Commit:
8e449f96970ff076c2101f34474f939b49b49b7e
Nick Burch
nick@apache.org
2011-11-25 15:38:32 +0000
Add CHANGES entry for TIKA-789
diff --git a/CHANGES.txt b/CHANGES.txt
index f218ae6b2..8fba2a176 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -34,6 +34,9 @@ Release 1.1 - Current Development
    allows for specific, detailed detectors to take preference over
    the default mime magic + filename detector. (TIKA-786)
 
+ * Microsoft Project (MPP): Filetype detection has been fixed,
+   and basic metadata (but no text) is now extracted. (TIKA-789)
+
 Release 1.0 - 11/4/2011
 ---------------------------------
 

Commit:
f05edfe4120445fc93dd781e9daa85a5c371a26d
Nick Burch
nick@apache.org
2011-11-25 15:26:02 +0000
TIKA-789 Add (metadata only) Project support to OfficeParser, and add a unit test that checks we correctly get Project metadata back from our sample files
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java
index 81637f01b..fd4629190 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/OfficeParser.java
@@ -81,6 +81,7 @@ public class OfficeParser extends AbstractParser {
         ENCRYPTED("ole", MediaType.application("x-tika-msoffice")),
         POWERPOINT("ppt", MediaType.application("vnd.ms-powerpoint")),
         PUBLISHER("pub", MediaType.application("x-mspublisher")),
+        PROJECT("mpp", MediaType.application("vnd.ms-project")),
         VISIO("vsd", MediaType.application("vnd.visio")),
         WORKS("wps", MediaType.application("vnd.ms-works")),
         OUTLOOK("msg", MediaType.application("vnd.ms-outlook"));
@@ -119,6 +120,7 @@ public class OfficeParser extends AbstractParser {
             return UNKNOWN;
         }
 
+        // TODO Avoid this duplication with POIFSContainerDetector (TIKA-790)
         private final static Map<String,POIFSDocumentType> typeMap = new HashMap<String,POIFSDocumentType>();
         static {
             typeMap.put("Workbook", WORKBOOK);
@@ -129,6 +131,9 @@ public class OfficeParser extends AbstractParser {
             typeMap.put("VisioDocument", VISIO);
             typeMap.put("CONTENTS", WORKS);
             typeMap.put("\u0001Ole10Native", POIFSDocumentType.OLE10_NATIVE);
+            typeMap.put("Props", PROJECT);  // Project 8
+            typeMap.put("Props9", PROJECT); // Project 9, 10, 11
+            typeMap.put("Props12", PROJECT); // Project 12+
         }
 
         public static POIFSDocumentType detectType(Entry entry) {
@@ -210,6 +215,9 @@ public class OfficeParser extends AbstractParser {
                     Locale locale = context.get(Locale.class, Locale.getDefault());
                     new ExcelExtractor(context).parse(root, xhtml, locale);
                     break;
+                case PROJECT:
+                    // We currently can't do anything beyond the metadata
+                    break;
                 case VISIO:
                     VisioTextExtractor visioTextExtractor =
                         new VisioTextExtractor(root);
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ProjectParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ProjectParserTest.java
new file mode 100644
index 000000000..b8a13aeeb
--- /dev/null
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ProjectParserTest.java
@@ -0,0 +1,89 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.parser.microsoft;
+
+import java.io.InputStream;
+
+import org.apache.tika.metadata.Metadata;
+import org.apache.tika.parser.ParseContext;
+import org.apache.tika.sax.BodyContentHandler;
+import org.xml.sax.ContentHandler;
+
+import junit.framework.TestCase;
+
+/**
+ * Tests for Microsoft Project (MPP) Files.
+ * 
+ * Note - we don't currently have a dedicated Project
+ *  Parser, all we have is the common office metadata
+ */
+public class ProjectParserTest extends TestCase {
+    public void testProject2003() throws Exception {
+       InputStream input = ProjectParserTest.class.getResourceAsStream(
+             "/test-documents/testPROJECT2003.mpp");
+       try {
+          doTestProject(input);
+       } finally {
+          input.close();
+       }
+    }
+
+    public void testProject2007() throws Exception {
+        InputStream input = ProjectParserTest.class.getResourceAsStream(
+                "/test-documents/testPROJECT2007.mpp");
+        try {
+            doTestProject(input);
+        } finally {
+            input.close();
+        }
+    }
+
+    private void doTestProject(InputStream input) throws Exception {
+       Metadata metadata = new Metadata();
+       ContentHandler handler = new BodyContentHandler();
+       new OfficeParser().parse(input, handler, metadata, new ParseContext());
+
+       assertEquals(
+               "application/vnd.ms-project",
+               metadata.get(Metadata.CONTENT_TYPE));
+       
+       assertEquals("The quick brown fox jumps over the lazy dog", metadata.get(Metadata.TITLE));
+       assertEquals("Gym class featuring a brown fox and lazy dog", metadata.get(Metadata.SUBJECT));
+       assertEquals("Nevin Nollop", metadata.get(Metadata.AUTHOR));
+       assertEquals("", metadata.get(Metadata.LAST_AUTHOR));
+       assertEquals("Pangram, fox, dog", metadata.get(Metadata.KEYWORDS));
+       assertEquals("Comment Vulpes vulpes comment", metadata.get(Metadata.COMMENTS));
+       
+       assertEquals("Category1", metadata.get(Metadata.CATEGORY));
+       assertEquals("Mr Burns", metadata.get(Metadata.MANAGER));
+       assertEquals("CompanyA", metadata.get(Metadata.COMPANY));
+       
+       assertEquals("2011-11-24T10:58:00Z", metadata.get(Metadata.CREATION_DATE));
+       assertEquals("2011-11-24T11:31:00Z", metadata.get(Metadata.LAST_SAVED));
+       
+       // Custom Project metadata is present with prefix
+       assertEquals("0%", metadata.get("custom:% Complete"));
+       assertEquals("0%", metadata.get("custom:% Work Complete"));
+       assertEquals("\u00a3"+"0.00", metadata.get("custom:Cost"));
+       assertEquals("2d?", metadata.get("custom:Duration"));
+       assertEquals("16h", metadata.get("custom:Work"));
+       
+       // Currently, we don't do textual contents of the file
+       String content = handler.toString();
+       assertEquals("", content);
+    }
+}

Commit:
39a1bac909c86b520467ab9705f56585d03815e9
Nick Burch
nick@apache.org
2011-11-25 15:24:09 +0000
TIKA-789 Improve MPP detection based on info from Alex Ott
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 47a9f01fc..28f720127 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -1327,7 +1327,7 @@
   <mime-type type="application/vnd.ms-project">
     <glob pattern="*.mpp"/>
     <glob pattern="*.mpt"/>
-    <sub-class-of type="application/x-tika-ooxml"/>
+    <sub-class-of type="application/x-tika-msoffice"/>
   </mime-type>
 
   <mime-type type="application/vnd.ms-tnef">
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java
index 22332ae8a..4ab5de485 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java
@@ -72,9 +72,8 @@ public class POIFSContainerDetector implements Detector {
     /** Microsoft Project */
     public static final MediaType MPP = application("vnd.ms-project");
 
-    /** Regexp for matching the MPP Project Properties stream */
+    /** Regexp for matching the MPP Project Data stream */
     private static final Pattern mppDataMatch = Pattern.compile("\\s\\s\\s\\d+");
-    private static final Pattern mppPropsMatch = Pattern.compile("Props\\d+");
     
     public MediaType detect(InputStream input, Metadata metadata)
              throws IOException {
@@ -142,16 +141,13 @@ public class POIFSContainerDetector implements Detector {
                //  of embedded non-office file inside an OLE2 document
                // This is most commonly triggered on nested directories
                return OLE;
-            } else if (names.contains("\u0001CompObj")) {
+            } else if (names.contains("\u0001CompObj") &&
+                  (names.contains("Props") || names.contains("Props9") || names.contains("Props12"))) {
                // Could be Project, look for common name patterns
-               boolean matchedProps = false;
-               boolean matchedData = false;
                for (String name : names) {
-                  if (mppDataMatch.matcher(name).matches()) matchedData = true;
-                  if (mppPropsMatch.matcher(name).matches()) matchedProps = true;
-               }
-               if (matchedProps && matchedData) {
-                  return MPP;
+                  if (mppDataMatch.matcher(name).matches()) {
+                     return MPP;
+                  }
                }
             } else if (names.contains("\u0001Ole10Native")) {
                 return OLE;

Commit:
1b01e4f1d943437f29f414dd75a3fa52a05e8d67
Nick Burch
nick@apache.org
2011-11-25 14:36:03 +0000
TIKA-789 POIFS Container Detection support for MPP files
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java
index fe53db41e..22332ae8a 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java
@@ -24,6 +24,7 @@ import java.nio.channels.FileChannel;
 import java.util.Collections;
 import java.util.HashSet;
 import java.util.Set;
+import java.util.regex.Pattern;
 
 import org.apache.poi.poifs.filesystem.DirectoryNode;
 import org.apache.poi.poifs.filesystem.Entry;
@@ -67,7 +68,14 @@ public class POIFSContainerDetector implements Detector {
 
     /** Microsoft Outlook */
     public static final MediaType MSG = application("vnd.ms-outlook");
-
+    
+    /** Microsoft Project */
+    public static final MediaType MPP = application("vnd.ms-project");
+
+    /** Regexp for matching the MPP Project Properties stream */
+    private static final Pattern mppDataMatch = Pattern.compile("\\s\\s\\s\\d+");
+    private static final Pattern mppPropsMatch = Pattern.compile("Props\\d+");
+    
     public MediaType detect(InputStream input, Metadata metadata)
              throws IOException {
         // Check if we have access to the document
@@ -134,6 +142,17 @@ public class POIFSContainerDetector implements Detector {
                //  of embedded non-office file inside an OLE2 document
                // This is most commonly triggered on nested directories
                return OLE;
+            } else if (names.contains("\u0001CompObj")) {
+               // Could be Project, look for common name patterns
+               boolean matchedProps = false;
+               boolean matchedData = false;
+               for (String name : names) {
+                  if (mppDataMatch.matcher(name).matches()) matchedData = true;
+                  if (mppPropsMatch.matcher(name).matches()) matchedProps = true;
+               }
+               if (matchedProps && matchedData) {
+                  return MPP;
+               }
             } else if (names.contains("\u0001Ole10Native")) {
                 return OLE;
             } else if (names.contains("PerfectOffice_MAIN")) {
diff --git a/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java b/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
index facc2ba12..90d987bc8 100644
--- a/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
+++ b/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
@@ -63,10 +63,17 @@ public class TestContainerAwareDetector extends TestCase {
         assertTypeByData("testEXCEL.xls", "application/vnd.ms-excel");
         assertTypeByData("testWORD.doc", "application/msword");
         assertTypeByData("testPPT.ppt", "application/vnd.ms-powerpoint");
-
-        // Try some ones that POI doesn't handle, that are still OLE2 based
+        
+        assertTypeByData("test-outlook.msg", "application/vnd.ms-outlook");
+        assertTypeByData("test-outlook2003.msg", "application/vnd.ms-outlook");
+        assertTypeByData("testVISIO.vsd", "application/vnd.visio");
+        assertTypeByData("testPUBLISHER.pub", "application/x-mspublisher");
         assertTypeByData("testWORKS.wps", "application/vnd.ms-works");
         assertTypeByData("testWORKS2000.wps", "application/vnd.ms-works");
+        assertTypeByData("testPROJECT2003.mpp", "application/vnd.ms-project");
+        assertTypeByData("testPROJECT2007.mpp", "application/vnd.ms-project");
+
+        // Try some ones that POI doesn't handle, that are still OLE2 based
         assertTypeByData("testCOREL.shw", "application/x-corelpresentations");
         assertTypeByData("testQUATTRO.qpw", "application/x-quattro-pro");
         assertTypeByData("testQUATTRO.wb3", "application/x-quattro-pro");

Commit:
a141b273d2b106b3a34227c65327817942357904
Nick Burch
nick@apache.org
2011-11-25 14:33:45 +0000
TIKA-789 Microsoft Project (MPP) is OLE2 based
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 41e3eecfc..47a9f01fc 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -1327,6 +1327,7 @@
   <mime-type type="application/vnd.ms-project">
     <glob pattern="*.mpp"/>
     <glob pattern="*.mpt"/>
+    <sub-class-of type="application/x-tika-ooxml"/>
   </mime-type>
 
   <mime-type type="application/vnd.ms-tnef">

Commit:
25fcdf9a78da45b31b1edddd14006d9cefa0e891
Nick Burch
nick@apache.org
2011-11-25 14:26:48 +0000
TIKA-789 More consistent naming for sample MPP files
diff --git a/tika-parsers/src/test/resources/test-documents/testMPP2003.mpp b/tika-parsers/src/test/resources/test-documents/testPROJECT2003.mpp
similarity index 100%
rename from tika-parsers/src/test/resources/test-documents/testMPP2003.mpp
rename to tika-parsers/src/test/resources/test-documents/testPROJECT2003.mpp
diff --git a/tika-parsers/src/test/resources/test-documents/testMPP2007.mpp b/tika-parsers/src/test/resources/test-documents/testPROJECT2007.mpp
similarity index 100%
rename from tika-parsers/src/test/resources/test-documents/testMPP2007.mpp
rename to tika-parsers/src/test/resources/test-documents/testPROJECT2007.mpp

Commit:
4073be5e61dc964a69d131c80e11f4ab962415c9
Nick Burch
nick@apache.org
2011-11-25 14:19:23 +0000
TIKA-789 Sample Microsoft Project (MPP) files
diff --git a/tika-parsers/src/test/resources/test-documents/testMPP2003.mpp b/tika-parsers/src/test/resources/test-documents/testMPP2003.mpp
new file mode 100644
index 000000000..69bad2c43
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testMPP2003.mpp differ
diff --git a/tika-parsers/src/test/resources/test-documents/testMPP2007.mpp b/tika-parsers/src/test/resources/test-documents/testMPP2007.mpp
new file mode 100644
index 000000000..964b2b03c
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testMPP2007.mpp differ

Commit:
f8e3364bfd7fa5d4d80c7b249894ebbe6a146b85
Maxim Valyanskiy
maxcom@apache.org
2011-11-23 13:39:43 +0000
TIKA-787: Improve charset detection for UTF-8 HTML fragment
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/txt/CharsetDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/txt/CharsetDetector.java
index e14ed45e0..2534f1c3d 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/txt/CharsetDetector.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/txt/CharsetDetector.java
@@ -94,7 +94,7 @@ public class CharsetDetector {
         return this;
     }
     
-    private static final int kBufSize = 8000;
+    private static final int kBufSize = 12000;
 
     private static final int MAX_CONFIDENCE = 100;
 
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/txt/CharsetDetectorTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/txt/CharsetDetectorTest.java
new file mode 100644
index 000000000..aee0414cc
--- /dev/null
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/txt/CharsetDetectorTest.java
@@ -0,0 +1,48 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.tika.parser.txt;
+
+import org.junit.Test;
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertTrue;
+
+import java.io.IOException;
+import java.io.InputStream;
+
+public class CharsetDetectorTest {
+  @Test
+  public void testTagDropper() throws IOException {
+    InputStream in = CharsetDetectorTest.class.getResourceAsStream( "/test-documents/resume.html" );
+
+    try {
+      CharsetDetector detector = new CharsetDetector();
+      detector.enableInputFilter(true);
+      detector.setText(in);
+      CharsetMatch [] matches = detector.detectAll();
+      CharsetMatch mm = null;
+      for ( CharsetMatch m : matches ) {
+        if ( mm == null || mm.getConfidence() < m.getConfidence() ) {
+          mm = m;
+        }
+      }
+      assertTrue( mm != null );
+      assertEquals( "UTF-8", mm.getName() );
+    } finally {
+      in.close();
+    }
+  }
+}
diff --git a/tika-parsers/src/test/resources/test-documents/resume.html b/tika-parsers/src/test/resources/test-documents/resume.html
new file mode 100644
index 000000000..1bd747a7b
--- /dev/null
+++ b/tika-parsers/src/test/resources/test-documents/resume.html
@@ -0,0 +1,73 @@
+
+
+	<div class="js-helper">
+	<style type="text/css">#style_13209008630000000884_BODY{background-color:#FFFFFF;color:#000000;MARGIN:0px 1px;font-family:Tahoma,Arial,Verdana,Sans-Serif}#style_13209008630000000884 TD{font-size:13px;font-family:Tahoma,Arial,Verdana,Sans-Serif;vertical-align:top}#style_13209008630000000884 CAPTION{font-size:13px;font-weight:bold;text-align:left}#style_13209008630000000884 TR.style_13209008630000000884thead TD{font-weight:bold;text-align:center; padding-bottom:6px;padding-top:6px;padding-left:2px;padding-right:2px}#style_13209008630000000884 H1{font-size:24px;margin-bottom:15px;margin-top:5px;display:block;font-weight:normal;}#style_13209008630000000884 H2{font-size:22px;margin-bottom:5px;margin-top:5px;display:block;font-weight:normal;letter-spacing:1px}#style_13209008630000000884 H1.style_13209008630000000884in, #style_13209008630000000884 H2.style_13209008630000000884in, #style_13209008630000000884 H3.style_13209008630000000884in{font-size:100%;margin-bottom:0px;margin-top:0px;display:inline;}#style_13209008630000000884 A, #style_13209008630000000884 A.style_13209008630000000884notvisited:visited, #style_13209008630000000884 .style_13209008630000000884notvisited A:visited, #style_13209008630000000884 .style_13209008630000000884menu A:visited{color:#00418F;text-decoration:none}#style_13209008630000000884 A:visited{color:#6699CC;text-decoration:none;}#style_13209008630000000884 A:hover, #style_13209008630000000884 A.style_13209008630000000884notvisited:hover, #style_13209008630000000884 .style_13209008630000000884notvisited A:hover, #style_13209008630000000884 .style_13209008630000000884menu A:hover{color:#990000;text-decoration:underline}#style_13209008630000000884 .style_13209008630000000884bold, #style_13209008630000000884 .style_13209008630000000884bold H1{font-weight:bold}#style_13209008630000000884 .style_13209008630000000884u{text-decoration:underline}#style_13209008630000000884 .style_13209008630000000884gray, #style_13209008630000000884 A.style_13209008630000000884gray:visited, #style_13209008630000000884 LEGEND{color:#7A7A7A}#style_13209008630000000884 .style_13209008630000000884red, #style_13209008630000000884 A.style_13209008630000000884red:visited{color:#C2311A}#style_13209008630000000884 EM, #style_13209008630000000884 .style_13209008630000000884imp, #style_13209008630000000884 .style_13209008630000000884field_warning{color:#C2311A;font-weight:bold;font-style:normal}#style_13209008630000000884 TABLE.style_13209008630000000884bl_table TR TD{padding:2px; padding-left:10px}#style_13209008630000000884 TD.style_13209008630000000884bl_row_name{color:#555; width:10%}#style_13209008630000000884 TD.style_13209008630000000884vacancydark, #style_13209008630000000884 TR.style_13209008630000000884vacancydark TD, #style_13209008630000000884 TD.style_13209008630000000884resumedark, #style_13209008630000000884 TR.style_13209008630000000884resumedark TD, #style_13209008630000000884 TD.style_13209008630000000884serverdark, #style_13209008630000000884 TR.style_13209008630000000884serverdark TD{text-align:center;padding-bottom:3px;padding-top:3px;padding-left:1px;padding-right:1px;font-weight:bold}#style_13209008630000000884 TD.style_13209008630000000884vacancydark, #style_13209008630000000884 TR.style_13209008630000000884vacancydark TD, #style_13209008630000000884 TD.style_13209008630000000884vacancydark A, #style_13209008630000000884 TD.style_13209008630000000884vacancydark A:visited, #style_13209008630000000884 TD.style_13209008630000000884vacancydark A:hover, #style_13209008630000000884 TD.style_13209008630000000884resumedark, #style_13209008630000000884 TR.style_13209008630000000884resumedark TD, #style_13209008630000000884 TD.style_13209008630000000884resumedark A, #style_13209008630000000884 TD.style_13209008630000000884resumedark A:visited, #style_13209008630000000884 TD.style_13209008630000000884resumedark A:hover, #style_13209008630000000884 TD.style_13209008630000000884serverdark, #style_13209008630000000884 TR.style_13209008630000000884serverdark TD, #style_13209008630000000884 TD.style_13209008630000000884serverdark A, #style_13209008630000000884 TD.style_13209008630000000884serverdark A:visited, #style_13209008630000000884 TD.style_13209008630000000884serverdark A:hover{color:#000000;}#style_13209008630000000884 TD.style_13209008630000000884vacancydark, #style_13209008630000000884 TR.style_13209008630000000884vacancydark TD{background-color:#FFDDBB;}#style_13209008630000000884 TD.style_13209008630000000884vacancylight, #style_13209008630000000884 TR.style_13209008630000000884vacancylight TD{background-color:#FFF5EC}#style_13209008630000000884 TD.style_13209008630000000884resumedark, #style_13209008630000000884 TR.style_13209008630000000884resumedark TD{background-color:#D3E9E9;}#style_13209008630000000884 TD.style_13209008630000000884resumelight, #style_13209008630000000884 TR.style_13209008630000000884resumelight TD{background-color:#ECF8F7}#style_13209008630000000884 TD.style_13209008630000000884serverdark, #style_13209008630000000884 TR.style_13209008630000000884serverdark TD{background-color:#ABC2D5;}#style_13209008630000000884 TR.style_13209008630000000884serverlight TD, #style_13209008630000000884 TD.style_13209008630000000884serverlight{background-color:#E2EBF5}#style_13209008630000000884 TD.style_13209008630000000884blankheader1{font-size:24px; padding:10px}#style_13209008630000000884 TD.style_13209008630000000884blankheader2{font-size:22px; padding:10px}#style_13209008630000000884 TABLE.style_13209008630000000884resumelist TR.thead TD{background-color:#ABC2D5;}#style_13209008630000000884 TABLE.style_13209008630000000884vaclist TR.thead TD{background-color:#ABC2D5;}#style_13209008630000000884 TABLE.style_13209008630000000884vaclist_for_mail TR.thead TD{background-color:#DBDBDB;}#style_13209008630000000884 TABLE TR.style_13209008630000000884wr TD{background-color:#FFFFFF}#style_13209008630000000884 TABLE.style_13209008630000000884vaclist_for_mail TD{border-bottom:#DBDBDB 1px solid}#style_13209008630000000884 .style_13209008630000000884list TR TD{background-color:#E2EBF5;padding:5px}#style_13209008630000000884 .style_13209008630000000884list TR.thead TD{background-color:#ABC2D5;color:#555555;text-align:center; padding-bottom:8px;padding-top:8px;padding-left:1px;padding-right:1px;font-weight:bold;}#style_13209008630000000884 .style_13209008630000000884list TR.wr TD{background-color:#F3F7FB}#style_13209008630000000884 A.style_13209008630000000884list_details, #style_13209008630000000884 A.style_13209008630000000884list_details:visited, #style_13209008630000000884 A.style_13209008630000000884list_details:hover{color:#7A7A7A;text-decoration:none;line-height:120%}#style_13209008630000000884 TD.style_13209008630000000884cell, #style_13209008630000000884 TD.style_13209008630000000884c{padding-top:3px;padding-left:5px;padding-right:5px}#style_13209008630000000884 BIG{font-size:24px}#style_13209008630000000884 .style_13209008630000000884small, #style_13209008630000000884 SMALL{font-size:85%}#style_13209008630000000884 UL{margin-left:25px;margin-bottom:0px}#style_13209008630000000884 TD.style_13209008630000000884small, #style_13209008630000000884 .style_13209008630000000884verysmall, #style_13209008630000000884 .style_13209008630000000884verysmall INPUT, #style_13209008630000000884 .style_13209008630000000884verysmall SELECT{font-size:11px}#style_13209008630000000884 DIV.style_13209008630000000884localmenu{padding-top:10px;margin-bottom:15px;}#style_13209008630000000884 DIV.style_13209008630000000884localmenu A, #style_13209008630000000884 DIV.style_13209008630000000884localmenu A:visited{text-decoration:underline;font-weight:bold}#style_13209008630000000884 DIV.style_13209008630000000884comment{font-size:85%; background-color:#DDFFDD; padding:4px; border:1px solid #CCC;cursor:default;}#style_13209008630000000884 HR{color:#ABC2D5;background-color:#ABC2D5;height:1px;border:0px solid #ABC2D5}#style_13209008630000000884 DIV.style_13209008630000000884dotsline{font-size:1px; margin-top:4px; margin-bottom:5px; border-bottom:#BACBD7 1px dotted}#style_13209008630000000884 TABLE.style_13209008630000000884rctable TR TD{background-color:#E5EDF7;}#style_13209008630000000884 TD.style_13209008630000000884rc1{padding-top:10px; padding-left:10px;}#style_13209008630000000884 TD.style_13209008630000000884rc2{font-size:1px; width:10px;}#style_13209008630000000884 TD.style_13209008630000000884rc3{height:10px; font-size:1px;}#style_13209008630000000884 TD.style_13209008630000000884rc4{height:10px; font-size:1px;}#style_13209008630000000884 SPAN.style_13209008630000000884super{color:#003398;font-size:150%}#style_13209008630000000884 SPAN.style_13209008630000000884job{color:#FF0000;font-size:150%}#style_13209008630000000884 TABLE.style_13209008630000000884vaclist_for_mail TD TABLE.to_site_button{background-color:#99cc00; margin:0px 5px 3px 0px;}#style_13209008630000000884 TABLE.style_13209008630000000884vaclist_for_mail TD TABLE.to_site_button TD{background-color:#99cc00; font-weight:normal; color:#ffffff; border-bottom:0px; padding-top:6px; padding-right:7px; padding-bottom:6px; padding-left:7px; vertical-align:middle; text-align:center;}#style_13209008630000000884 TABLE.style_13209008630000000884vaclist_for_mail TD TABLE.to_site_button TD A, #style_13209008630000000884 TABLE.style_13209008630000000884to_site_button TD A:visited{color:#ffffff; text-decoration:none; font-weight:normal;}#style_13209008630000000884 TABLE.style_13209008630000000884vaclist_for_mail TD TABLE.to_site_button TD A:hover{color:#ffffff; text-decoration:underline; font-weight:normal;}#style_13209008630000000884 .style_13209008630000000884row{clear:left; padding-bottom:4px;}#style_13209008630000000884 .style_13209008630000000884row2{margin-bottom:8px;}#style_13209008630000000884 .style_13209008630000000884col1{float:left; width:140px; color:#555555; margin-right:-145px;}#style_13209008630000000884 .style_13209008630000000884col2{margin-left:145px;}#style_13209008630000000884 DIV.style_13209008630000000884resume_rightcol{float:right; width:280px; margin:0px 0px 10px 30px;}#style_13209008630000000884 DIV.style_13209008630000000884blankheader1{font-size:190%;}
+</style>
+	<div id="style_13209008630000000884" class="mr_read__body">
+		<base target="_self" href="http://e.mail.ru/cgi-bin/" />
+		
+			<div id="style_13209008630000000884_BODY">
+
+
+
+<style type="text/css" ></style>
+
+
+<table width="100%" cellspacing="0" cellpadding="0" height="100%" border="0" >
+<tr ><td >
+
+</td></tr>
+<tr ><td style="padding:5px" height="100%" >
+, !<br >
+<br >
+      ,        .<br >
+<br >
+<li ><a target="_blank" href="/cgi-bin/link?check=1&cnf=710139&url=http%3A%2F%2;0,0" >,    .</a> : <b >1.</b></li><br >
+<br >
+      .    ,        Superjob     .<br >
+<br >
+      ,       ,     .<br >
+           .<br >
+<br >
+<br >
+<b >!</b><br >
+             ,        (  ,   ,    ,      ,     ..)      (,  ,  ,  ,    ..)       ,    .<br >
+    !                 .<br >
+<br >
+       SMS-                 .  ,    ,     ,       .<br >
+<br >
+<br >
+<em >x</em> <a target="_blank" href="/cgi-bin/link?check=1&cnf=8d972a&url=http%3A%2F%2Fwww.sup;0,0" >      </a><br >
+<br >
+           .
+<br ><br >
+</td>
+</tr>
+<tr >
+<td >
+<span class="style_13209008630000000884noprint" ><br ><br >          Superjob, , <a target="_blank" href="/cgi-bin/link?check=1;0,0" > </a>.<br ><br ></span>
+<table width="100%" cellspacing="0" cellpadding="10" border="0" class="style_13209008630000000884noprint" >
+<tr ><td align="center" style="border-top:1px solid #BACBD7;" >
+<a target="_blank" href="/cgi-bin/link?check=1&cnf=8fa2f9&url=http%3A%2F%2Fwww.;0,0" ><big >Superjob     !</big></a>
+</td></tr>
+</table>
+<table width="100%" cellspacing="1" cellpadding="0" border="0" class="style_13209008630000000884noprint" >
+<tr ><td align="center" style="padding:5px" >
+<span style="color:#999999;font-size:8pt;" > : xx.xx.xxxx xx:xx:xx</span>
+</td></tr>
+</table>
+
+</td></tr>
+</table>
+
+
+
+</div>
+			
+		
+		<base target="_self" href="http://e.mail.ru/cgi-bin/" />
+	</div>
+</div>
+
+
+

Commit:
482cf37542e4fe863d4563e512663c9228a6d9c1
Nick Burch
nick@apache.org
2011-11-21 13:15:29 +0000
Add a note about TIKA-786 to Changes
diff --git a/CHANGES.txt b/CHANGES.txt
index 019dce12a..f218ae6b2 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -27,6 +27,13 @@ Release 1.1 - Current Development
    mimetype detectors that are available, similar to the existing
    "--list-parsers" option for parsers. (TIKA-785).
 
+ * Detectors: The order of detectors, as supplied via the service
+   registry loader, is now controlled. User supplied detectors are
+   prefered, then Tika detectors (such as the container aware ones),
+   and finally the core Tika MimeTypes is used as a backup. This
+   allows for specific, detailed detectors to take preference over
+   the default mime magic + filename detector. (TIKA-786)
+
 Release 1.0 - 11/4/2011
 ---------------------------------
 

Commit:
2b39c7599a9930f8847f8839e9612ae5cdc56407
Nick Burch
nick@apache.org
2011-11-21 12:55:49 +0000
TIKA-786 Control the ordering of detectors in DefaultDetector, so that user supplied detectors come first, then Tika ones, and finally MimeTypes. This ensures that more specific detectors get to try first
diff --git a/tika-core/src/main/java/org/apache/tika/detect/DefaultDetector.java b/tika-core/src/main/java/org/apache/tika/detect/DefaultDetector.java
index f24d664d9..749871b24 100644
--- a/tika-core/src/main/java/org/apache/tika/detect/DefaultDetector.java
+++ b/tika-core/src/main/java/org/apache/tika/detect/DefaultDetector.java
@@ -17,6 +17,8 @@
 package org.apache.tika.detect;
 
 import java.util.ArrayList;
+import java.util.Collections;
+import java.util.Comparator;
 import java.util.List;
 
 import javax.imageio.spi.ServiceRegistry;
@@ -27,6 +29,12 @@ import org.apache.tika.mime.MimeTypes;
 /**
  * A composite detector based on all the {@link Detector} implementations
  * available through the {@link ServiceRegistry service provider mechanism}.
+ * 
+ * Detectors are loaded and returned in a specified order, of user supplied
+ *  followed by non-MimeType Tika, followed by the Tika MimeType class.
+ * If you need to control the order of the Detectors, you should instead
+ *  construct your own {@link CompositeDetector} and pass in the list
+ *  of Detectors in the required order.
  *
  * @since Apache Tika 0.9
  */
@@ -37,9 +45,35 @@ public class DefaultDetector extends CompositeDetector {
 
     private static List<Detector> getDefaultDetectors(
             MimeTypes types, ServiceLoader loader) {
-        List<Detector> detectors = new ArrayList<Detector>();
+        // Find all the detectors available as services
+        List<Detector> svcDetectors = loader.loadServiceProviders(Detector.class);
+        List<Detector> detectors = new ArrayList<Detector>(svcDetectors.size()+1);
+        
+        // Sort the list by classname, rather than discovery order 
+        Collections.sort(svcDetectors, new Comparator<Detector>() {
+            public int compare(Detector d1, Detector d2) {
+               return d1.getClass().getName().compareTo(
+                     d2.getClass().getName());
+            }
+        });
+        
+        // Add the non-Tika (user supplied) detectors First
+        for (Detector d : svcDetectors) {
+           if (! d.getClass().getName().startsWith("org.apache.tika")) {
+              detectors.add(d);
+           }
+        }
+        
+        // Add the Tika detectors next
+        for (Detector d : svcDetectors) {
+           if (d.getClass().getName().startsWith("org.apache.tika")) {
+              detectors.add(d);
+           }
+        }
+        
+        // Finally add the Tika MimeTypes as a fallback
         detectors.add(types);
-        detectors.addAll(loader.loadServiceProviders(Detector.class));
+        
         return detectors;
     }
 
diff --git a/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java b/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
index 6ef8cdbd4..facc2ba12 100644
--- a/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
+++ b/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
@@ -77,10 +77,9 @@ public class TestContainerAwareDetector extends TestCase {
         assertTypeByNameAndData("testPPT.ppt", "application/vnd.ms-powerpoint");
         
         // With the wrong filename supplied, data will trump filename
-        // TODO Fix this! (TIKA-786)
-//        assertTypeByNameAndData("testEXCEL.xls", "notWord.doc",  "application/vnd.ms-excel");
-//        assertTypeByNameAndData("testWORD.doc",  "notExcel.xls", "application/msword");
-//        assertTypeByNameAndData("testPPT.ppt",   "notWord.doc",  "application/vnd.ms-powerpoint");
+        assertTypeByNameAndData("testEXCEL.xls", "notWord.doc",  "application/vnd.ms-excel");
+        assertTypeByNameAndData("testWORD.doc",  "notExcel.xls", "application/msword");
+        assertTypeByNameAndData("testPPT.ppt",   "notWord.doc",  "application/vnd.ms-powerpoint");
         
         // With a filename of a totally different type, data will trump filename
         assertTypeByNameAndData("testEXCEL.xls", "notPDF.pdf",  "application/vnd.ms-excel");
@@ -127,10 +126,9 @@ public class TestContainerAwareDetector extends TestCase {
         assertTypeByNameAndData("testPPT.pptx", "application/vnd.openxmlformats-officedocument.presentationml.presentation");
         
         // With the wrong filename supplied, data will trump filename
-        // TODO Fix this! (TIKA-786)
-//        assertTypeByNameAndData("testEXCEL.xlsx", "notWord.docx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet");
-//        assertTypeByNameAndData("testWORD.docx",  "notExcel.xlsx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document");
-//        assertTypeByNameAndData("testPPT.pptx",   "notWord.docx", "application/vnd.openxmlformats-officedocument.presentationml.presentation");
+        assertTypeByNameAndData("testEXCEL.xlsx", "notWord.docx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet");
+        assertTypeByNameAndData("testWORD.docx",  "notExcel.xlsx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document");
+        assertTypeByNameAndData("testPPT.pptx",   "notWord.docx", "application/vnd.openxmlformats-officedocument.presentationml.presentation");
         
         // With an incorrect filename of a different container type, data trumps filename
         assertTypeByNameAndData("testEXCEL.xlsx", "notOldExcel.xls", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet");

Commit:
fa077bfba10828d5512ede9db89124d252448898
Nick Burch
nick@apache.org
2011-11-21 12:17:48 +0000
Add basic JavaDoc for a few MediaType methods that lacked it
diff --git a/tika-core/src/main/java/org/apache/tika/mime/MediaType.java b/tika-core/src/main/java/org/apache/tika/mime/MediaType.java
index 82964217d..bca232b31 100644
--- a/tika-core/src/main/java/org/apache/tika/mime/MediaType.java
+++ b/tika-core/src/main/java/org/apache/tika/mime/MediaType.java
@@ -288,6 +288,11 @@ public final class MediaType implements Comparable<MediaType>, Serializable {
                 union(type.parameters, parameters));
     }
 
+    /**
+     * Returns the base form of the MediaType, excluding
+     *  any parameters, such as "text/plain" for
+     *  "text/plain; charset=utf-8"
+     */
     public MediaType getBaseType() {
         if (parameters.isEmpty()) {
             return this;
@@ -296,10 +301,18 @@ public final class MediaType implements Comparable<MediaType>, Serializable {
         }
     }
 
+    /**
+     * Return the Type of the MediaType, such as
+     *  "text" for "text/plain"
+     */
     public String getType() {
         return string.substring(0, slash);
     }
 
+    /**
+     * Return the Sub-Type of the MediaType, 
+     *  such as "plain" for "text/plain"
+     */
     public String getSubtype() {
         return string.substring(slash + 1, semicolon);
     }

Commit:
ba101bb023a9553d0b5c22b0b625d0a0f1b8a707
Nick Burch
nick@apache.org
2011-11-21 10:41:57 +0000
A few more TIKA-786 related tests
diff --git a/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java b/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
index b0eeea2a3..6ef8cdbd4 100644
--- a/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
+++ b/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
@@ -81,6 +81,10 @@ public class TestContainerAwareDetector extends TestCase {
 //        assertTypeByNameAndData("testEXCEL.xls", "notWord.doc",  "application/vnd.ms-excel");
 //        assertTypeByNameAndData("testWORD.doc",  "notExcel.xls", "application/msword");
 //        assertTypeByNameAndData("testPPT.ppt",   "notWord.doc",  "application/vnd.ms-powerpoint");
+        
+        // With a filename of a totally different type, data will trump filename
+        assertTypeByNameAndData("testEXCEL.xls", "notPDF.pdf",  "application/vnd.ms-excel");
+        assertTypeByNameAndData("testEXCEL.xls", "notPNG.png",  "application/vnd.ms-excel");
     }
 
     public void testOpenContainer() throws Exception {
@@ -201,21 +205,50 @@ public class TestContainerAwareDetector extends TestCase {
 
     public void testTruncatedFiles() throws Exception {
         // First up a truncated OOXML (zip) file
+       
+        // With only the data supplied, the best we can do is the container
         TikaInputStream xlsx = getTruncatedFile("testEXCEL.xlsx", 300);
+        Metadata m = new Metadata();
         try {
             assertEquals(
                     MediaType.application("x-tika-ooxml"),
-                    detector.detect(xlsx, new Metadata()));
+                    detector.detect(xlsx, m));
+        } finally {
+            xlsx.close();
+        }
+        
+        // With truncated data + filename, we can use the filename to specialise
+        xlsx = getTruncatedFile("testEXCEL.xlsx", 300);
+        m = new Metadata();
+        m.add(Metadata.RESOURCE_NAME_KEY, "testEXCEL.xlsx");
+        try {
+            assertEquals(
+                    MediaType.application("vnd.openxmlformats-officedocument.spreadsheetml.sheet"),
+                    detector.detect(xlsx, m));
         } finally {
             xlsx.close();
         }
+        
 
         // Now a truncated OLE2 file 
         TikaInputStream xls = getTruncatedFile("testEXCEL.xls", 400);
+        m = new Metadata();
         try {
             assertEquals(
                     MediaType.application("x-tika-msoffice"),
-                    detector.detect(xls, new Metadata()));
+                    detector.detect(xls, m));
+        } finally {
+            xls.close();
+        }
+        
+        // Finally a truncated OLE2 file, with a filename available
+        xls = getTruncatedFile("testEXCEL.xls", 400);
+        m = new Metadata();
+        m.add(Metadata.RESOURCE_NAME_KEY, "testEXCEL.xls");
+        try {
+            assertEquals(
+                    MediaType.application("vnd.ms-excel"),
+                    detector.detect(xls, m));
         } finally {
             xls.close();
         }

Commit:
78f6eac056f8298cdcb80381a1628023a2392a4d
Nick Burch
nick@apache.org
2011-11-21 10:30:22 +0000
Expand container detection tests, and added disabled (failing) tests for TIKA-786
diff --git a/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java b/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
index 3ea99b4aa..b0eeea2a3 100644
--- a/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
+++ b/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
@@ -35,31 +35,52 @@ public class TestContainerAwareDetector extends TestCase {
 
     private final Detector detector = new DefaultDetector();
 
-    private void assertDetect(String file, String type) throws Exception {
-        TikaInputStream stream = TikaInputStream.get(
-                TestContainerAwareDetector.class.getResource(
-                        "/test-documents/" + file));
-        try {
-            assertEquals(
-                    MediaType.parse(type),
-                    detector.detect(stream, new Metadata()));
-        } finally {
-            stream.close();
-        }
+    private void assertTypeByData(String file, String type) throws Exception {
+       assertTypeByNameAndData(file, null, type);
+    }
+    private void assertTypeByNameAndData(String file, String type) throws Exception {
+       assertTypeByNameAndData(file, file, type);
+    }
+    private void assertTypeByNameAndData(String dataFile, String name, String type) throws Exception {
+       TikaInputStream stream = TikaInputStream.get(
+               TestContainerAwareDetector.class.getResource(
+                       "/test-documents/" + dataFile));
+       try {
+           Metadata m = new Metadata();
+           if (name != null)
+              m.add(Metadata.RESOURCE_NAME_KEY, name);
+           
+           assertEquals(
+                   MediaType.parse(type),
+                   detector.detect(stream, m));
+       } finally {
+           stream.close();
+       }
     }
 
     public void testDetectOLE2() throws Exception {
         // Microsoft office types known by POI
-        assertDetect("testEXCEL.xls", "application/vnd.ms-excel");
-        assertDetect("testWORD.doc", "application/msword");
-        assertDetect("testPPT.ppt", "application/vnd.ms-powerpoint");
+        assertTypeByData("testEXCEL.xls", "application/vnd.ms-excel");
+        assertTypeByData("testWORD.doc", "application/msword");
+        assertTypeByData("testPPT.ppt", "application/vnd.ms-powerpoint");
 
         // Try some ones that POI doesn't handle, that are still OLE2 based
-        assertDetect("testWORKS.wps", "application/vnd.ms-works");
-        assertDetect("testWORKS2000.wps", "application/vnd.ms-works");
-        assertDetect("testCOREL.shw", "application/x-corelpresentations");
-        assertDetect("testQUATTRO.qpw", "application/x-quattro-pro");
-        assertDetect("testQUATTRO.wb3", "application/x-quattro-pro");
+        assertTypeByData("testWORKS.wps", "application/vnd.ms-works");
+        assertTypeByData("testWORKS2000.wps", "application/vnd.ms-works");
+        assertTypeByData("testCOREL.shw", "application/x-corelpresentations");
+        assertTypeByData("testQUATTRO.qpw", "application/x-quattro-pro");
+        assertTypeByData("testQUATTRO.wb3", "application/x-quattro-pro");
+        
+        // With the filename and data
+        assertTypeByNameAndData("testEXCEL.xls", "application/vnd.ms-excel");
+        assertTypeByNameAndData("testWORD.doc", "application/msword");
+        assertTypeByNameAndData("testPPT.ppt", "application/vnd.ms-powerpoint");
+        
+        // With the wrong filename supplied, data will trump filename
+        // TODO Fix this! (TIKA-786)
+//        assertTypeByNameAndData("testEXCEL.xls", "notWord.doc",  "application/vnd.ms-excel");
+//        assertTypeByNameAndData("testWORD.doc",  "notExcel.xls", "application/msword");
+//        assertTypeByNameAndData("testPPT.ppt",   "notWord.doc",  "application/vnd.ms-powerpoint");
     }
 
     public void testOpenContainer() throws Exception {
@@ -78,23 +99,37 @@ public class TestContainerAwareDetector extends TestCase {
     }
 
     public void testDetectODF() throws Exception {
-        assertDetect("testODFwithOOo3.odt", "application/vnd.oasis.opendocument.text");
-        assertDetect("testOpenOffice2.odf", "application/vnd.oasis.opendocument.formula");
+        assertTypeByData("testODFwithOOo3.odt", "application/vnd.oasis.opendocument.text");
+        assertTypeByData("testOpenOffice2.odf", "application/vnd.oasis.opendocument.formula");
     }
 
     public void testDetectOOXML() throws Exception {
-        assertDetect("testEXCEL.xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet");
-        assertDetect("testWORD.docx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document");
-        assertDetect("testPPT.pptx", "application/vnd.openxmlformats-officedocument.presentationml.presentation");
+        assertTypeByData("testEXCEL.xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet");
+        assertTypeByData("testWORD.docx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document");
+        assertTypeByData("testPPT.pptx", "application/vnd.openxmlformats-officedocument.presentationml.presentation");
 
         // Check some of the less common OOXML types
-        assertDetect("testPPT.pptm", "application/vnd.ms-powerpoint.presentation.macroenabled.12");
-        assertDetect("testPPT.ppsx", "application/vnd.openxmlformats-officedocument.presentationml.slideshow");
-        assertDetect("testPPT.ppsm", "application/vnd.ms-powerpoint.slideshow.macroEnabled.12");
+        assertTypeByData("testPPT.pptm", "application/vnd.ms-powerpoint.presentation.macroenabled.12");
+        assertTypeByData("testPPT.ppsx", "application/vnd.openxmlformats-officedocument.presentationml.slideshow");
+        assertTypeByData("testPPT.ppsm", "application/vnd.ms-powerpoint.slideshow.macroEnabled.12");
         
         // .xlsb is an OOXML file containing the binary parts, and not
         //  an OLE2 file as you might initially expect!
-        assertDetect("testEXCEL.xlsb", "application/vnd.ms-excel.sheet.binary.macroEnabled.12");
+        assertTypeByData("testEXCEL.xlsb", "application/vnd.ms-excel.sheet.binary.macroEnabled.12");
+
+        // With the filename and data
+        assertTypeByNameAndData("testEXCEL.xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet");
+        assertTypeByNameAndData("testWORD.docx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document");
+        assertTypeByNameAndData("testPPT.pptx", "application/vnd.openxmlformats-officedocument.presentationml.presentation");
+        
+        // With the wrong filename supplied, data will trump filename
+        // TODO Fix this! (TIKA-786)
+//        assertTypeByNameAndData("testEXCEL.xlsx", "notWord.docx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet");
+//        assertTypeByNameAndData("testWORD.docx",  "notExcel.xlsx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document");
+//        assertTypeByNameAndData("testPPT.pptx",   "notWord.docx", "application/vnd.openxmlformats-officedocument.presentationml.presentation");
+        
+        // With an incorrect filename of a different container type, data trumps filename
+        assertTypeByNameAndData("testEXCEL.xlsx", "notOldExcel.xls", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet");
     }
 
     /**
@@ -131,15 +166,15 @@ public class TestContainerAwareDetector extends TestCase {
     }
 
     public void testDetectIWork() throws Exception {
-        assertDetect("testKeynote.key", "application/vnd.apple.keynote");
-        assertDetect("testNumbers.numbers", "application/vnd.apple.numbers");
-        assertDetect("testPages.pages", "application/vnd.apple.pages");
+        assertTypeByData("testKeynote.key", "application/vnd.apple.keynote");
+        assertTypeByData("testNumbers.numbers", "application/vnd.apple.numbers");
+        assertTypeByData("testPages.pages", "application/vnd.apple.pages");
     }
 
     public void testDetectZip() throws Exception {
-        assertDetect("test-documents.zip", "application/zip");
-        assertDetect("test-zip-of-zip.zip", "application/zip");
-        assertDetect("testJAR.jar", "application/java-archive");
+        assertTypeByData("test-documents.zip", "application/zip");
+        assertTypeByData("test-zip-of-zip.zip", "application/zip");
+        assertTypeByData("testJAR.jar", "application/java-archive");
     }
 
     private TikaInputStream getTruncatedFile(String name, int n)

Commit:
e3f9af7270d955dd1112d3ac364c2f7f9f397a49
Nick Burch
nick@apache.org
2011-11-21 01:24:58 +0000
TIKA-784 Switch the DITA types to be format specialisations, rather than their own dedicated mimetypes, to match the OASIS recommendation
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 57077be59..41e3eecfc 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -75,25 +75,34 @@
     <_comment>Darwin Information Typing Architecture</_comment>
   </mime-type>
 
-  <mime-type type="application/dita+map+xml">
+  <mime-type type="application/dita+xml;format=map">
     <sub-class-of type="application/dita+xml"/>
     <_comment>DITA Map</_comment>
     <root-XML localName="map"/>
     <root-XML localName="map" namespaceURI="http://docs.oasis-open.org/namespace"/>
     <glob pattern="*.ditamap"/>
   </mime-type>
-  <mime-type type="application/dita+topic+xml">
+  <mime-type type="application/dita+xml;format=topic">
     <sub-class-of type="application/dita+xml"/>
     <_comment>DITA Topic</_comment>
     <root-XML localName="topic"/>
     <root-XML localName="topic" namespaceURI="http://docs.oasis-open.org/namespace"/>
+    <!-- Topic is the default, Task and Concept are specialisations -->
+    <glob pattern="*.dita"/>
+  </mime-type>
+  <mime-type type="application/dita+xml;format=task">
+    <sub-class-of type="application/dita+xml;format=task"/>
+    <_comment>DITA Task Topic</_comment>
     <root-XML localName="task"/>
     <root-XML localName="task" namespaceURI="http://docs.oasis-open.org/namespace"/>
+  </mime-type>
+  <mime-type type="application/dita+xml;format=concept">
+    <sub-class-of type="application/dita+xml;format=topic"/>
+    <_comment>DITA Concept Topic</_comment>
     <root-XML localName="concept"/>
     <root-XML localName="concept" namespaceURI="http://docs.oasis-open.org/namespace"/>
-    <glob pattern="*.dita"/>
   </mime-type>
-  <mime-type type="application/dita+val+xml">
+  <mime-type type="application/dita+xml;format=val">
     <sub-class-of type="application/dita+xml"/>
     <_comment>DITA Conditional Processing Profile</_comment>
     <root-XML localName="val"/>
diff --git a/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java b/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
index 4e9e88256..9c4068c83 100644
--- a/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
+++ b/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
@@ -348,25 +348,25 @@ public class TestMimeTypes extends TestCase {
      *  but we specialise them 
      */
     public void testDITADetection() throws Exception {
-       assertTypeByName("application/dita+topic+xml", "test.dita");
-       assertTypeByName("application/dita+map+xml", "test.ditamap");
-       assertTypeByName("application/dita+val+xml", "test.ditaval");
+       assertTypeByName("application/dita+xml; format=topic", "test.dita");
+       assertTypeByName("application/dita+xml; format=map", "test.ditamap");
+       assertTypeByName("application/dita+xml; format=val", "test.ditaval");
        
-       assertTypeByData("application/dita+topic+xml", "testDITA.dita");
-       assertTypeByData("application/dita+topic+xml", "testDITA2.dita");
-       assertTypeByData("application/dita+map+xml", "testDITA.ditamap");
+       assertTypeByData("application/dita+xml; format=task", "testDITA.dita");
+       assertTypeByData("application/dita+xml; format=concept", "testDITA2.dita");
+       assertTypeByData("application/dita+xml; format=map", "testDITA.ditamap");
        
-       assertTypeByNameAndData("application/dita+topic+xml", "testDITA.dita");
-       assertTypeByNameAndData("application/dita+topic+xml", "testDITA2.dita");
-       assertTypeByNameAndData("application/dita+map+xml", "testDITA.ditamap");
+       assertTypeByNameAndData("application/dita+xml; format=task", "testDITA.dita");
+       assertTypeByNameAndData("application/dita+xml; format=concept", "testDITA2.dita");
+       assertTypeByNameAndData("application/dita+xml; format=map", "testDITA.ditamap");
        
        // These are all children of the official type
+       assertEquals("application/dita+xml", 
+             repo.getMediaTypeRegistry().getSupertype(getTypeByNameAndData("testDITA.ditamap")).toString());
        assertEquals("application/dita+xml", 
              repo.getMediaTypeRegistry().getSupertype(getTypeByNameAndData("testDITA.dita")).toString());
        assertEquals("application/dita+xml", 
              repo.getMediaTypeRegistry().getSupertype(getTypeByNameAndData("testDITA2.dita")).toString());
-       assertEquals("application/dita+xml", 
-             repo.getMediaTypeRegistry().getSupertype(getTypeByNameAndData("testDITA.ditamap")).toString());
     }
 
     /**

Commit:
1cbd62ac78ebfa918a96735ec7e3f430692a6a7d
Nick Burch
nick@apache.org
2011-11-21 01:04:07 +0000
TIKA-785 Add a --list-detectors method to TikaCLI, along the lines of the existing --list-parsers one
diff --git a/CHANGES.txt b/CHANGES.txt
index 12f0dd895..019dce12a 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -23,6 +23,10 @@ Release 1.1 - Current Development
    previously it could cause the parser to incorrectly extract binary
    content as text (TIKA-782).
 
+ * CLI: New TikaCLI option "--list-detectors", which displays the
+   mimetype detectors that are available, similar to the existing
+   "--list-parsers" option for parsers. (TIKA-785).
+
 Release 1.0 - 11/4/2011
 ---------------------------------
 
diff --git a/tika-app/src/main/java/org/apache/tika/cli/TikaCLI.java b/tika-app/src/main/java/org/apache/tika/cli/TikaCLI.java
index 6eb44f701..f9d3c2d94 100644
--- a/tika-app/src/main/java/org/apache/tika/cli/TikaCLI.java
+++ b/tika-app/src/main/java/org/apache/tika/cli/TikaCLI.java
@@ -37,6 +37,7 @@ import java.util.Arrays;
 import java.util.Comparator;
 import java.util.HashMap;
 import java.util.HashSet;
+import java.util.List;
 import java.util.Map;
 import java.util.Map.Entry;
 import java.util.Set;
@@ -54,6 +55,7 @@ import org.apache.log4j.SimpleLayout;
 import org.apache.log4j.WriterAppender;
 import org.apache.tika.Tika;
 import org.apache.tika.config.TikaConfig;
+import org.apache.tika.detect.CompositeDetector;
 import org.apache.tika.detect.DefaultDetector;
 import org.apache.tika.detect.Detector;
 import org.apache.tika.extractor.EmbeddedDocumentExtractor;
@@ -312,6 +314,9 @@ public class TikaCLI {
         } else if (arg.equals("--list-parser") || arg.equals("--list-parsers")) {
             pipeMode = false;
             displayParsers(false);
+        } else if (arg.equals("--list-detector") || arg.equals("--list-detectors")) {
+           pipeMode = false;
+           displayDetectors();
         } else if (arg.equals("--list-parser-detail") || arg.equals("--list-parser-details")) {
             pipeMode = false;
             displayParsers(true);
@@ -430,6 +435,8 @@ public class TikaCLI {
         out.println("         List the available document parsers");
         out.println("    --list-parser-details");
         out.println("         List the available document parsers, and their supported mime types");
+        out.println("    --list-detectors");
+        out.println("         List the available document detectors");
         out.println("    --list-met-models");
         out.println("         List the available metadata models, and their supported keys");
         out.println("    --list-supported-types");
@@ -522,6 +529,27 @@ public class TikaCLI {
         }
     }
 
+    /*
+     * Displays loaded detectors and their mime types
+     * If a detector is a composite detector, it will list the
+     *  sub detectors.
+     */
+    private void displayDetectors() {
+        displayDetector(detector, 0);
+    }
+     
+    private void displayDetector(Detector d, int i) {
+        boolean isComposite = (d instanceof CompositeDetector);
+        String name = d.getClass().getName();
+        System.out.println(indent(i) + name + (isComposite ? " (Composite Detector):" : ""));
+        if (isComposite) {
+            List<Detector> subDetectors = ((CompositeDetector)d).getDetectors();
+            for(Detector sd : subDetectors) {
+                displayDetector(sd, i+2);
+            }
+        }
+    }
+
     private String indent(int indent) {
         return "                     ".substring(0, indent);
     }
diff --git a/tika-core/src/main/java/org/apache/tika/detect/CompositeDetector.java b/tika-core/src/main/java/org/apache/tika/detect/CompositeDetector.java
index 2874ca682..4a4db2d1a 100644
--- a/tika-core/src/main/java/org/apache/tika/detect/CompositeDetector.java
+++ b/tika-core/src/main/java/org/apache/tika/detect/CompositeDetector.java
@@ -19,6 +19,7 @@ package org.apache.tika.detect;
 import java.io.IOException;
 import java.io.InputStream;
 import java.util.Arrays;
+import java.util.Collections;
 import java.util.List;
 
 import org.apache.tika.metadata.Metadata;
@@ -65,4 +66,10 @@ public class CompositeDetector implements Detector {
         return type;
     }
 
+    /**
+     * Returns the component detectors.
+     */
+    public List<Detector> getDetectors() {
+       return Collections.unmodifiableList(detectors);
+    }
 }

Commit:
9ae596cdaee275b4a11b3839a33373fcc0fa9e2f
Nick Burch
nick@apache.org
2011-11-18 15:13:52 +0000
TIKA-784 DITA mimetype entries for the 3 subtypes, plus tests
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 2b1ae18eb..57077be59 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -72,8 +72,32 @@
 
   <mime-type type="application/dita+xml">
     <sub-class-of type="application/xml"/>
-    <glob pattern="*.dita"/>
+    <_comment>Darwin Information Typing Architecture</_comment>
+  </mime-type>
+
+  <mime-type type="application/dita+map+xml">
+    <sub-class-of type="application/dita+xml"/>
+    <_comment>DITA Map</_comment>
+    <root-XML localName="map"/>
+    <root-XML localName="map" namespaceURI="http://docs.oasis-open.org/namespace"/>
     <glob pattern="*.ditamap"/>
+  </mime-type>
+  <mime-type type="application/dita+topic+xml">
+    <sub-class-of type="application/dita+xml"/>
+    <_comment>DITA Topic</_comment>
+    <root-XML localName="topic"/>
+    <root-XML localName="topic" namespaceURI="http://docs.oasis-open.org/namespace"/>
+    <root-XML localName="task"/>
+    <root-XML localName="task" namespaceURI="http://docs.oasis-open.org/namespace"/>
+    <root-XML localName="concept"/>
+    <root-XML localName="concept" namespaceURI="http://docs.oasis-open.org/namespace"/>
+    <glob pattern="*.dita"/>
+  </mime-type>
+  <mime-type type="application/dita+val+xml">
+    <sub-class-of type="application/dita+xml"/>
+    <_comment>DITA Conditional Processing Profile</_comment>
+    <root-XML localName="val"/>
+    <root-XML localName="val" namespaceURI="http://docs.oasis-open.org/namespace"/>
     <glob pattern="*.ditaval"/>
   </mime-type>
 
diff --git a/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java b/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
index 38ef2e9ff..4e9e88256 100644
--- a/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
+++ b/tika-parsers/src/test/java/org/apache/tika/mime/TestMimeTypes.java
@@ -333,7 +333,7 @@ public class TestMimeTypes extends TestCase {
         assertTypeByName("application/postscript", "x.epsi");
     }
     
-    public void testMicrosoftMultiMedia() throws Exception {
+    public void testMicrosoftMultiMediaDetection() throws Exception {
        assertTypeByName("video/x-ms-asf", "x.asf");
        assertTypeByName("video/x-ms-wmv", "x.wmv");
        assertTypeByName("audio/x-ms-wma", "x.wma");
@@ -342,6 +342,32 @@ public class TestMimeTypes extends TestCase {
        assertTypeByData("video/x-ms-wmv", "testWMV.wmv");
        assertTypeByData("audio/x-ms-wma", "testWMA.wma");
     }
+    
+    /**
+     * All 3 DITA types are in theory handled by the same mimetype,
+     *  but we specialise them 
+     */
+    public void testDITADetection() throws Exception {
+       assertTypeByName("application/dita+topic+xml", "test.dita");
+       assertTypeByName("application/dita+map+xml", "test.ditamap");
+       assertTypeByName("application/dita+val+xml", "test.ditaval");
+       
+       assertTypeByData("application/dita+topic+xml", "testDITA.dita");
+       assertTypeByData("application/dita+topic+xml", "testDITA2.dita");
+       assertTypeByData("application/dita+map+xml", "testDITA.ditamap");
+       
+       assertTypeByNameAndData("application/dita+topic+xml", "testDITA.dita");
+       assertTypeByNameAndData("application/dita+topic+xml", "testDITA2.dita");
+       assertTypeByNameAndData("application/dita+map+xml", "testDITA.ditamap");
+       
+       // These are all children of the official type
+       assertEquals("application/dita+xml", 
+             repo.getMediaTypeRegistry().getSupertype(getTypeByNameAndData("testDITA.dita")).toString());
+       assertEquals("application/dita+xml", 
+             repo.getMediaTypeRegistry().getSupertype(getTypeByNameAndData("testDITA2.dita")).toString());
+       assertEquals("application/dita+xml", 
+             repo.getMediaTypeRegistry().getSupertype(getTypeByNameAndData("testDITA.ditamap")).toString());
+    }
 
     /**
      * @since TIKA-194
@@ -499,15 +525,18 @@ public class TestMimeTypes extends TestCase {
     
     private void assertTypeByNameAndData(String expected, String filename)
 	    throws IOException {
-	InputStream stream = TestMimeTypes.class.getResourceAsStream(
-	        "/test-documents/" + filename);
-	try {
-	    Metadata metadata = new Metadata();
-	    metadata.set(Metadata.RESOURCE_NAME_KEY, filename);
-	    assertEquals(expected, repo.detect(stream, metadata).toString());
-	} finally {
-	    stream.close();
-	}
-}
-
+       assertEquals(expected, getTypeByNameAndData(filename).toString());
+    }
+    private MediaType getTypeByNameAndData(String filename) throws IOException {
+       InputStream stream = TestMimeTypes.class.getResourceAsStream(
+             "/test-documents/" + filename);
+       assertNotNull("Test document not found: " + filename, stream);
+       try {
+          Metadata metadata = new Metadata();
+          metadata.set(Metadata.RESOURCE_NAME_KEY, filename);
+          return repo.detect(stream, metadata);
+       } finally {
+          stream.close();
+       }
+    }
 }

Commit:
0edc3adbe921e8013808dd5d259387b122b10a92
Nick Burch
nick@apache.org
2011-11-18 15:01:07 +0000
TIKA-784 Sample DITA task, concept and map files. (Based on some Alfresco documentation, with content replaced with Tika info)
diff --git a/tika-parsers/src/test/resources/test-documents/testDITA.dita b/tika-parsers/src/test/resources/test-documents/testDITA.dita
new file mode 100644
index 000000000..b68da7b0b
--- /dev/null
+++ b/tika-parsers/src/test/resources/test-documents/testDITA.dita
@@ -0,0 +1,34 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<!DOCTYPE task PUBLIC "-//OASIS//DTD DITA Task//EN" "task.dtd">
+<task id="apache-tika">
+    <title>Apache Tika</title>
+    <shortdesc>Apache Tika - a content analysis toolkit.</shortdesc>
+    <prolog>
+        <author>Apache Software Foundation</author>
+        <copyright>
+            <copyryear year="2011"/>
+            <copyrholder>Apache Software Foundation</copyrholder>
+        </copyright>
+        <metadata>
+            <audience experiencelevel="expert" job="Customizing" type="Coder"/>
+            <category>Metadata</category>
+            <keywords>
+                <keyword>Tika</keyword>
+                <keyword>Content</keyword>
+            </keywords>
+            <prodinfo>
+                <prodname>Apache Tika</prodname>
+                <vrmlist>
+                    <vrm version="1.x" release="Final" modification="2011/11/11"/>
+                </vrmlist>
+            </prodinfo>
+        </metadata>
+    </prolog>
+    <taskbody>
+        <context>
+            <p>The Apache Tika toolkit detects and extracts metadata and structured text content from various documents using existing parser libraries. You can find the latest release on the download page. See the Getting Started guide for instructions on how to start using Tika.</p>
+
+            <p>Tika is a project of the Apache Software Foundation, and was formerly a subproject of Apache Lucene.</p>
+        </context>
+    </taskbody>
+</task>
diff --git a/tika-parsers/src/test/resources/test-documents/testDITA.ditamap b/tika-parsers/src/test/resources/test-documents/testDITA.ditamap
new file mode 100644
index 000000000..e7b2a5506
--- /dev/null
+++ b/tika-parsers/src/test/resources/test-documents/testDITA.ditamap
@@ -0,0 +1,23 @@
+<?xml version='1.0' encoding='UTF-8'?>
+<!DOCTYPE map PUBLIC "-//OASIS//DTD DITA Map//EN" "http://docs.oasis-open.org/dita/v1.1/OS/dtd/map.dtd">
+<map id="apache-tika" title="Apache Tika">
+    <topicmeta>
+        <author>Apache Tika</author>
+        <copyright>
+            <copyryear year="2011"/>
+            <copyrholder>Apache Software Foundation</copyrholder>
+        </copyright>
+        <category>Version 1.x</category>
+        <category>Tika</category>
+        <category>Mime</category>
+        <prodinfo>
+            <prodname>Apache Tika</prodname>
+            <vrmlist>
+                <vrm version="1.x" release="Final" modification="2011/11/11"/>
+            </vrmlist>
+        </prodinfo>
+    </topicmeta>
+    <topicref href="testDITA.dita">
+        <topicref href="testDITA2.dita" />
+    </topicref>
+</map>
diff --git a/tika-parsers/src/test/resources/test-documents/testDITA2.dita b/tika-parsers/src/test/resources/test-documents/testDITA2.dita
new file mode 100644
index 000000000..1dd7fe343
--- /dev/null
+++ b/tika-parsers/src/test/resources/test-documents/testDITA2.dita
@@ -0,0 +1,33 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "http://docs.oasis-open.org/dita/v1.1/OS/dtd/concept.dtd">
+<concept id="tika-arch">
+ <title>Apache Tika Architecture</title>
+ <shortdesc>This section describes the Apache Tika architecture.</shortdesc>
+ <prolog>
+  <author>Apache Software Foundation</author>
+  <copyright>
+   <copyryear year="2011"/>
+   <copyrholder>Apache Software Foundation</copyrholder>
+  </copyright>
+  <metadata>
+      <audience experiencelevel="expert" job="Customizing" type="Coder"/>
+      <category>Metadata</category>
+      <keywords>
+          <keyword>Tika</keyword>
+          <keyword>Content</keyword>
+      </keywords>
+      <prodinfo>
+          <prodname>Apache Tika</prodname>
+          <vrmlist>
+              <vrm version="1.x" release="Final" modification="2011/11/11"/>
+          </vrmlist>
+      </prodinfo>
+  </metadata>
+ </prolog>
+ <conbody>
+  <p>The Detector Interface</p>
+
+  <p>The org.apache.tika.detect.Detector interface is the basis for most of the content type detection in Apache Tika. All the different ways of detecting content all implement the same common method:</p>
+  <image href="http://tika.apache.org/tika.png" id="tika_logo" />
+ </conbody>
+</concept>

Commit:
a7e1524d4b3e30f70e51d64f084b0b2f19c5b85a
Nick Burch
nick@apache.org
2011-11-18 12:43:16 +0000
TIKA-784 Mimetype entry and glob for DITA
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index b3118f669..2b1ae18eb 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -69,6 +69,14 @@
   <mime-type type="application/dec-dx"/>
   <mime-type type="application/dialog-info+xml"/>
   <mime-type type="application/dicom"/>
+
+  <mime-type type="application/dita+xml">
+    <sub-class-of type="application/xml"/>
+    <glob pattern="*.dita"/>
+    <glob pattern="*.ditamap"/>
+    <glob pattern="*.ditaval"/>
+  </mime-type>
+
   <mime-type type="application/dns"/>
   <mime-type type="application/dvcs"/>
   <mime-type type="application/ecmascript">

Commit:
c631563b6e2d3f3754ebdb365a63be86fac1109a
Michael McCandless
mikemccand@apache.org
2011-11-17 20:33:42 +0000
TIKA-782: properly handle \bin control word
diff --git a/CHANGES.txt b/CHANGES.txt
index 69c4fb173..12f0dd895 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -18,7 +18,10 @@ Release 1.1 - Current Development
  * RTF: Fixed case where a font change would result in processing
    bytes in the wrong font's charset, producing bogus text output
    (TIKA-777).  Don't output whitespace in ignored group states,
-   avoiding excessive whitespace output (TIKA-781).
+   avoiding excessive whitespace output (TIKA-781).  Binary embedded
+   content (using \bin control word) is now skipped correctly;
+   previously it could cause the parser to incorrectly extract binary
+   content as text (TIKA-782).
 
 Release 1.0 - 11/4/2011
 ---------------------------------
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/rtf/TextExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/rtf/TextExtractor.java
index 728ca6ad5..7d2287d5b 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/rtf/TextExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/rtf/TextExtractor.java
@@ -19,6 +19,7 @@ package org.apache.tika.parser.rtf;
 
 import java.io.IOException;
 import java.io.InputStream;
+import java.io.PushbackInputStream;
 import java.nio.ByteBuffer;
 import java.nio.CharBuffer;
 import java.nio.charset.CharsetDecoder;
@@ -86,8 +87,6 @@ final class TextExtractor {
     private GroupState groupState = new GroupState();
 
     private boolean inHeader = true;
-    private int chIndex;
-    private int lastGroupStart;
     private int fontTableState;
     private int fontTableDepth;
 
@@ -233,22 +232,22 @@ final class TextExtractor {
         this.out = out;
     }
 
-    private static boolean isHexChar(char ch) {
+    private static boolean isHexChar(int ch) {
         return (ch >= '0' && ch <= '9') ||
             (ch >= 'a' && ch <= 'f') ||
             (ch >= 'A' && ch <= 'F');
     }
 
-    private static boolean isAlpha(char ch) {
+    private static boolean isAlpha(int ch) {
         return (ch >= 'a' && ch <= 'z') ||
             (ch >= 'A' && ch <= 'Z');
     }
 
-    private static boolean isDigit(char ch) {
+    private static boolean isDigit(int ch) {
         return ch >= '0' && ch <= '9';
     }
 
-    private static int hexValue(char ch) {
+    private static int hexValue(int ch) {
         if (ch >= '0' && ch <= '9') {
             return ch - '0';
         } else if (ch >= 'a' && ch <= 'z') {
@@ -271,7 +270,8 @@ final class TextExtractor {
 
     // Buffers the byte (unit in the current charset) for
     // output:
-    private void addOutputByte(byte b) throws IOException, SAXException, TikaException {
+    private void addOutputByte(int b) throws IOException, SAXException, TikaException {
+        assert b >= 0 && b < 256 : "byte value out of range: " + b;
 
         if (pendingCharCount != 0) {
             pushChars();
@@ -285,12 +285,12 @@ final class TextExtractor {
             pendingBytes = newArray;
             pendingByteBuffer = ByteBuffer.wrap(pendingBytes);
         }
-        pendingBytes[pendingByteCount++] = b;
+        pendingBytes[pendingByteCount++] = (byte) b;
     }
 
-    // Buffers a byte as part of a control word:
-    private void addControl(byte b) {
-        assert isAlpha((char) b);
+   // Buffers a byte as part of a control word:
+    private void addControl(int b) {
+        assert isAlpha(b);
         // Save the byte in pending buffer:
         if (pendingControlCount == pendingControl.length) {
             // Gradual but exponential growth:
@@ -298,7 +298,7 @@ final class TextExtractor {
             System.arraycopy(pendingControl, 0, newArray, 0, pendingControl.length);
             pendingControl = newArray;
         }
-        pendingControl[pendingControlCount++] = b;
+        pendingControl[pendingControlCount++] = (byte) b;
     }
 
     // Buffers a UTF16 code unit for output
@@ -323,166 +323,145 @@ final class TextExtractor {
     // Shallow parses the entire doc, writing output to
     // this.out and this.metadata
     public void extract(InputStream in) throws IOException, SAXException, TikaException {
+//        in = new FilterInputStream(in) {
+//            public int read() throws IOException {
+//                int r = super.read();
+//                System.out.write(r);
+//                System.out.flush();
+//                return r;
+//            }
+//            public int read(byte b[], int off, int len) throws IOException {
+//                int r = super.read(b, off, len);
+//                System.out.write(b, off, r);
+//                System.out.flush();
+//                return r;
+//            }
+//        };
+        extract(new PushbackInputStream(in, 2));
+    }
+    
+    private void extract(PushbackInputStream in) throws IOException, SAXException, TikaException {
         out.startDocument();
 
-        int state = 0;
-        int pushBack = -2;
-        boolean negParam = false;
-        char hex1 = 0;
-        long param = 0;
-
         while (true) {
-            final int b;
-            if (pushBack != -2) {
-                b = pushBack;
-                pushBack = -2;
-            } else {
-                b = in.read();
-                chIndex++;
-            }
+            final int b = in.read();
             if (b == -1) {
                 break;
-            }
-
-            // NOTE: this is always a 8bit clean byte (ie
-            // < 128), but we use a char for
-            // convenience in the testing below:
-            final char ch = (char) b;
-
-            switch (state) {
-
-            case 0:
-                if (ch == '\\') {
-                    state = 1;
-                } else if (ch == '{') {
-                    pushText();
-                    processGroupStart();
-                } else if (ch == '}') {
-                    pushText();
-                    processGroupEnd();
-                } else if (ch != '\r' && ch != '\n' && (!groupState.ignore || nextMetaData != null)) {
-                    // Linefeed and carriage return are not
-                    // significant
-                    if (ansiSkip != 0) {
-                        ansiSkip--;
-                    } else {
-                        addOutputByte((byte) ch);
-                    }
-                }
-                break;
-
-            // saw \
-            case 1:
-                if (ch == '\'') {
-                    // escaped hex char
-                    state = 2;
-                } else if (isAlpha(ch)) {
-                    // control word
-                    //pushText();
-                    addControl((byte) ch);
-                    state = 4;
-                } else if (ch == '{' || ch == '}' || ch == '\\' || ch == '\r' || ch == '\n') {
-                    // escaped char
-                    addOutputByte((byte) ch);
-                    state = 0;
-                } else {
-                    // control symbol, eg \* or \~
-                    //pushText();
-                    processControlSymbol(ch);
-                    state = 0;
-                }
-                break;
-
-            // saw \'
-            case 2:
-                if (isHexChar(ch)) {
-                    hex1 = ch;
-                    state = 3;
-                } else {
-                    // DOC ERROR (malformed hex escape): ignore 
-                    state = 0;
-                }
-                break;
-
-            // saw \'x
-            case 3: 
-                if (isHexChar(ch)) {
-                    if (ansiSkip != 0) {
-                        // Skip this ansi char since we are
-                        // still in the shadow of a unicode
-                        // escape:
-                        ansiSkip--;
-                    } else {
-                        // Unescape:
-                        addOutputByte((byte) (16*hexValue(hex1) + hexValue(ch)));
-                    }
-                    state = 0;
-                } else {
-                    // TODO: log a warning here, somehow?
-                    // DOC ERROR (malformed hex escape):
-                    // ignore
-                    state = 0;
+            } else if (b == '\\') {
+                parseControlToken(in);
+            } else if (b == '{') {
+                pushText();
+                processGroupStart(in);
+             } else if (b == '}') {
+                pushText();
+                processGroupEnd();
+                if (groupStates.isEmpty()) {
+                    // parsed document closing brace
+                    break;
                 }
-                break;
-
-            // inside control word
-            case 4:
-                if (isAlpha(ch)) {
-                    // still in control word
-                    addControl((byte) ch);
-                } else if (ch == '-') {
-                    // end of control word, start of negative parameter
-                    negParam = true;
-                    param = 0;
-                    state = 5;
-                } else if (isDigit(ch)) {
-                    // end of control word, start of positive parameter
-                    negParam = false;
-                    param = (long) (ch - '0');
-                    state = 5;
-                } else if (ch == ' ') {
-                    // space is consumed as part of the
-                    // control word, but is not added to the
-                    // control word
-                    processControlWord();
-                    pendingControlCount = 0;
-                    state = 0;
+            } else if (b != '\r' && b != '\n' && (!groupState.ignore || nextMetaData != null)) {
+                // Linefeed and carriage return are not
+                // significant
+                if (ansiSkip != 0) {
+                    ansiSkip--;
                 } else {
-                    processControlWord();
-                    pendingControlCount = 0;
-                    // eps transition back to start state
-                    pushBack = ch;
-                    state = 0;
+                    addOutputByte(b);
                 }
-                break;
-
-            // inside control word's numeric param
-            case 5:
-                if (isDigit(ch)) {
-                    param = (10*param) + (long) (ch - '0');
-                } else {
-                    if (negParam) {
-                        param = -param;
-                    }
-                    processControlWord(param);
-                    pendingControlCount = 0;
-                    if (ch != ' ') {
-                        // space is consumed as part of the
-                        // control word
-                        pushBack = ch;
-                    }
-                    state = 0;
-                }
-                break;
-              
-            default:
-                throw new RuntimeException("invalid state");
             }
         }
 
         endParagraph(false);
         out.endDocument();
     }
+    
+    private void parseControlToken(PushbackInputStream in) throws IOException, SAXException, TikaException {
+        int b = in.read();
+        if (b == '\'') {
+            // escaped hex char
+            parseHexChar(in);
+        } else if (isAlpha(b)) {
+            // control word
+            parseControlWord((char)b, in);
+        } else if (b == '{' || b == '}' || b == '\\' || b == '\r' || b == '\n') {
+            // escaped char
+            addOutputByte(b);
+        } else if (b != -1) {
+            // control symbol, eg \* or \~
+            processControlSymbol((char)b);
+        }
+    }
+    
+    private void parseHexChar(PushbackInputStream in) throws IOException, SAXException, TikaException {
+        int hex1 = in.read();
+        if (!isHexChar(hex1)) {
+            // DOC ERROR (malformed hex escape): ignore 
+            in.unread(hex1);
+            return;
+        }
+        
+        int hex2 = in.read();
+        if (!isHexChar(hex2)) {
+            // TODO: log a warning here, somehow?
+            // DOC ERROR (malformed hex escape):
+            // ignore
+            in.unread(hex2);
+            return;
+        }
+        
+        if (ansiSkip != 0) {
+            // Skip this ansi char since we are
+            // still in the shadow of a unicode
+            // escape:
+            ansiSkip--;
+        } else {
+            // Unescape:
+            addOutputByte(16*hexValue(hex1) + hexValue(hex2));
+        }
+    }
+
+    private void parseControlWord(int firstChar, PushbackInputStream in) throws IOException, SAXException, TikaException {
+        addControl(firstChar);
+        
+        int b = in.read();
+        while (isAlpha(b)) {
+            addControl(b);
+            b = in.read();
+        }
+        
+        boolean hasParam = false;
+        boolean negParam = false;
+        if (b == '-') {
+            negParam = true;
+            hasParam = true;
+            b = in.read();
+        }
+
+        int param = 0;
+        while (isDigit(b)) {
+            param *= 10;
+            param += (b - '0');
+            hasParam = true;
+            b = in.read();
+        }
+        
+        // space is consumed as part of the
+        // control word, but is not added to the
+        // control word
+        if (b != ' ') {
+            in.unread(b);
+        }
+        
+        if (hasParam) {
+            if (negParam) {
+                param = -param;
+            }
+            processControlWord(param, in);
+        } else {
+            processControlWord();
+        }
+        
+        pendingControlCount = 0;
+    }
 
     private void lazyStartParagraph() throws IOException, SAXException, TikaException {
         if (!inParagraph) {
@@ -624,14 +603,9 @@ final class TextExtractor {
             addOutputChar('\u00a0');
             break;
         case '*':
-            // Ignorable destination (control words defined
-            // after the 1987 RTF spec).  Note that
-            // sometimes we un-ignore within this group, eg
-            // when handling upr escape.
-            if (chIndex == lastGroupStart+2) {
-                // Only ignore if \* comes right after {:
-                groupState.ignore = true;
-            }
+            // Ignorable destination (control words defined after
+            // the 1987 RTF spec). These are already handled by
+            // processGroupStart()
             break;
         case '-':
             // Optional hyphen -> unicode SOFT HYPHEN
@@ -689,8 +663,7 @@ final class TextExtractor {
     }
 
     // Handle control word that takes a parameter:
-    // Param is long because spec says max value is 1+ Integer.MAX_VALUE!
-    private void processControlWord(long param) throws IOException, SAXException, TikaException {
+    private void processControlWord(int param, PushbackInputStream in) throws IOException, SAXException, TikaException {
 
         // TODO: afN?  (associated font number)
 
@@ -719,13 +692,13 @@ final class TextExtractor {
         if (inHeader) {
             if (equals("ansicpg")) {
                 // ANSI codepage
-                final String cs = ANSICPG_MAP.get((int) param);
+                final String cs = ANSICPG_MAP.get(param);
                 if (cs != null) {
                     globalCharset = cs;
                 }
             } else if (equals("deff")) {
                 // Default font
-                globalDefaultFont = (int) param;
+                globalDefaultFont = param;
             }
 
             if (fontTableState == 1) {
@@ -736,9 +709,9 @@ final class TextExtractor {
                 } else {
                     if (equals("f")) {
                         // Start new font definition
-                        curFontID = (int) param;
+                        curFontID = param;
                     } else if (equals("fcharset")) {
-                        final String cs = FCHARSET_MAP.get((int) param);
+                        final String cs = FCHARSET_MAP.get(param);
                         if (cs != null) {
                             fontToCharset.put(curFontID, cs);
                         }
@@ -771,7 +744,7 @@ final class TextExtractor {
                 }
             } else if (equals("f")) {
                 // Change current font
-                final String fontCharset = fontToCharset.get((int) param);
+                final String fontCharset = fontToCharset.get(param);
 
                 // Push any buffered text before changing
                 // font:
@@ -788,24 +761,36 @@ final class TextExtractor {
             }
         }
 
-        // Process unicode escape.  This can appear in doc
+        // Process unicode escape. This can appear in doc
         // or in header, since the metadata (info) fields
         // in the header can be unicode escaped as well:
-        if (pendingControl[0] == 'u') {
-            if (pendingControlCount == 1) {
-                // Unicode escape
-                if (!groupState.ignore) {
-                    final char utf16CodeUnit = (char) (((int) param) & 0xffff);
-                    addOutputChar(utf16CodeUnit);
-                }
+        if (equals("u")) {
+            // Unicode escape
+            if (!groupState.ignore) {
+                final char utf16CodeUnit = (char) (param & 0xffff);
+                addOutputChar(utf16CodeUnit);
+            }
 
-                // After seeing a unicode escape we must
-                // skip the next ucSkip ansi chars (the
-                // "unicode shadow")
-                ansiSkip = groupState.ucSkip;
-            } else if (pendingControlCount == 2 && pendingControl[1] == 'c') {
-                // Change unicode shadow length
-                groupState.ucSkip = (int) param;
+            // After seeing a unicode escape we must
+            // skip the next ucSkip ansi chars (the
+            // "unicode shadow")
+            ansiSkip = groupState.ucSkip;
+        } else if (equals("uc")) {
+            // Change unicode shadow length
+            groupState.ucSkip = (int) param;
+        } else if (equals("bin")) {
+            if (param >= 0) {
+                int bytesToRead = param;
+                byte[] tmpArray = new byte[Math.min(1024, bytesToRead)];
+                while (bytesToRead > 0) {
+                    int r = in.read(tmpArray, 0, Math.min(bytesToRead, tmpArray.length));
+                    if (r < 0) {
+                        throw new TikaException("unexpected end of file: need " + param + " bytes of binary data, found " + (param-bytesToRead));
+                    }
+                    bytesToRead -= r;
+                }
+            } else {
+                // log some warning?
             }
         }
     }
@@ -1043,7 +1028,7 @@ final class TextExtractor {
     }
 
     // Push new GroupState
-    private void processGroupStart() throws IOException {
+    private void processGroupStart(PushbackInputStream in) throws IOException {
         ansiSkip = 0;
         // Push current groupState onto the stack
         groupStates.add(groupState);
@@ -1056,8 +1041,19 @@ final class TextExtractor {
             uprState = 1;
             groupState.ignore = true;
         }
-
-        lastGroupStart = chIndex;
+        
+        // Check for ignorable groups. Note that
+        // sometimes we un-ignore within this group, eg
+        // when handling upr escape.
+        int b2 = in.read();
+        if (b2 == '\\') {
+            int b3 = in.read();
+            if (b3 == '*') {
+                groupState.ignore = true;
+            }
+               in.unread(b3);
+        }
+        in.unread(b2);
     }
 
     // Pop current GroupState
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/rtf/RTFParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/rtf/RTFParserTest.java
index 9ed24e234..7c87395cd 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/rtf/RTFParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/rtf/RTFParserTest.java
@@ -280,6 +280,11 @@ public class RTFParserTest extends TikaTest {
                        getXML("testFontAfterBufferedText.rtf").xml);
     }
 
+    // TIKA-782
+    public void testBinControlWord() throws Exception {
+        assertTrue(getXML("testBinControlWord.rtf").xml.indexOf("\u00ff\u00ff\u00ff\u00ff") == -1);
+    }
+
     private Result getResult(String filename) throws Exception {
         File file = getResourceAsFile("/test-documents/" + filename);
        
diff --git a/tika-parsers/src/test/resources/test-documents/testBinControlWord.rtf b/tika-parsers/src/test/resources/test-documents/testBinControlWord.rtf
new file mode 100755
index 000000000..9efc7cb05
--- /dev/null
+++ b/tika-parsers/src/test/resources/test-documents/testBinControlWord.rtf
@@ -0,0 +1,2 @@
+{\rtf1\ansi\ansicpg1252\uc1 \deff0\deflang1033\deflangfe1033{\fonttbl{\f0\froman\fcharset0\fprq2{\*\panose 02020603050405020304}Times New Roman;}{\f1\fswiss\fcharset0\fprq2{\*\panose 020b0604020202020204}Arial;}{\f3\froman\fcharset2\fprq2{\*\panose 05050102010706020507}Symbol;}{\f8\froman\fcharset0\fprq2{\*\panose 00000000000000000000}Tms Rmn;}{\f15\fswiss\fcharset0\fprq3{\*\panose 020b0604030504040204}Tahoma;}{\f16\froman\fcharset0\fprq2{\*\panose 00000000000000000000}Book Antiqua;}{\f18\froman\fcharset238\fprq2 Times New Roman CE;}{\f19\froman\fcharset204\fprq2 Times New Roman Cyr;}{\f21\froman\fcharset161\fprq2 Times New Roman Greek;}{\f22\froman\fcharset162\fprq2 Times New Roman Tur;}{\f23\froman\fcharset186\fprq2 Times New Roman Baltic;}{\f24\fswiss\fcharset238\fprq2 Arial CE;}{\f25\fswiss\fcharset204\fprq2 Arial Cyr;}{\f27\fswiss\fcharset161\fprq2 Arial Greek;}{\f28\fswiss\fcharset162\fprq2 Arial Tur;}{\f29\fswiss\fcharset186\fprq2 Arial Baltic;}}{\colortbl;\red0\green0\blue0;\red0\green0\blue255;\red0\green255\blue255;\red0\green255\blue0;\red255\green0\blue255;\red255\green0\blue0;\red255\green255\blue0;\red255\green255\blue255;\red0\green0\blue128;\red0\green128\blue128;\red0\green128\blue0;\red128\green0\blue128;\red128\green0\blue0;\red128\green128\blue0;\red128\green128\blue128;\red192\green192\blue192;}{\stylesheet{\widctlpar\adjustright \f1\cgrid \snext0 Normal;}{\s1\qc\keepn\widctlpar\adjustright \f15\fs96\cgrid \sbasedon0 \snext0 heading 1;}{\s3\li360\widctlpar\adjustright \b\f8\cgrid \sbasedon0 \snext15 heading 3;}{\*\cs10 \additive Default Paragraph Font;}{\s15\li720\widctlpar\adjustright \f1\cgrid \sbasedon0 \snext15 Normal Indent;}{\s16\widctlpar\tqc\tx4320\tqr\tx8640\adjustright \f1\cgrid \sbasedon0 \snext16 header;}{\s17\widctlpar\tqc\tx4320\tqr\tx8640\adjustright \f1\fs16\cgrid \sbasedon0 \snext17 footer;}{\s18\li1440\ri1440\sb120\sa120\sl360\slmult1\widctlpar\adjustright \f1\cgrid \sbasedon0 \snext18 dsbody;}{\s19\qc\widctlpar\adjustright \f1\cgrid \sbasedon0 \snext19 dmstitle;}{\s20\fi-720\li720\widctlpar\adjustright \b\i\caps\f16\cgrid \sbasedon0 \snext20 dms;}{\s21\fi-360\li360\widctlpar{\*\pn \pnlvlbody\ilvl11\ls2047\pnrnot0\pnf3\pnstart1\pnindent360\pnhang{\pntxtb \'88}}\ls2047\ilvl11\adjustright \f1\cgrid \sbasedon0 \snext21 checklist;}{\s22\fi-2880\li2880\widctlpar\tx2880\adjustright \f1\cgrid \sbasedon0 \snext22 Indent;}{\s23\fi-288\li3150\widctlpar\tx2880\adjustright \cgrid \sbasedon22 \snext23 indent2;}{\s24\fi-360\li3528\widctlpar\tx2880\adjustright \cgrid \sbasedon22 \snext24 indent3;}{\s25\widctlpar\adjustright \b\i\caps\f16\cgrid \sbasedon0 \snext25 ds;}}{\info{\title  }{\author Nicole Mendez}{\operator Nicole Mendez}{\creatim\yr2000\mo1\dy25\hr14\min4}{\revtim\yr2000\mo1\dy25\hr14\min4}{\printim\yr1999\mo1\dy27\hr15\min44}{\version3}{\edmins1}{\nofpages1}{\nofwords5}{\nofchars29}{\*\company ect}{\nofcharsws35}{\vern89}}\paperw15840\paperh12240\margl1440\margr1440 \widowctrl\ftnbj\aenddoc\noextrasprl\prcolbl\cvmme\sprsspbf\brkfrm\swpbdr\lytprtmet\hyphcaps0\fracwidth\viewkind1\viewscale150\pgbrdrhead\pgbrdrfoot \fet0\sectd \lndscpsxn\psz1\linex0\endnhere\sectdefaultcl {\*\pnseclvl1\pnucrm\pnstart1\pnindent720\pnhang{\pntxta .}}{\*\pnseclvl2\pnucltr\pnstart1\pnindent720\pnhang{\pntxta .}}{\*\pnseclvl3\pndec\pnstart1\pnindent720\pnhang{\pntxta .}}{\*\pnseclvl4\pnlcltr\pnstart1\pnindent720\pnhang{\pntxta )}}{\*\pnseclvl5\pndec\pnstart1\pnindent720\pnhang{\pntxtb (}{\pntxta )}}{\*\pnseclvl6\pnlcltr\pnstart1\pnindent720\pnhang{\pntxtb (}{\pntxta )}}{\*\pnseclvl7\pnlcrm\pnstart1\pnindent720\pnhang{\pntxtb (}{\pntxta )}}{\*\pnseclvl8\pnlcltr\pnstart1\pnindent720\pnhang{\pntxtb (}{\pntxta )}}{\*\pnseclvl9\pnlcrm\pnstart1\pnindent720\pnhang{\pntxtb (}{\pntxta )}}\pard\plain \widctlpar\adjustright \f1\cgrid {\pard\plain \widctlpar\adjustright \f1\cgrid {\object\objemb\objw3600\objh3600\objscalex55\objscaley56{\*\objclass PBrush}{\result {\fs20 {\pict\wmetafile8\picw6350\pich6350\picwgoal3600\pichgoal3600 \picscalex55\picscaley56 \bin10 }}}}{\tab \tab \tab  
+\par }}
\ No newline at end of file

Commit:
7b8096174908f1bc0e388c88b0e25566eee2b8e8
Michael McCandless
mikemccand@apache.org
2011-11-17 17:24:26 +0000
TIKA-612: enable controlling PDFBox's setSortByPosition from PDFParser
diff --git a/CHANGES.txt b/CHANGES.txt
index 5271d97dc..69c4fb173 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -10,7 +10,10 @@ Release 1.1 - Current Development
  * PDF: Allow controlling whether overlapping duplicated text should
    be removed.  Disabling this (the default) can give big
    speedups to text extraction and may workaround cases where
-   non-duplicated characters were incorrectly removed.  (TIKA-767)
+   non-duplicated characters were incorrectly removed (TIKA-767).
+   Allow controlling whether text tokens should be sorted by their x/y
+   position before extracting text (TIKA-612); this is necessary for
+   certain PDFs.
 
  * RTF: Fixed case where a font change would result in processing
    bytes in the wrong font's charset, producing bogus text output
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDF2XHTML.java b/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDF2XHTML.java
index 73cb7515e..09f32d3cf 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDF2XHTML.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDF2XHTML.java
@@ -55,14 +55,14 @@ class PDF2XHTML extends PDFTextStripper {
     public static void process(
             PDDocument document, ContentHandler handler, Metadata metadata,
             boolean extractAnnotationText, boolean enableAutoSpace,
-            boolean suppressDuplicateOverlappingText)
+            boolean suppressDuplicateOverlappingText, boolean sortByPosition)
             throws SAXException, TikaException {
         try {
             // Extract text using a dummy Writer as we override the
             // key methods to output to the given content handler.
             new PDF2XHTML(handler, metadata,
                           extractAnnotationText, enableAutoSpace,
-                          suppressDuplicateOverlappingText).writeText(document, new Writer() {
+                          suppressDuplicateOverlappingText, sortByPosition).writeText(document, new Writer() {
                 @Override
                 public void write(char[] cbuf, int off, int len) {
                 }
@@ -87,12 +87,12 @@ class PDF2XHTML extends PDFTextStripper {
 
     private PDF2XHTML(ContentHandler handler, Metadata metadata,
                       boolean extractAnnotationText, boolean enableAutoSpace,
-                      boolean suppressDuplicateOverlappingText)
+                      boolean suppressDuplicateOverlappingText, boolean sortByPosition)
             throws IOException {
         this.handler = new XHTMLContentHandler(handler, metadata);
         this.extractAnnotationText = extractAnnotationText;
         setForceParsing(true);
-        setSortByPosition(false);
+        setSortByPosition(sortByPosition);
         if (enableAutoSpace) {
             setWordSeparator(" ");
         } else {
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java
index a4f97b96e..fc2948eb9 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java
@@ -60,6 +60,14 @@ public class PDFParser extends AbstractParser {
     // True if we let PDFBox remove duplicate overlapping text:
     private boolean suppressDuplicateOverlappingText;
 
+    // True if we extract annotation text ourselves
+    // (workaround for PDFBOX-1143):
+    private boolean extractAnnotationText = true;
+
+    // True if we should sort text tokens by position
+    // (necessary for some PDFs, but messes up other PDFs):
+    private boolean sortByPosition = false;
+
     /**
      * Metadata key for giving the document password to the parser.
      *
@@ -67,8 +75,6 @@ public class PDFParser extends AbstractParser {
      */
     public static final String PASSWORD = "org.apache.tika.parser.pdf.password";
 
-    private boolean extractAnnotationText = true;
-
     private static final Set<MediaType> SUPPORTED_TYPES =
         Collections.singleton(MediaType.application("pdf"));
 
@@ -96,7 +102,9 @@ public class PDFParser extends AbstractParser {
             }
             metadata.set(Metadata.CONTENT_TYPE, "application/pdf");
             extractMetadata(pdfDocument, metadata);
-            PDF2XHTML.process(pdfDocument, handler, metadata, extractAnnotationText, enableAutoSpace, suppressDuplicateOverlappingText);
+            PDF2XHTML.process(pdfDocument, handler, metadata,
+                              extractAnnotationText, enableAutoSpace,
+                              suppressDuplicateOverlappingText, sortByPosition);
         } finally {
             pdfDocument.close();
         }
@@ -222,4 +230,21 @@ public class PDFParser extends AbstractParser {
         return suppressDuplicateOverlappingText;
     }
 
+    /**
+     *  If true, sort text tokens by their x/y position
+     *  before extracting text.  This may be necessary for
+     *  some PDFs (if the text tokens are not rendered "in
+     *  order"), while for other PDFs it can produce the
+     *  wrong result (for example if there are 2 columns,
+     *  the text will be interleaved).  Default is false.
+     */
+    public void setSortByPosition(boolean v) {
+        sortByPosition = v;
+    }
+
+    /** @see #setSortByPosition. */
+    public boolean getSortByPosition() {
+        return sortByPosition;
+    }
+
 }
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java
index 098de564d..4d13d1a20 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java
@@ -323,6 +323,39 @@ public class PDFParserTest extends TikaTest {
         assertContains("Text the first timesecond time", content);
     }
 
+    public void testSortByPosition() throws Exception {
+        PDFParser parser = new PDFParser();
+        parser.setEnableAutoSpace(false);
+        ContentHandler handler = new BodyContentHandler();
+        Metadata metadata = new Metadata();
+        ParseContext context = new ParseContext();
+        InputStream stream = getResourceAsStream("/test-documents/testPDFTwoTextBoxes.pdf");
+        // Default is false (do not sort):
+        try {
+            parser.parse(stream, handler, metadata, context);
+        } finally {
+            stream.close();
+        }
+        String content = handler.toString();
+        content = content.replaceAll("\\s+", " ");
+        assertContains("Left column line 1 Left column line 2 Right column line 1 Right column line 2", content);
+
+        parser.setSortByPosition(true);
+        handler = new BodyContentHandler();
+        metadata = new Metadata();
+        context = new ParseContext();
+        stream = getResourceAsStream("/test-documents/testPDFTwoTextBoxes.pdf");
+        try {
+            parser.parse(stream, handler, metadata, context);
+        } finally {
+            stream.close();
+        }
+        content = handler.toString();
+        content = content.replaceAll("\\s+", " ");
+        // Column text is now interleaved:
+        assertContains("Left column line 1 Right column line 1 Left colu mn line 2 Right column line 2", content);
+    }
+
     private static class XMLResult {
         public final String xml;
         public final Metadata metadata;

Commit:
17529470f534107f17da6f5632d40c857f8886ee
Nick Burch
nick@apache.org
2011-11-15 09:41:46 +0000
TIKA-779 Works 2000 container aware detection, plus test
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java
index 91301d401..fe53db41e 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/microsoft/POIFSContainerDetector.java
@@ -124,10 +124,14 @@ public class POIFSContainerDetector implements Detector {
             } else if (names.contains("VisioDocument")) {
                 return VSD;
             } else if (names.contains("CONTENTS") && names.contains("SPELLING")) {
+               // Newer Works files
+               return WPS;
+            } else if (names.contains("CONTENTS") && names.contains("\u0001CompObj")) {
+               // Normally an older Works file
                return WPS;
             } else if (names.contains("CONTENTS")) {
-               // CONTENTS without SPELLING normally means some sort of
-               //  embedded non-office file inside an OLE2 document
+               // CONTENTS without SPELLING nor CompObj normally means some sort
+               //  of embedded non-office file inside an OLE2 document
                // This is most commonly triggered on nested directories
                return OLE;
             } else if (names.contains("\u0001Ole10Native")) {
diff --git a/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java b/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
index 39588dcf0..3ea99b4aa 100644
--- a/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
+++ b/tika-parsers/src/test/java/org/apache/tika/detect/TestContainerAwareDetector.java
@@ -56,6 +56,7 @@ public class TestContainerAwareDetector extends TestCase {
 
         // Try some ones that POI doesn't handle, that are still OLE2 based
         assertDetect("testWORKS.wps", "application/vnd.ms-works");
+        assertDetect("testWORKS2000.wps", "application/vnd.ms-works");
         assertDetect("testCOREL.shw", "application/x-corelpresentations");
         assertDetect("testQUATTRO.qpw", "application/x-quattro-pro");
         assertDetect("testQUATTRO.wb3", "application/x-quattro-pro");
diff --git a/tika-parsers/src/test/resources/test-documents/testWORKS2000.wps b/tika-parsers/src/test/resources/test-documents/testWORKS2000.wps
new file mode 100644
index 000000000..ff8a31ad7
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testWORKS2000.wps differ

Commit:
5e91e71556b700e9a84fd433bb40d7011c1ef35b
Nick Burch
nick@apache.org
2011-11-15 08:39:05 +0000
TIKA-663 Mimetype entry for JSP with magic
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 2b98b2f9e..b3118f669 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -3828,7 +3828,6 @@
     <glob pattern=".htaccess"/>
     <glob pattern="*.ihtml"/>
     <glob pattern="*.jmx"/>
-    <glob pattern="*.jsp"/>
     <glob pattern="*.junit"/>
     <glob pattern="*.jx"/>
     <glob pattern="*.manifest"/>
@@ -3870,6 +3869,15 @@
     <glob pattern="*.xwelcome"/>
   </mime-type>
 
+  <mime-type type="application/x-httpd-jsp">
+    <sub-class-of type="text/plain"/>
+    <magic priority="50">
+      <match value="&lt;%@" type="string" offset="0"/>
+      <match value="&lt;%--" type="string" offset="0"/>
+    </magic>
+    <glob pattern="*.jsp"/>
+  </mime-type>
+
   <mime-type type="text/prs.fallenstein.rst"/>
   <mime-type type="text/prs.lines.tag">
     <glob pattern="*.dsc"/>

Commit:
ad78ecd3a85fcfc61b22cb045b3881cc9c170b13
Michael McCandless
mikemccand@apache.org
2011-11-11 18:27:08 +0000
TIKA-781: don't output whitespace when we are in an ignored GroupState
diff --git a/CHANGES.txt b/CHANGES.txt
index 3a05f7964..5271d97dc 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -14,7 +14,8 @@ Release 1.1 - Current Development
 
  * RTF: Fixed case where a font change would result in processing
    bytes in the wrong font's charset, producing bogus text output
-   (TIKA-777)
+   (TIKA-777).  Don't output whitespace in ignored group states,
+   avoiding excessive whitespace output (TIKA-781).
 
 Release 1.0 - 11/4/2011
 ---------------------------------
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/rtf/TextExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/rtf/TextExtractor.java
index f51eb7ea3..728ca6ad5 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/rtf/TextExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/rtf/TextExtractor.java
@@ -901,6 +901,8 @@ final class TextExtractor {
             }
         }
 
+        final boolean ignored = groupState.ignore;
+
         if (equals("pard")) {
             // Reset styles
             pushText();
@@ -913,7 +915,9 @@ final class TextExtractor {
                 groupState.bold = false;
             }
         } else if (equals("par")) {
-            endParagraph(true);
+            if (!ignored) {
+                endParagraph(true);
+            }
         } else if (equals("shptxt")) {
             pushText();
             // Text inside a shape
@@ -940,19 +944,33 @@ final class TextExtractor {
             // embedded image data?
             groupState.ignore = true;
         } else if (equals("line")) {
-            addOutputChar('\n');
+            if (!ignored) {
+                addOutputChar('\n');
+            }
         } else if (equals("column")) {
-            addOutputChar(' ');
+            if (!ignored) {
+                addOutputChar(' ');
+            }
         } else if (equals("page")) {
-            addOutputChar('\n');
+            if (!ignored) {
+                addOutputChar('\n');
+            }
         } else if (equals("softline")) {
-            addOutputChar('\n');
+            if (!ignored) {
+                addOutputChar('\n');
+            }
         } else if (equals("softcolumn")) {
-            addOutputChar(' ');
+            if (!ignored) {
+                addOutputChar(' ');
+            }
         } else if (equals("softpage")) {
-            addOutputChar('\n');
+            if (!ignored) {
+                addOutputChar('\n');
+            }
         } else if (equals("tab")) {
-            addOutputChar('\t');
+            if (!ignored) {
+                addOutputChar('\t');
+            }
         } else if (equals("upr")) {
             uprState = 0;
         } else if (equals("ud") && uprState == 1) {
@@ -962,35 +980,55 @@ final class TextExtractor {
             // we want to keep that:
             groupState.ignore = false;
         } else if (equals("bullet")) {
-            // unicode BULLET
-            addOutputChar('\u2022');
+            if (!ignored) {
+                // unicode BULLET
+                addOutputChar('\u2022');
+            }
         } else if (equals("endash")) {
-            // unicode EN DASH
-            addOutputChar('\u2013');
+            if (!ignored) {
+                // unicode EN DASH
+                addOutputChar('\u2013');
+            }
         } else if (equals("emdash")) {
-            // unicode EM DASH
-            addOutputChar('\u2014');
+            if (!ignored) {
+                // unicode EM DASH
+                addOutputChar('\u2014');
+            }
         } else if (equals("enspace")) {
-            // unicode EN SPACE
-            addOutputChar('\u2002');
+            if (!ignored) {
+                // unicode EN SPACE
+                addOutputChar('\u2002');
+            }
         } else if (equals("qmspace")) {
-            // quarter em space -> unicode FOUR-PER-EM SPACE
-            addOutputChar('\u2005');
+            if (!ignored) {
+                // quarter em space -> unicode FOUR-PER-EM SPACE
+                addOutputChar('\u2005');
+            }
         } else if (equals("emspace")) {
-            // unicode EM SPACE
-            addOutputChar('\u2003');
+            if (!ignored) {
+                // unicode EM SPACE
+                addOutputChar('\u2003');
+            }
         } else if (equals("lquote")) {
-            // unicode LEFT SINGLE QUOTATION MARK
-            addOutputChar('\u2018');
+            if (!ignored) {
+                // unicode LEFT SINGLE QUOTATION MARK
+                addOutputChar('\u2018');
+            }
         } else if (equals("rquote")) {
-            // unicode RIGHT SINGLE QUOTATION MARK
-            addOutputChar('\u2019');
+            if (!ignored) {
+                // unicode RIGHT SINGLE QUOTATION MARK
+                addOutputChar('\u2019');
+            }
         } else if (equals("ldblquote")) {
-            // unicode LEFT DOUBLE QUOTATION MARK
-            addOutputChar('\u201C');
+            if (!ignored) {
+                // unicode LEFT DOUBLE QUOTATION MARK
+                addOutputChar('\u201C');
+            }
         } else if (equals("rdblquote")) {
-            // unicode RIGHT DOUBLE QUOTATION MARK
-            addOutputChar('\u201D');
+            if (!ignored) {
+                // unicode RIGHT DOUBLE QUOTATION MARK
+                addOutputChar('\u201D');
+            }
         } else if (equals("fldinst")) {
             fieldState = 1;
             groupState.ignore = false;
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/rtf/RTFParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/rtf/RTFParserTest.java
index 47e831cad..9ed24e234 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/rtf/RTFParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/rtf/RTFParserTest.java
@@ -268,6 +268,7 @@ public class RTFParserTest extends TikaTest {
     public void testHyperlink() throws Exception {
         String content = getXML("testRTFHyperlink.rtf").xml;
         assertContains("our most <a href=\"http://r.office.microsoft.com/r/rlidwelcomeFAQ?clid=1033\">frequently asked questions</a>", content);
+        assertEquals(-1, content.indexOf("<p>\t\t</p>"));
     }
 
     public void testIgnoredControlWord() throws Exception {

Commit:
350d1be2ace9a1dbb917288abac97e65552aa591
Jukka Zitting
jukka@apache.org
2011-11-11 14:02:06 +0000
Exclude the enum types from clirr checks.
diff --git a/tika-core/pom.xml b/tika-core/pom.xml
index a7d3125af..e230b455c 100644
--- a/tika-core/pom.xml
+++ b/tika-core/pom.xml
@@ -91,6 +91,10 @@
               <goal>check</goal>
             </goals>
             <configuration>
+              <excludes>
+                <exlude>org/apache/tika/metadata/Property$PropertyType</exlude>
+                <exlude>org/apache/tika/metadata/Property$ValueType</exlude>
+              </excludes>
               <comparisonArtifacts>
                 <comparisonArtifact>
                   <groupId>org.apache.tika</groupId>

Commit:
b7a58ef835b37d2f4dd8753de470b3d6c93b6512
Jukka Zitting
jukka@apache.org
2011-11-11 12:22:48 +0000
TIKA-780: Optimize loading of the media type registry
diff --git a/CHANGES.txt b/CHANGES.txt
index dc9dc8a4c..3a05f7964 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -4,6 +4,9 @@ Apache Tika Change Log
 Release 1.1 - Current Development
 ---------------------------------
 
+ * Performance: Loading of the default media type registry is now
+   significantly faster. (TIKA-780)
+
  * PDF: Allow controlling whether overlapping duplicated text should
    be removed.  Disabling this (the default) can give big
    speedups to text extraction and may workaround cases where

Commit:
9f8c762f571417707dfd4cd72446ae2b299f010c
Jukka Zitting
jukka@apache.org
2011-11-11 12:18:56 +0000
TIKA-780: Optimize loading of the media type registry
diff --git a/tika-core/src/main/java/org/apache/tika/mime/MimeTypesReader.java b/tika-core/src/main/java/org/apache/tika/mime/MimeTypesReader.java
index 46ea1b7ee..864442f19 100644
--- a/tika-core/src/main/java/org/apache/tika/mime/MimeTypesReader.java
+++ b/tika-core/src/main/java/org/apache/tika/mime/MimeTypesReader.java
@@ -101,14 +101,7 @@ class MimeTypesReader extends DefaultHandler implements MimeTypesReaderMetKeys {
 
     private int priority;
 
-    private Clause clause = null;
-
-    private List<Clause> clauses = new LinkedList<Clause>();
-
-    private final LinkedList<List<Clause>> clauseStack =
-            new LinkedList<List<Clause>>();
-
-    private final StringBuilder characters = new StringBuilder();
+    private StringBuilder characters = null;
 
     MimeTypesReader(MimeTypes types) {
         this.types = types;
@@ -161,6 +154,8 @@ class MimeTypesReader extends DefaultHandler implements MimeTypesReaderMetKeys {
         } else if (SUB_CLASS_OF_TAG.equals(qName)) {
             String parent = attributes.getValue(SUB_CLASS_TYPE_ATTR);
             types.setSuperType(type, MediaType.parse(parent));
+        } else if (COMMENT_TAG.equals(qName)) {
+            characters = new StringBuilder();
         } else if (GLOB_TAG.equals(qName)) {
             String pattern = attributes.getValue(PATTERN_ATTR);
             String isRegex = attributes.getValue(ISREGEX_ATTR);
@@ -183,9 +178,8 @@ class MimeTypesReader extends DefaultHandler implements MimeTypesReaderMetKeys {
             if (kind == null) {
                 kind = "string";
             }
-            clause = new MagicMatch(type.getType(), kind, offset, value, mask);
-            clauseStack.addLast(clauses);
-            clauses = null;
+            current = new ClauseRecord(
+                    new MagicMatch(type.getType(), kind, offset, value, mask));
         } else if (MAGIC_TAG.equals(qName)) {
             String value = attributes.getValue(MAGIC_PRIORITY_ATTR);
             if (value != null && value.length() > 0) {
@@ -193,6 +187,7 @@ class MimeTypesReader extends DefaultHandler implements MimeTypesReaderMetKeys {
             } else {
                 priority = 50;
             }
+            current = new ClauseRecord(null);
         }
     }
 
@@ -203,40 +198,66 @@ class MimeTypesReader extends DefaultHandler implements MimeTypesReaderMetKeys {
                 type = null;
             } else if (COMMENT_TAG.equals(qName)) {
                 type.setDescription(characters.toString().trim());
+                characters = null;
             } else if (MATCH_TAG.equals(qName)) {
-                if (clauses != null) {
-                    Clause subclause;
-                    if (clauses.size() == 1) {
-                        subclause = clauses.get(0);
-                    } else {
-                        subclause = new OrClause(clauses);
-                    }
-                    clause = new AndClause(clause, subclause);
-                }
-                clauses = clauseStack.removeLast();
-                if (clauses == null) {
-                    clauses = Collections.singletonList(clause);
-                } else {
-                    if (clauses.size() == 1) {
-                        clauses = new ArrayList<Clause>(clauses);
-                    }
-                    clauses.add(clause);
-                }
+                current.stop();
             } else if (MAGIC_TAG.equals(qName)) {
-                if (clauses != null) {
-                    for (Clause clause : clauses) {
-                        type.addMagic(new Magic(type, priority, clause));
-                    }
-                    clauses = null;
+                for (Clause clause : current.getClauses()) {
+                    type.addMagic(new Magic(type, priority, clause));
                 }
+                current = null;
             }
         }
-        characters.setLength(0);
     }
 
     @Override
     public void characters(char[] ch, int start, int length) {
-        characters.append(ch, start, length);
+        if (characters != null) {
+            characters.append(ch, start, length);
+        }
+    }
+
+    private ClauseRecord current = new ClauseRecord(null);
+
+    private class ClauseRecord {
+
+        private ClauseRecord parent;
+
+        private Clause clause;
+
+        private List<Clause> subclauses = null;
+
+        public ClauseRecord(Clause clause) {
+            this.parent = current;
+            this.clause = clause;
+        }
+
+        public void stop() {
+            if (subclauses != null) {
+                Clause subclause;
+                if (subclauses.size() == 1) {
+                    subclause = subclauses.get(0);
+                } else {
+                    subclause = new OrClause(subclauses);
+                }
+                clause = new AndClause(clause, subclause);
+            }
+            if (parent.subclauses == null) {
+                parent.subclauses = Collections.singletonList(clause);
+            } else {
+                if (parent.subclauses.size() == 1) {
+                    parent.subclauses = new ArrayList<Clause>(parent.subclauses);
+                }
+                parent.subclauses.add(clause);
+            }
+
+            current = current.parent;
+        }
+ 
+        public List<Clause> getClauses() {
+            return subclauses;
+        }
+
     }
 
 }

Commit:
85878f6562f9c848a5b4d1a95ad8ccc6296c8af3
Jukka Zitting
jukka@apache.org
2011-11-11 11:25:57 +0000
fix typo
diff --git a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
index 7f34ea4c9..2b98b2f9e 100644
--- a/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
+++ b/tika-core/src/main/resources/org/apache/tika/mime/tika-mimetypes.xml
@@ -2144,7 +2144,7 @@
       <match value="=&lt;ar&gt;" type="string" offset="0"/>
       <match value="=!&lt;arch&gt;" type="string" offset="0"/>
     </magic>
-    <glob patter="*.ar"/>
+    <glob pattern="*.ar"/>
   </mime-type>
 
   <mime-type type="application/x-authorware-bin">

Commit:
2e5cd686acbf87590965936cb403db59711ef1a5
Jukka Zitting
jukka@apache.org
2011-11-11 11:25:46 +0000
TIKA-780: Optimize loading of the media type registry
diff --git a/tika-core/src/main/java/org/apache/tika/mime/MimeTypesReader.java b/tika-core/src/main/java/org/apache/tika/mime/MimeTypesReader.java
index 9bcf6a369..46ea1b7ee 100644
--- a/tika-core/src/main/java/org/apache/tika/mime/MimeTypesReader.java
+++ b/tika-core/src/main/java/org/apache/tika/mime/MimeTypesReader.java
@@ -16,24 +16,28 @@
  */
 package org.apache.tika.mime;
 
+import java.io.ByteArrayInputStream;
 import java.io.IOException;
 import java.io.InputStream;
 import java.util.ArrayList;
 import java.util.Collections;
+import java.util.LinkedList;
 import java.util.List;
 
-import javax.xml.parsers.DocumentBuilder;
-import javax.xml.parsers.DocumentBuilderFactory;
 import javax.xml.parsers.ParserConfigurationException;
+import javax.xml.parsers.SAXParser;
+import javax.xml.parsers.SAXParserFactory;
+import javax.xml.transform.Transformer;
+import javax.xml.transform.TransformerException;
+import javax.xml.transform.TransformerFactory;
+import javax.xml.transform.dom.DOMSource;
+import javax.xml.transform.sax.SAXResult;
 
-import org.w3c.dom.Attr;
 import org.w3c.dom.Document;
-import org.w3c.dom.Element;
-import org.w3c.dom.NamedNodeMap;
-import org.w3c.dom.Node;
-import org.w3c.dom.NodeList;
+import org.xml.sax.Attributes;
 import org.xml.sax.InputSource;
 import org.xml.sax.SAXException;
+import org.xml.sax.helpers.DefaultHandler;
 
 /**
  * A reader for XML files compliant with the freedesktop MIME-info DTD.
@@ -85,25 +89,37 @@ import org.xml.sax.SAXException;
  *         type CDATA #REQUIRED&gt;
  *  ]&gt;
  * </pre>
- * 
- * 
+ *
  * @see http://freedesktop.org/wiki/Standards_2fshared_2dmime_2dinfo_2dspec
- * 
  */
-final class MimeTypesReader implements MimeTypesReaderMetKeys {
+class MimeTypesReader extends DefaultHandler implements MimeTypesReaderMetKeys {
 
     private final MimeTypes types;
 
+    /** Current type */
+    private MimeType type = null;
+
+    private int priority;
+
+    private Clause clause = null;
+
+    private List<Clause> clauses = new LinkedList<Clause>();
+
+    private final LinkedList<List<Clause>> clauseStack =
+            new LinkedList<List<Clause>>();
+
+    private final StringBuilder characters = new StringBuilder();
+
     MimeTypesReader(MimeTypes types) {
         this.types = types;
     }
 
     void read(InputStream stream) throws IOException, MimeTypeException {
         try {
-            DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance();
-            DocumentBuilder builder = factory.newDocumentBuilder();
-            Document document = builder.parse(new InputSource(stream));
-            read(document);
+            SAXParserFactory factory = SAXParserFactory.newInstance();
+            factory.setNamespaceAware(false);
+            SAXParser parser = factory.newSAXParser();
+            parser.parse(stream, this);
         } catch (ParserConfigurationException e) {
             throw new MimeTypeException("Unable to create an XML parser", e);
         } catch (SAXException e) {
@@ -112,144 +128,115 @@ final class MimeTypesReader implements MimeTypesReaderMetKeys {
     }
 
     void read(Document document) throws MimeTypeException {
-        Element element = document.getDocumentElement();
-        if (element != null && element.getTagName().equals(MIME_INFO_TAG)) {
-            NodeList nodes = element.getChildNodes();
-            for (int i = 0; i < nodes.getLength(); i++) {
-                Node node = nodes.item(i);
-                if (node.getNodeType() == Node.ELEMENT_NODE) {
-                    Element child = (Element) node;
-                    if (child.getTagName().equals(MIME_TYPE_TAG)) {
-                        readMimeType(child);
-                    }
-                }
-            }
-        } else {
-            throw new MimeTypeException(
-                    "Not a <" + MIME_INFO_TAG + "/> configuration document: "
-                    + element.getTagName());
-        }
-    }
-
-    /** Read Element named mime-type. */
-    private void readMimeType(Element element) throws MimeTypeException {
-        String name = element.getAttribute(MIME_TYPE_TYPE_ATTR);
-        MimeType type = types.forName(name);
-
-        NodeList nodes = element.getChildNodes();
-        for (int i = 0; i < nodes.getLength(); i++) {
-            Node node = nodes.item(i);
-            if (node.getNodeType() == Node.ELEMENT_NODE) {
-                Element nodeElement = (Element) node;
-                if (nodeElement.getTagName().equals(COMMENT_TAG)) {
-                    type.setDescription(
-                            nodeElement.getFirstChild().getNodeValue());
-                } else if (nodeElement.getTagName().equals(GLOB_TAG)) {
-                    boolean useRegex = Boolean.valueOf(nodeElement.getAttribute(ISREGEX_ATTR));
-                    types.addPattern(type, nodeElement.getAttribute(PATTERN_ATTR), useRegex);
-                } else if (nodeElement.getTagName().equals(MAGIC_TAG)) {
-                    readMagic(nodeElement, type);
-                } else if (nodeElement.getTagName().equals(ALIAS_TAG)) {
-                    String alias = nodeElement.getAttribute(ALIAS_TYPE_ATTR);
-                    MediaType aliasType = MediaType.parse(alias);
-                    if (aliasType != null) {
-                        types.addAlias(type, aliasType);
-                    } else {
-                        throw new MimeTypeException(
-                                "Invalid media type alias: " + alias);
-                    }
-                } else if (nodeElement.getTagName().equals(ROOT_XML_TAG)) {
-                    readRootXML(nodeElement, type);
-                } else if (nodeElement.getTagName().equals(SUB_CLASS_OF_TAG)) {
-                    String parent = nodeElement.getAttribute(SUB_CLASS_TYPE_ATTR);
-                    types.setSuperType(type, MediaType.parse(parent));
-                }
-            }
+        try {
+            TransformerFactory factory = TransformerFactory.newInstance();
+            Transformer transformer = factory.newTransformer();
+            transformer.transform(new DOMSource(document), new SAXResult(this));
+        } catch (TransformerException e) {
+            throw new MimeTypeException("Failed to parse type registry", e);
         }
-
-        types.add(type);
     }
 
-    /**
-     * Read Element named magic. 
-     * @throws MimeTypeException if the configuration is invalid
-     */
-    private void readMagic(Element element, MimeType mimeType)
-            throws MimeTypeException {
-        int priority = 50;
-        String value = element.getAttribute(MAGIC_PRIORITY_ATTR);
-        if (value != null && value.length() > 0) {
-            priority = Integer.parseInt(value);
-        }
-
-        for (Clause clause : readMatches(element, mimeType.getType())) {
-            Magic magic = new Magic(mimeType, priority, clause);
-            mimeType.addMagic(magic);
-        }
+    @Override
+    public InputSource resolveEntity(String publicId, String systemId) {
+        return new InputSource(new ByteArrayInputStream(new byte[0]));
     }
 
-    private List<Clause> readMatches(Element element, MediaType mediaType) throws MimeTypeException {
-        NodeList nodes = element.getChildNodes();
-        int n = nodes.getLength();
-        if (n == 0) {
-            return Collections.emptyList();
-        }
-
-        List<Clause> clauses = new ArrayList<Clause>();
-        for (int i = 0; i < n; i++) {
-            Node node = nodes.item(i);
-            if (node.getNodeType() == Node.ELEMENT_NODE) {
-                Element nodeElement = (Element) node;
-                if (nodeElement.getTagName().equals(MATCH_TAG)) {
-                    clauses.add(readMatch(nodeElement, mediaType));
+    @Override
+    public void startElement(
+            String uri, String localName, String qName,
+            Attributes attributes) throws SAXException {
+        if (type == null) {
+            if (MIME_TYPE_TAG.equals(qName)) {
+                String name = attributes.getValue(MIME_TYPE_TYPE_ATTR);
+                try {
+                    type = types.forName(name);
+                } catch (MimeTypeException e) {
+                    throw new SAXException(e);
                 }
             }
-        }
-        return clauses;
-    }
-
-    /** Read Element named match. */
-    private Clause readMatch(Element element, MediaType mediaType) throws MimeTypeException {
-        Clause clause = getMagicClause(element, mediaType);
-
-        List<Clause> subClauses = readMatches(element, mediaType);
-        if (subClauses.size() == 0) {
-            return clause;
-        } else if (subClauses.size() == 1) {
-            return new AndClause(clause, subClauses.get(0));
-        } else {
-            return new AndClause(clause, new OrClause(subClauses));
+        } else if (ALIAS_TAG.equals(qName)) {
+            String alias = attributes.getValue(ALIAS_TYPE_ATTR);
+            types.addAlias(type, MediaType.parse(alias));
+        } else if (SUB_CLASS_OF_TAG.equals(qName)) {
+            String parent = attributes.getValue(SUB_CLASS_TYPE_ATTR);
+            types.setSuperType(type, MediaType.parse(parent));
+        } else if (GLOB_TAG.equals(qName)) {
+            String pattern = attributes.getValue(PATTERN_ATTR);
+            String isRegex = attributes.getValue(ISREGEX_ATTR);
+            if (pattern != null) {
+                try {
+                    types.addPattern(type, pattern, Boolean.valueOf(isRegex));
+                } catch (MimeTypeException e) {
+                    throw new SAXException(e);
+                }
+            }
+        } else if (ROOT_XML_TAG.equals(qName)) {
+            String namespace = attributes.getValue(NS_URI_ATTR);
+            String name = attributes.getValue(LOCAL_NAME_ATTR);
+            type.addRootXML(namespace, name);
+        } else if (MATCH_TAG.equals(qName)) {
+            String kind = attributes.getValue(MATCH_TYPE_ATTR);
+            String offset = attributes.getValue(MATCH_OFFSET_ATTR);
+            String value = attributes.getValue(MATCH_VALUE_ATTR);
+            String mask = attributes.getValue(MATCH_MASK_ATTR);
+            if (kind == null) {
+                kind = "string";
+            }
+            clause = new MagicMatch(type.getType(), kind, offset, value, mask);
+            clauseStack.addLast(clauses);
+            clauses = null;
+        } else if (MAGIC_TAG.equals(qName)) {
+            String value = attributes.getValue(MAGIC_PRIORITY_ATTR);
+            if (value != null && value.length() > 0) {
+                priority = Integer.parseInt(value);
+            } else {
+                priority = 50;
+            }
         }
     }
 
-    private Clause getMagicClause(Element element, MediaType mediaType)
-            throws MimeTypeException {
-        String type = "string";
-        String offset = null;
-        String value = null;
-        String mask = null;
-
-        NamedNodeMap attrs = element.getAttributes();
-        for (int i = 0; i < attrs.getLength(); i++) {
-            Attr attr = (Attr) attrs.item(i);
-            if (attr.getName().equals(MATCH_OFFSET_ATTR)) {
-                offset = attr.getValue();
-            } else if (attr.getName().equals(MATCH_TYPE_ATTR)) {
-                type = attr.getValue();
-            } else if (attr.getName().equals(MATCH_VALUE_ATTR)) {
-                value = attr.getValue();
-            } else if (attr.getName().equals(MATCH_MASK_ATTR)) {
-                mask = attr.getValue();
+    @Override
+    public void endElement(String uri, String localName, String qName) {
+        if (type != null) {
+            if (MIME_TYPE_TAG.equals(qName)) {
+                type = null;
+            } else if (COMMENT_TAG.equals(qName)) {
+                type.setDescription(characters.toString().trim());
+            } else if (MATCH_TAG.equals(qName)) {
+                if (clauses != null) {
+                    Clause subclause;
+                    if (clauses.size() == 1) {
+                        subclause = clauses.get(0);
+                    } else {
+                        subclause = new OrClause(clauses);
+                    }
+                    clause = new AndClause(clause, subclause);
+                }
+                clauses = clauseStack.removeLast();
+                if (clauses == null) {
+                    clauses = Collections.singletonList(clause);
+                } else {
+                    if (clauses.size() == 1) {
+                        clauses = new ArrayList<Clause>(clauses);
+                    }
+                    clauses.add(clause);
+                }
+            } else if (MAGIC_TAG.equals(qName)) {
+                if (clauses != null) {
+                    for (Clause clause : clauses) {
+                        type.addMagic(new Magic(type, priority, clause));
+                    }
+                    clauses = null;
+                }
             }
         }
-
-        return new MagicMatch(mediaType, type, offset, value, mask);
+        characters.setLength(0);
     }
 
-    /** Read Element named root-XML. */
-    private void readRootXML(Element element, MimeType mimeType) {
-        mimeType.addRootXML(element.getAttribute(NS_URI_ATTR), element
-                .getAttribute(LOCAL_NAME_ATTR));
+    @Override
+    public void characters(char[] ch, int start, int length) {
+        characters.append(ch, start, length);
     }
 
 }

Commit:
c57d94dc11723154d94aa33c79a7dad95fd4e06b
Jukka Zitting
jukka@apache.org
2011-11-11 11:25:34 +0000
TIKA-780: Optimize loading of the media type registry
diff --git a/tika-core/src/main/java/org/apache/tika/mime/MediaType.java b/tika-core/src/main/java/org/apache/tika/mime/MediaType.java
index 184ad4e70..82964217d 100644
--- a/tika-core/src/main/java/org/apache/tika/mime/MediaType.java
+++ b/tika-core/src/main/java/org/apache/tika/mime/MediaType.java
@@ -17,8 +17,10 @@
 package org.apache.tika.mime;
 
 import java.io.Serializable;
+import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
+import java.util.List;
 import java.util.Locale;
 import java.util.Map;
 import java.util.SortedMap;
@@ -115,7 +117,8 @@ public final class MediaType implements Comparable<MediaType>, Serializable {
                 int slash = string.indexOf('/');
                 if (slash == -1) {
                     return null;
-                } else if (isSimpleName(string.substring(0, slash))
+                } else if (SIMPLE_TYPES.size() < 10000
+                        && isSimpleName(string.substring(0, slash))
                         && isSimpleName(string.substring(slash + 1))) {
                     type = new MediaType(string, slash);
                     SIMPLE_TYPES.put(string, type);
@@ -228,18 +231,15 @@ public final class MediaType implements Comparable<MediaType>, Serializable {
             builder.append(subtype);
 
             SortedMap<String, String> map = new TreeMap<String, String>();
-            if (!(parameters instanceof SortedMap<?, ?>)) {
-                parameters = new TreeMap<String, String>(parameters);
-            }
             for (Map.Entry<String, String> entry : parameters.entrySet()) {
                 String key = entry.getKey().trim().toLowerCase(Locale.ENGLISH);
-                String value = entry.getValue();
-
-                map.put(key, value);
-
+                map.put(key, entry.getValue());
+            }
+            for (Map.Entry<String, String> entry : map.entrySet()) {
                 builder.append("; ");
-                builder.append(key);
+                builder.append(entry.getKey());
                 builder.append("=");
+                String value = entry.getValue();
                 if (SPECIAL_OR_WHITESPACE.matcher(value).find()) {
                     builder.append('"');
                     builder.append(SPECIAL.matcher(value).replaceAll("\\\\$0"));

Commit:
72646ef5a40eb7f947bfc36c5b83af97fccd4928
Jukka Zitting
jukka@apache.org
2011-11-11 11:25:23 +0000
Adjust clirr checks to use Tika 1.0 as the baseline.
diff --git a/tika-core/pom.xml b/tika-core/pom.xml
index cd8a219f9..a7d3125af 100644
--- a/tika-core/pom.xml
+++ b/tika-core/pom.xml
@@ -91,12 +91,11 @@
               <goal>check</goal>
             </goals>
             <configuration>
-              <skip>true</skip>
               <comparisonArtifacts>
                 <comparisonArtifact>
                   <groupId>org.apache.tika</groupId>
                   <artifactId>tika-core</artifactId>
-                  <version>0.10</version>
+                  <version>1.0</version>
                   <type>jar</type>
                 </comparisonArtifact>
               </comparisonArtifacts>

Commit:
d57de4c1a2264aa2ce3a0cd4ea15484faec510ab
Jukka Zitting
jukka@apache.org
2011-11-11 11:25:15 +0000
TIKA-780: Optimize loading of the media type registry
diff --git a/tika-core/src/main/java/org/apache/tika/mime/MediaType.java b/tika-core/src/main/java/org/apache/tika/mime/MediaType.java
index 2b8260463..184ad4e70 100644
--- a/tika-core/src/main/java/org/apache/tika/mime/MediaType.java
+++ b/tika-core/src/main/java/org/apache/tika/mime/MediaType.java
@@ -36,9 +36,6 @@ public final class MediaType implements Comparable<MediaType>, Serializable {
      */
     private static final long serialVersionUID = -3831000556189036392L;
 
-    private static final SortedMap<String, String> NO_PARAMETERS =
-        Collections.unmodifiableSortedMap(new TreeMap<String, String>());
-
     private static final Pattern SPECIAL =
         Pattern.compile("[\\(\\)<>@,;:\\\\\"/\\[\\]\\?=]");
 
@@ -60,41 +57,50 @@ public final class MediaType implements Comparable<MediaType>, Serializable {
             "(?is)\\s*(charset\\s*=\\s*[^\\c;\\s]+)\\s*;\\s*"
             + VALID_CHARS + "\\s*/\\s*" + VALID_CHARS + "\\s*");
 
-    public static final MediaType OCTET_STREAM = application("octet-stream");
+    /**
+     * Set of basic types with normalized "type/subtype" names.
+     * Used to optimize type lookup and to avoid having too many
+     * {@link MediaType} instances in memory.
+     */
+    private static final Map<String, MediaType> SIMPLE_TYPES =
+            new HashMap<String, MediaType>();
+
+    public static final MediaType OCTET_STREAM =
+            parse("application/octet-stream");
 
-    public static final MediaType TEXT_PLAIN = text("plain");
+    public static final MediaType TEXT_PLAIN = parse("text/plain");
 
-    public static final MediaType APPLICATION_XML = application("xml");
+    public static final MediaType APPLICATION_XML = parse("application/xml");
 
-    public static final MediaType APPLICATION_ZIP = application("zip");
+    public static final MediaType APPLICATION_ZIP = parse("application/zip");
 
     public static MediaType application(String type) {
-        return new MediaType("application", type);
+        return MediaType.parse("application/" + type);
     }
 
     public static MediaType audio(String type) {
-        return new MediaType("audio", type);
+        return MediaType.parse("audio/" + type);
     }
 
     public static MediaType image(String type) {
-        return new MediaType("image", type);
+        return MediaType.parse("image/" + type);
     }
 
     public static MediaType text(String type) {
-        return new MediaType("text", type);
+        return MediaType.parse("text/" + type);
     }
 
     public static MediaType video(String type) {
-        return new MediaType("video", type);
+        return MediaType.parse("video/" + type);
     }
 
     /**
-     * Parses the given string to a media type. The string is expected to be of
-     * the form "type/subtype(; parameter=...)*" as defined in RFC 2045, though
-     * we also handle "charset=xxx; type/subtype" for broken web servers.
-     * 
-     * @param string
-     *            media type string to be parsed
+     * Parses the given string to a media type. The string is expected
+     * to be of the form "type/subtype(; parameter=...)*" as defined in
+     * RFC 2045, though we also handle "charset=xxx; type/subtype" for
+     * broken web servers.
+     *
+     * @param string media type string to be parsed
      * @return parsed media type, or <code>null</code> if parsing fails
      */
     public static MediaType parse(String string) {
@@ -102,16 +108,22 @@ public final class MediaType implements Comparable<MediaType>, Serializable {
             return null;
         }
 
-        int slash = string.indexOf('/');
-        if (slash == -1) {
-            return null;
-        }
-
-        // Optimization for the common case
-        String type = string.substring(0, slash);
-        String subtype = string.substring(slash + 1);
-        if (isValidName(type) && isValidName(subtype)) {
-            return new MediaType(type, subtype);
+        // Optimization for the common cases
+        synchronized (SIMPLE_TYPES) {
+            MediaType type = SIMPLE_TYPES.get(string);
+            if (type == null) {
+                int slash = string.indexOf('/');
+                if (slash == -1) {
+                    return null;
+                } else if (isSimpleName(string.substring(0, slash))
+                        && isSimpleName(string.substring(slash + 1))) {
+                    type = new MediaType(string, slash);
+                    SIMPLE_TYPES.put(string, type);
+                }
+            }
+            if (type != null) {
+                return type;
+            }
         }
 
         Matcher matcher;
@@ -131,12 +143,11 @@ public final class MediaType implements Comparable<MediaType>, Serializable {
         return null;
     }
 
-    private static boolean isValidName(String name) {
+    private static boolean isSimpleName(String name) {
         for (int i = 0; i < name.length(); i++) {
             char c = name.charAt(i);
             if (c != '-' && c != '+' && c != '.' && c != '_'
                     && !('0' <= c && c <= '9')
-                    && !('A' <= c && c <= 'Z')
                     && !('a' <= c && c <= 'z')) {
                 return false;
             }
@@ -146,7 +157,7 @@ public final class MediaType implements Comparable<MediaType>, Serializable {
 
     private static Map<String, String> parseParameters(String string) {
         if (string.length() == 0) {
-            return NO_PARAMETERS;
+            return Collections.<String, String>emptyMap();
         }
 
         Map<String, String> parameters = new HashMap<String, String>();
@@ -176,33 +187,86 @@ public final class MediaType implements Comparable<MediaType>, Serializable {
         return parameters;
     }
 
-    private final String type;
+    /**
+     * Canonical string representation of this media type.
+     */
+    private final String string;
 
-    private final String subtype;
+    /**
+     * Location of the "/" character separating the type and the subtype
+     * tokens in {@link #string}.
+     */
+    private final int slash;
 
     /**
-     * Immutable map of media type parameters.
+     * Location of the first ";" character separating the type part of
+     * {@link #string} from possible parameters. Length of {@link #string}
+     * in case there are no parameters.
      */
-    private final SortedMap<String, String> parameters;
+    private final int semicolon;
+
+    /**
+     * Immutable sorted map of media type parameters.
+     */
+    private final Map<String, String> parameters;
 
     public MediaType(
             String type, String subtype, Map<String, String> parameters) {
-        this.type = type.trim().toLowerCase(Locale.ENGLISH);
-        this.subtype = subtype.trim().toLowerCase(Locale.ENGLISH);
+        type = type.trim().toLowerCase(Locale.ENGLISH);
+        subtype = subtype.trim().toLowerCase(Locale.ENGLISH);
+
+        this.slash = type.length();
+        this.semicolon = slash + 1 + subtype.length();
+
         if (parameters.isEmpty()) {
-            this.parameters = NO_PARAMETERS;
+            this.parameters = Collections.emptyMap();
+            this.string = type + '/' + subtype;
         } else {
+            StringBuilder builder = new StringBuilder();
+            builder.append(type);
+            builder.append('/');
+            builder.append(subtype);
+
             SortedMap<String, String> map = new TreeMap<String, String>();
+            if (!(parameters instanceof SortedMap<?, ?>)) {
+                parameters = new TreeMap<String, String>(parameters);
+            }
             for (Map.Entry<String, String> entry : parameters.entrySet()) {
-                map.put(entry.getKey().trim().toLowerCase(Locale.ENGLISH),
-                        entry.getValue());
+                String key = entry.getKey().trim().toLowerCase(Locale.ENGLISH);
+                String value = entry.getValue();
+
+                map.put(key, value);
+
+                builder.append("; ");
+                builder.append(key);
+                builder.append("=");
+                if (SPECIAL_OR_WHITESPACE.matcher(value).find()) {
+                    builder.append('"');
+                    builder.append(SPECIAL.matcher(value).replaceAll("\\\\$0"));
+                    builder.append('"');
+                } else {
+                    builder.append(value);
+                }
             }
+
+            this.string = builder.toString();
             this.parameters = Collections.unmodifiableSortedMap(map);
         }
     }
 
     public MediaType(String type, String subtype) {
-        this(type, subtype, NO_PARAMETERS);
+        this(type, subtype, Collections.<String, String>emptyMap());
+    }
+
+    private MediaType(String string, int slash) {
+        assert slash != -1;
+        assert string.charAt(slash) == '/';
+        assert isSimpleName(string.substring(0, slash));
+        assert isSimpleName(string.substring(slash + 1));
+        this.string = string;
+        this.slash = slash;
+        this.semicolon = string.length();
+        this.parameters = Collections.emptyMap();
     }
 
     private static Map<String, String> union(
@@ -220,23 +284,24 @@ public final class MediaType implements Comparable<MediaType>, Serializable {
     }
 
     public MediaType(MediaType type, Map<String, String> parameters) {
-        this(type.type, type.subtype, union(type.parameters, parameters));
+        this(type.getType(), type.getSubtype(),
+                union(type.parameters, parameters));
     }
 
     public MediaType getBaseType() {
         if (parameters.isEmpty()) {
             return this;
         } else {
-            return new MediaType(type, subtype);
+            return MediaType.parse(string.substring(0, semicolon));
         }
     }
 
     public String getType() {
-        return type;
+        return string.substring(0, slash);
     }
 
     public String getSubtype() {
-        return subtype;
+        return string.substring(slash + 1, semicolon);
     }
 
     /**
@@ -261,47 +326,24 @@ public final class MediaType implements Comparable<MediaType>, Serializable {
     }
 
     public String toString() {
-        StringBuilder builder = new StringBuilder();
-        builder.append(type);
-        builder.append('/');
-        builder.append(subtype);
-        for (Map.Entry<String, String> entry : parameters.entrySet()) {
-            builder.append("; ");
-            builder.append(entry.getKey());
-            builder.append("=");
-            String value = entry.getValue();
-            if (SPECIAL_OR_WHITESPACE.matcher(value).find()) {
-                builder.append('"');
-                builder.append(SPECIAL.matcher(value).replaceAll("\\\\$0"));
-                builder.append('"');
-            } else {
-                builder.append(value);
-            }
-        }
-        return builder.toString();
+        return string;
     }
 
     public boolean equals(Object object) {
         if (object instanceof MediaType) {
             MediaType that = (MediaType) object;
-            return type.equals(that.type)
-                && subtype.equals(that.subtype)
-                && parameters.equals(that.parameters);
+            return string.equals(that.string);
         } else {
             return false;
         }
     }
 
     public int hashCode() {
-        int hash = 17;
-        hash = hash * 31 + type.hashCode();
-        hash = hash * 31 + subtype.hashCode();
-        hash = hash * 31 + parameters.hashCode();
-        return hash;
+        return string.hashCode();
     }
 
     public int compareTo(MediaType that) {
-        return toString().compareTo(that.toString());
+        return string.compareTo(that.string);
     }
 
 }

Commit:
6d7b5d433152220cff25f88b5a28c00154ac5393
Jukka Zitting
jukka@apache.org
2011-11-11 07:51:12 +0000
TIKA-780: Optimize loading of the media type registry
diff --git a/tika-core/src/main/java/org/apache/tika/detect/MagicDetector.java b/tika-core/src/main/java/org/apache/tika/detect/MagicDetector.java
index b26a3d1a3..ceb2205ab 100644
--- a/tika-core/src/main/java/org/apache/tika/detect/MagicDetector.java
+++ b/tika-core/src/main/java/org/apache/tika/detect/MagicDetector.java
@@ -16,6 +16,7 @@
  */
 package org.apache.tika.detect;
 
+import java.io.CharArrayWriter;
 import java.io.IOException;
 import java.io.InputStream;
 
@@ -30,6 +31,141 @@ import org.apache.tika.mime.MediaType;
  */
 public class MagicDetector implements Detector {
 
+    public static MagicDetector parse(
+            MediaType mediaType,
+            String type, String offset, String value, String mask) {
+        int start = 0;
+        int end = 0;
+        if (offset != null) {
+            int colon = offset.indexOf(':');
+            if (colon == -1) {
+                start = Integer.parseInt(offset);
+                end = start;
+            } else {
+                start = Integer.parseInt(offset.substring(0, colon));
+                end = Integer.parseInt(offset.substring(colon + 1));
+            }
+        }
+
+        byte[] patternBytes = decodeValue(value, type);
+        byte[] maskBytes = null;
+        if (mask != null) {
+            maskBytes = decodeValue(mask, type);
+        }
+
+        return new MagicDetector(
+                mediaType, patternBytes, maskBytes, start, end);
+    }
+
+    private static byte[] decodeValue(String value, String type) {
+        // Preliminary check
+        if ((value == null) || (type == null)) {
+            return null;
+        }
+
+        byte[] decoded = null;
+        String tmpVal = null;
+        int radix = 8;
+
+        // hex
+        if (value.startsWith("0x")) {
+            tmpVal = value.substring(2);
+            radix = 16;
+        } else {
+            tmpVal = value;
+            radix = 8;
+        }
+
+        if (type.equals("string") || type.equals("unicodeLE")
+                || type.equals("unicodeBE")) {
+            decoded = decodeString(value, type);
+        } else if (type.equals("byte")) {
+            decoded = tmpVal.getBytes();
+        } else if (type.equals("host16") || type.equals("little16")) {
+            int i = Integer.parseInt(tmpVal, radix);
+            decoded = new byte[] { (byte) (i >> 8), (byte) (i & 0x00FF) };
+        } else if (type.equals("big16")) {
+            int i = Integer.parseInt(tmpVal, radix);
+            decoded = new byte[] { (byte) (i >> 8), (byte) (i & 0x00FF) };
+        } else if (type.equals("host32") || type.equals("little32")) {
+            long i = Long.parseLong(tmpVal, radix);
+            decoded = new byte[] {
+                    (byte) ((i & 0x000000FF)),
+                    (byte) ((i & 0x0000FF00) >> 8),
+                    (byte) ((i & 0x00FF0000) >> 16),
+                    (byte) ((i & 0xFF000000) >> 24) };
+        } else if (type.equals("big32")) {
+            long i = Long.parseLong(tmpVal, radix);
+            decoded = new byte[] {
+                    (byte) ((i & 0xFF000000) >> 24),
+                    (byte) ((i & 0x00FF0000) >> 16),
+                    (byte) ((i & 0x0000FF00) >> 8),
+                    (byte) ((i & 0x000000FF)) };
+        }
+        return decoded;
+    }
+
+    private static byte[] decodeString(String value, String type) {
+        if (value.startsWith("0x")) {
+            byte[] vals = new byte[(value.length() - 2) / 2];
+            for (int i = 0; i < vals.length; i++) {
+                vals[i] = (byte)
+                Integer.parseInt(value.substring(2 + i * 2, 4 + i * 2), 16);
+            }
+            return vals;
+        }
+
+        CharArrayWriter decoded = new CharArrayWriter();
+
+        for (int i = 0; i < value.length(); i++) {
+            if (value.charAt(i) == '\\') {
+                if (value.charAt(i + 1) == '\\') {
+                    decoded.write('\\');
+                    i++;
+                } else if (value.charAt(i + 1) == 'x') {
+                    decoded.write(Integer.parseInt(
+                            value.substring(i + 2, i + 4), 16));
+                    i += 3;
+                } else {
+                    int j = i + 1;
+                    while ((j < i + 4) && (j < value.length())
+                            && (Character.isDigit(value.charAt(j)))) {
+                        j++;
+                    }
+                    decoded.write(Short.decode(
+                            "0" + value.substring(i + 1, j)).byteValue());
+                    i = j - 1;
+                }
+            } else {
+                decoded.write(value.charAt(i));
+            }
+        }
+
+        // Now turn the chars into bytes
+        char[] chars = decoded.toCharArray();
+        byte[] bytes;
+        if ("unicodeLE".equals(type)) {
+            bytes = new byte[chars.length * 2];
+            for (int i = 0; i < chars.length; i++) {
+                bytes[i * 2] = (byte) (chars[i] & 0xff);
+                bytes[i * 2 + 1] = (byte) (chars[i] >> 8);
+            }
+        } else if ("unicodeBE".equals(type)) {
+            bytes = new byte[chars.length * 2];
+            for(int i = 0; i < chars.length; i++) {
+                bytes[i * 2] = (byte) (chars[i] >> 8);
+                bytes[i * 2 + 1] = (byte) (chars[i] & 0xff);
+            }
+        } else {
+            // Copy with truncation
+            bytes = new byte[chars.length];
+            for(int i = 0; i < bytes.length; i++) {
+                bytes[i] = (byte) chars[i];
+            }
+        }
+        return bytes;
+    }
+
     /**
      * The matching media type. Returned by the
      * {@link #detect(InputStream, Metadata)} method if a match is found.
@@ -69,8 +205,6 @@ public class MagicDetector implements Detector {
      * starts at this offset.
      */
     private final int offsetRangeEnd;
-    
-    private final String asString;
 
     /**
      * Creates a detector for input documents that have the exact given byte
@@ -136,13 +270,6 @@ public class MagicDetector implements Detector {
 
         this.offsetRangeBegin = offsetRangeBegin;
         this.offsetRangeEnd = offsetRangeEnd;
-        
-        // Build the string representation. Needs to be unique, as
-        //  these get compared. Compute now as may get compared a lot!
-        this.asString = "Magic Detection for " + type.toString() +
-          " looking for " + pattern.length + 
-          " bytes = " + this.pattern + 
-          " mask = " + this.mask;
     }
 
     /**
@@ -205,12 +332,20 @@ public class MagicDetector implements Detector {
         }
     }
 
+    public int getLength() {
+        return length;
+    }
+
     /**
      * Returns a string representation of the Detection Rule.
      * Should sort nicely by type and details, as we sometimes
      *  compare these.
      */
     public String toString() {
-       return asString;
+        // Needs to be unique, as these get compared.
+        return "Magic Detection for " + type +
+                " looking for " + pattern.length + 
+                " bytes = " + this.pattern + 
+                " mask = " + this.mask;
     }
 }
diff --git a/tika-core/src/main/java/org/apache/tika/mime/Magic.java b/tika-core/src/main/java/org/apache/tika/mime/Magic.java
index b363487f5..2168d96af 100644
--- a/tika-core/src/main/java/org/apache/tika/mime/Magic.java
+++ b/tika-core/src/main/java/org/apache/tika/mime/Magic.java
@@ -26,30 +26,27 @@ class Magic implements Clause, Comparable<Magic> {
 
     private final MimeType type;
 
-    private int priority = 50;
+    private final int priority;
 
-    private Clause clause = null;
+    private final Clause clause;
 
-    Magic(MimeType type) {
+    private final String string;
+
+    Magic(MimeType type, int priority, Clause clause) {
         this.type = type;
+        this.priority = priority;
+        this.clause = clause;
+        this.string = "[" + priority + "/" + clause + "]";
     }
 
     MimeType getType() {
         return type;
     }
 
-    void setPriority(int priority) {
-        this.priority = priority;
-    }
-
     int getPriority() {
         return priority;
     }
 
-    void setClause(Clause clause) {
-        this.clause = clause;
-    }
-
     public boolean eval(byte[] data) {
         return clause.eval(data);
     }
@@ -59,9 +56,7 @@ class Magic implements Clause, Comparable<Magic> {
     }
 
     public String toString() {
-        StringBuffer buf = new StringBuffer();
-        buf.append("[").append(priority).append("/").append(clause).append("]");
-        return buf.toString();
+        return string;
     }
 
     public int compareTo(Magic o) {
@@ -73,7 +68,7 @@ class Magic implements Clause, Comparable<Magic> {
             diff = o.type.compareTo(type);
         }
         if (diff == 0) {
-            diff = o.toString().compareTo(toString());
+            diff = o.string.compareTo(string);
         }
         return diff;
     }
@@ -81,23 +76,13 @@ class Magic implements Clause, Comparable<Magic> {
     public boolean equals(Object o) {
         if (o instanceof Magic) {
             Magic that = (Magic) o;
-
-            if (this.size() != that.size()) {
-                return false;
-            }
-
-            if (!this.type.equals(that.type)) {
-                return false;
-            }
-
-            return this.toString().equals(that.toString());
+            return type.equals(that.type) && string.equals(that.string);
         }
-
         return false;
     }
 
     public int hashCode() {
-        return size() ^ type.hashCode() ^ toString().hashCode();
+        return type.hashCode() ^ string.hashCode();
     }
 
 }
diff --git a/tika-core/src/main/java/org/apache/tika/mime/MagicMatch.java b/tika-core/src/main/java/org/apache/tika/mime/MagicMatch.java
index 14a09b6ca..7ae7c933f 100644
--- a/tika-core/src/main/java/org/apache/tika/mime/MagicMatch.java
+++ b/tika-core/src/main/java/org/apache/tika/mime/MagicMatch.java
@@ -27,18 +27,38 @@ import org.apache.tika.metadata.Metadata;
  */
 class MagicMatch implements Clause {
 
-    private final MagicDetector detector;
+    private final MediaType mediaType;
 
-    private final int length;
+    private final String type;
 
-    MagicMatch(MagicDetector detector, int length) throws MimeTypeException {
-        this.detector = detector;
-        this.length = length;
+    private final String offset;
+
+    private final String value;
+
+    private final String mask;
+
+    private MagicDetector detector = null;
+
+    MagicMatch(
+            MediaType mediaType,
+            String type, String offset, String value, String mask) {
+        this.mediaType = mediaType;
+        this.type = type;
+        this.offset = offset;
+        this.value = value;
+        this.mask = mask;
+    }
+
+    private synchronized MagicDetector getDetector() {
+        if (detector == null) {
+            detector = MagicDetector.parse(mediaType, type, offset, value, mask);
+        }
+        return detector;
     }
 
     public boolean eval(byte[] data) {
         try {
-            return detector.detect(
+            return getDetector().detect(
                     new ByteArrayInputStream(data), new Metadata())
                     != MediaType.OCTET_STREAM;
         } catch (IOException e) {
@@ -48,11 +68,12 @@ class MagicMatch implements Clause {
     }
 
     public int size() {
-        return length;
+        return getDetector().getLength();
     }
 
     public String toString() {
-        return detector.toString();
+        return mediaType.toString()
+                + " " + type + " " + offset + " " +  value + " " + mask;
     }
 
 }
diff --git a/tika-core/src/main/java/org/apache/tika/mime/MediaType.java b/tika-core/src/main/java/org/apache/tika/mime/MediaType.java
index 3c96d4695..2b8260463 100644
--- a/tika-core/src/main/java/org/apache/tika/mime/MediaType.java
+++ b/tika-core/src/main/java/org/apache/tika/mime/MediaType.java
@@ -45,15 +45,20 @@ public final class MediaType implements Comparable<MediaType>, Serializable {
     private static final Pattern SPECIAL_OR_WHITESPACE =
         Pattern.compile("[\\(\\)<>@,;:\\\\\"/\\[\\]\\?=\\s]");
 
+    /**
+     * See http://www.ietf.org/rfc/rfc2045.txt for valid mime-type characters.
+     */
+    private static final String VALID_CHARS =
+            "([^\\c\\(\\)<>@,;:\\\\\"/\\[\\]\\?=\\s]+)";
+
+    private static final Pattern TYPE_PATTERN = Pattern.compile(
+                    "(?s)\\s*" + VALID_CHARS + "\\s*/\\s*" + VALID_CHARS
+                    + "\\s*($|;.*)");
+
     // TIKA-350: handle charset as first element in content-type
-    // See http://www.ietf.org/rfc/rfc2045.txt for valid mime-type characters.
-    private static final String VALID_MIMETYPE_CHARS = "[^\\c\\(\\)<>@,;:\\\\\"/\\[\\]\\?=\\s]";
-    private static final String MIME_TYPE_PATTERN_STRING = "(" + VALID_MIMETYPE_CHARS + "+)"
-                    + "\\s*/\\s*" + "(" + VALID_MIMETYPE_CHARS + "+)";
-    private static final Pattern CONTENT_TYPE_PATTERN = Pattern.compile(
-                    "(?is)\\s*" + MIME_TYPE_PATTERN_STRING + "\\s*($|;.*)");
-    private static final Pattern CONTENT_TYPE_CHARSET_FIRST_PATTERN = Pattern.compile(
-                    "(?i)\\s*(charset\\s*=\\s*[^\\c;\\s]+)\\s*;\\s*" + MIME_TYPE_PATTERN_STRING);
+    private static final Pattern CHARSET_FIRST_PATTERN = Pattern.compile(
+            "(?is)\\s*(charset\\s*=\\s*[^\\c;\\s]+)\\s*;\\s*"
+            + VALID_CHARS + "\\s*/\\s*" + VALID_CHARS + "\\s*");
 
     public static final MediaType OCTET_STREAM = application("octet-stream");
 
@@ -97,39 +102,78 @@ public final class MediaType implements Comparable<MediaType>, Serializable {
             return null;
         }
 
-        String type;
-        String subtype;
-        String params;
-        
-        Matcher m = CONTENT_TYPE_PATTERN.matcher(string);
-        if (m.matches()) {
-            type = m.group(1);
-            subtype = m.group(2);
-            params = m.group(3);
-        } else {
-            m = CONTENT_TYPE_CHARSET_FIRST_PATTERN.matcher(string);
-            if (m.matches()) {
-                params = m.group(1);
-                type = m.group(2);
-                subtype = m.group(3);
-            } else {
-                return null;
+        int slash = string.indexOf('/');
+        if (slash == -1) {
+            return null;
+        }
+
+        // Optimization for the common case
+        String type = string.substring(0, slash);
+        String subtype = string.substring(slash + 1);
+        if (isValidName(type) && isValidName(subtype)) {
+            return new MediaType(type, subtype);
+        }
+
+        Matcher matcher;
+        matcher = TYPE_PATTERN.matcher(string);
+        if (matcher.matches()) {
+            return new MediaType(
+                    matcher.group(1), matcher.group(2),
+                    parseParameters(matcher.group(3)));
+        }
+        matcher = CHARSET_FIRST_PATTERN.matcher(string);
+        if (matcher.matches()) {
+            return new MediaType(
+                    matcher.group(2), matcher.group(3),
+                    parseParameters(matcher.group(1)));
+        }
+
+        return null;
+    }
+
+    private static boolean isValidName(String name) {
+        for (int i = 0; i < name.length(); i++) {
+            char c = name.charAt(i);
+            if (c != '-' && c != '+' && c != '.' && c != '_'
+                    && !('0' <= c && c <= '9')
+                    && !('A' <= c && c <= 'Z')
+                    && !('a' <= c && c <= 'z')) {
+                return false;
             }
         }
+        return name.length() > 0;
+    }
+
+    private static Map<String, String> parseParameters(String string) {
+        if (string.length() == 0) {
+            return NO_PARAMETERS;
+        }
 
         Map<String, String> parameters = new HashMap<String, String>();
-        for (String paramPiece : params.split(";")) {
-            String[] keyValue = paramPiece.split("=", 2);
-            String key = keyValue[0].trim();
+        while (string.length() > 0) {
+            String key = string;
+            String value = "";
+
+            int semicolon = string.indexOf(';');
+            if (semicolon != -1) {
+                key = string.substring(0, semicolon);
+                string = string.substring(semicolon + 1);
+            } else {
+                string = "";
+            }
+
+            int equals = key.indexOf('=');
+            if (equals != -1) {
+                value = key.substring(equals + 1);
+                key = key.substring(0, equals);
+            }
+
+            key = key.trim();
             if (key.length() > 0) {
-                if (keyValue.length > 1) {
-                    parameters.put(key, keyValue[1].trim());
-                } else {
-                    parameters.put(key, "");
-                }
+                parameters.put(key, value.trim());
             }
         }
-        return new MediaType(type, subtype, parameters);
+        return parameters;
     }
 
     private final String type;
diff --git a/tika-core/src/main/java/org/apache/tika/mime/MimeType.java b/tika-core/src/main/java/org/apache/tika/mime/MimeType.java
index 66b9225ba..2d10ffbc0 100644
--- a/tika-core/src/main/java/org/apache/tika/mime/MimeType.java
+++ b/tika-core/src/main/java/org/apache/tika/mime/MimeType.java
@@ -80,10 +80,10 @@ public final class MimeType implements Comparable<MimeType>, Serializable {
     private String description = "";
 
     /** The magics associated to this Mime-Type */
-    private final ArrayList<Magic> magics = new ArrayList<Magic>();
+    private List<Magic> magics = null;
 
     /** The root-XML associated to this Mime-Type */
-    private final ArrayList<RootXML> rootXML = new ArrayList<RootXML>();
+    private List<RootXML> rootXML = null;
 
     /** The minimum length of data to provides for magic analyzis */
     private int minLength = 0;
@@ -92,7 +92,7 @@ public final class MimeType implements Comparable<MimeType>, Serializable {
      * All known file extensions of this type, in order of preference
      * (best first).
      */
-    private final List<String> extensions = new ArrayList<String>();
+    private List<String> extensions = null;
 
     /**
      * Creates a media type with the give name and containing media type
@@ -156,34 +156,42 @@ public final class MimeType implements Comparable<MimeType>, Serializable {
      * @param localName
      */
     void addRootXML(String namespaceURI, String localName) {
+        if (rootXML == null) {
+            rootXML = new ArrayList<RootXML>();
+        }
         rootXML.add(new RootXML(this, namespaceURI, localName));
     }
 
     boolean matchesXML(String namespaceURI, String localName) {
-        for (RootXML xml : rootXML) {
-            if (xml.matches(namespaceURI, localName)) {
-                return true;
+        if (rootXML != null) {
+            for (RootXML xml : rootXML) {
+                if (xml.matches(namespaceURI, localName)) {
+                    return true;
+                }
             }
         }
         return false;
     }
 
     boolean hasRootXML() {
-        return (rootXML.size() > 0);
+        return rootXML != null;
     }
 
-    RootXML[] getRootXMLs() {
-        return rootXML.toArray(new RootXML[rootXML.size()]);
-    }
-
-    Magic[] getMagics() {
-        return magics.toArray(new Magic[magics.size()]);
+    List<Magic> getMagics() {
+        if (magics != null) {
+            return magics;
+        } else {
+            return Collections.emptyList();
+        }
     }
 
     void addMagic(Magic magic) {
         if (magic == null) {
             return;
         }
+        if (magics == null) {
+            magics = new ArrayList<Magic>();
+        }
         magics.add(magic);
     }
 
@@ -192,11 +200,11 @@ public final class MimeType implements Comparable<MimeType>, Serializable {
     }
 
     public boolean hasMagic() {
-        return (magics.size() > 0);
+        return magics != null;
     }
 
     public boolean matchesMagic(byte[] data) {
-        for (int i = 0; i < magics.size(); i++) {
+        for (int i = 0; magics != null && i < magics.size(); i++) {
             Magic magic = magics.get(i);
             if (magic.eval(data)) {
                 return true;
@@ -330,7 +338,7 @@ public final class MimeType implements Comparable<MimeType>, Serializable {
      * @return preferred file extension or empty string
      */
     public String getExtension() {
-        if (extensions.isEmpty()) {
+        if (extensions == null) {
             return "";
         } else {
             return extensions.get(0);
@@ -344,7 +352,11 @@ public final class MimeType implements Comparable<MimeType>, Serializable {
      * @return known extensions in order of preference (best first)
      */
     public List<String> getExtensions() {
-        return Collections.unmodifiableList(extensions);
+        if (extensions != null) {
+            return Collections.unmodifiableList(extensions);
+        } else {
+            return Collections.emptyList();
+        }
     }
 
     /**
@@ -353,6 +365,11 @@ public final class MimeType implements Comparable<MimeType>, Serializable {
      * @param extension file extension
      */
     void addExtension(String extension) {
+        if (extensions == null) {
+            extensions = Collections.singletonList(extension);
+        } else if (extensions.size() == 1) {
+            extensions = new ArrayList<String>(extensions);
+        }
         if (!extensions.contains(extension)) {
             extensions.add(extension);
         }
diff --git a/tika-core/src/main/java/org/apache/tika/mime/MimeTypes.java b/tika-core/src/main/java/org/apache/tika/mime/MimeTypes.java
index 26e74f042..91d25e03f 100644
--- a/tika-core/src/main/java/org/apache/tika/mime/MimeTypes.java
+++ b/tika-core/src/main/java/org/apache/tika/mime/MimeTypes.java
@@ -24,12 +24,12 @@ import java.io.InputStream;
 import java.io.Serializable;
 import java.net.URI;
 import java.net.URISyntaxException;
-import java.util.Arrays;
+import java.util.ArrayList;
+import java.util.Collections;
 import java.util.HashMap;
+import java.util.List;
 import java.util.Locale;
 import java.util.Map;
-import java.util.SortedSet;
-import java.util.TreeSet;
 
 import javax.xml.namespace.QName;
 
@@ -102,11 +102,11 @@ public final class MimeTypes implements Detector, Serializable {
     /** The patterns matcher */
     private Patterns patterns = new Patterns(registry);
 
-    /** List of all registered magics */
-    private SortedSet<Magic> magics = new TreeSet<Magic>();
+    /** Sorted list of all registered magics */
+    private final List<Magic> magics = new ArrayList<Magic>();
 
-    /** List of all registered rootXML */
-    private SortedSet<MimeType> xmls = new TreeSet<MimeType>();
+    /** Sorted list of all registered rootXML */
+    private final List<MimeType> xmls = new ArrayList<MimeType>();
 
     public MimeTypes() {
         rootMimeType = new MimeType(MediaType.OCTET_STREAM);
@@ -362,7 +362,7 @@ public final class MimeTypes implements Detector, Serializable {
 
         // Update the magics index...
         if (type.hasMagic()) {
-            magics.addAll(Arrays.asList(type.getMagics()));
+            magics.addAll(type.getMagics());
         }
 
         // Update the xml (xmlRoot) index...
@@ -371,6 +371,21 @@ public final class MimeTypes implements Detector, Serializable {
         }
     }
 
+    /**
+     * Called after all configured types have been loaded.
+     * Initializes the magics and xmls sets.
+     */
+    void init() {
+        for (MimeType type : types.values()) {
+            magics.addAll(type.getMagics());
+            if (type.hasRootXML()) {
+                xmls.add(type);
+            }
+        }
+        Collections.sort(magics);
+        Collections.sort(xmls);
+    }
+
     /**
      * Automatically detects the MIME type of a document based on magic
      * markers in the stream prefix and any given metadata hints.
@@ -441,23 +456,29 @@ public final class MimeTypes implements Detector, Serializable {
 
         return type;
     }
-    
+
+    private static MimeTypes DEFAULT_TYPES = null;
+
     /**
      * Get the default MimeTypes. This includes all the build in
-     *  mimetypes, and any custom override ones present. 
+     * media types, and any custom override ones present.
      * 
-     * @return MimeTypes
-     * @throws MimeTypeException
-     * @throws IOException
+     * @return MimeTypes default type registry
      */
-    public static MimeTypes getDefaultMimeTypes() {
-        try {
-            return MimeTypesFactory.create("tika-mimetypes.xml", "custom-mimetypes.xml");
-        } catch (MimeTypeException e) {
-            throw new RuntimeException("Unable to read default mimetypes", e);
-        } catch (IOException e) {
-            throw new RuntimeException("Unable to read default mimetypes", e);
+    public static synchronized MimeTypes getDefaultMimeTypes() {
+        if (DEFAULT_TYPES == null) {
+            try {
+                DEFAULT_TYPES = MimeTypesFactory.create(
+                        "tika-mimetypes.xml", "custom-mimetypes.xml");
+            } catch (MimeTypeException e) {
+                throw new RuntimeException(
+                        "Unable to parse the default media type registry", e);
+            } catch (IOException e) {
+                throw new RuntimeException(
+                        "Unable to read the default media type registry", e);
+            }
         }
+        return DEFAULT_TYPES;
     }
 
 }
diff --git a/tika-core/src/main/java/org/apache/tika/mime/MimeTypesFactory.java b/tika-core/src/main/java/org/apache/tika/mime/MimeTypesFactory.java
index 8c473eeda..4facad243 100644
--- a/tika-core/src/main/java/org/apache/tika/mime/MimeTypesFactory.java
+++ b/tika-core/src/main/java/org/apache/tika/mime/MimeTypesFactory.java
@@ -46,6 +46,7 @@ public class MimeTypesFactory {
     public static MimeTypes create(Document document) throws MimeTypeException {
         MimeTypes mimeTypes = new MimeTypes();
         new MimeTypesReader(mimeTypes).read(document);
+        mimeTypes.init();
         return mimeTypes;
     }
 
@@ -62,6 +63,7 @@ public class MimeTypesFactory {
         for(InputStream inputStream : inputStreams) {
            reader.read(inputStream);
         }
+        mimeTypes.init();
         return mimeTypes;
     }
 
diff --git a/tika-core/src/main/java/org/apache/tika/mime/MimeTypesReader.java b/tika-core/src/main/java/org/apache/tika/mime/MimeTypesReader.java
index 610b13e4d..9bcf6a369 100644
--- a/tika-core/src/main/java/org/apache/tika/mime/MimeTypesReader.java
+++ b/tika-core/src/main/java/org/apache/tika/mime/MimeTypesReader.java
@@ -16,17 +16,16 @@
  */
 package org.apache.tika.mime;
 
-import java.io.CharArrayWriter;
 import java.io.IOException;
 import java.io.InputStream;
 import java.util.ArrayList;
+import java.util.Collections;
 import java.util.List;
 
 import javax.xml.parsers.DocumentBuilder;
 import javax.xml.parsers.DocumentBuilderFactory;
 import javax.xml.parsers.ParserConfigurationException;
 
-import org.apache.tika.detect.MagicDetector;
 import org.w3c.dom.Attr;
 import org.w3c.dom.Document;
 import org.w3c.dom.Element;
@@ -184,17 +183,20 @@ final class MimeTypesReader implements MimeTypesReaderMetKeys {
         }
 
         for (Clause clause : readMatches(element, mimeType.getType())) {
-            Magic magic = new Magic(mimeType);
-            magic.setPriority(priority);
-            magic.setClause(clause);
+            Magic magic = new Magic(mimeType, priority, clause);
             mimeType.addMagic(magic);
         }
     }
 
     private List<Clause> readMatches(Element element, MediaType mediaType) throws MimeTypeException {
-        List<Clause> clauses = new ArrayList<Clause>();
         NodeList nodes = element.getChildNodes();
-        for (int i = 0; i < nodes.getLength(); i++) {
+        int n = nodes.getLength();
+        if (n == 0) {
+            return Collections.emptyList();
+        }
+
+        List<Clause> clauses = new ArrayList<Clause>();
+        for (int i = 0; i < n; i++) {
             Node node = nodes.item(i);
             if (node.getNodeType() == Node.ELEMENT_NODE) {
                 Element nodeElement = (Element) node;
@@ -208,9 +210,22 @@ final class MimeTypesReader implements MimeTypesReaderMetKeys {
 
     /** Read Element named match. */
     private Clause readMatch(Element element, MediaType mediaType) throws MimeTypeException {
+        Clause clause = getMagicClause(element, mediaType);
+
+        List<Clause> subClauses = readMatches(element, mediaType);
+        if (subClauses.size() == 0) {
+            return clause;
+        } else if (subClauses.size() == 1) {
+            return new AndClause(clause, subClauses.get(0));
+        } else {
+            return new AndClause(clause, new OrClause(subClauses));
+        }
+    }
+
+    private Clause getMagicClause(Element element, MediaType mediaType)
+            throws MimeTypeException {
         String type = "string";
-        int start = 0;
-        int end = 0;
+        String offset = null;
         String value = null;
         String mask = null;
 
@@ -218,15 +233,7 @@ final class MimeTypesReader implements MimeTypesReaderMetKeys {
         for (int i = 0; i < attrs.getLength(); i++) {
             Attr attr = (Attr) attrs.item(i);
             if (attr.getName().equals(MATCH_OFFSET_ATTR)) {
-                String offset = attr.getValue();
-                int colon = offset.indexOf(':');
-                if (colon == -1) {
-                    start = Integer.parseInt(offset);
-                    end = start;
-                } else {
-                    start = Integer.parseInt(offset.substring(0, colon));
-                    end = Integer.parseInt(offset.substring(colon + 1));
-                }
+                offset = attr.getValue();
             } else if (attr.getName().equals(MATCH_TYPE_ATTR)) {
                 type = attr.getValue();
             } else if (attr.getName().equals(MATCH_VALUE_ATTR)) {
@@ -236,151 +243,7 @@ final class MimeTypesReader implements MimeTypesReaderMetKeys {
             }
         }
 
-        if (value == null) {
-            throw new MimeTypeException("Missing magic byte pattern");
-        } else if (start < 0 || end < start) {
-            throw new MimeTypeException(
-                    "Invalid offset range: [" + start + "," + end + "]");
-        }
-
-        byte[] patternBytes = decodeValue(type, value);
-        int length = patternBytes.length;
-        byte[] maskBytes = null;
-        if (mask != null) {
-            maskBytes = decodeValue(type, mask);
-            length = Math.max(patternBytes.length, maskBytes.length);
-        }
-
-        MagicDetector detector = new MagicDetector(
-                mediaType, patternBytes, maskBytes, start, end);
-        Clause clause = new MagicMatch(detector, length);
-
-        List<Clause> subClauses = readMatches(element, mediaType);
-        if (subClauses.size() == 0) {
-            return clause;
-        } else if (subClauses.size() == 1) {
-            return new AndClause(clause, subClauses.get(0));
-        } else {
-            return new AndClause(clause, new OrClause(subClauses));
-        }
-    }
-
-    private byte[] decodeValue(String type, String value)
-            throws MimeTypeException {
-        // Preliminary check
-        if ((value == null) || (type == null)) {
-            return null;
-        }
-
-        byte[] decoded = null;
-        String tmpVal = null;
-        int radix = 8;
-
-        // hex
-        if (value.startsWith("0x")) {
-            tmpVal = value.substring(2);
-            radix = 16;
-        } else {
-            tmpVal = value;
-            radix = 8;
-        }
-
-        if (type.equals("string") || type.equals("unicodeLE") || type.equals("unicodeBE")) {
-            decoded = decodeString(value, type);
-            
-        } else if (type.equals("byte")) {
-            decoded = tmpVal.getBytes();
-
-        } else if (type.equals("host16") || type.equals("little16")) {
-            int i = Integer.parseInt(tmpVal, radix);
-            decoded = new byte[] { (byte) (i >> 8), (byte) (i & 0x00FF) };
-
-        } else if (type.equals("big16")) {
-            int i = Integer.parseInt(tmpVal, radix);
-            decoded = new byte[] { (byte) (i >> 8), (byte) (i & 0x00FF) };
-
-        } else if (type.equals("host32") || type.equals("little32")) {
-            long i = Long.parseLong(tmpVal, radix);
-            decoded = new byte[] { (byte) ((i & 0x000000FF)),
-                    (byte) ((i & 0x0000FF00) >> 8),
-                    (byte) ((i & 0x00FF0000) >> 16),
-                    (byte) ((i & 0xFF000000) >> 24) };
-
-        } else if (type.equals("big32")) {
-            long i = Long.parseLong(tmpVal, radix);
-            decoded = new byte[] { (byte) ((i & 0xFF000000) >> 24),
-                    (byte) ((i & 0x00FF0000) >> 16),
-                    (byte) ((i & 0x0000FF00) >> 8), (byte) ((i & 0x000000FF)) };
-        }
-        return decoded;
-    }
-
-    private byte[] decodeString(String value, String type) throws MimeTypeException {
-        if (value.startsWith("0x")) {
-            byte[] vals = new byte[(value.length() - 2) / 2];
-            for (int i = 0; i < vals.length; i++) {
-                vals[i] = (byte)
-                Integer.parseInt(value.substring(2 + i * 2, 4 + i * 2), 16);
-            }
-            return vals;
-        }
-
-        try {
-            CharArrayWriter decoded = new CharArrayWriter();
-
-            for (int i = 0; i < value.length(); i++) {
-                if (value.charAt(i) == '\\') {
-                    if (value.charAt(i + 1) == '\\') {
-                        decoded.write('\\');
-                        i++;
-                    } else if (value.charAt(i + 1) == 'x') {
-                        decoded.write(Integer.parseInt(
-                                value.substring(i + 2, i + 4), 16));
-                        i += 3;
-                    } else {
-                        int j = i + 1;
-                        while ((j < i + 4) && (j < value.length())
-                                && (Character.isDigit(value.charAt(j)))) {
-                            j++;
-                        }
-                        decoded.write(Short.decode(
-                                "0" + value.substring(i + 1, j)).byteValue());
-                        i = j - 1;
-                    }
-                } else {
-                    decoded.write(value.charAt(i));
-                }
-            }
-            
-            // Now turn the chars into bytes
-            char[] chars = decoded.toCharArray();
-            byte[] bytes;
-            if("unicodeLE".equals(type)) {
-               bytes = new byte[chars.length*2];
-               for(int i=0; i<chars.length; i++) {
-                  bytes[i*2] = (byte)(chars[i] & 0xff);
-                  bytes[i*2+1] = (byte)(chars[i] >> 8);
-               }
-            }
-            else if("unicodeBE".equals(type)) {
-               bytes = new byte[chars.length*2];
-               for(int i=0; i<chars.length; i++) {
-                  bytes[i*2] = (byte)(chars[i] >> 8);
-                  bytes[i*2+1] = (byte)(chars[i] & 0xff);
-               }
-            }
-            else {
-               // Copy with truncation
-               bytes = new byte[chars.length];
-               for(int i=0; i<bytes.length; i++) {
-                  bytes[i] = (byte)chars[i];
-               }
-            }
-            
-            return bytes;
-        } catch (NumberFormatException e) {
-            throw new MimeTypeException("Invalid string value: " + value, e);
-        }
+        return new MagicMatch(mediaType, type, offset, value, mask);
     }
 
     /** Read Element named root-XML. */
diff --git a/tika-core/src/test/java/org/apache/tika/mime/MimeTypesReaderTest.java b/tika-core/src/test/java/org/apache/tika/mime/MimeTypesReaderTest.java
index c07d60688..900e4fdc4 100644
--- a/tika-core/src/test/java/org/apache/tika/mime/MimeTypesReaderTest.java
+++ b/tika-core/src/test/java/org/apache/tika/mime/MimeTypesReaderTest.java
@@ -43,8 +43,7 @@ import org.apache.tika.metadata.Metadata;
 public class MimeTypesReaderTest extends TestCase {
 
     private MimeTypes mimeTypes;
-    private SortedSet<Magic> magics;
-    private SortedSet<MimeType> xmls;
+    private List<Magic> magics;
 
     @Override
     @SuppressWarnings("unchecked")
@@ -54,11 +53,7 @@ public class MimeTypesReaderTest extends TestCase {
 
         Field magicsField = mimeTypes.getClass().getDeclaredField("magics");
         magicsField.setAccessible(true);
-        magics = (SortedSet<Magic>)magicsField.get(mimeTypes);
-
-        Field xmlsField = mimeTypes.getClass().getDeclaredField("xmls");
-        xmlsField.setAccessible(true);
-        xmls = (SortedSet<MimeType>)xmlsField.get(mimeTypes);
+        magics = (List<Magic>)magicsField.get(mimeTypes);
     }
 
     public void testHtmlMatches() throws Exception {
@@ -68,8 +63,8 @@ public class MimeTypesReaderTest extends TestCase {
        MimeType html = mimeTypes.forName("text/html");
        assertTrue(html.hasMagic());
        assertTrue(
-             "There should be at least "+minMatches+" HTML matches, found " + html.getMagics().length,
-             html.getMagics().length >= minMatches
+             "There should be at least "+minMatches+" HTML matches, found " + html.getMagics().size(),
+             html.getMagics().size() >= minMatches
        );
 
        // Check on the overall magics
@@ -93,8 +88,8 @@ public class MimeTypesReaderTest extends TestCase {
        MimeType excel = mimeTypes.forName("application/vnd.ms-excel");
        assertTrue(excel.hasMagic());
        assertTrue(
-             "There should be at least "+minMatches+" Excel matches, found " + excel.getMagics().length,
-             excel.getMagics().length >= minMatches
+             "There should be at least "+minMatches+" Excel matches, found " + excel.getMagics().size(),
+             excel.getMagics().size() >= minMatches
        );
 
        // Check on the overall magics

Commit:
79150b7bd48602ec619ac4a9a6232a7d400f24ec
Jukka Zitting
jukka@apache.org
2011-11-10 19:50:49 +0000
TIKA-773: .NET version of Tika
diff --git a/tika-app/pom.xml b/tika-app/pom.xml
index c359765a2..6fa79b9e7 100644
--- a/tika-app/pom.xml
+++ b/tika-app/pom.xml
@@ -34,14 +34,12 @@
   <name>Apache Tika application</name>
   <url>http://tika.apache.org/</url>
 
+  <properties>
+    <ikvm>${env.IKVM_HOME}</ikvm>
+  </properties>
+
   <dependencies>
-  	<dependency>
-  		<groupId>junit</groupId>
-  		<artifactId>junit</artifactId>
-  		<version>3.8.2</version>
-  		<scope>test</scope>
-  	</dependency>
-  	<dependency>
+    <dependency>
       <groupId>${project.groupId}</groupId>
       <artifactId>tika-parsers</artifactId>
       <version>${project.version}</version>
@@ -59,7 +57,11 @@
       <version>1.7.1</version>
       <scope>provided</scope>
     </dependency>
- 
+    <dependency>
+      <groupId>junit</groupId>
+      <artifactId>junit</artifactId>
+      <scope>test</scope>
+    </dependency>
   </dependencies>
 
   <build>
@@ -118,4 +120,75 @@
     </plugins>
   </build>
 
+  <profiles>
+    <profile>
+      <id>ikvm</id>
+      <activation>
+        <file>
+          <exists>${ikvm}/bin/ikvmc.exe</exists>
+        </file>
+      </activation>
+      <build>
+        <plugins>
+          <plugin>
+            <artifactId>maven-antrun-plugin</artifactId>
+            <executions>
+              <execution>
+                <phase>package</phase>
+                <goals>
+                  <goal>run</goal>
+                </goals>
+                <configuration>
+                  <target>
+                    <exec executable="${ikvm}/bin/ikvmc.exe">
+                      <arg value="-nowarn:0100"/>
+                      <arg value="-nowarn:0105"/>
+                      <arg value="-nowarn:0109"/>
+                      <arg value="-nowarn:0111"/>
+                      <arg value="-nowarn:0112"/>
+                      <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.Util.dll"/>
+                      <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.Charsets.dll"/>
+                      <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.Text.dll"/>
+                      <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.Core.dll"/>
+                      <arg value="-reference:${ikvm}/bin/IKVM.AWT.WinForms.dll"/>
+                      <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.Media.dll"/>
+                      <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.Misc.dll"/>
+                      <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.Security.dll"/>
+                      <arg value="-reference:${ikvm}/bin/IKVM.OpenJDK.SwingAWT.dll"/>
+                      <arg value="-target:library" />
+                      <arg value="-compressresources" />
+                      <arg value="-out:${project.build.directory}/${project.build.finalName}.dll" />
+                      <arg value="${project.build.directory}/${project.build.finalName}.jar" />
+                    </exec>
+                  </target>
+                </configuration>
+              </execution>
+            </executions>
+          </plugin>
+          <plugin>
+            <groupId>org.codehaus.mojo</groupId>
+            <artifactId>build-helper-maven-plugin</artifactId>
+            <version>1.7</version>
+            <executions>
+              <execution>
+                <phase>package</phase>
+                <goals>
+                  <goal>attach-artifact</goal>
+                </goals>
+                <configuration>
+                  <artifacts>
+                    <artifacts>
+                      <file>${project.build.directory}/${project.build.finalName}.dll</file>
+                      <type>dll</type>
+                    </artifacts>
+                  </artifacts>
+                </configuration>
+              </execution>
+            </executions>
+          </plugin>
+        </plugins>
+      </build>
+    </profile>
+  </profiles>
+
 </project>

Commit:
2c3dbde39c16161dafc4b5cc03db4e259bf7fb7f
Michael McCandless
mikemccand@apache.org
2011-11-08 23:21:38 +0000
TIKA-777: process buffered bytes/text on font change
diff --git a/CHANGES.txt b/CHANGES.txt
index 26bdd31ad..dc9dc8a4c 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -9,6 +9,10 @@ Release 1.1 - Current Development
    speedups to text extraction and may workaround cases where
    non-duplicated characters were incorrectly removed.  (TIKA-767)
 
+ * RTF: Fixed case where a font change would result in processing
+   bytes in the wrong font's charset, producing bogus text output
+   (TIKA-777)
+
 Release 1.0 - 11/4/2011
 ---------------------------------
 
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/rtf/TextExtractor.java b/tika-parsers/src/main/java/org/apache/tika/parser/rtf/TextExtractor.java
index 6cc014718..f51eb7ea3 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/rtf/TextExtractor.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/rtf/TextExtractor.java
@@ -772,6 +772,11 @@ final class TextExtractor {
             } else if (equals("f")) {
                 // Change current font
                 final String fontCharset = fontToCharset.get((int) param);
+
+                // Push any buffered text before changing
+                // font:
+                pushText();
+
                 if (fontCharset != null) {
                     groupState.fontCharset = fontCharset;
                 } else {
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/rtf/RTFParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/rtf/RTFParserTest.java
index e2d1d3bfd..47e831cad 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/rtf/RTFParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/rtf/RTFParserTest.java
@@ -274,6 +274,11 @@ public class RTFParserTest extends TikaTest {
         assertContains("<p>The quick brown fox jumps over the lazy dog</p>", getXML("testRTFIgnoredControlWord.rtf").xml);
     }
 
+    public void testFontAfterBufferedText() throws Exception {
+        assertContains("\u0423\u0432\u0430\u0436\u0430\u0435\u043c\u044b\u0439 \u043a\u043b\u0438\u0435\u043d\u0442!",
+                       getXML("testFontAfterBufferedText.rtf").xml);
+    }
+
     private Result getResult(String filename) throws Exception {
         File file = getResourceAsFile("/test-documents/" + filename);
        
diff --git a/tika-parsers/src/test/resources/test-documents/testFontAfterBufferedText.rtf b/tika-parsers/src/test/resources/test-documents/testFontAfterBufferedText.rtf
new file mode 100644
index 000000000..de6dc2fe2
--- /dev/null
+++ b/tika-parsers/src/test/resources/test-documents/testFontAfterBufferedText.rtf
@@ -0,0 +1,7 @@
+{\rtf1\ansi\ansicpg1252\fromtext \fbidis \deff0
+{\fonttbl
+
+{\f0\fswiss\fcharset0 Arial;} {\f1\fswiss\fcharset204 Arial;}
+}
+\par{\f1\fs20 \'d3\'e2\'e0\'e6\'e0\'e5\'ec\'fb\'e9 \'ea\'eb\'e8\'e5\'ed\'f2!\f0}\par
+}

Commit:
a157a6f025c4b5eda63881124919b4271f85ba0b
Michael McCandless
mikemccand@apache.org
2011-11-08 19:07:07 +0000
TIKA-529: don't allocate byte[] for each byte when detecting IBM420 charset
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/txt/CharsetRecog_sbcs.java b/tika-parsers/src/main/java/org/apache/tika/parser/txt/CharsetRecog_sbcs.java
index 4b9523bed..c62132855 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/txt/CharsetRecog_sbcs.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/txt/CharsetRecog_sbcs.java
@@ -1297,11 +1297,12 @@ abstract class CharsetRecog_sbcs extends CharsetRecognizer {
         }
         
         private boolean isLamAlef(byte b) {
-            byte shapedLamAlef[] = {(byte)0xb2,(byte)0xb3,(byte)0xb4,(byte)0xb5,(byte)0xb7,(byte)0xb8 };
-            for (int i = 0; i<shapedLamAlef.length; i++)
-                if (b == shapedLamAlef[i])
-                    return true;
-            return false;
+            // Return true if byte is any of these:
+            //
+            //   {(byte)0xb2,(byte)0xb3,(byte)0xb4,(byte)0xb5,(byte)0xb7,(byte)0xb8}
+            // 
+            // NOTE: 0xb2 is -78; 0xb8 is -72:
+            return (b <= (byte)0xb8) && (b >= (byte)0xb2) && (b != (byte)0xb6);
         }
         
         protected void matchFinish(CharsetDetector det) {

Commit:
a39d5824b631d13571abc60ad7e15d7afbf449dc
Michael McCandless
mikemccand@apache.org
2011-11-06 11:14:34 +0000
TIKA-714: add test case for PPTX to extract text from word art
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
index ec87a0bf9..3daecd2f5 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/ooxml/OOXMLParserTest.java
@@ -661,4 +661,20 @@ public class OOXMLParserTest extends TikaTest {
         assertContains("Text that I added to the master slide", content);
     }
     */
+
+    public void testWordArt() throws Exception {
+        ContentHandler handler = new BodyContentHandler();
+        Metadata metadata = new Metadata();
+
+        InputStream stream = OOXMLParserTest.class.getResourceAsStream(
+                "/test-documents/testWordArt.pptx");
+        try {
+            new AutoDetectParser().parse(stream, handler, metadata, new ParseContext());
+        } finally {
+            stream.close();
+        }
+        String content = handler.toString();
+        assertContains("Here is some red word Art", content);
+    }
+
 }
diff --git a/tika-parsers/src/test/resources/test-documents/testWordArt.pptx b/tika-parsers/src/test/resources/test-documents/testWordArt.pptx
new file mode 100644
index 000000000..eb09a85e0
Binary files /dev/null and b/tika-parsers/src/test/resources/test-documents/testWordArt.pptx differ

Commit:
1a7dfa176b588047b54a2cb8798365aaf41a9ebd
Michael McCandless
mikemccand@apache.org
2011-11-05 11:01:38 +0000
TIKA-712: strengthen the test cases here to not only validate the text came through but also to make sure boilerplate text did not
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PowerPointParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PowerPointParserTest.java
index b0a1b7704..6ca34a055 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PowerPointParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/microsoft/PowerPointParserTest.java
@@ -129,6 +129,9 @@ public class PowerPointParserTest extends TikaTest {
 
         String content = handler.toString();
         assertContains("Master footer is here", content);
+
+        // Make sure boilerplate text didn't come through:
+        assertEquals(-1, content.indexOf("Click to edit Master"));
     }
 
     // TODO: once we fix TIKA-712, re-enable this
@@ -147,6 +150,9 @@ public class PowerPointParserTest extends TikaTest {
 
         String content = handler.toString();
         assertContains("Text that I added to the master slide", content);
+
+        // Make sure boilerplate text didn't come through:
+        assertEquals(-1, content.indexOf("Click to edit Master"));
     }
     */
 
@@ -166,6 +172,9 @@ public class PowerPointParserTest extends TikaTest {
 
         String content = handler.toString();
         assertContains("Text that I added to the master slide", content);
+
+        // Make sure boilerplate text didn't come through:
+        assertEquals(-1, content.indexOf("Click to edit Master"));
     }
     */
 

Commit:
7f970efcd233a100f1cf8b50890c042ab6a8f30d
Michael McCandless
mikemccand@apache.org
2011-11-04 16:28:38 +0000
TIKA-767: allow controlling whether PDFBox should try to remove overlapped duplicated text; default to disabled
diff --git a/CHANGES.txt b/CHANGES.txt
index 6404493b4..26bdd31ad 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -1,6 +1,14 @@
 Apache Tika Change Log
 ======================
 
+Release 1.1 - Current Development
+---------------------------------
+
+ * PDF: Allow controlling whether overlapping duplicated text should
+   be removed.  Disabling this (the default) can give big
+   speedups to text extraction and may workaround cases where
+   non-duplicated characters were incorrectly removed.  (TIKA-767)
+
 Release 1.0 - 11/4/2011
 ---------------------------------
 
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDF2XHTML.java b/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDF2XHTML.java
index c719f8c8a..73cb7515e 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDF2XHTML.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDF2XHTML.java
@@ -53,12 +53,16 @@ class PDF2XHTML extends PDFTextStripper {
      * @throws TikaException if the PDF document can not be processed
      */
     public static void process(
-            PDDocument document, ContentHandler handler, Metadata metadata, boolean extractAnnotationText, boolean enableAutoSpace)
+            PDDocument document, ContentHandler handler, Metadata metadata,
+            boolean extractAnnotationText, boolean enableAutoSpace,
+            boolean suppressDuplicateOverlappingText)
             throws SAXException, TikaException {
         try {
             // Extract text using a dummy Writer as we override the
             // key methods to output to the given content handler.
-            new PDF2XHTML(handler, metadata, extractAnnotationText, enableAutoSpace).writeText(document, new Writer() {
+            new PDF2XHTML(handler, metadata,
+                          extractAnnotationText, enableAutoSpace,
+                          suppressDuplicateOverlappingText).writeText(document, new Writer() {
                 @Override
                 public void write(char[] cbuf, int off, int len) {
                 }
@@ -81,7 +85,9 @@ class PDF2XHTML extends PDFTextStripper {
     private final XHTMLContentHandler handler;
     private final boolean extractAnnotationText;
 
-    private PDF2XHTML(ContentHandler handler, Metadata metadata, boolean extractAnnotationText, boolean enableAutoSpace)
+    private PDF2XHTML(ContentHandler handler, Metadata metadata,
+                      boolean extractAnnotationText, boolean enableAutoSpace,
+                      boolean suppressDuplicateOverlappingText)
             throws IOException {
         this.handler = new XHTMLContentHandler(handler, metadata);
         this.extractAnnotationText = extractAnnotationText;
@@ -95,6 +101,7 @@ class PDF2XHTML extends PDFTextStripper {
         // TODO: maybe expose setting these too:
         //setAverageCharTolerance(1.0f);
         //setSpacingTolerance(1.0f);
+        setSuppressDuplicateOverlappingText(suppressDuplicateOverlappingText);
     }
 
     @Override
diff --git a/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java b/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java
index aa3141d92..a4f97b96e 100644
--- a/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java
+++ b/tika-parsers/src/main/java/org/apache/tika/parser/pdf/PDFParser.java
@@ -57,6 +57,9 @@ public class PDFParser extends AbstractParser {
     // True if we let PDFBox "guess" where spaces should go:
     private boolean enableAutoSpace = true;
 
+    // True if we let PDFBox remove duplicate overlapping text:
+    private boolean suppressDuplicateOverlappingText;
+
     /**
      * Metadata key for giving the document password to the parser.
      *
@@ -93,7 +96,7 @@ public class PDFParser extends AbstractParser {
             }
             metadata.set(Metadata.CONTENT_TYPE, "application/pdf");
             extractMetadata(pdfDocument, metadata);
-            PDF2XHTML.process(pdfDocument, handler, metadata, extractAnnotationText, enableAutoSpace);
+            PDF2XHTML.process(pdfDocument, handler, metadata, extractAnnotationText, enableAutoSpace, suppressDuplicateOverlappingText);
         } finally {
             pdfDocument.close();
         }
@@ -200,4 +203,23 @@ public class PDFParser extends AbstractParser {
     public boolean getExtractAnnotationText() {
         return extractAnnotationText;
     }
+
+    /**
+     *  If true, the parser should try to remove duplicated
+     *  text over the same region.  This is needed for some
+     *  PDFs that achieve bolding by re-writing the same
+     *  text in the same area.  Note that this can
+     *  slow down extraction substantially (PDFBOX-956) and
+     *  sometimes remove characters that were not in fact
+     *  duplicated (PDFBOX-1155).  By default this is disabled.
+     */
+    public void setSuppressDuplicateOverlappingText(boolean v) {
+        suppressDuplicateOverlappingText = v;
+    }
+
+    /** @see #setSuppressDuplicateOverlappingText. */
+    public boolean getSuppressDuplicateOverlappingText() {
+        return suppressDuplicateOverlappingText;
+    }
+
 }
diff --git a/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java b/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java
index 12eabbd9a..098de564d 100644
--- a/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java
+++ b/tika-parsers/src/test/java/org/apache/tika/parser/pdf/PDFParserTest.java
@@ -293,6 +293,36 @@ public class PDFParserTest extends TikaTest {
         assertEquals(-1, content.indexOf("Here is some formatted text"));
     }
 
+    public void testDuplicateOverlappingText() throws Exception {
+        PDFParser parser = new PDFParser();
+        ContentHandler handler = new BodyContentHandler();
+        Metadata metadata = new Metadata();
+        ParseContext context = new ParseContext();
+        InputStream stream = getResourceAsStream("/test-documents/testOverlappingText.pdf");
+        // Default is false (keep overlapping text):
+        try {
+            parser.parse(stream, handler, metadata, context);
+        } finally {
+            stream.close();
+        }
+        String content = handler.toString();
+        assertContains("Text the first timeText the second time", content);
+
+        parser.setSuppressDuplicateOverlappingText(true);
+        handler = new BodyContentHandler();
+        metadata = new Metadata();
+        context = new ParseContext();
+        stream = getResourceAsStream("/test-documents/testOverlappingText.pdf");
+        try {
+            parser.parse(stream, handler, metadata, context);
+        } finally {
+            stream.close();
+        }
+        content = handler.toString();
+        // "Text the first" was dedup'd:
+        assertContains("Text the first timesecond time", content);
+    }
+
     private static class XMLResult {
         public final String xml;
         public final Metadata metadata;
diff --git a/tika-parsers/src/test/resources/test-documents/testOverlappingText.pdf b/tika-parsers/src/test/resources/test-documents/testOverlappingText.pdf
new file mode 100644
index 000000000..282a1abfb
--- /dev/null
+++ b/tika-parsers/src/test/resources/test-documents/testOverlappingText.pdf
@@ -0,0 +1,2 @@
+Text the fsiersctotnimdetime
+
\ No newline at end of file

Commit:
2c128e823b1fdc315d980d3a5538cc8689f5f0cf
Chris Mattmann
mattmann@apache.org
2011-11-04 15:56:21 +0000
- add release date: updated on RC vote area, and will push to dist.apache.org on release (if successful).
diff --git a/CHANGES.txt b/CHANGES.txt
index 269c3418b..6404493b4 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -1,7 +1,7 @@
 Apache Tika Change Log
 ======================
 
-Release 1.0 - Current Development
+Release 1.0 - 11/4/2011
 ---------------------------------
 
 The most notable changes in Tika 1.0 over previous releases are:

Commit:
012128845aa323b42c07bb9aaa275f625770fbe5
Chris Mattmann
mattmann@apache.org
2011-11-03 19:41:17 +0000
[maven-release-plugin] prepare for next development iteration
diff --git a/pom.xml b/pom.xml
index 7e2feb275..f8496d32c 100644
--- a/pom.xml
+++ b/pom.xml
@@ -25,7 +25,7 @@
   <parent>
     <groupId>org.apache.tika</groupId>
     <artifactId>tika-parent</artifactId>
-    <version>1.0</version>
+    <version>1.1-SNAPSHOT</version>
     <relativePath>tika-parent/pom.xml</relativePath>
   </parent>
 
@@ -36,12 +36,12 @@
 
   <scm>
     <connection>
-      scm:svn:http://svn.apache.org/repos/asf/tika/tags/1.0
+      scm:svn:http://svn.apache.org/repos/asf/tika/trunk
     </connection>
     <developerConnection>
-      scm:svn:https://svn.apache.org/repos/asf/tika/tags/1.0
+      scm:svn:https://svn.apache.org/repos/asf/tika/trunk
     </developerConnection>
-    <url>http://svn.apache.org/viewvc/tika/tags/1.0</url>
+    <url>http://svn.apache.org/viewvc/tika/trunk</url>
   </scm>
 
   <modules>
diff --git a/tika-app/pom.xml b/tika-app/pom.xml
index 0a96ecb45..c359765a2 100644
--- a/tika-app/pom.xml
+++ b/tika-app/pom.xml
@@ -25,7 +25,7 @@
   <parent>
     <groupId>org.apache.tika</groupId>
     <artifactId>tika-parent</artifactId>
-    <version>1.0</version>
+    <version>1.1-SNAPSHOT</version>
     <relativePath>../tika-parent/pom.xml</relativePath>
   </parent>
 
diff --git a/tika-bundle/pom.xml b/tika-bundle/pom.xml
index 02173ca1c..cf781c9ac 100644
--- a/tika-bundle/pom.xml
+++ b/tika-bundle/pom.xml
@@ -25,7 +25,7 @@
   <parent>
     <groupId>org.apache.tika</groupId>
     <artifactId>tika-parent</artifactId>
-    <version>1.0</version>
+    <version>1.1-SNAPSHOT</version>
     <relativePath>../tika-parent/pom.xml</relativePath>
   </parent>
 
diff --git a/tika-core/pom.xml b/tika-core/pom.xml
index 6af996a86..cd8a219f9 100644
--- a/tika-core/pom.xml
+++ b/tika-core/pom.xml
@@ -25,7 +25,7 @@
   <parent>
     <groupId>org.apache.tika</groupId>
     <artifactId>tika-parent</artifactId>
-    <version>1.0</version>
+    <version>1.1-SNAPSHOT</version>
     <relativePath>../tika-parent/pom.xml</relativePath>
   </parent>
 
diff --git a/tika-parent/pom.xml b/tika-parent/pom.xml
index 4a9d9d0ca..5702653fc 100644
--- a/tika-parent/pom.xml
+++ b/tika-parent/pom.xml
@@ -31,7 +31,7 @@
 
   <groupId>org.apache.tika</groupId>
   <artifactId>tika-parent</artifactId>
-  <version>1.0</version>
+  <version>1.1-SNAPSHOT</version>
   <packaging>pom</packaging>
 
   <name>Apache Tika parent</name>
@@ -302,10 +302,4 @@
       </build>
     </profile>
   </profiles>
-
-  <scm>
-    <connection>scm:svn:http://svn.apache.org/repos/asf/maven/pom/tags/1.0/tika-parent</connection>
-    <developerConnection>scm:svn:https://svn.apache.org/repos/asf/maven/pom/tags/1.0/tika-parent</developerConnection>
-    <url>http://svn.apache.org/viewvc/maven/pom/tags/1.0/tika-parent</url>
-  </scm>
 </project>
diff --git a/tika-parsers/pom.xml b/tika-parsers/pom.xml
index b315ffd62..5bee31742 100644
--- a/tika-parsers/pom.xml
+++ b/tika-parsers/pom.xml
@@ -25,7 +25,7 @@
   <parent>
     <groupId>org.apache.tika</groupId>
     <artifactId>tika-parent</artifactId>
-    <version>1.0</version>
+    <version>1.1-SNAPSHOT</version>
     <relativePath>../tika-parent/pom.xml</relativePath>
   </parent>
 

Commit:
15f252db76b546edd75a61d4489562bb4461fc72
Chris Mattmann
mattmann@apache.org
2011-11-03 19:41:03 +0000
[maven-release-plugin] prepare release 1.0
diff --git a/pom.xml b/pom.xml
index d2f1c6157..7e2feb275 100644
--- a/pom.xml
+++ b/pom.xml
@@ -25,7 +25,7 @@
   <parent>
     <groupId>org.apache.tika</groupId>
     <artifactId>tika-parent</artifactId>
-    <version>1.0-SNAPSHOT</version>
+    <version>1.0</version>
     <relativePath>tika-parent/pom.xml</relativePath>
   </parent>
 
@@ -36,12 +36,12 @@
 
   <scm>
     <connection>
-      scm:svn:http://svn.apache.org/repos/asf/tika/trunk
+      scm:svn:http://svn.apache.org/repos/asf/tika/tags/1.0
     </connection>
     <developerConnection>
-      scm:svn:https://svn.apache.org/repos/asf/tika/trunk
+      scm:svn:https://svn.apache.org/repos/asf/tika/tags/1.0
     </developerConnection>
-    <url>http://svn.apache.org/viewvc/tika/trunk</url>
+    <url>http://svn.apache.org/viewvc/tika/tags/1.0</url>
   </scm>
 
   <modules>
diff --git a/tika-app/pom.xml b/tika-app/pom.xml
index b48b0a315..0a96ecb45 100644
--- a/tika-app/pom.xml
+++ b/tika-app/pom.xml
@@ -25,7 +25,7 @@
   <parent>
     <groupId>org.apache.tika</groupId>
     <artifactId>tika-parent</artifactId>
-    <version>1.0-SNAPSHOT</version>
+    <version>1.0</version>
     <relativePath>../tika-parent/pom.xml</relativePath>
   </parent>
 
diff --git a/tika-bundle/pom.xml b/tika-bundle/pom.xml
index b10bbdbfe..02173ca1c 100644
--- a/tika-bundle/pom.xml
+++ b/tika-bundle/pom.xml
@@ -25,7 +25,7 @@
   <parent>
     <groupId>org.apache.tika</groupId>
     <artifactId>tika-parent</artifactId>
-    <version>1.0-SNAPSHOT</version>
+    <version>1.0</version>
     <relativePath>../tika-parent/pom.xml</relativePath>
   </parent>
 
diff --git a/tika-core/pom.xml b/tika-core/pom.xml
index e7b4e18a7..6af996a86 100644
--- a/tika-core/pom.xml
+++ b/tika-core/pom.xml
@@ -25,7 +25,7 @@
   <parent>
     <groupId>org.apache.tika</groupId>
     <artifactId>tika-parent</artifactId>
-    <version>1.0-SNAPSHOT</version>
+    <version>1.0</version>
     <relativePath>../tika-parent/pom.xml</relativePath>
   </parent>
 
diff --git a/tika-parent/pom.xml b/tika-parent/pom.xml
index 0aff13463..4a9d9d0ca 100644
--- a/tika-parent/pom.xml
+++ b/tika-parent/pom.xml
@@ -31,7 +31,7 @@
 
   <groupId>org.apache.tika</groupId>
   <artifactId>tika-parent</artifactId>
-  <version>1.0-SNAPSHOT</version>
+  <version>1.0</version>
   <packaging>pom</packaging>
 
   <name>Apache Tika parent</name>
@@ -302,4 +302,10 @@
       </build>
     </profile>
   </profiles>
+
+  <scm>
+    <connection>scm:svn:http://svn.apache.org/repos/asf/maven/pom/tags/1.0/tika-parent</connection>
+    <developerConnection>scm:svn:https://svn.apache.org/repos/asf/maven/pom/tags/1.0/tika-parent</developerConnection>
+    <url>http://svn.apache.org/viewvc/maven/pom/tags/1.0/tika-parent</url>
+  </scm>
 </project>
diff --git a/tika-parsers/pom.xml b/tika-parsers/pom.xml
index f980ecde8..b315ffd62 100644
--- a/tika-parsers/pom.xml
+++ b/tika-parsers/pom.xml
@@ -25,7 +25,7 @@
   <parent>
     <groupId>org.apache.tika</groupId>
     <artifactId>tika-parent</artifactId>
-    <version>1.0-SNAPSHOT</version>
+    <version>1.0</version>
     <relativePath>../tika-parent/pom.xml</relativePath>
   </parent>
 
